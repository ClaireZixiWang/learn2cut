{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_policy_gradient.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ad219b399b44471bc490c2b5c91713f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60ac11db0064467d9749b65cd81fee82",
              "IPY_MODEL_7ea347ef3c8c44778b2490a4b374fce1"
            ],
            "layout": "IPY_MODEL_ff202ffc63ea444089192b817e453725"
          }
        },
        "60ac11db0064467d9749b65cd81fee82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90d478299c25496b8b23d186e8309435",
            "placeholder": "​",
            "style": "IPY_MODEL_5abf4e83301542dd9f0df60a63b9e506",
            "value": "0.733 MB of 0.733 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "7ea347ef3c8c44778b2490a4b374fce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f63691b8d784549a3311d45cb330af0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ff18ac0e9a34ae792976faf45a8a97a",
            "value": 1
          }
        },
        "ff202ffc63ea444089192b817e453725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90d478299c25496b8b23d186e8309435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5abf4e83301542dd9f0df60a63b9e506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f63691b8d784549a3311d45cb330af0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ff18ac0e9a34ae792976faf45a8a97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ClaireZixiWang/learn2cut/blob/main/Project_policy_gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## See README.md file for further details about the project and the environment.\n",
        "\n",
        "### State-Action Description\n",
        "\n",
        "### State\n",
        "State s is an array with give components\n",
        "\n",
        "* s[0]:  constraint matrix $A$of the current LP ($\\max  -c^Tx \\text{ s.t. }Ax \\le  b$) . Dimension is $m \\times n$. See by printing s[0].shape. Here $n$ is the (fixed) number of variables. For instances of size 60 by 60 used in the above command, $n$ will remain fixed as 60. And $m$ is the current number of constraints. Initially, $m$ is to the number of constraints in the IP instance. (For instances generated with --num-c=60, $m$ is 60 at the first step).  But $m$ will increase by one in every step of the episode as one new constraint (cut) is added on taking an action.\n",
        "* s[1]: rhs $b$ for the current LP ($Ax\\le b$). Dimension same as the number $m$ in matrix A.\n",
        "* s[2]: coefficient vector $c$ from the LP objective ($-c^Tx$). Dimension same as the number of variables, i.e., $n$.\n",
        "* s[3],  s[4]: Gomory cuts available in the current round of Gomory's cutting plane algorithm. Each cut $i$ is of the form $D_i x\\le d_i$.   s[3] gives the matrix $D$ (of dimension $k \\times n$) of cuts and s[4] gives the rhs $d$ (of dimension $k$). The number of cuts $k$ available in each round changes, you can find it out by printing the size of last component of state, i.e., s[4].size or s[-1].size.\n",
        "\n",
        "### Actions\n",
        "There are k=s[4].size actions available in each state $s$, with $i^{th}$ action corresponding to the $i^{th}$ cut with inequality $D_i x\\le d_i$ in $s[3], s[4]$."
      ],
      "metadata": {
        "id": "5TN-sMTvcG_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***QUESTIONS***:\n",
        "1. By \"current\" LP, you mean the LP that the agent was running in the last state? As in, the LP with all the added constraints? \n",
        "  * ==> I think so.\n",
        "1. What do you mean Gomory cuts *available*? As in, after doing Simplex methods, the *variables* that you can choose to cut?\n",
        "  * Yes I think so.\n",
        "2. Isn't the number of variables (n) changing? in the C-G cutting plane method?\n",
        "  * No, as the spec says, **$n$ is the fixed number of variables**.\n",
        "  * If you look that cuttng plane lecture notes, you can see that after each step, the dummy variable is not added in the constraint. They are merely there for the sake of the LP solver (simplex method), but not really relevant for us.\n",
        "    * This is not correct, I think they are still very much relevant, it's just that I think among the 60 variables a lot of them are space holders for dummy variables so that our $n$ is fixed, so that we don't have to worry about using LSTM. Since each time the sequence [a, b] will be of size n+1. And we can just use a fixed-input-size network to do that.\n",
        "    * But still need to verify with the TA about the place holder understanding.\n",
        "3. dimension of s[3] and s[4]? Where is the \"available all\" stored? In which dimension?\n",
        "  * Each row of D is an \"available cut\". Therefore each $D_i x\\le d_i$ is an \"available\" cut in CG method solved from the simplex method.\n",
        "4. pointing towards the slides: why does the number of constraints m increase 1 in each step, if you can choose *multiple* cuts in one step? (OR in the algorithm we just choose one cut each time? or is that a more vanilla version to start, but to expand on multiple cuts a time later?)\n",
        "5. What do you mean by each \"instance\"?"
      ],
      "metadata": {
        "id": "XJE0bz30UL1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYROdPaaZOVa",
        "outputId": "fce21055-e604-4e9f-df59-0f85ac810147"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -i https://pypi.gurobi.com gurobipy"
      ],
      "metadata": {
        "id": "xSXTKB2zurrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24e844a4-7bc1-4209-dd5a-6a66f1130417"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.gurobi.com\n",
            "Requirement already satisfied: gurobipy in /usr/local/lib/python3.7/dist-packages (9.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qqq"
      ],
      "metadata": {
        "id": "YULy9ymNvDxN"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/IEOR_RL/Project_learn2cut\n",
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "lTnvB0_iZUrX",
        "outputId": "94b07aab-a8a1-45b2-bc49-344fd4158f11"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/IEOR_RL/Project_learn2cut'\n",
            "/content/drive/MyDrive/IEOR_RL/Project_learn2cut\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/IEOR_RL/Project_learn2cut'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "Q8PiSPj5us0O"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.Sequential(\n",
        "            torch.nn.Linear(4, 40),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(40, 20), \n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(20, 10)\n",
        "        )\n",
        "\n",
        "datapoint = torch.FloatTensor([\n",
        "                               [[1,2,3,4],\n",
        "                                [2,3,4,5]],\n",
        "                               [[3,4,5,6],\n",
        "                                [4,5,6,7]]\n",
        "                              ])\n"
      ],
      "metadata": {
        "id": "ojB8UvBAPAWk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(datapoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r_nraniPaKl",
        "outputId": "7584658a-c0e7-48d5-f6ac-7b9eb3281863"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.5739, -0.0712, -0.1939, -0.1789,  0.2275,  0.0254, -0.4184,\n",
              "           0.4109,  0.1992,  0.0089],\n",
              "         [-0.6962, -0.0828, -0.1940, -0.2345,  0.2921,  0.0213, -0.4829,\n",
              "           0.5324,  0.2761,  0.0707]],\n",
              "\n",
              "        [[-0.8191, -0.0946, -0.1938, -0.2877,  0.3556,  0.0170, -0.5495,\n",
              "           0.6553,  0.3525,  0.1308],\n",
              "         [-0.9420, -0.1064, -0.1935, -0.3409,  0.4190,  0.0126, -0.6160,\n",
              "           0.7781,  0.4288,  0.1908]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Code for Policy Model\n",
        "\n",
        "class Policy(object):\n",
        "\n",
        "    # inputsize = n+1 = 61\n",
        "    def __init__(self, lr, input_size, attention_size=10, temperature=1) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Linear(input_size, 40),\n",
        "            # torch.nn.Sigmoid(),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(40, 30), \n",
        "            # torch.nn.Sigmoid(),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(30, 20), \n",
        "            # torch.nn.Sigmoid(),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(20, attention_size)\n",
        "        )\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
        "\n",
        "        # RECORD HYPER-PARAMS\n",
        "        self.input_size = input_size\n",
        "        self.attention_size = attention_size\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def compute_logits_big_batch(self, obs_matrix, act_matrix, batchsize):\n",
        "        '''\n",
        "        Function that takes in a batch of observations and computes the action logits for each of observations in this batch\n",
        "        Args: obs_matrix: np.array(m * batchsize, n+1) # TODO maybe change this to tensor\n",
        "              act_matrix: np.array(k * batchsize, n+1)\n",
        "        Return: batch_logit: tensor(batchsize, k)\n",
        "        '''\n",
        "\n",
        "        # Get the batch result\n",
        "\n",
        "        # transform to tensor\n",
        "        obs_attention = self.model(torch.FloatTensor(obs_matrix)) # tensor(m * batchsize, u)\n",
        "        act_attention = self.model(torch.FloatTensor(act_matrix)) # tensor(k * batchsize, u)\n",
        "\n",
        "        assert obs_attention.shape == (obs_matrix.shape[0], self.attention_size)\n",
        "        assert act_attention.shape == (act_matrix.shape[0], self.attention_size)\n",
        "\n",
        "        # split a batch of output of size tensor(m * batchsize, u) into (batchsize, m, u)\n",
        "        batch_obs_output = torch.reshape(obs_attention, (batchsize, obs_attention.shape[0]/batchsize, obs_attention.shape[1]))\n",
        "        \n",
        "        # split a batch of output of size tensor(k * batchsize, u) into (batchsize, k, u)\n",
        "        batch_act_output = torch.reshape(act_attention, (batchsize, act_attention.shape[0]/batchsize, act_attention.shape[1]))\n",
        "\n",
        "        # To do batch matrix multiplication, transpose (batchsize, k, u) into (batchsize, u, k)\n",
        "        # (batchsize, m, u) @ (batchsize, u, k) =  (batchsize, m, k)\n",
        "        # (batchsize, m, k) == mean across all observation ==> (batchsize, k)\n",
        "        batch_logit = torch.bmm(batch_obs_output, batch_act_output.transpose(0, 2, 1)).mean(dim=1)\n",
        "\n",
        "        assert batch_logit.shape == (batchsize, act_matrix.shape[0]/batchsize)\n",
        "\n",
        "        return batch_logit\n",
        "\n",
        "    def compute_batch_selected_prob(self, batch_probs):\n",
        "        '''\n",
        "        Function that takes in a batch of probabilities and return the max probability for each \"datapoint\" in the batch\n",
        "        Args:    batch_logit: tensor(batchsize, k)\n",
        "        Return:  batch_selected_prob: tensor(batchsize,)\n",
        "        '''\n",
        "        # TODO\n",
        "\n",
        "        return\n",
        "\n",
        "\n",
        "    def compute_one_step_logits(self, obs, act):\n",
        "        '''\n",
        "        Function that takes in ONE observation and action space, computes the action logits\n",
        "        Args:   obs_matrix: np.array(m, n+1)\n",
        "                act_matrix: np.array(k, n+1)\n",
        "        Return: logit: tensor(k)\n",
        "        '''\n",
        "\n",
        "        obs_attention = self.model(torch.FloatTensor(obs)) #-> (m, 10)\n",
        "        act_attention = self.model(torch.FloatTensor(act)) #-> (k, 10)\n",
        "        # print(\"DEBUGGING: obs_attention looks like:\", obs_attention)\n",
        "        # print(\"DEBUGGING: act_attention looks like:\", act_attention)\n",
        "\n",
        "        # attention matrix multiplication & mean to get the score\n",
        "        logits = torch.mm(obs_attention, act_attention.transpose(1, 0)).mean(dim=0)\n",
        "        # print(\"DEBUGGING: logits looks like:\", logits)\n",
        "\n",
        "        # print(\"DEBUGGING: act.shape =\", act_attention.shape)\n",
        "        # print(\"DEBUGGING: logits.shape =\", logits.shape)\n",
        "        assert logits.shape[0] == act_attention.shape[0]\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def predict_prob(self, obs, act):\n",
        "        # Function that uses softmax to transform logits to probabilities\n",
        "        # TODO: What shape should obs and act take?\n",
        "        # Args:   obs_matrix: np.array(m, n+1)\n",
        "        #         act_matrix: np.array(k, n+1)\n",
        "        # Return: probs: tensor(k)\n",
        "\n",
        "        logits = self.compute_one_step_logits(obs, act)\n",
        "\n",
        "        # TODO: make temperature a argument in the function, so that it's depended on the steps\n",
        "        probs = torch.nn.functional.softmax(logits/self.temperature, dim=0)\n",
        "        return probs\n",
        "\n",
        "    def selected_prob(self, probs, action):\n",
        "\n",
        "\n",
        "        # TODO: do I need this function?\n",
        "        one_hot = torch.zeros()\n",
        "        return probs.max()\n",
        "\n",
        "    def choose_action(self, obs, act):\n",
        "\n",
        "        # TODO: is this returning a number?\n",
        "        return torch.argmax(self.predict_prob(obs, act)).item()\n",
        "\n",
        "\n",
        "    def train(self, obs_matrix, act_matrix, actions, Qs):\n",
        "        \"\"\"\n",
        "        Args: obs_matrix: np.array(batchsize * m, n+1) => changed to [np.array(m, n+1)] * batchsize, note that m are varied!\n",
        "              act_matrix: np.array(batchsize * k, n+1)  \n",
        "              actions: => [[action number]] * batchsize      \n",
        "              Qs: np.array(batchsize, )\n",
        "        \"\"\"\n",
        "        # Convert numpy array to tensor\n",
        "\n",
        "        # use compute_batch_prob to compute the batch logits for every datapoint in batch.\n",
        "        # use compute_batch_selected_prob the compute the max probabilty for every datapoint in batch.\n",
        "        start = time.time()\n",
        "        print(\"DEBUGGING: I'm inside the training now!\")\n",
        "        \n",
        "        Qs = torch.FloatTensor(Qs)\n",
        "\n",
        "\n",
        "        # Try using a for loop first, see whether it really cost too much time & whether it works at all\n",
        "        prob_selected = torch.zeros(len(actions))\n",
        "        for i in range(len(obs_matrix)):\n",
        "            #TODO: adjust the temperatures based on trajectory steps\n",
        "            probs = self.predict_prob(obs_matrix[i], act_matrix[i])\n",
        "            one_hot = torch.zeros_like(probs)\n",
        "            one_hot[actions[i][0]] = 1\n",
        "            prob_selected[i] = torch.sum(probs * one_hot)\n",
        "\n",
        "\n",
        "        # For robustness add in noise for prob_selected # TODO: why do this?\n",
        "\n",
        "        # define loss function as in lab 4\n",
        "        # TODO define loss function as described in the text above\n",
        "        loss = - (torch.sum(Qs * torch.log(prob_selected)) / (len(obs_matrix) + 1))\n",
        "        print(\"DEBUGGING: the loss =\", loss)\n",
        "\n",
        "        print(\"DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\")\n",
        "        print(\"   First layer:\")\n",
        "        print(policy.model[0].weight.grad)\n",
        "        print(\"   Last layer:\")\n",
        "        print(policy.model[6].weight.grad)\n",
        "\n",
        "        # backward pass\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        print(\"DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\")\n",
        "        print(\"   First layer:\")\n",
        "        print(policy.model[0].weight.grad)\n",
        "        print(\"   Last layer:\")\n",
        "        print(policy.model[6].weight.grad)\n",
        "\n",
        "        # step\n",
        "        self.optimizer.step()\n",
        "\n",
        "\n",
        "        print(\"DEBUGGING: training for one iteration takes %f min:\" % ((time.time() - start)/60))\n",
        "\n",
        "\n",
        "        # return detached loss (why?)\n",
        "        return loss.detach().cpu().data.numpy()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HViRnY1ssGfc"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchsummary import summary\n",
        "# summary(policy.model, (61,))\n",
        "# print(policy.model)"
      ],
      "metadata": {
        "id": "OGm4an0pWPHr"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(policy.model[6].weight.grad)"
      ],
      "metadata": {
        "id": "dfkXKSJWW6OR"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP model for policy model:\n",
        "#   model.forward\n",
        "#   model.train --> What is in this function? what are the function arguments?\n",
        "# Baseline function b(s) ==> Okay maybe we stil need the V model as a proper baseline\n",
        "\n",
        "\n",
        "# Q value model ==> Discard this right now, just do vanilla policy gradient\n",
        "#   Can I just use the one in Lab4? What does it mean? what does the states and actions mean? --> Print out the s, r to check\n",
        "#   What is a Q-value in our set-up?\n",
        "#   How do I used this? \n",
        "#   (What's the baseline function??)"
      ],
      "metadata": {
        "id": "ACiQz-gESgOO"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "2xI0riE6md5V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "850c2d93-9e4b-4890-d5b5-c466637bc82f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/IEOR_RL/Project_learn2cut/wandb/run-20220508_230428-1md5pyok</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ieor4575-spring2022/finalproject/runs/1md5pyok\" target=\"_blank\">deft-field-2710</a></strong> to <a href=\"https://wandb.ai/ieor4575-spring2022/finalproject\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# import gymenv_v2\n",
        "from gymenv_v2 import make_multiple_env\n",
        "\n",
        "\n",
        "import wandb\n",
        "wandb.login()\n",
        "run=wandb.init(project=\"finalproject\", entity=\"ieor4575-spring2022\", tags=[\"training-easy\"])\n",
        "#run=wandb.init(project=\"finalproject\", entity=\"ieor-4575\", tags=[\"training-hard\"])\n",
        "#run=wandb.init(project=\"finalproject\", entity=\"ieor-4575\", tags=[\"test\"])\n",
        "\n",
        "### TRAINING\n",
        "\n",
        "# Setup: You may generate your own instances on which you train the cutting agent.\n",
        "custom_config = {\n",
        "    \"load_dir\"        : 'instances/randomip_n60_m60',   # this is the location of the randomly generated instances (you may specify a different directory)\n",
        "    \"idx_list\"        : list(range(20)),                # take the first 20 instances from the directory\n",
        "    \"timelimit\"       : 50,                             # the maximum horizon length is 50\n",
        "    \"reward_type\"     : 'obj'                           # DO NOT CHANGE reward_type\n",
        "}\n",
        "\n",
        "# Easy Setup: Use the following environment settings. We will evaluate your agent with the same easy config below:\n",
        "easy_config = {\n",
        "    \"load_dir\"        : 'instances/train_10_n60_m60',\n",
        "    \"idx_list\"        : list(range(5)),\n",
        "    \"timelimit\"       : 50,\n",
        "    \"reward_type\"     : 'obj'\n",
        "}\n",
        "\n",
        "# Hard Setup: Use the following environment settings. We will evaluate your agent with the same hard config below:\n",
        "hard_config = {\n",
        "    \"load_dir\"        : 'instances/train_100_n60_m60',\n",
        "    \"idx_list\"        : list(range(99)),\n",
        "    \"timelimit\"       : 50,\n",
        "    \"reward_type\"     : 'obj'\n",
        "}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch._C import dtype\n",
        "def discounted_rewards(r, gamma):\n",
        "    \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
        "    discounted_r = np.zeros_like(r, dtype=float)\n",
        "    running_sum = 0\n",
        "    for i in reversed(range(0,len(r))):\n",
        "        discounted_r[i] = running_sum * gamma + r[i]\n",
        "        running_sum = discounted_r[i]\n",
        "    return list(discounted_r)"
      ],
      "metadata": {
        "id": "COyIO0TEDRjt"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = make_multiple_env(**easy_config) \n",
        "s = env.reset()   # samples a RANDOM INSTANCE every time env.reset() is called\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFhvgi_q53V4",
        "outputId": "5b7e73fc-e387-47fb-b6ea-4f95231745af"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading training instances, dir instances/train_10_n60_m60 idx 0\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 1\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 2\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 3\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "A, b, c0, cuts_a, cuts_b = s\n",
        "concat = np.hstack((s[0], np.expand_dims(s[1], axis=1)))\n",
        "concat\n",
        "# np.linalg.norm(concat, axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJXouQZx9DQ7",
        "outputId": "72aa1d4c-02af-4a69-b91e-2aefd0192735"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   1,   3, ...,   3,   3, 577],\n",
              "       [  1,   4,   4, ...,   0,   2, 588],\n",
              "       [  0,   1,   1, ...,   0,   1, 541],\n",
              "       ...,\n",
              "       [  0,   1,   1, ...,   1,   4, 578],\n",
              "       [  3,   1,   1, ...,   4,   0, 599],\n",
              "       [  2,   3,   4, ...,   2,   2, 562]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.expand_dims(s[1], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSUhT5go6czx",
        "outputId": "fc1b3c4c-cb7e-40a9-b395-441bd8616b1b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[577],\n",
              "       [588],\n",
              "       [541],\n",
              "       [566],\n",
              "       [563],\n",
              "       [586],\n",
              "       [589],\n",
              "       [555],\n",
              "       [585],\n",
              "       [589],\n",
              "       [543],\n",
              "       [549],\n",
              "       [574],\n",
              "       [584],\n",
              "       [554],\n",
              "       [543],\n",
              "       [555],\n",
              "       [553],\n",
              "       [552],\n",
              "       [559],\n",
              "       [547],\n",
              "       [588],\n",
              "       [582],\n",
              "       [576],\n",
              "       [555],\n",
              "       [590],\n",
              "       [548],\n",
              "       [587],\n",
              "       [563],\n",
              "       [551],\n",
              "       [547],\n",
              "       [576],\n",
              "       [576],\n",
              "       [581],\n",
              "       [563],\n",
              "       [589],\n",
              "       [565],\n",
              "       [553],\n",
              "       [562],\n",
              "       [587],\n",
              "       [554],\n",
              "       [564],\n",
              "       [573],\n",
              "       [546],\n",
              "       [561],\n",
              "       [551],\n",
              "       [570],\n",
              "       [547],\n",
              "       [540],\n",
              "       [594],\n",
              "       [578],\n",
              "       [570],\n",
              "       [562],\n",
              "       [544],\n",
              "       [557],\n",
              "       [598],\n",
              "       [579],\n",
              "       [578],\n",
              "       [599],\n",
              "       [562]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.hstack((s[0], np.expand_dims(s[1], axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjIckPCE7n2z",
        "outputId": "8662c055-72f4-4b0d-b507-31a20e898477"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   1,   3, ...,   3,   3, 577],\n",
              "       [  1,   4,   4, ...,   0,   2, 588],\n",
              "       [  0,   1,   1, ...,   0,   1, 541],\n",
              "       ...,\n",
              "       [  0,   1,   1, ...,   1,   4, 578],\n",
              "       [  3,   1,   1, ...,   4,   0, 599],\n",
              "       [  2,   3,   4, ...,   2,   2, 562]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([\n",
        "              [1,2,3,4],\n",
        "              [3,3,3,3],\n",
        "              [2,2,2,2],\n",
        "              [1,1,1,1]\n",
        "])\n",
        "print(a.mean(axis=0, keepdims=True))\n",
        "a = a - a.mean(axis=0, keepdims=True)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMUMT8x_A8I0",
        "outputId": "2da478c6-0e4e-4b99-d1cd-ee98b1fc6889"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.75 2.   2.25 2.5 ]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.75,  0.  ,  0.75,  1.5 ],\n",
              "       [ 1.25,  1.  ,  0.75,  0.5 ],\n",
              "       [ 0.25,  0.  , -0.25, -0.5 ],\n",
              "       [-0.75, -1.  , -1.25, -1.5 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "empty = [np.array([1,2]), np.array([3,4])]\n",
        "a = []\n",
        "b = a + empty + empty\n",
        "\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBFhGXfSJz3l",
        "outputId": "fe22ccda-0bc9-4c27-eeb4-2d5c706c6c5c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 2]), array([3, 4]), array([1, 2]), array([3, 4])]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "empty = [np.array([10,20])]\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJY9NttjZiM7",
        "outputId": "e5f28774-15ec-47b3-bebd-4273ab3bdc8f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 2]), array([3, 4]), array([1, 2]), array([3, 4])]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%wandb\n",
        "# create env\n",
        "env = make_multiple_env(**easy_config) \n",
        "# Parameter initialization\n",
        "numtrajs = 4  # num of trajecories from the current policy to collect in each iteration\n",
        "lr_pg = 1e-2  # learning rate for PG\n",
        "attention_size = 10\n",
        "iterations = 25\n",
        "discount_gamma = .99\n",
        "\n",
        "# Network initialize\n",
        "policy = Policy(lr_pg, 61, attention_size, 0.5)\n",
        "\n",
        "#To record training reward for logging and plotting purposes\n",
        "rrecord = []\n",
        "\n",
        "VAL_ALL = []  # Monte carlo value predictions of ALL trajectories (to compute baseline, and policy gradient) => 2 d list (numtrajs, #steps per traj)\n",
        "\n",
        "# For every training iteration, we roll out 5 random instances using the policy network\n",
        "# collect observation and action matrices from these 5 roll-outs, consider this a BATCH\n",
        "# train the network using this BATCH\n",
        "for ite in range(iterations):\n",
        "\n",
        "    print(\"==========================================================================================================\")\n",
        "    print(\"Outer iteration no\", ite)\n",
        "\n",
        "    # To record traectories generated from current policy\n",
        "    OBS_MAT = []  # observations: [obs_matrices_batch_traj1, obs_matrices_batch_traj2, ....]\n",
        "    ACT_MAT = []  # actions\n",
        "    ADS = []  # advantages (to compute policy gradient)\n",
        "    VAL = []  # Monte carlo value predictions (to compute baseline, and policy gradient) => 2 d list (numtrajs, #steps per traj)\n",
        "    traj_returns = []  # a list of 5 numbers, each number represents the RETURN of that roll-out\n",
        "    actions = []\n",
        "    \n",
        "    # collect some trajectories\n",
        "    for num in range(numtrajs):\n",
        "        print(\"-------------------------------------------------------------------------------------------\")\n",
        "        print(\"Running trajectories:\", num)\n",
        "        # Initialize a list of obs_matrices and act_matrices, to store all the obs_matrix and act_matrix in the trajectory\n",
        "        obs_matrices = []  # states: [obs_matrix_state1, obs_matrix_state2, ...]\n",
        "        act_matrices = []  # actions matrices\n",
        "        \n",
        "        # this is used to collect all the immedaite rewards in this trajectory\n",
        "        rews = []  # instant rewards\n",
        "        rel_rews = []\n",
        "\n",
        "        # gym loop\n",
        "        s = env.reset()   # samples a RANDOM INSTANCE every time env.reset() is called\n",
        "        done = False\n",
        "\n",
        "        # TODO: wandb logging -> what reward average should we log??\n",
        "        t = 0 # TODO: how is this used?\n",
        "        repisode = 0  # TODO: how is this used?\n",
        "\n",
        "        inner_step = 1\n",
        "        \n",
        "\n",
        "        # roll out ONE policy\n",
        "        while not done:\n",
        "\n",
        "            # TODO compute the running average RETURN as basline\n",
        "            A, b, c0, cuts_a, cuts_b = s\n",
        "\n",
        "            # choose the action according to the model output probabilities\n",
        "\n",
        "            # Concat [A,b] and [cuts_a, cuts_b]\n",
        "            assert A.shape[0] == b.shape[0]\n",
        "            assert cuts_a.shape[0] == cuts_b.shape[0]\n",
        "\n",
        "            obs_matrix = np.hstack((A, np.expand_dims(b, axis=1)))\n",
        "            act_matrix = np.hstack((cuts_a, np.expand_dims(cuts_b, axis=1)))\n",
        "\n",
        "            assert obs_matrix.shape == (A.shape[0], A.shape[1]+1)\n",
        "            assert act_matrix.shape == (cuts_a.shape[0], cuts_a.shape[1]+1)\n",
        "\n",
        "            # Normalize on a row (MIGHT NOT NEED THIS)\n",
        "            \n",
        "            # The reason we want to normalize a row: we want the numeric space of the model input to be just between 0, 1\n",
        "            # Right now I'm normalizing such that the largest number has value 1 --> each row divided by the largest num in that row\n",
        "            #   => This would result in b vector always be 1 (does it make sense?)\n",
        "            # another option is to normalize such that the SUM of the row is 1\n",
        "            #   => I think this makes more sense, consider this differentiates the max among datapoints\n",
        "            #   => According to prof in OH this might cause some information loss\n",
        "            \n",
        "            obs_matrix = obs_matrix / obs_matrix.max(axis=1, keepdims=True) * 100\n",
        "            act_matrix = act_matrix / act_matrix.max(axis=1, keepdims=True) * 100\n",
        "            \n",
        "            # print(\"DEBUGGING: obs_matrix.shape = \", obs_matrix.shape)\n",
        "            # print(\"DEBUGGING: act_matrix.shape = \", act_matrix.shape)\n",
        "\n",
        "            action_prob = policy.predict_prob(obs_matrix, act_matrix)\n",
        "            action = random.choices(range(0, len(cuts_b)), action_prob) # this returns a list\n",
        "            actions.append(action)\n",
        "\n",
        "            if  inner_step %10 == 0:\n",
        "                # TODO: print the logits as well as well.\n",
        "                print(\"DEBUGGING: the action_prob is:\", action_prob)\n",
        "                print(\"DEBUGGING: the actual action to take is:\", action)\n",
        "                logits_dbg = policy.compute_one_step_logits(obs_matrix, act_matrix)\n",
        "                print(\"DEBUGGING: logits looks like:\", logits_dbg)\n",
        "\n",
        "\n",
        "\n",
        "            # take the action in the environment\n",
        "            # TODO: why does the environment.step function takes in a list?\n",
        "            # TODO: remember to go in the environment to change the returned r to the NORMALIZED r!!\n",
        "            s, r, done, _ = env.step(action)\n",
        "            \n",
        "            # Record the observed immediate reward & observed matrices along the trajectory\n",
        "            abs_reward, rel_reward = r\n",
        "            # print(\"DEBUGGING: rel_reward looks like:\", rel_reward)\n",
        "            rews.append(abs_reward) # rews = list(len of trajectory)\n",
        "            rel_rews.append(rel_reward * 10 * inner_step)\n",
        "            obs_matrices.append(obs_matrix)\n",
        "            act_matrices.append(act_matrix)\n",
        "\n",
        "            inner_step += 1\n",
        "\n",
        "            # TODO: do we need to also record the one step of observation and action where the environment terminates?\n",
        "            #   ==> RN I'm thinking maybe don't need to\n",
        "        print(\"-------------------------------------------------------------------------------------------\")\n",
        "        #Below is for logging training performance\n",
        "        print(\"DEBUGGING: the total abs reward of the trajectory =\", np.sum(rews), \"and immediate abs rewards look like:\", rews)\n",
        "        print(\"DEBUGGING: the total relative reward of the trajectory =\", np.sum(rel_rews), \"and immediate relative rewards look like:\", rel_rews)\n",
        "\n",
        "        rrecord.append(np.sum(rews))\n",
        "\n",
        "        # After the policy roll out for this trajectory,\n",
        "        # compute the monte-carlo RETURN of this trajectory (i.e. discounted sum of rewards), add to big list\n",
        "        # TODO: one of the next steps could be: to make the basline state-dependent\n",
        "        v_hat = discounted_rewards(rel_rews, discount_gamma) # This is a list\n",
        "        traj_returns.append(v_hat[0])\n",
        "        # OBS_MAT.append(np.concatenate(obs_matrices, axis=1))\n",
        "        # ACT_MAT.append(np.concatenate(act_matrices, aixs=1))\n",
        "        VAL.append(v_hat) # VAL -> 2d list\n",
        "        VAL_ALL.append(v_hat) # VAL_ALL -> 2d list\n",
        "        OBS_MAT += obs_matrices\n",
        "        ACT_MAT += act_matrices\n",
        "\n",
        "        # TODO: do I need to specify batchsize somewhere?\n",
        "\n",
        "    print(\"+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\")\n",
        "    \n",
        "    # After collecting 5 (or however many) trajectories,\n",
        "    print(\"DEBUGGING: OBS_MAT has %d number of matrices\" % len(OBS_MAT))\n",
        "    print(\"DEBUGGING: ACT_MAT has %d number of matrices\" % len(ACT_MAT))\n",
        "    print(\"DEBUGGING: VAL looks like:\", VAL)\n",
        "    # print(\"DEBUGGING: OBS_MAT looks like:\", OBS_MAT)\n",
        "    # print(\"DEBUGGING: ACT_MAT looks like:\", ACT_MAT)\n",
        "    print(\"DEBUGGING: traj_returns =\", traj_returns)\n",
        "    print(\"DEBUGGING: actions =\", actions)\n",
        "    print(\"DEBUGGING: actions length =\", len(actions))\n",
        "\n",
        "    ## For debugging purposes, let's look at what does the model output\n",
        "    print(\"DEBUGGING: what does the model output in this round of roll-out?\")\n",
        "    obs_attention_dbg = policy.model(torch.FloatTensor(obs_matrix))\n",
        "    act_attention_dbg = policy.model(torch.FloatTensor(act_matrix))\n",
        "    logits_dbg = policy.compute_one_step_logits(obs_matrix, act_matrix)\n",
        "    print(\"DEBUGGING: obs_attention looks like:\", obs_attention_dbg)\n",
        "    print(\"DEBUGGING: act_attention looks like:\", act_attention_dbg)\n",
        "    print(\"DEBUGGING: logits looks like:\", logits_dbg)\n",
        "\n",
        "\n",
        "    assert len(traj_returns) == numtrajs\n",
        "    VAL = np.array(VAL)\n",
        "    VAL_ALL_np = np.array(VAL_ALL)\n",
        "    # 1. calculate the baseline: average return of the trajectories\n",
        "    # TODO: potentially can make this into *running average*, take into account of all the previous trajectories as well\n",
        "    # TODO: potentially make the baseline the average *VALUE* of every *state*, \n",
        "    #       but I'm not sure whether that \"state\" is useful in this concept, since the first *step*\n",
        "    #       doesn't really mean the same thing among instances\n",
        "    #       I think prof says it makes sense in the OH, also it would make more sense if you engineered the reward\n",
        "    baseline = np.mean(traj_returns)\n",
        "    baseline_2 = VAL.mean(axis=0, keepdims=True) # This is NOT a good baseline, this is only the mean of that episode, NOT running mean\n",
        "    baseline_3 = VAL_ALL_np.mean(axis=0, keepdims=True)\n",
        "    # assert baseline_2.shape == VAL.shape\n",
        "\n",
        "    # 2. Update the policy\n",
        "    ADS = (VAL - baseline_2).flatten()\n",
        "    print(\"DEBUGGING: baseline2 looks like:\", baseline_2)\n",
        "    print(\"DEBUGGING: baseline2 looks like:\", baseline)\n",
        "    print(\"DEBUGGING: ADS looks like:\", ADS)\n",
        "\n",
        "\n",
        "    # Train the agent using the batch\n",
        "    # obs_batch = np.concatenate(OBS_MAT)\n",
        "    # act_batch = np.concatenate(ACT_MAT)\n",
        "\n",
        "    assert ADS.shape[0] == len(actions)\n",
        "\n",
        "    # scaling up the rewards to artificially make bigger loss, improve learning\n",
        "\n",
        "    loss = policy.train(OBS_MAT, ACT_MAT, actions, ADS)\n",
        "\n",
        "    fixedWindow=100\n",
        "    movingAverage=0\n",
        "    if len(rrecord) >= fixedWindow:\n",
        "        movingAverage=np.mean(rrecord[len(rrecord)-fixedWindow:len(rrecord)-1])\n",
        "\n",
        "    # TODO: wandb logging\n",
        "    wandb.log({ \"training reward\" : rrecord[-1], \"training reward moving average\" : movingAverage, \"training loss\": loss})\n",
        "    #make sure to use the correct tag in wandb.init in the initialization on top\n"
      ],
      "metadata": {
        "id": "aeQHQnp1-8fR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ba4fda85-3b77-45d6-d381-fa4a7a386b2a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<wandb.jupyter.IFrame at 0x7f787a4565d0>"
            ],
            "text/html": [
              "<iframe src=\"https://wandb.ai/ieor4575-spring2022/finalproject/runs/1md5pyok?jupyter=true\" style=\"border:none;width:100%;height:420px;\"></iframe>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [ 0.0339,  0.0040,  0.0332,  ...,  0.0587, -0.0685, -0.1578],\n",
            "        [ 0.0249,  0.0030,  0.0244,  ...,  0.0432, -0.0505, -0.1170]])\n",
            "   Last layer:\n",
            "tensor([[-0.0589, -0.0158,  0.0000, -0.0551,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0578,\n",
            "          0.0000, -0.0589, -0.0665, -0.0109],\n",
            "        [-0.0485, -0.0123,  0.0000, -0.0448,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0462,\n",
            "          0.0000, -0.0468, -0.0526, -0.0084],\n",
            "        [-0.0515, -0.0141,  0.0000, -0.0485,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0511,\n",
            "          0.0000, -0.0523, -0.0590, -0.0098],\n",
            "        [ 0.0148,  0.0039,  0.0000,  0.0138,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0143,\n",
            "          0.0000,  0.0145,  0.0163,  0.0026],\n",
            "        [ 0.0127,  0.0038,  0.0000,  0.0123,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0133,\n",
            "          0.0000,  0.0138,  0.0157,  0.0027],\n",
            "        [-0.0464, -0.0125,  0.0000, -0.0435,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0457,\n",
            "          0.0000, -0.0467, -0.0527, -0.0087],\n",
            "        [ 0.0914,  0.0246,  0.0000,  0.0857,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0899,\n",
            "          0.0000,  0.0917,  0.1035,  0.0170],\n",
            "        [ 0.0452,  0.0126,  0.0000,  0.0427,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0454,\n",
            "          0.0000,  0.0465,  0.0526,  0.0088],\n",
            "        [ 0.0503,  0.0145,  0.0000,  0.0480,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0515,\n",
            "          0.0000,  0.0531,  0.0601,  0.0102],\n",
            "        [ 0.0703,  0.0191,  0.0000,  0.0661,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0697,\n",
            "          0.0000,  0.0712,  0.0804,  0.0133]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.0509, -0.1165, -0.0590,  ...,  0.0268,  0.0200, -0.1092],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0665, -0.1523, -0.0772,  ...,  0.0350,  0.0261, -0.1435],\n",
            "        [ 0.0449, -0.1028, -0.0521,  ...,  0.0236,  0.0176, -0.0969]])\n",
            "   Last layer:\n",
            "tensor([[-0.0384, -0.0150,  0.0000, -0.0440,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0446,\n",
            "          0.0000, -0.0505, -0.0688, -0.0131],\n",
            "        [-0.0350, -0.0137,  0.0000, -0.0401,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0409,\n",
            "          0.0000, -0.0463, -0.0627, -0.0120],\n",
            "        [-0.0347, -0.0137,  0.0000, -0.0398,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0409,\n",
            "          0.0000, -0.0462, -0.0622, -0.0119],\n",
            "        [ 0.0086,  0.0032,  0.0000,  0.0098,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0095,\n",
            "          0.0000,  0.0109,  0.0154,  0.0029],\n",
            "        [ 0.0072,  0.0028,  0.0000,  0.0083,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0083,\n",
            "          0.0000,  0.0094,  0.0129,  0.0025],\n",
            "        [-0.0323, -0.0128,  0.0000, -0.0370,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0381,\n",
            "          0.0000, -0.0430, -0.0578, -0.0110],\n",
            "        [ 0.0636,  0.0252,  0.0000,  0.0729,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0750,\n",
            "          0.0000,  0.0847,  0.1139,  0.0218],\n",
            "        [ 0.0309,  0.0123,  0.0000,  0.0354,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0366,\n",
            "          0.0000,  0.0413,  0.0553,  0.0106],\n",
            "        [ 0.0331,  0.0132,  0.0000,  0.0380,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0393,\n",
            "          0.0000,  0.0443,  0.0593,  0.0113],\n",
            "        [ 0.0473,  0.0187,  0.0000,  0.0543,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0556,\n",
            "          0.0000,  0.0628,  0.0847,  0.0162]])\n",
            "DEBUGGING: training for one iteration takes 0.007057 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 18\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([0.0114, 0.0174, 0.0133, 0.0137, 0.0135, 0.0133, 0.0189, 0.0124, 0.0259,\n",
            "        0.0139, 0.0092, 0.0147, 0.0013, 0.0151, 0.0188, 0.0146, 0.0158, 0.0165,\n",
            "        0.0114, 0.0048, 0.0138, 0.0103, 0.0154, 0.0288, 0.0173, 0.0125, 0.0157,\n",
            "        0.0098, 0.0173, 0.0196, 0.0144, 0.0125, 0.0132, 0.0121, 0.0196, 0.0149,\n",
            "        0.0125, 0.0157, 0.0165, 0.0130, 0.0120, 0.0186, 0.0165, 0.0209, 0.0158,\n",
            "        0.0110, 0.0185, 0.0158, 0.0158, 0.0132, 0.0136, 0.0140, 0.0129, 0.0126,\n",
            "        0.0167, 0.0145, 0.0110, 0.0136, 0.0220, 0.0261, 0.0163, 0.0068, 0.0211,\n",
            "        0.0082, 0.0182, 0.0155, 0.0050, 0.0130], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [11]\n",
            "DEBUGGING: logits looks like: tensor([478.9813, 479.1915, 479.0579, 479.0735, 479.0641, 479.0573, 479.2344,\n",
            "        479.0240, 479.3905, 479.0813, 478.8751, 479.1060, 477.8983, 479.1196,\n",
            "        479.2298, 479.1026, 479.1439, 479.1662, 478.9792, 478.5499, 479.0769,\n",
            "        478.9321, 479.1304, 479.4443, 479.1903, 479.0259, 479.1403, 478.9031,\n",
            "        479.1891, 479.2518, 479.0981, 479.0281, 479.0526, 479.0094, 479.2527,\n",
            "        479.1156, 479.0280, 479.1405, 479.1643, 479.0443, 479.0044, 479.2259,\n",
            "        479.1641, 479.2837, 479.1435, 478.9621, 479.2219, 479.1449, 479.1445,\n",
            "        479.0533, 479.0686, 479.0845, 479.0415, 479.0286, 479.1719, 479.0992,\n",
            "        478.9619, 479.0677, 479.3089, 479.3947, 479.1583, 478.7250, 479.2888,\n",
            "        478.8171, 479.2133, 479.1330, 478.5701, 479.0471],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0153, 0.0150, 0.0141, 0.0070, 0.0130, 0.0091, 0.0143, 0.0156, 0.0170,\n",
            "        0.0149, 0.0122, 0.0140, 0.0025, 0.0164, 0.0146, 0.0139, 0.0159, 0.0101,\n",
            "        0.0205, 0.0074, 0.0150, 0.0124, 0.0147, 0.0106, 0.0214, 0.0152, 0.0124,\n",
            "        0.0124, 0.0148, 0.0149, 0.0136, 0.0100, 0.0166, 0.0158, 0.0146, 0.0124,\n",
            "        0.0135, 0.0125, 0.0019, 0.0138, 0.0134, 0.0078, 0.0064, 0.0162, 0.0129,\n",
            "        0.0120, 0.0137, 0.0096, 0.0060, 0.0108, 0.0136, 0.0113, 0.0116, 0.0114,\n",
            "        0.0079, 0.0169, 0.0136, 0.0151, 0.0124, 0.0113, 0.0124, 0.0143, 0.0068,\n",
            "        0.0150, 0.0078, 0.0121, 0.0102, 0.0118, 0.0158, 0.0166, 0.0145, 0.0150,\n",
            "        0.0132, 0.0062, 0.0116, 0.0088, 0.0064, 0.0150, 0.0108, 0.0102],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [1]\n",
            "DEBUGGING: logits looks like: tensor([478.8793, 478.8714, 478.8415, 478.4923, 478.8010, 478.6235, 478.8477,\n",
            "        478.8913, 478.9335, 478.8669, 478.7664, 478.8359, 477.9820, 478.9168,\n",
            "        478.8563, 478.8338, 478.8991, 478.6707, 479.0273, 478.5188, 478.8709,\n",
            "        478.7746, 478.8591, 478.6988, 479.0492, 478.8779, 478.7771, 478.7743,\n",
            "        478.8656, 478.8670, 478.8235, 478.6689, 478.9213, 478.8956, 478.8559,\n",
            "        478.7758, 478.8181, 478.7816, 477.8448, 478.8291, 478.8135, 478.5438,\n",
            "        478.4481, 478.9080, 478.7949, 478.7600, 478.8239, 478.6465, 478.4157,\n",
            "        478.7082, 478.8217, 478.7281, 478.7416, 478.7332, 478.5484, 478.9304,\n",
            "        478.8236, 478.8745, 478.7743, 478.7287, 478.7756, 478.8484, 478.4785,\n",
            "        478.8713, 478.5451, 478.7653, 478.6760, 478.7527, 478.8983, 478.9206,\n",
            "        478.8535, 478.8713, 478.8078, 478.4293, 478.7409, 478.6039, 478.4449,\n",
            "        478.8713, 478.7078, 478.6760], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0172, 0.0125, 0.0120, 0.0123, 0.0117, 0.0121, 0.0120, 0.0126, 0.0099,\n",
            "        0.0126, 0.0120, 0.0122, 0.0119, 0.0124, 0.0127, 0.0119, 0.0126, 0.0111,\n",
            "        0.0119, 0.0120, 0.0107, 0.0120, 0.0116, 0.0115, 0.0122, 0.0118, 0.0124,\n",
            "        0.0119, 0.0113, 0.0112, 0.0100, 0.0122, 0.0119, 0.0117, 0.0121, 0.0111,\n",
            "        0.0116, 0.0117, 0.0076, 0.0116, 0.0116, 0.0120, 0.0124, 0.0126, 0.0120,\n",
            "        0.0120, 0.0121, 0.0122, 0.0121, 0.0124, 0.0110, 0.0119, 0.0117, 0.0117,\n",
            "        0.0119, 0.0119, 0.0124, 0.0123, 0.0117, 0.0126, 0.0128, 0.0115, 0.0090,\n",
            "        0.0120, 0.0123, 0.0122, 0.0124, 0.0121, 0.0121, 0.0120, 0.0125, 0.0117,\n",
            "        0.0120, 0.0118, 0.0125, 0.0126, 0.0126, 0.0123, 0.0107, 0.0122, 0.0118,\n",
            "        0.0104, 0.0122, 0.0118], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [6]\n",
            "DEBUGGING: logits looks like: tensor([478.9316, 478.7747, 478.7511, 478.7656, 478.7402, 478.7552, 478.7524,\n",
            "        478.7789, 478.6591, 478.7757, 478.7532, 478.7609, 478.7489, 478.7701,\n",
            "        478.7810, 478.7492, 478.7792, 478.7158, 478.7494, 478.7541, 478.6958,\n",
            "        478.7538, 478.7350, 478.7314, 478.7601, 478.7432, 478.7686, 478.7489,\n",
            "        478.7238, 478.7205, 478.6617, 478.7632, 478.7483, 478.7403, 478.7567,\n",
            "        478.7146, 478.7363, 478.7387, 478.5225, 478.7372, 478.7363, 478.7538,\n",
            "        478.7703, 478.7783, 478.7519, 478.7539, 478.7567, 478.7612, 478.7566,\n",
            "        478.7685, 478.7086, 478.7481, 478.7417, 478.7415, 478.7493, 478.7488,\n",
            "        478.7698, 478.7670, 478.7400, 478.7772, 478.7857, 478.7315, 478.6086,\n",
            "        478.7531, 478.7658, 478.7624, 478.7699, 478.7573, 478.7559, 478.7510,\n",
            "        478.7725, 478.7400, 478.7541, 478.7443, 478.7730, 478.7766, 478.7778,\n",
            "        478.7655, 478.6973, 478.7607, 478.7438, 478.6831, 478.7603, 478.7465],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0168, 0.0085, 0.0110, 0.0110, 0.0073, 0.0110, 0.0069, 0.0112, 0.0111,\n",
            "        0.0111, 0.0064, 0.0074, 0.0146, 0.0096, 0.0077, 0.0075, 0.0109, 0.0110,\n",
            "        0.0102, 0.0111, 0.0100, 0.0109, 0.0100, 0.0098, 0.0111, 0.0110, 0.0098,\n",
            "        0.0098, 0.0100, 0.0109, 0.0110, 0.0110, 0.0110, 0.0103, 0.0071, 0.0092,\n",
            "        0.0067, 0.0075, 0.0110, 0.0110, 0.0027, 0.0109, 0.0111, 0.0101, 0.0091,\n",
            "        0.0100, 0.0057, 0.0111, 0.0089, 0.0110, 0.0097, 0.0074, 0.0072, 0.0141,\n",
            "        0.0106, 0.0109, 0.0109, 0.0111, 0.0092, 0.0076, 0.0111, 0.0093, 0.0110,\n",
            "        0.0088, 0.0056, 0.0109, 0.0110, 0.0111, 0.0110, 0.0110, 0.0110, 0.0109,\n",
            "        0.0110, 0.0085, 0.0110, 0.0108, 0.0110, 0.0111, 0.0110, 0.0110, 0.0110,\n",
            "        0.0110, 0.0110, 0.0108, 0.0111, 0.0110, 0.0109, 0.0110, 0.0110, 0.0109,\n",
            "        0.0110, 0.0110, 0.0108, 0.0110, 0.0112, 0.0110, 0.0108, 0.0042, 0.0108],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [65]\n",
            "DEBUGGING: logits looks like: tensor([478.8907, 478.5535, 478.6788, 478.6789, 478.4779, 478.6806, 478.4507,\n",
            "        478.6899, 478.6834, 478.6842, 478.4059, 478.4794, 478.8205, 478.6109,\n",
            "        478.5026, 478.4898, 478.6743, 478.6799, 478.6440, 478.6828, 478.6339,\n",
            "        478.6768, 478.6352, 478.6247, 478.6833, 478.6817, 478.6202, 478.6249,\n",
            "        478.6306, 478.6754, 478.6785, 478.6815, 478.6826, 478.6469, 478.4601,\n",
            "        478.5905, 478.4359, 478.4872, 478.6786, 478.6794, 477.9773, 478.6777,\n",
            "        478.6831, 478.6400, 478.5841, 478.6329, 478.3518, 478.6863, 478.5751,\n",
            "        478.6801, 478.6176, 478.4848, 478.4655, 478.8033, 478.6636, 478.6777,\n",
            "        478.6770, 478.6862, 478.5909, 478.4987, 478.6850, 478.5947, 478.6799,\n",
            "        478.5686, 478.3401, 478.6754, 478.6783, 478.6859, 478.6808, 478.6805,\n",
            "        478.6804, 478.6771, 478.6784, 478.5535, 478.6789, 478.6736, 478.6782,\n",
            "        478.6837, 478.6798, 478.6805, 478.6786, 478.6797, 478.6785, 478.6723,\n",
            "        478.6857, 478.6787, 478.6759, 478.6782, 478.6800, 478.6778, 478.6797,\n",
            "        478.6784, 478.6733, 478.6819, 478.6894, 478.6789, 478.6731, 478.2021,\n",
            "        478.6731], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0169, 0.0084, 0.0106, 0.0098, 0.0073, 0.0101, 0.0065, 0.0099, 0.0093,\n",
            "        0.0104, 0.0087, 0.0073, 0.0081, 0.0097, 0.0109, 0.0074, 0.0102, 0.0099,\n",
            "        0.0092, 0.0098, 0.0096, 0.0099, 0.0113, 0.0099, 0.0106, 0.0099, 0.0086,\n",
            "        0.0082, 0.0104, 0.0100, 0.0103, 0.0104, 0.0098, 0.0078, 0.0087, 0.0072,\n",
            "        0.0093, 0.0059, 0.0090, 0.0104, 0.0103, 0.0065, 0.0101, 0.0100, 0.0096,\n",
            "        0.0091, 0.0094, 0.0096, 0.0107, 0.0038, 0.0099, 0.0042, 0.0100, 0.0131,\n",
            "        0.0094, 0.0098, 0.0103, 0.0102, 0.0098, 0.0085, 0.0098, 0.0084, 0.0099,\n",
            "        0.0070, 0.0072, 0.0101, 0.0104, 0.0105, 0.0100, 0.0103, 0.0102, 0.0097,\n",
            "        0.0075, 0.0097, 0.0098, 0.0100, 0.0102, 0.0103, 0.0102, 0.0101, 0.0100,\n",
            "        0.0101, 0.0097, 0.0093, 0.0096, 0.0075, 0.0103, 0.0101, 0.0101, 0.0099,\n",
            "        0.0077, 0.0094, 0.0102, 0.0111, 0.0085, 0.0100, 0.0100, 0.0067, 0.0096,\n",
            "        0.0102, 0.0095, 0.0103, 0.0083, 0.0098, 0.0086, 0.0099],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [2]\n",
            "DEBUGGING: logits looks like: tensor([478.8540, 478.5058, 478.6184, 478.5822, 478.4364, 478.5987, 478.3741,\n",
            "        478.5850, 478.5537, 478.6127, 478.5241, 478.4363, 478.4839, 478.5772,\n",
            "        478.6335, 478.4394, 478.5992, 478.5864, 478.5504, 478.5796, 478.5705,\n",
            "        478.5874, 478.6525, 478.5864, 478.6193, 478.5884, 478.5189, 478.4947,\n",
            "        478.6108, 478.5892, 478.6066, 478.6122, 478.5806, 478.4659, 478.5221,\n",
            "        478.4287, 478.5547, 478.3281, 478.5412, 478.6123, 478.6086, 478.3781,\n",
            "        478.5947, 478.5924, 478.5697, 478.5469, 478.5598, 478.5727, 478.6273,\n",
            "        478.1127, 478.5867, 478.1591, 478.5927, 478.7282, 478.5616, 478.5805,\n",
            "        478.6083, 478.6017, 478.5806, 478.5076, 478.5831, 478.5013, 478.5859,\n",
            "        478.4165, 478.4297, 478.5970, 478.6112, 478.6163, 478.5927, 478.6067,\n",
            "        478.6007, 478.5742, 478.4482, 478.5772, 478.5792, 478.5938, 478.6022,\n",
            "        478.6050, 478.6001, 478.5960, 478.5894, 478.5962, 478.5781, 478.5529,\n",
            "        478.5724, 478.4456, 478.6077, 478.5948, 478.5952, 478.5872, 478.4624,\n",
            "        478.5593, 478.5998, 478.6433, 478.5082, 478.5907, 478.5930, 478.3936,\n",
            "        478.5719, 478.6035, 478.5638, 478.6063, 478.4955, 478.5811, 478.5175,\n",
            "        478.5857], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.06315464246108604 and immediate abs rewards look like: [0.0011903380845978973, 0.013530657945466373, 0.0003352835237819818, 0.007608537098803936, 0.009674415981862694, 0.00498627185334044, 0.0022796137723162246, 0.0046338201368598675, 2.921592749771662e-05, 0.00015718612257842324, 0.0010521985482228047, 5.086157671030378e-05, 5.6360833241342334e-05, 2.9987122161401203e-05, 0.004034178488836915, 0.0006816954032728972, 0.0011016058147106378, 0.0015019082866274402, 0.002233368355973653, 0.001838394062815496, 0.0014727057728123327, 8.441256750302273e-05, 0.0010801348671520827, 0.00017302617789027863, 0.0001061385328284814, 4.646903153116e-05, 0.0003217413245693024, 0.0006076111226320791, 6.828983532614075e-05, 4.9018580739357276e-05, 5.769820245404844e-05, 0.00019851070101140067, 0.00021157199671506532, 3.199738011971931e-05, 2.1323909095372073e-05, 5.3090691380930366e-05, 3.793822088482557e-05, 2.3085440261638723e-06, 7.424831801472465e-05, 0.00015340202435254469, 2.8549950457090745e-05, 5.302594763634261e-05, 3.523296800267417e-05, 2.5478579573245952e-05, 3.085661774093751e-06, 1.8220357105747098e-05, 8.244194759754464e-06, 5.072837529951357e-05, 0.00026172852085437626, 0.0008128111649057246]\n",
            "DEBUGGING: the total relative reward of the trajectory = 1.930611919840986 and immediate relative rewards look like: [0.0038381769835229562, 0.0872911671927041, 0.003258775997420131, 0.09861191074729957, 0.15712126567299356, 0.09748421460492032, 0.05208019410894207, 0.12107812256307937, 0.0008601149544533956, 0.005141770196377857, 0.03786266474162086, 0.0019972911163302935, 0.002397719034709489, 0.001373878630013111, 0.19803236500638408, 0.03574159218271854, 0.06138124791857226, 0.08864073093039278, 0.13920194059097393, 0.12070304706205438, 0.10158909598042534, 0.00610311771611434, 0.08164692359461033, 0.0136524707944622, 0.008724207659081305, 0.00397251028975394, 0.028563097782324375, 0.055945400828807924, 0.006513606064938234, 0.00483681156430247, 0.005883126135458145, 0.020894227841110478, 0.02296639909261165, 0.0035788570050199514, 0.0024552201903991714, 0.006287521865969646, 0.004617903960829014, 0.0002885980485524271, 0.009526276633046211, 0.020187086894889454, 0.0038511789967157865, 0.007327339210531999, 0.004984640363839265, 0.0036884938897852296, 0.00045686264969654157, 0.0027576552855781496, 0.0012748936718153744, 0.008011636438785117, 0.0421971793983989, 0.13373138975764995]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([0.0220, 0.0182, 0.0013, 0.0115, 0.0121, 0.0050, 0.0013, 0.0152, 0.0052,\n",
            "        0.0003, 0.0469, 0.0253, 0.0146, 0.0842, 0.0044, 0.0136, 0.0068, 0.0143,\n",
            "        0.0042, 0.0124, 0.0045, 0.0333, 0.0331, 0.0234, 0.0048, 0.0146, 0.0227,\n",
            "        0.0096, 0.0031, 0.0087, 0.0143, 0.0031, 0.0046, 0.0279, 0.0027, 0.0175,\n",
            "        0.0023, 0.0203, 0.0052, 0.0271, 0.0116, 0.0198, 0.0156, 0.0022, 0.0275,\n",
            "        0.0088, 0.0223, 0.0241, 0.0066, 0.0133, 0.0036, 0.0124, 0.0055, 0.0158,\n",
            "        0.0036, 0.0469, 0.0125, 0.0026, 0.0362, 0.0163, 0.0051, 0.0094, 0.0194,\n",
            "        0.0291, 0.0039, 0.0093, 0.0072, 0.0079], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [46]\n",
            "DEBUGGING: logits looks like: tensor([479.8370, 479.7424, 478.4120, 479.5135, 479.5379, 479.0957, 478.4106,\n",
            "        479.6519, 479.1157, 477.7495, 480.2165, 479.9082, 479.6338, 480.5091,\n",
            "        479.0318, 479.5990, 479.2489, 479.6219, 479.0069, 479.5526, 479.0433,\n",
            "        480.0453, 480.0424, 479.8693, 479.0754, 479.6315, 479.8537, 479.4221,\n",
            "        478.8555, 479.3760, 479.6219, 478.8609, 479.0591, 479.9568, 478.7881,\n",
            "        479.7231, 478.7160, 479.7986, 479.1156, 479.9425, 479.5191, 479.7843,\n",
            "        479.6673, 478.6761, 479.9494, 479.3818, 479.8438, 479.8831, 479.2338,\n",
            "        479.5868, 478.9300, 479.5522, 479.1474, 479.6737, 478.9376, 480.2165,\n",
            "        479.5534, 478.7645, 480.0866, 479.6886, 479.1109, 479.4121, 479.7742,\n",
            "        479.9772, 478.9721, 479.4078, 479.2804, 479.3234],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0140, 0.0108, 0.0106, 0.0174, 0.0133, 0.0080, 0.0220, 0.0185, 0.0156,\n",
            "        0.0121, 0.0167, 0.0167, 0.0080, 0.0083, 0.0107, 0.0078, 0.0099, 0.0118,\n",
            "        0.0118, 0.0120, 0.0203, 0.0108, 0.0133, 0.0113, 0.0098, 0.0119, 0.0142,\n",
            "        0.0169, 0.0143, 0.0120, 0.0157, 0.0082, 0.0156, 0.0080, 0.0139, 0.0129,\n",
            "        0.0051, 0.0264, 0.0138, 0.0104, 0.0246, 0.0095, 0.0131, 0.0165, 0.0104,\n",
            "        0.0123, 0.0150, 0.0138, 0.0158, 0.0095, 0.0271, 0.0166, 0.0139, 0.0098,\n",
            "        0.0115, 0.0171, 0.0163, 0.0082, 0.0067, 0.0145, 0.0130, 0.0155, 0.0137,\n",
            "        0.0168, 0.0085, 0.0113, 0.0086, 0.0074, 0.0091, 0.0127, 0.0147, 0.0156,\n",
            "        0.0110, 0.0114, 0.0133, 0.0144], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [11]\n",
            "DEBUGGING: logits looks like: tensor([479.8535, 479.7269, 479.7152, 479.9619, 479.8301, 479.5744, 480.0808,\n",
            "        479.9931, 479.9086, 479.7829, 479.9441, 479.9418, 479.5753, 479.5938,\n",
            "        479.7211, 479.5603, 479.6796, 479.7694, 479.7704, 479.7762, 480.0396,\n",
            "        479.7257, 479.8301, 479.7458, 479.6757, 479.7713, 479.8611, 479.9492,\n",
            "        479.8635, 479.7773, 479.9124, 479.5840, 479.9080, 479.5764, 479.8521,\n",
            "        479.8153, 479.3514, 480.1714, 479.8466, 479.7042, 480.1368, 479.6596,\n",
            "        479.8194, 479.9357, 479.7057, 479.7914, 479.8874, 479.8471, 479.9149,\n",
            "        479.6602, 480.1850, 479.9393, 479.8516, 479.6776, 479.7576, 479.9531,\n",
            "        479.9297, 479.5891, 479.4861, 479.8721, 479.8170, 479.9041, 479.8434,\n",
            "        479.9460, 479.6042, 479.7487, 479.6083, 479.5326, 479.6404, 479.8061,\n",
            "        479.8795, 479.9086, 479.7361, 479.7531, 479.8297, 479.8687],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0091, 0.0083, 0.0119, 0.0131, 0.0121, 0.0124, 0.0112, 0.0164, 0.0106,\n",
            "        0.0150, 0.0201, 0.0095, 0.0098, 0.0125, 0.0184, 0.0124, 0.0072, 0.0077,\n",
            "        0.0171, 0.0088, 0.0089, 0.0145, 0.0081, 0.0082, 0.0103, 0.0093, 0.0117,\n",
            "        0.0092, 0.0079, 0.0151, 0.0128, 0.0089, 0.0088, 0.0048, 0.0115, 0.0095,\n",
            "        0.0118, 0.0134, 0.0097, 0.0132, 0.0184, 0.0087, 0.0135, 0.0124, 0.0092,\n",
            "        0.0122, 0.0139, 0.0127, 0.0100, 0.0140, 0.0083, 0.0083, 0.0106, 0.0131,\n",
            "        0.0157, 0.0138, 0.0174, 0.0153, 0.0134, 0.0129, 0.0151, 0.0088, 0.0141,\n",
            "        0.0147, 0.0107, 0.0123, 0.0137, 0.0154, 0.0096, 0.0077, 0.0091, 0.0104,\n",
            "        0.0096, 0.0115, 0.0089, 0.0138, 0.0055, 0.0095, 0.0056, 0.0121, 0.0064,\n",
            "        0.0147, 0.0106, 0.0104, 0.0082, 0.0161, 0.0104],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [81]\n",
            "DEBUGGING: logits looks like: tensor([480.0187, 479.9754, 480.1544, 480.2011, 480.1604, 480.1728, 480.1238,\n",
            "        480.3142, 480.0946, 480.2709, 480.4165, 480.0438, 480.0548, 480.1793,\n",
            "        480.3709, 480.1729, 479.9057, 479.9386, 480.3364, 480.0025, 480.0075,\n",
            "        480.2527, 479.9611, 479.9670, 480.0815, 480.0298, 480.1463, 480.0249,\n",
            "        479.9478, 480.2736, 480.1895, 480.0110, 480.0030, 479.7039, 480.1351,\n",
            "        480.0399, 480.1480, 480.2128, 480.0504, 480.2056, 480.3727, 479.9961,\n",
            "        480.2153, 480.1733, 480.0260, 480.1669, 480.2314, 480.1849, 480.0647,\n",
            "        480.2353, 479.9725, 479.9742, 480.0961, 480.2037, 480.2930, 480.2284,\n",
            "        480.3446, 480.2792, 480.2137, 480.1948, 480.2733, 480.0050, 480.2397,\n",
            "        480.2610, 480.1017, 480.1684, 480.2255, 480.2833, 480.0470, 479.9345,\n",
            "        480.0173, 480.0886, 480.0446, 480.1351, 480.0092, 480.2274, 479.7717,\n",
            "        480.0395, 479.7797, 480.1636, 479.8472, 480.2586, 480.0980, 480.0877,\n",
            "        479.9675, 480.3037, 480.0851], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0495, 0.0103, 0.0073, 0.0135, 0.0147, 0.0299, 0.0020, 0.0300, 0.0083,\n",
            "        0.0025, 0.0073, 0.0060, 0.0010, 0.0090, 0.0002, 0.0149, 0.0033, 0.0020,\n",
            "        0.0046, 0.0280, 0.0249, 0.0313, 0.0027, 0.0018, 0.0216, 0.0015, 0.0002,\n",
            "        0.0032, 0.0126, 0.0024, 0.0158, 0.0018, 0.0059, 0.0110, 0.0138, 0.0118,\n",
            "        0.0001, 0.0028, 0.0185, 0.0007, 0.0009, 0.0017, 0.0270, 0.0019, 0.0167,\n",
            "        0.0022, 0.0005, 0.0047, 0.0179, 0.0084, 0.0061, 0.0048, 0.0071, 0.0380,\n",
            "        0.0025, 0.0050, 0.0124, 0.0035, 0.0399, 0.0054, 0.0034, 0.0048, 0.0044,\n",
            "        0.0043, 0.0103, 0.0067, 0.0151, 0.0072, 0.0046, 0.0055, 0.0380, 0.0040,\n",
            "        0.0052, 0.0121, 0.0110, 0.0035, 0.0040, 0.0410, 0.0219, 0.0030, 0.0148,\n",
            "        0.0046, 0.0126, 0.0055, 0.0171, 0.0079, 0.0099, 0.0066, 0.0174, 0.0067,\n",
            "        0.0023, 0.0088, 0.0058, 0.0065, 0.0018, 0.0037, 0.0118, 0.0111],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [87]\n",
            "DEBUGGING: logits looks like: tensor([480.0834, 479.2966, 479.1242, 479.4325, 479.4750, 479.8318, 478.4751,\n",
            "        479.8337, 479.1927, 478.5932, 479.1267, 479.0267, 478.1248, 479.2292,\n",
            "        477.3722, 479.4837, 478.7295, 478.4841, 478.8924, 479.7983, 479.7407,\n",
            "        479.8545, 478.6233, 478.4244, 479.6677, 478.3272, 477.3250, 478.7099,\n",
            "        479.4002, 478.5782, 479.5116, 478.4171, 479.0237, 479.3319, 479.4456,\n",
            "        479.3679, 477.1440, 478.6433, 479.5915, 477.9432, 478.0816, 478.3987,\n",
            "        479.7794, 478.4590, 479.5412, 478.5323, 477.7759, 478.9081, 479.5757,\n",
            "        479.1973, 479.0355, 478.9172, 479.1104, 479.9514, 478.5866, 478.9366,\n",
            "        479.3898, 478.7541, 479.9760, 478.9727, 478.7379, 478.9131, 478.8763,\n",
            "        478.8614, 479.2989, 479.0864, 479.4906, 479.1169, 478.8920, 478.9818,\n",
            "        479.9516, 478.8211, 478.9521, 479.3778, 479.3307, 478.7541, 478.8203,\n",
            "        479.9892, 479.6766, 478.6822, 479.4799, 478.8961, 479.3999, 478.9868,\n",
            "        479.5515, 479.1631, 479.2794, 479.0788, 479.5610, 479.0808, 478.5411,\n",
            "        479.2193, 479.0089, 479.0689, 478.4226, 478.7922, 479.3650, 479.3371],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0088, 0.0119, 0.0101, 0.0039, 0.0093, 0.0050, 0.0107, 0.0056, 0.0092,\n",
            "        0.0130, 0.0122, 0.0083, 0.0106, 0.0043, 0.0072, 0.0057, 0.0076, 0.0040,\n",
            "        0.0058, 0.0093, 0.0058, 0.0074, 0.0098, 0.0065, 0.0015, 0.0074, 0.0217,\n",
            "        0.0144, 0.0156, 0.0083, 0.0245, 0.0122, 0.0138, 0.0066, 0.0027, 0.0055,\n",
            "        0.0122, 0.0078, 0.0186, 0.0135, 0.0063, 0.0073, 0.0073, 0.0097, 0.0064,\n",
            "        0.0197, 0.0078, 0.0122, 0.0067, 0.0009, 0.0134, 0.0070, 0.0056, 0.0126,\n",
            "        0.0062, 0.0095, 0.0175, 0.0048, 0.0069, 0.0069, 0.0055, 0.0089, 0.0087,\n",
            "        0.0103, 0.0047, 0.0071, 0.0067, 0.0048, 0.0136, 0.0101, 0.0058, 0.0103,\n",
            "        0.0066, 0.0092, 0.0044, 0.0103, 0.0069, 0.0109, 0.0190, 0.0167, 0.0093,\n",
            "        0.0081, 0.0085, 0.0049, 0.0085, 0.0153, 0.0106, 0.0106, 0.0136, 0.0121,\n",
            "        0.0095, 0.0075, 0.0190, 0.0179, 0.0112, 0.0038, 0.0079, 0.0067, 0.0123,\n",
            "        0.0052, 0.0149, 0.0091, 0.0054, 0.0075, 0.0079, 0.0085, 0.0107],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [105]\n",
            "DEBUGGING: logits looks like: tensor([479.6140, 479.7646, 479.6836, 479.2021, 479.6402, 479.3356, 479.7113,\n",
            "        479.3880, 479.6363, 479.8102, 479.7784, 479.5843, 479.7064, 479.2525,\n",
            "        479.5112, 479.3939, 479.5437, 479.2166, 479.4028, 479.6433, 479.4038,\n",
            "        479.5243, 479.6653, 479.4601, 478.7441, 479.5295, 480.0649, 479.8589,\n",
            "        479.9010, 479.5866, 480.1267, 479.7760, 479.8403, 479.4705, 479.0260,\n",
            "        479.3796, 479.7772, 479.5564, 479.9889, 479.8273, 479.4440, 479.5230,\n",
            "        479.5205, 479.6649, 479.4512, 480.0159, 479.5521, 479.7780, 479.4801,\n",
            "        478.4503, 479.8243, 479.5002, 479.3847, 479.7925, 479.4411, 479.6526,\n",
            "        479.9567, 479.3147, 479.4921, 479.4894, 479.3811, 479.6216, 479.6096,\n",
            "        479.6926, 479.3001, 479.5045, 479.4796, 479.3119, 479.8310, 479.6838,\n",
            "        479.4082, 479.6947, 479.4728, 479.6355, 479.2632, 479.6915, 479.4921,\n",
            "        479.7217, 479.9980, 479.9352, 479.6404, 479.5713, 479.5953, 479.3162,\n",
            "        479.5985, 479.8911, 479.7082, 479.7051, 479.8318, 479.7747, 479.6504,\n",
            "        479.5310, 479.9979, 479.9679, 479.7359, 479.1912, 479.5616, 479.4795,\n",
            "        479.7807, 479.3502, 479.8778, 479.6282, 479.3693, 479.5331, 479.5623,\n",
            "        479.5944, 479.7116], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.7058461509386689 and immediate abs rewards look like: [0.7058461509227527, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 9.094947017729282e-13, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13, 9.094947017729282e-13, 0.0, 4.547473508864641e-13, 0.0, 9.094947017729282e-13, 0.0, 0.0, 0.0, 4.547473508864641e-13]\n",
            "DEBUGGING: the total relative reward of the trajectory = 2.6085967646009935 and immediate relative rewards look like: [2.608596762540988, 9.094947017735486e-12, 6.821210263298513e-12, 9.094947017729282e-12, 1.1368683772164188e-11, 0.0, 1.5916157281026244e-11, 0.0, 2.0463630789895538e-11, 0.0, 0.0, 2.7284841053187847e-11, 0.0, 3.1832314562059726e-11, 0.0, 0.0, 3.865352482534945e-11, 8.185452315954493e-11, 4.3200998334223914e-11, 0.0, 0.0, 0.0, 0.0, 5.4569682106375694e-11, 1.1368683772164188e-10, 1.182343112304538e-10, 6.139089236968661e-11, 6.366462912410498e-11, 6.593836587855229e-11, 0.0, 0.0, 7.275957614183426e-11, 7.503331289624952e-11, 7.73070496506989e-11, 0.0, 8.185452315954493e-11, 0.0, 0.0, 8.86757334228605e-11, 9.09494701773135e-11, 1.864464138634503e-10, 1.9099388737222808e-10, 0.0, 1.000444171950221e-10, 0.0, 2.0918378140772593e-10, 0.0, 0.0, 0.0, 1.1368683772164188e-10]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([0.0051, 0.0068, 0.0211, 0.0033, 0.0078, 0.0078, 0.0205, 0.0191, 0.0083,\n",
            "        0.0564, 0.0159, 0.0182, 0.0109, 0.0171, 0.0052, 0.0094, 0.0076, 0.0414,\n",
            "        0.0199, 0.0114, 0.0116, 0.0238, 0.0020, 0.0140, 0.0095, 0.0080, 0.0165,\n",
            "        0.0148, 0.0069, 0.0238, 0.0055, 0.0072, 0.0205, 0.0061, 0.0059, 0.0884,\n",
            "        0.0220, 0.0036, 0.0184, 0.0049, 0.0273, 0.0069, 0.0159, 0.0072, 0.0121,\n",
            "        0.0433, 0.0065, 0.0050, 0.0088, 0.0040, 0.0283, 0.0235, 0.0132, 0.0065,\n",
            "        0.0079, 0.0084, 0.0282, 0.0075, 0.0062, 0.0131, 0.0061, 0.0030, 0.0145,\n",
            "        0.0251, 0.0145, 0.0112, 0.0069, 0.0117], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [35]\n",
            "DEBUGGING: logits looks like: tensor([479.7291, 479.8706, 480.4372, 479.5083, 479.9404, 479.9378, 480.4226,\n",
            "        480.3876, 479.9686, 480.9280, 480.2950, 480.3625, 480.1071, 480.3323,\n",
            "        479.7387, 480.0310, 479.9229, 480.7740, 480.4084, 480.1303, 480.1390,\n",
            "        480.4977, 479.2489, 480.2321, 480.0384, 479.9518, 480.3139, 480.2591,\n",
            "        479.8804, 480.4973, 479.7640, 479.9010, 480.4213, 479.8181, 479.8031,\n",
            "        481.1531, 480.4572, 479.5475, 480.3686, 479.7100, 480.5657, 479.8773,\n",
            "        480.2947, 479.9006, 480.1595, 480.7965, 479.8507, 479.7142, 480.0010,\n",
            "        479.6106, 480.5842, 480.4904, 480.2011, 479.8496, 479.9429, 479.9760,\n",
            "        480.5818, 479.9193, 479.8252, 480.1988, 479.8145, 479.4674, 480.2495,\n",
            "        480.5234, 480.2495, 480.1200, 479.8773, 480.1410],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0148, 0.0087, 0.0125, 0.0149, 0.0112, 0.0111, 0.0163, 0.0146, 0.0186,\n",
            "        0.0082, 0.0131, 0.0137, 0.0165, 0.0107, 0.0206, 0.0123, 0.0145, 0.0084,\n",
            "        0.0106, 0.0169, 0.0140, 0.0094, 0.0078, 0.0124, 0.0119, 0.0083, 0.0093,\n",
            "        0.0082, 0.0119, 0.0162, 0.0127, 0.0138, 0.0072, 0.0107, 0.0119, 0.0128,\n",
            "        0.0098, 0.0081, 0.0183, 0.0147, 0.0139, 0.0091, 0.0075, 0.0144, 0.0161,\n",
            "        0.0098, 0.0203, 0.0106, 0.0109, 0.0058, 0.0104, 0.0125, 0.0171, 0.0118,\n",
            "        0.0096, 0.0171, 0.0104, 0.0306, 0.0136, 0.0160, 0.0100, 0.0223, 0.0120,\n",
            "        0.0122, 0.0100, 0.0161, 0.0105, 0.0232, 0.0106, 0.0120, 0.0079, 0.0106,\n",
            "        0.0143, 0.0133, 0.0080, 0.0168, 0.0142, 0.0108],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [30]\n",
            "DEBUGGING: logits looks like: tensor([480.2951, 480.0293, 480.2129, 480.2989, 480.1578, 480.1514, 480.3425,\n",
            "        480.2904, 480.4097, 479.9999, 480.2357, 480.2561, 480.3513, 480.1351,\n",
            "        480.4616, 480.2022, 480.2853, 480.0115, 480.1308, 480.3625, 480.2679,\n",
            "        480.0687, 479.9724, 480.2089, 480.1882, 480.0046, 480.0658, 480.0034,\n",
            "        480.1870, 480.3418, 480.2184, 480.2591, 479.9370, 480.1314, 480.1855,\n",
            "        480.2230, 480.0889, 479.9926, 480.4032, 480.2914, 480.2633, 480.0540,\n",
            "        479.9571, 480.2813, 480.3380, 480.0878, 480.4549, 480.1309, 480.1415,\n",
            "        479.8247, 480.1217, 480.2109, 480.3686, 480.1809, 480.0779, 480.3680,\n",
            "        480.1198, 480.6596, 480.2538, 480.3356, 480.0997, 480.5003, 480.1915,\n",
            "        480.1992, 480.0977, 480.3366, 480.1217, 480.5213, 480.1296, 480.1910,\n",
            "        479.9805, 480.1292, 480.2786, 480.2406, 479.9908, 480.3604, 480.2749,\n",
            "        480.1375], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0055, 0.0104, 0.0195, 0.0103, 0.0180, 0.0120, 0.0120, 0.0096, 0.0080,\n",
            "        0.0078, 0.0125, 0.0152, 0.0067, 0.0091, 0.0075, 0.0230, 0.0144, 0.0110,\n",
            "        0.0080, 0.0174, 0.0198, 0.0209, 0.0079, 0.0075, 0.0105, 0.0070, 0.0066,\n",
            "        0.0117, 0.0098, 0.0080, 0.0088, 0.0141, 0.0105, 0.0109, 0.0071, 0.0129,\n",
            "        0.0086, 0.0105, 0.0221, 0.0068, 0.0123, 0.0124, 0.0125, 0.0111, 0.0104,\n",
            "        0.0114, 0.0080, 0.0116, 0.0081, 0.0114, 0.0076, 0.0077, 0.0100, 0.0088,\n",
            "        0.0063, 0.0120, 0.0298, 0.0214, 0.0146, 0.0172, 0.0058, 0.0188, 0.0125,\n",
            "        0.0174, 0.0090, 0.0171, 0.0090, 0.0118, 0.0265, 0.0051, 0.0098, 0.0093,\n",
            "        0.0070, 0.0155, 0.0112, 0.0105, 0.0069, 0.0079, 0.0115, 0.0101, 0.0074,\n",
            "        0.0115, 0.0124, 0.0106, 0.0117, 0.0093], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [84]\n",
            "DEBUGGING: logits looks like: tensor([480.0776, 480.4005, 480.7138, 480.3926, 480.6718, 480.4695, 480.4711,\n",
            "        480.3574, 480.2690, 480.2573, 480.4918, 480.5898, 480.1817, 480.3312,\n",
            "        480.2325, 480.7951, 480.5596, 480.4267, 480.2664, 480.6554, 480.7214,\n",
            "        480.7468, 480.2582, 480.2337, 480.4041, 480.2033, 480.1696, 480.4583,\n",
            "        480.3673, 480.2689, 480.3161, 480.5513, 480.4032, 480.4241, 480.2066,\n",
            "        480.5046, 480.3035, 480.4022, 480.7744, 480.1883, 480.4818, 480.4856,\n",
            "        480.4890, 480.4292, 480.3979, 480.4439, 480.2653, 480.4523, 480.2723,\n",
            "        480.4458, 480.2408, 480.2489, 480.3805, 480.3131, 480.1512, 480.4696,\n",
            "        480.9253, 480.7586, 480.5672, 480.6494, 480.1075, 480.6942, 480.4908,\n",
            "        480.6547, 480.3268, 480.6478, 480.3268, 480.4608, 480.8669, 480.0434,\n",
            "        480.3670, 480.3419, 480.2026, 480.5974, 480.4362, 480.4018, 480.1903,\n",
            "        480.2606, 480.4486, 480.3844, 480.2264, 480.4486, 480.4866, 480.4085,\n",
            "        480.4555, 480.3445], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0087, 0.0228, 0.0097, 0.0186, 0.0077, 0.0049, 0.0060, 0.0021, 0.0052,\n",
            "        0.0126, 0.0091, 0.0212, 0.0052, 0.0070, 0.0107, 0.0226, 0.0097, 0.0036,\n",
            "        0.0169, 0.0128, 0.0090, 0.0132, 0.0102, 0.0106, 0.0142, 0.0153, 0.0048,\n",
            "        0.0106, 0.0071, 0.0066, 0.0034, 0.0084, 0.0134, 0.0063, 0.0177, 0.0076,\n",
            "        0.0065, 0.0126, 0.0099, 0.0043, 0.0101, 0.0150, 0.0085, 0.0084, 0.0060,\n",
            "        0.0116, 0.0049, 0.0113, 0.0038, 0.0132, 0.0088, 0.0099, 0.0068, 0.0108,\n",
            "        0.0097, 0.0081, 0.0054, 0.0049, 0.0123, 0.0070, 0.0061, 0.0067, 0.0188,\n",
            "        0.0114, 0.0120, 0.0085, 0.0080, 0.0085, 0.0067, 0.0080, 0.0153, 0.0072,\n",
            "        0.0108, 0.0043, 0.0090, 0.0089, 0.0073, 0.0179, 0.0066, 0.0191, 0.0273,\n",
            "        0.0126, 0.0027, 0.0123, 0.0068, 0.0060, 0.0137, 0.0070, 0.0132, 0.0097,\n",
            "        0.0188, 0.0086, 0.0108, 0.0093, 0.0112, 0.0079, 0.0152, 0.0113, 0.0093],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [54]\n",
            "DEBUGGING: logits looks like: tensor([479.9209, 480.4015, 479.9738, 480.2981, 479.8596, 479.6277, 479.7356,\n",
            "        479.2002, 479.6609, 480.1046, 479.9435, 480.3639, 479.6587, 479.8140,\n",
            "        480.0221, 480.3966, 479.9745, 479.4794, 480.2503, 480.1107, 479.9361,\n",
            "        480.1266, 479.9966, 480.0162, 480.1660, 480.2027, 479.6223, 480.0196,\n",
            "        479.8169, 479.7820, 479.4565, 479.9001, 480.1346, 479.7593, 480.2755,\n",
            "        479.8510, 479.7701, 480.1061, 479.9852, 479.5692, 479.9928, 480.1920,\n",
            "        479.9081, 479.9031, 479.7308, 480.0634, 479.6349, 480.0499, 479.5067,\n",
            "        480.1272, 479.9232, 479.9841, 479.7965, 480.0253, 479.9742, 479.8856,\n",
            "        479.6793, 479.6278, 480.0912, 479.8121, 479.7447, 479.7908, 480.3039,\n",
            "        480.0548, 480.0805, 479.9079, 479.8755, 479.9079, 479.7898, 479.8751,\n",
            "        480.2029, 479.8269, 480.0293, 479.5680, 479.9384, 479.9311, 479.8292,\n",
            "        480.2791, 479.7821, 480.3116, 480.4914, 480.1028, 479.3385, 480.0942,\n",
            "        479.7928, 479.7322, 480.1477, 479.8121, 480.1266, 479.9738, 480.3042,\n",
            "        479.9112, 480.0291, 479.9544, 480.0459, 479.8731, 480.1987, 480.0522,\n",
            "        479.9505], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0078, 0.0137, 0.0094, 0.0035, 0.0055, 0.0115, 0.0047, 0.0050, 0.0143,\n",
            "        0.0088, 0.0117, 0.0088, 0.0102, 0.0184, 0.0092, 0.0156, 0.0024, 0.0194,\n",
            "        0.0076, 0.0068, 0.0083, 0.0063, 0.0099, 0.0067, 0.0225, 0.0084, 0.0009,\n",
            "        0.0153, 0.0066, 0.0057, 0.0015, 0.0076, 0.0046, 0.0029, 0.0152, 0.0078,\n",
            "        0.0047, 0.0061, 0.0114, 0.0049, 0.0201, 0.0086, 0.0069, 0.0039, 0.0029,\n",
            "        0.0063, 0.0032, 0.0067, 0.0022, 0.0083, 0.0110, 0.0036, 0.0132, 0.0061,\n",
            "        0.0059, 0.0105, 0.0039, 0.0022, 0.0068, 0.0078, 0.0080, 0.0108, 0.0115,\n",
            "        0.0047, 0.0115, 0.0021, 0.0154, 0.0173, 0.0137, 0.0085, 0.0130, 0.0058,\n",
            "        0.0027, 0.0105, 0.0282, 0.0074, 0.0087, 0.0149, 0.0207, 0.0087, 0.0042,\n",
            "        0.0279, 0.0094, 0.0044, 0.0032, 0.0075, 0.0021, 0.0062, 0.0064, 0.0071,\n",
            "        0.0060, 0.0052, 0.0146, 0.0161, 0.0049, 0.0101, 0.0133, 0.0101, 0.0056,\n",
            "        0.0214, 0.0161, 0.0218, 0.0072, 0.0339, 0.0127, 0.0070],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [96]\n",
            "DEBUGGING: logits looks like: tensor([480.0908, 480.3731, 480.1848, 479.6851, 479.9124, 480.2859, 479.8377,\n",
            "        479.8632, 480.3939, 480.1503, 480.2914, 480.1513, 480.2222, 480.5194,\n",
            "        480.1746, 480.4353, 479.5049, 480.5446, 480.0754, 480.0214, 480.1219,\n",
            "        479.9819, 480.2099, 480.0163, 480.6192, 480.1255, 479.0143, 480.4261,\n",
            "        480.0069, 479.9349, 479.2700, 480.0764, 479.8275, 479.5915, 480.4237,\n",
            "        480.0908, 479.8395, 479.9681, 480.2799, 479.8582, 480.5640, 480.1394,\n",
            "        480.0282, 479.7388, 479.5919, 479.9814, 479.6522, 480.0155, 479.4460,\n",
            "        480.1222, 480.2615, 479.7023, 480.3543, 479.9669, 479.9481, 480.2365,\n",
            "        479.7425, 479.4479, 480.0191, 480.0884, 480.0997, 480.2521, 480.2847,\n",
            "        479.8323, 480.2847, 479.4309, 480.4296, 480.4871, 480.3716, 480.1310,\n",
            "        480.3443, 479.9460, 479.5543, 480.2374, 480.7334, 480.0611, 480.1465,\n",
            "        480.4130, 480.5774, 480.1465, 479.7817, 480.7279, 480.1848, 479.8020,\n",
            "        479.6452, 480.0708, 479.4399, 479.9774, 479.9903, 480.0450, 479.9580,\n",
            "        479.8921, 480.4023, 480.4532, 479.8569, 480.2184, 480.3565, 480.2193,\n",
            "        479.9214, 480.5950, 480.4531, 480.6037, 480.0523, 480.8246, 480.3339,\n",
            "        480.0387], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.7082653196334832 and immediate abs rewards look like: [0.03063765095475901, 0.0013805546900584886, 0.005591373069364636, 0.6706557409065681, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.094947017729282e-13, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0]\n",
            "DEBUGGING: the total relative reward of the trajectory = 7.444049672772948 and immediate relative rewards look like: [0.08261989991023588, 0.007507854597796232, 0.04562837776690295, 7.308293539302028, 0.0, 9.094947017732039e-12, 1.0610771520685771e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.244308608273665e-11, 4.5474735088660196e-11, 2.4253192047278084e-11, 2.5769016550229062e-11, 0.0, 2.8800665556142725e-11, 3.0316490059093015e-11, 0.0, 0.0, 0.0, 0.0, 3.789561257387201e-11, 0.0, 4.0927261579787975e-11, 4.244308608273665e-11, 4.395891058568487e-11, 0.0, 4.699055959160129e-11, 4.850638409456353e-11, 5.0022208597511047e-11, 5.1538033100458125e-11, 5.305385760342081e-11, 1.0913936421276795e-10, 5.6085506609322075e-11, 0.0, 0.0, 6.063298011819521e-11, 6.214880462115953e-11, 0.0, 0.0, 6.669627813001473e-11, 6.821210263295928e-11, 6.972792713592449e-11, 7.124375163886858e-11, 0.0, 0.0, 0.0]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 3\n",
            "DEBUGGING: the action_prob is: tensor([0.0131, 0.0171, 0.0072, 0.0071, 0.0338, 0.0121, 0.0168, 0.0128, 0.0233,\n",
            "        0.0074, 0.0254, 0.0342, 0.0076, 0.0012, 0.0235, 0.0206, 0.0150, 0.0200,\n",
            "        0.0202, 0.0024, 0.0220, 0.0077, 0.0298, 0.0028, 0.0191, 0.0136, 0.0088,\n",
            "        0.0125, 0.0156, 0.0061, 0.0065, 0.0169, 0.0136, 0.0074, 0.0087, 0.0211,\n",
            "        0.0079, 0.0439, 0.0150, 0.0179, 0.0180, 0.0262, 0.0183, 0.0233, 0.0094,\n",
            "        0.0077, 0.0070, 0.0099, 0.0202, 0.0167, 0.0207, 0.0295, 0.0117, 0.0340,\n",
            "        0.0306, 0.0053, 0.0085, 0.0040, 0.0220, 0.0129, 0.0176, 0.0129, 0.0160],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [17]\n",
            "DEBUGGING: logits looks like: tensor([479.6864, 479.8200, 479.3868, 479.3791, 480.1606, 479.6487, 479.8117,\n",
            "        479.6747, 479.9744, 479.4028, 480.0184, 480.1663, 479.4145, 478.5006,\n",
            "        479.9792, 479.9121, 479.7529, 479.8986, 479.9037, 478.8324, 479.9459,\n",
            "        479.4196, 480.0982, 478.9150, 479.8765, 479.7048, 479.4872, 479.6617,\n",
            "        479.7729, 479.3030, 479.3399, 479.8147, 479.7036, 479.4038, 479.4825,\n",
            "        479.9244, 479.4327, 480.2916, 479.7527, 479.8418, 479.8457, 480.0335,\n",
            "        479.8549, 479.9737, 479.5189, 479.4178, 479.3761, 479.5457, 479.9029,\n",
            "        479.8077, 479.9164, 480.0929, 479.6294, 480.1633, 480.1110, 479.2338,\n",
            "        479.4689, 479.0941, 479.9459, 479.6784, 479.8345, 479.6780, 479.7874],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0359, 0.0241, 0.0099, 0.0162, 0.0131, 0.0033, 0.0041, 0.0046, 0.0057,\n",
            "        0.0056, 0.0451, 0.0246, 0.0178, 0.0012, 0.0002, 0.0130, 0.0054, 0.0046,\n",
            "        0.0060, 0.0085, 0.0121, 0.0199, 0.0182, 0.0065, 0.0320, 0.0014, 0.0179,\n",
            "        0.0164, 0.0015, 0.0122, 0.0143, 0.0122, 0.0024, 0.0135, 0.0162, 0.0081,\n",
            "        0.0128, 0.0061, 0.0118, 0.0049, 0.0066, 0.0250, 0.0117, 0.0171, 0.0143,\n",
            "        0.0182, 0.0054, 0.0102, 0.0116, 0.0092, 0.0025, 0.0076, 0.0251, 0.0104,\n",
            "        0.0050, 0.0062, 0.0106, 0.0236, 0.0011, 0.0066, 0.0087, 0.0132, 0.0071,\n",
            "        0.0413, 0.0088, 0.0048, 0.0047, 0.0107, 0.0291, 0.0121, 0.0201, 0.0090,\n",
            "        0.0140, 0.0160, 0.0113, 0.0458, 0.0259], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [36]\n",
            "DEBUGGING: logits looks like: tensor([481.1971, 480.9963, 480.5542, 480.7995, 480.6928, 480.0058, 480.1161,\n",
            "        480.1716, 480.2769, 480.2650, 481.3112, 481.0072, 480.8460, 479.4839,\n",
            "        478.6929, 480.6885, 480.2528, 480.1685, 480.3041, 480.4755, 480.6540,\n",
            "        480.9023, 480.8568, 480.3406, 481.1389, 479.5786, 480.8489, 480.8034,\n",
            "        479.6096, 480.6571, 480.7365, 480.6589, 479.8340, 480.7060, 480.7982,\n",
            "        480.4514, 480.6800, 480.3074, 480.6410, 480.1992, 480.3532, 481.0159,\n",
            "        480.6366, 480.8264, 480.7359, 480.8557, 480.2528, 480.5667, 480.6308,\n",
            "        480.5185, 479.8618, 480.4197, 481.0171, 480.5792, 480.2085, 480.3199,\n",
            "        480.5854, 480.9864, 479.4584, 480.3520, 480.4883, 480.6959, 480.3872,\n",
            "        481.2665, 480.4962, 480.1872, 480.1837, 480.5914, 481.0917, 480.6528,\n",
            "        480.9059, 480.5044, 480.7263, 480.7915, 480.6167, 481.3187, 481.0339],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0059, 0.0096, 0.0257, 0.0148, 0.0147, 0.0137, 0.0107, 0.0050, 0.0254,\n",
            "        0.0129, 0.0075, 0.0091, 0.0064, 0.0192, 0.0245, 0.0061, 0.0073, 0.0197,\n",
            "        0.0086, 0.0051, 0.0075, 0.0034, 0.0117, 0.0060, 0.0041, 0.0067, 0.0173,\n",
            "        0.0019, 0.0106, 0.0085, 0.0041, 0.0126, 0.0109, 0.0086, 0.0048, 0.0178,\n",
            "        0.0188, 0.0045, 0.0184, 0.0069, 0.0031, 0.0081, 0.0312, 0.0051, 0.0029,\n",
            "        0.0128, 0.0246, 0.0065, 0.0109, 0.0075, 0.0104, 0.0207, 0.0190, 0.0002,\n",
            "        0.0066, 0.0080, 0.0068, 0.0035, 0.0181, 0.0123, 0.0085, 0.0059, 0.0020,\n",
            "        0.0077, 0.0038, 0.0192, 0.0087, 0.0101, 0.0123, 0.0090, 0.0123, 0.0106,\n",
            "        0.0715, 0.0095, 0.0051, 0.0596, 0.0043, 0.0060, 0.0051, 0.0033, 0.0049,\n",
            "        0.0069, 0.0079, 0.0066, 0.0104, 0.0195, 0.0140],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [4]\n",
            "DEBUGGING: logits looks like: tensor([479.9705, 480.2126, 480.7047, 480.4281, 480.4276, 480.3906, 480.2665,\n",
            "        479.8882, 480.6996, 480.3604, 480.0870, 480.1843, 480.0070, 480.5600,\n",
            "        480.6808, 479.9901, 480.0732, 480.5722, 480.1558, 479.8934, 480.0864,\n",
            "        479.6904, 480.3102, 479.9789, 479.7861, 480.0344, 480.5069, 479.3958,\n",
            "        480.2623, 480.1498, 479.7915, 480.3501, 480.2761, 480.1602, 479.8649,\n",
            "        480.5215, 480.5485, 479.8322, 480.5380, 480.0471, 479.6495, 480.1257,\n",
            "        480.8018, 479.9001, 479.6198, 480.3575, 480.6831, 480.0172, 480.2781,\n",
            "        480.0881, 480.2522, 480.5972, 480.5532, 478.3139, 480.0276, 480.1229,\n",
            "        480.0411, 479.7079, 480.5296, 480.3385, 480.1533, 479.9670, 479.4363,\n",
            "        480.1031, 479.7482, 480.5594, 480.1613, 480.2395, 480.3366, 480.1813,\n",
            "        480.3374, 480.2632, 481.2168, 480.2075, 479.8918, 481.1261, 479.8129,\n",
            "        479.9792, 479.8919, 479.6857, 479.8816, 480.0494, 480.1183, 480.0289,\n",
            "        480.2539, 480.5668, 480.4004], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0129, 0.0218, 0.0150, 0.0056, 0.0098, 0.0030, 0.0093, 0.0084, 0.0039,\n",
            "        0.0042, 0.0047, 0.0059, 0.0010, 0.0066, 0.0040, 0.0100, 0.0083, 0.0054,\n",
            "        0.0006, 0.0154, 0.0071, 0.0041, 0.0086, 0.0047, 0.0074, 0.0124, 0.0045,\n",
            "        0.0069, 0.0163, 0.0136, 0.0059, 0.0419, 0.0065, 0.0190, 0.0079, 0.0018,\n",
            "        0.0126, 0.0057, 0.0035, 0.0062, 0.0068, 0.0134, 0.0056, 0.0018, 0.0022,\n",
            "        0.0043, 0.0137, 0.0083, 0.0041, 0.0167, 0.0105, 0.0198, 0.0023, 0.0102,\n",
            "        0.0058, 0.0053, 0.0067, 0.0049, 0.0069, 0.0019, 0.0075, 0.0183, 0.0229,\n",
            "        0.0307, 0.0085, 0.0006, 0.0107, 0.0354, 0.0050, 0.0025, 0.0235, 0.0086,\n",
            "        0.0222, 0.0130, 0.0021, 0.0087, 0.0071, 0.0031, 0.0251, 0.0014, 0.0058,\n",
            "        0.0029, 0.0079, 0.0148, 0.0090, 0.0394, 0.0006, 0.0089, 0.0119, 0.0213,\n",
            "        0.0122, 0.0032, 0.0430, 0.0131, 0.0152, 0.0087, 0.0028, 0.0099, 0.0089],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [80]\n",
            "DEBUGGING: logits looks like: tensor([480.6263, 480.8906, 480.7047, 480.2082, 480.4918, 479.9033, 480.4637,\n",
            "        480.4149, 480.0354, 480.0722, 480.1205, 480.2399, 479.3352, 480.2953,\n",
            "        480.0390, 480.5002, 480.4089, 480.1905, 479.0780, 480.7158, 480.3269,\n",
            "        480.0581, 480.4263, 480.1194, 480.3502, 480.6083, 480.1024, 480.3173,\n",
            "        480.7435, 480.6530, 480.2329, 481.2169, 480.2848, 480.8221, 480.3828,\n",
            "        479.6557, 480.6159, 480.2184, 479.9779, 480.2622, 480.3100, 480.6456,\n",
            "        480.2091, 479.6430, 479.7333, 480.0764, 480.6598, 480.4089, 480.0569,\n",
            "        480.7559, 480.5243, 480.8420, 479.7745, 480.5119, 480.2302, 480.1791,\n",
            "        480.3016, 480.1476, 480.3118, 479.6623, 480.3597, 480.8022, 480.9149,\n",
            "        481.0610, 480.4167, 479.1029, 480.5360, 481.1329, 480.1491, 479.8024,\n",
            "        480.9278, 480.4243, 480.9002, 480.6323, 479.7261, 480.4327, 480.3273,\n",
            "        479.9074, 480.9602, 479.5267, 480.2274, 479.8879, 480.3815, 480.6950,\n",
            "        480.4474, 481.1857, 479.0927, 480.4449, 480.5885, 480.8792, 480.6012,\n",
            "        479.9292, 481.2303, 480.6344, 480.7096, 480.4328, 479.8566, 480.4956,\n",
            "        480.4416], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0101, 0.0091, 0.0089, 0.0086, 0.0098, 0.0082, 0.0100, 0.0058, 0.0031,\n",
            "        0.0088, 0.0104, 0.0087, 0.0078, 0.0100, 0.0096, 0.0090, 0.0070, 0.0051,\n",
            "        0.0122, 0.0109, 0.0094, 0.0080, 0.0090, 0.0095, 0.0073, 0.0104, 0.0100,\n",
            "        0.0095, 0.0094, 0.0110, 0.0119, 0.0100, 0.0096, 0.0077, 0.0068, 0.0080,\n",
            "        0.0124, 0.0064, 0.0098, 0.0081, 0.0082, 0.0112, 0.0152, 0.0106, 0.0086,\n",
            "        0.0085, 0.0073, 0.0085, 0.0112, 0.0119, 0.0095, 0.0128, 0.0103, 0.0087,\n",
            "        0.0072, 0.0062, 0.0099, 0.0068, 0.0126, 0.0109, 0.0092, 0.0102, 0.0080,\n",
            "        0.0073, 0.0077, 0.0085, 0.0091, 0.0083, 0.0085, 0.0079, 0.0090, 0.0177,\n",
            "        0.0078, 0.0150, 0.0087, 0.0084, 0.0099, 0.0091, 0.0094, 0.0063, 0.0134,\n",
            "        0.0091, 0.0120, 0.0090, 0.0087, 0.0100, 0.0087, 0.0103, 0.0085, 0.0108,\n",
            "        0.0097, 0.0095, 0.0100, 0.0098, 0.0099, 0.0071, 0.0095, 0.0078, 0.0081,\n",
            "        0.0086, 0.0122, 0.0086, 0.0097, 0.0127, 0.0132, 0.0057, 0.0080],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [95]\n",
            "DEBUGGING: logits looks like: tensor([480.8789, 480.8281, 480.8164, 480.7981, 480.8618, 480.7756, 480.8717,\n",
            "        480.6018, 480.2814, 480.8103, 480.8921, 480.8011, 480.7499, 480.8746,\n",
            "        480.8504, 480.8219, 480.6967, 480.5375, 480.9733, 480.9144, 480.8423,\n",
            "        480.7617, 480.8210, 480.8494, 480.7181, 480.8921, 480.8717, 480.8459,\n",
            "        480.8402, 480.9223, 480.9615, 480.8730, 480.8528, 480.7402, 480.6770,\n",
            "        480.7609, 480.9786, 480.6525, 480.8609, 480.7666, 480.7715, 480.9275,\n",
            "        481.0832, 480.9042, 480.7992, 480.7934, 480.7159, 480.7920, 480.9308,\n",
            "        480.9607, 480.8498, 480.9957, 480.8892, 480.8061, 480.7097, 480.6317,\n",
            "        480.8676, 480.6792, 480.9901, 480.9179, 480.8329, 480.8820, 480.7595,\n",
            "        480.7174, 480.7402, 480.7891, 480.8264, 480.7823, 480.7907, 480.7549,\n",
            "        480.8228, 481.1595, 480.7490, 481.0748, 480.8035, 480.7866, 480.8682,\n",
            "        480.8278, 480.8414, 480.6456, 481.0208, 480.8233, 480.9650, 480.8201,\n",
            "        480.8028, 480.8707, 480.8037, 480.8874, 480.7914, 480.9120, 480.8558,\n",
            "        480.8499, 480.8724, 480.8614, 480.8666, 480.6991, 480.8475, 480.7520,\n",
            "        480.7670, 480.7964, 480.9732, 480.7967, 480.8556, 480.9908, 481.0109,\n",
            "        480.5900, 480.7620], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.7058461509350309 and immediate abs rewards look like: [0.0028750212532031583, 0.0007551344438070373, 0.7022159952243783, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13, 9.094947017729282e-13, 4.547473508864641e-13, 1.3642420526593924e-12, 9.094947017729282e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13, 9.094947017729282e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "DEBUGGING: the total relative reward of the trajectory = 7.812214126935732 and immediate relative rewards look like: [0.010625220699351894, 0.005587439950938263, 7.796001464709742, 0.0, 0.0, 1.3642420526593924e-11, 1.5916157281029863e-11, 1.8189894035458565e-11, 2.0463630789886232e-11, 4.547473508864641e-11, 5.00222085975338e-11, 2.7284841053187847e-11, 8.867573342284034e-11, 6.366462912413393e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2295945351943374e-11, 5.4569682106363287e-11, 5.6843418860808015e-11, 5.911715561525378e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.503331289626658e-11, 1.5461409930136265e-10, 7.958078640514932e-11, 8.185452315956354e-11, 1.6825651982795347e-10, 1.7280399333689566e-10, 8.867573342284034e-11, 0.0, 9.322320693172514e-11, 9.549694368617918e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 200 number of matrices\n",
            "DEBUGGING: ACT_MAT has 200 number of matrices\n",
            "DEBUGGING: VAL looks like: [[1.629901573782177, 1.6424882795946, 1.5709061741433292, 1.5834822203494032, 1.4998689995980845, 1.3563108423485768, 1.2715420482259157, 1.2317796506232055, 1.1219207354142686, 1.1323844651109245, 1.1386289847621685, 1.1118851717379268, 1.121098869314744, 1.1300011618990247, 1.1400275588575874, 0.9515102968193975, 0.925018893572403, 0.8723612582361927, 0.7916368962684848, 0.6590252077550615, 0.5437597582757647, 0.4466370326215549, 0.444983752429738, 0.36700689781326024, 0.35692366365535155, 0.3517166222184548, 0.35125667871585947, 0.3259531120540759, 0.272735061843705, 0.2689105613926937, 0.2667411614428194, 0.26349296495693053, 0.24504922940991922, 0.22432609122960362, 0.22297700426725622, 0.22274927684531015, 0.2186482373528692, 0.21619225595155575, 0.2180845029323266, 0.21066487504977818, 0.19240180621705932, 0.19045517901044803, 0.18497761595951115, 0.1818110864602746, 0.17992181067726198, 0.18127772528036912, 0.1803233030250414, 0.18085697914467275, 0.17459125525847236, 0.13373138975764995], [2.608596764032225, 1.5063000614425928e-09, 1.5123283984089468e-09, 1.5207143314602508e-09, 1.5268882671136581e-09, 1.530827861961105e-09, 1.5462907696576818e-09, 1.5458329417946015e-09, 1.5614474159541429e-09, 1.556549277943684e-09, 1.5722719979229133e-09, 1.588153533255468e-09, 1.5766350426285658e-09, 1.5925606491197635e-09, 1.5764932672300038e-09, 1.5924174416464686e-09, 1.6085024663095643e-09, 1.585706001499207e-09, 1.51904189731279e-09, 1.4907483828066326e-09, 1.5058064472794268e-09, 1.5210166134135624e-09, 1.536380417589457e-09, 1.5518994117065222e-09, 1.5124542723233804e-09, 1.4128963985876148e-09, 1.3077394821789505e-09, 1.258937969504307e-09, 1.2073468084648504e-09, 1.1529378207942404e-09, 1.1645836573679197e-09, 1.1763471286544644e-09, 1.1147349015279091e-09, 1.0502036248804642e-09, 9.827238133633992e-10, 9.926503165286862e-10, 9.199957508779203e-10, 9.292886372504246e-10, 9.38675391162045e-10, 8.585855128678633e-10, 7.753899421116665e-10, 5.948924527759759e-10, 4.079783488926746e-10, 4.120993423158329e-10, 3.152069950715261e-10, 3.183909041126526e-10, 1.103102249544714e-10, 1.114244696509812e-10, 1.1254996934442546e-10, 1.1368683772164188e-10], [7.226002962772677, 7.2155384473358, 7.28083898256364, 7.308293540198725, 9.057546131623245e-10, 9.149036496589136e-10, 9.14958285496143e-10, 9.134823373489466e-10, 9.227094316656027e-10, 9.320297289551542e-10, 9.41444170661772e-10, 9.509537077391637e-10, 9.6055930074663e-10, 9.70261919946091e-10, 9.371907412761155e-10, 9.007232385731872e-10, 8.853232793191001e-10, 8.682366290594657e-10, 8.770066960196624e-10, 8.567737681449694e-10, 8.348053313998752e-10, 8.432377084847224e-10, 8.517552610956791e-10, 8.603588495915951e-10, 8.690493430218133e-10, 8.395492226746882e-10, 8.480295178532204e-10, 8.152548043165984e-10, 7.80617897205921e-10, 7.440999864850871e-10, 7.516161479647345e-10, 7.117430185587204e-10, 6.699359944082392e-10, 6.261755412229578e-10, 5.804419273964643e-10, 5.327152220131751e-10, 4.278544018185931e-10, 3.7552413657502124e-10, 3.7931730967173865e-10, 3.831487976482209e-10, 3.2577355306063196e-10, 2.662876246863358e-10, 2.6897739867306647e-10, 2.7169434209400655e-10, 2.070687514787796e-10, 1.4025924125840438e-10, 7.124375163886858e-11, 0.0, 0.0, 0.0], [7.657017823000092, 7.7236288912128686, 7.796001465921142, 1.223636311299683e-09, 1.235996274040084e-09, 1.2484810848889737e-09, 1.247311782184222e-09, 1.243833964548679e-09, 1.2380243136497175e-09, 1.2298592756159914e-09, 1.1963480207346919e-09, 1.157904860744604e-09, 1.1420404239307235e-09, 1.0640047378867507e-09, 1.0104445543056735e-09, 1.0206510649552258e-09, 1.0309606716719452e-09, 1.0413744158302478e-09, 1.0518933493234827e-09, 1.0625185346701846e-09, 1.0732510451213987e-09, 1.0840919647690895e-09, 1.095042388655646e-09, 1.0532792356603057e-09, 1.0087975288423661e-09, 9.6156980806218e-10, 9.11568335804976e-10, 9.20776096772703e-10, 9.300768654269728e-10, 9.394715812393664e-10, 9.489611931710772e-10, 9.58546659768765e-10, 9.682289492613787e-10, 9.022178145102142e-10, 7.551552678877288e-10, 6.823984661440197e-10, 6.066100434186426e-10, 4.4278133696029196e-10, 2.727043874983801e-10, 1.858875293692321e-10, 1.8776518118104253e-10, 9.549694368617918e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]\n",
            "DEBUGGING: traj_returns = [1.629901573782177, 2.608596764032225, 7.226002962772677, 7.657017823000092]\n",
            "DEBUGGING: actions = [[21], [13], [13], [61], [32], [30], [31], [65], [46], [11], [57], [52], [1], [16], [18], [54], [68], [65], [1], [1], [54], [35], [66], [28], [23], [6], [67], [17], [60], [6], [61], [28], [33], [93], [6], [58], [50], [21], [4], [65], [42], [11], [52], [69], [74], [65], [54], [6], [13], [2], [0], [13], [2], [4], [8], [38], [60], [65], [9], [46], [31], [30], [57], [17], [0], [24], [70], [70], [4], [11], [12], [79], [50], [27], [77], [32], [27], [3], [19], [81], [87], [2], [24], [77], [26], [71], [42], [77], [23], [87], [61], [29], [38], [4], [94], [25], [70], [97], [73], [105], [12], [11], [4], [0], [26], [25], [16], [29], [66], [35], [17], [49], [33], [56], [9], [20], [35], [54], [44], [30], [30], [8], [73], [40], [12], [16], [77], [5], [83], [84], [52], [28], [19], [9], [65], [31], [29], [21], [22], [54], [27], [52], [95], [44], [6], [97], [32], [61], [48], [96], [57], [8], [0], [7], [13], [61], [59], [12], [26], [17], [43], [2], [59], [13], [4], [38], [16], [25], [72], [36], [17], [6], [28], [73], [2], [60], [38], [46], [55], [4], [17], [27], [75], [33], [24], [12], [8], [66], [64], [80], [74], [13], [82], [45], [12], [52], [11], [40], [22], [95]]\n",
            "DEBUGGING: actions length = 200\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[ 7.5716,  6.8606,  6.4517,  ..., -5.6773, -6.0757, -8.9885],\n",
            "        [ 7.5688,  6.8634,  6.4420,  ..., -5.6632, -6.0678, -8.9779],\n",
            "        [ 7.7456,  7.0213,  6.6100,  ..., -5.8287, -6.2475, -9.2092],\n",
            "        ...,\n",
            "        [ 7.6014,  6.8895,  6.4725,  ..., -5.6960, -6.0970, -9.0204],\n",
            "        [ 7.6034,  6.8921,  6.4742,  ..., -5.6981, -6.0992, -9.0235],\n",
            "        [ 7.6041,  6.8926,  6.4746,  ..., -5.6985, -6.0998, -9.0241]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[ 7.6046,  6.8930,  6.4754,  ..., -5.6992, -6.1004, -9.0249],\n",
            "        [ 7.6038,  6.8925,  6.4746,  ..., -5.6984, -6.0995, -9.0239],\n",
            "        [ 7.6036,  6.8924,  6.4743,  ..., -5.6983, -6.0995, -9.0238],\n",
            "        ...,\n",
            "        [ 7.6065,  6.8949,  6.4772,  ..., -5.7009, -6.1022, -9.0273],\n",
            "        [ 7.6002,  6.8893,  6.4713,  ..., -5.6954, -6.0964, -9.0195],\n",
            "        [ 7.6029,  6.8917,  6.4737,  ..., -5.6976, -6.0986, -9.0226]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([480.8789, 480.8281, 480.8164, 480.7981, 480.8618, 480.7756, 480.8717,\n",
            "        480.6018, 480.2814, 480.8103, 480.8921, 480.8011, 480.7499, 480.8746,\n",
            "        480.8504, 480.8219, 480.6967, 480.5375, 480.9733, 480.9144, 480.8423,\n",
            "        480.7617, 480.8210, 480.8494, 480.7181, 480.8921, 480.8717, 480.8459,\n",
            "        480.8402, 480.9223, 480.9615, 480.8730, 480.8528, 480.7402, 480.6770,\n",
            "        480.7609, 480.9786, 480.6525, 480.8609, 480.7666, 480.7715, 480.9275,\n",
            "        481.0832, 480.9042, 480.7992, 480.7934, 480.7159, 480.7920, 480.9308,\n",
            "        480.9607, 480.8498, 480.9957, 480.8892, 480.8061, 480.7097, 480.6317,\n",
            "        480.8676, 480.6792, 480.9901, 480.9179, 480.8329, 480.8820, 480.7595,\n",
            "        480.7174, 480.7402, 480.7891, 480.8264, 480.7823, 480.7907, 480.7549,\n",
            "        480.8228, 481.1595, 480.7490, 481.0748, 480.8035, 480.7866, 480.8682,\n",
            "        480.8278, 480.8414, 480.6456, 481.0208, 480.8233, 480.9650, 480.8201,\n",
            "        480.8028, 480.8707, 480.8037, 480.8874, 480.7914, 480.9120, 480.8558,\n",
            "        480.8499, 480.8724, 480.8614, 480.8666, 480.6991, 480.8475, 480.7520,\n",
            "        480.7670, 480.7964, 480.9732, 480.7967, 480.8556, 480.9908, 481.0109,\n",
            "        480.5900, 480.7620], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[4.78037978 4.1454139  4.16193666 2.22294394 0.37496725 0.33907771\n",
            "  0.31788551 0.30794491 0.28048018 0.28309612 0.28465725 0.27797129\n",
            "  0.28027472 0.28250029 0.28500689 0.23787758 0.23125472 0.21809032\n",
            "  0.19790922 0.1647563  0.13593994 0.11165926 0.11124594 0.09175173\n",
            "  0.08923092 0.08792916 0.08781417 0.08148828 0.06818377 0.06722764\n",
            "  0.06668529 0.06587324 0.06126231 0.05608152 0.05574425 0.05568732\n",
            "  0.05466206 0.05404806 0.05452113 0.05266622 0.04810045 0.04761379\n",
            "  0.0462444  0.04545277 0.04498045 0.04531943 0.04508083 0.04521424\n",
            "  0.04364781 0.03343285]]\n",
            "DEBUGGING: baseline2 looks like: 4.7803797808967925\n",
            "DEBUGGING: ADS looks like: [-3.15047821 -2.50292563 -2.59103048 -0.63946172  1.12490175  1.01723313\n",
            "  0.95365654  0.92383474  0.84144055  0.84928835  0.85397174  0.83391388\n",
            "  0.84082415  0.84750087  0.85502067  0.71363272  0.69376417  0.65427094\n",
            "  0.59372767  0.4942689   0.40781982  0.33497777  0.33373781  0.27525517\n",
            "  0.26769275  0.26378747  0.26344251  0.24446483  0.2045513   0.20168292\n",
            "  0.20005587  0.19761972  0.18378692  0.16824457  0.16723275  0.16706196\n",
            "  0.16398618  0.16214419  0.16356338  0.15799866  0.14430135  0.14284138\n",
            "  0.13873321  0.13635831  0.13494136  0.13595829  0.13524248  0.13564273\n",
            "  0.13094344  0.10029854 -2.17178302 -4.1454139  -4.16193665 -2.22294394\n",
            " -0.37496725 -0.33907771 -0.31788551 -0.30794491 -0.28048018 -0.28309612\n",
            " -0.28465725 -0.27797129 -0.28027472 -0.28250029 -0.28500689 -0.23787757\n",
            " -0.23125472 -0.21809031 -0.19790922 -0.1647563  -0.13593994 -0.11165926\n",
            " -0.11124594 -0.09175172 -0.08923092 -0.08792915 -0.08781417 -0.08148828\n",
            " -0.06818376 -0.06722764 -0.06668529 -0.06587324 -0.06126231 -0.05608152\n",
            " -0.05574425 -0.05568732 -0.05466206 -0.05404806 -0.05452113 -0.05266622\n",
            " -0.04810045 -0.04761379 -0.0462444  -0.04545277 -0.04498045 -0.04531943\n",
            " -0.04508083 -0.04521424 -0.04364781 -0.03343285  2.44562318  3.07012454\n",
            "  3.11890233  5.0853496  -0.37496725 -0.33907771 -0.31788551 -0.30794491\n",
            " -0.28048018 -0.28309612 -0.28465725 -0.27797129 -0.28027472 -0.28250029\n",
            " -0.28500689 -0.23787757 -0.23125472 -0.21809031 -0.19790922 -0.1647563\n",
            " -0.13593994 -0.11165926 -0.11124594 -0.09175172 -0.08923092 -0.08792916\n",
            " -0.08781417 -0.08148828 -0.06818377 -0.06722764 -0.06668529 -0.06587324\n",
            " -0.06126231 -0.05608152 -0.05574425 -0.05568732 -0.05466206 -0.05404806\n",
            " -0.05452113 -0.05266622 -0.04810045 -0.04761379 -0.0462444  -0.04545277\n",
            " -0.04498045 -0.04531943 -0.04508083 -0.04521424 -0.04364781 -0.03343285\n",
            "  2.87663804  3.57821499  3.63406481 -2.22294394 -0.37496725 -0.33907771\n",
            " -0.31788551 -0.30794491 -0.28048018 -0.28309612 -0.28465725 -0.27797129\n",
            " -0.28027472 -0.28250029 -0.28500689 -0.23787757 -0.23125472 -0.21809031\n",
            " -0.19790922 -0.1647563  -0.13593994 -0.11165926 -0.11124594 -0.09175172\n",
            " -0.08923092 -0.08792916 -0.08781417 -0.08148828 -0.06818377 -0.06722764\n",
            " -0.06668529 -0.06587324 -0.06126231 -0.05608152 -0.05574425 -0.05568732\n",
            " -0.05466206 -0.05404806 -0.05452113 -0.05266622 -0.04810045 -0.04761379\n",
            " -0.0462444  -0.04545277 -0.04498045 -0.04531943 -0.04508083 -0.04521424\n",
            " -0.04364781 -0.03343285]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(0.1811, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.0509, -0.1165, -0.0590,  ...,  0.0268,  0.0200, -0.1092],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0665, -0.1523, -0.0772,  ...,  0.0350,  0.0261, -0.1435],\n",
            "        [ 0.0449, -0.1028, -0.0521,  ...,  0.0236,  0.0176, -0.0969]])\n",
            "   Last layer:\n",
            "tensor([[-0.0384, -0.0150,  0.0000, -0.0440,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0446,\n",
            "          0.0000, -0.0505, -0.0688, -0.0131],\n",
            "        [-0.0350, -0.0137,  0.0000, -0.0401,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0409,\n",
            "          0.0000, -0.0463, -0.0627, -0.0120],\n",
            "        [-0.0347, -0.0137,  0.0000, -0.0398,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0409,\n",
            "          0.0000, -0.0462, -0.0622, -0.0119],\n",
            "        [ 0.0086,  0.0032,  0.0000,  0.0098,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0095,\n",
            "          0.0000,  0.0109,  0.0154,  0.0029],\n",
            "        [ 0.0072,  0.0028,  0.0000,  0.0083,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0083,\n",
            "          0.0000,  0.0094,  0.0129,  0.0025],\n",
            "        [-0.0323, -0.0128,  0.0000, -0.0370,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0381,\n",
            "          0.0000, -0.0430, -0.0578, -0.0110],\n",
            "        [ 0.0636,  0.0252,  0.0000,  0.0729,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0750,\n",
            "          0.0000,  0.0847,  0.1139,  0.0218],\n",
            "        [ 0.0309,  0.0123,  0.0000,  0.0354,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0366,\n",
            "          0.0000,  0.0413,  0.0553,  0.0106],\n",
            "        [ 0.0331,  0.0132,  0.0000,  0.0380,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0393,\n",
            "          0.0000,  0.0443,  0.0593,  0.0113],\n",
            "        [ 0.0473,  0.0187,  0.0000,  0.0543,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0556,\n",
            "          0.0000,  0.0628,  0.0847,  0.0162]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-0.0063, -0.0092, -0.0065,  ...,  0.0192,  0.0161,  0.0562],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0083, -0.0121, -0.0087,  ...,  0.0253,  0.0213,  0.0743],\n",
            "        [-0.0053, -0.0077, -0.0055,  ...,  0.0161,  0.0136,  0.0467]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0173,  0.0105,  0.0000,  0.0232,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0254,\n",
            "          0.0000,  0.0249,  0.0291,  0.0052],\n",
            "        [ 0.0163,  0.0098,  0.0000,  0.0218,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0240,\n",
            "          0.0000,  0.0235,  0.0275,  0.0049],\n",
            "        [ 0.0151,  0.0092,  0.0000,  0.0202,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0222,\n",
            "          0.0000,  0.0218,  0.0255,  0.0045],\n",
            "        [-0.0058, -0.0034,  0.0000, -0.0077,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0085,\n",
            "          0.0000, -0.0085, -0.0099, -0.0018],\n",
            "        [-0.0036, -0.0022,  0.0000, -0.0049,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0054,\n",
            "          0.0000, -0.0052, -0.0061, -0.0011],\n",
            "        [ 0.0146,  0.0087,  0.0000,  0.0194,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0214,\n",
            "          0.0000,  0.0210,  0.0246,  0.0044],\n",
            "        [-0.0283, -0.0171,  0.0000, -0.0378,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0416,\n",
            "          0.0000, -0.0409, -0.0478, -0.0085],\n",
            "        [-0.0146, -0.0087,  0.0000, -0.0194,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0214,\n",
            "          0.0000, -0.0212, -0.0247, -0.0044],\n",
            "        [-0.0148, -0.0089,  0.0000, -0.0197,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0217,\n",
            "          0.0000, -0.0214, -0.0250, -0.0045],\n",
            "        [-0.0216, -0.0130,  0.0000, -0.0289,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0318,\n",
            "          0.0000, -0.0312, -0.0365, -0.0065]])\n",
            "DEBUGGING: training for one iteration takes 0.004192 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 19\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([0.0253, 0.0133, 0.0126, 0.0075, 0.0150, 0.0083, 0.0160, 0.0142, 0.0173,\n",
            "        0.0140, 0.0161, 0.0081, 0.0159, 0.0109, 0.0210, 0.0223, 0.0052, 0.0173,\n",
            "        0.0183, 0.0224, 0.0116, 0.0074, 0.0169, 0.0159, 0.0186, 0.0135, 0.0137,\n",
            "        0.0150, 0.0104, 0.0140, 0.0105, 0.0089, 0.0155, 0.0170, 0.0151, 0.0185,\n",
            "        0.0136, 0.0100, 0.0194, 0.0119, 0.0242, 0.0133, 0.0183, 0.0091, 0.0176,\n",
            "        0.0155, 0.0128, 0.0171, 0.0121, 0.0216, 0.0125, 0.0256, 0.0132, 0.0133,\n",
            "        0.0132, 0.0208, 0.0151, 0.0159, 0.0153, 0.0162, 0.0080, 0.0150, 0.0124,\n",
            "        0.0075, 0.0155, 0.0114, 0.0152, 0.0137], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [39]\n",
            "DEBUGGING: logits looks like: tensor([536.8282, 536.5074, 536.4780, 536.2191, 536.5653, 536.2704, 536.5990,\n",
            "        536.5402, 536.6379, 536.5325, 536.6004, 536.2582, 536.5950, 536.4091,\n",
            "        536.7349, 536.7650, 536.0363, 536.6392, 536.6657, 536.7670, 536.4400,\n",
            "        536.2114, 536.6260, 536.5960, 536.6752, 536.5129, 536.5226, 536.5652,\n",
            "        536.3853, 536.5322, 536.3886, 536.3079, 536.5842, 536.6289, 536.5695,\n",
            "        536.6724, 536.5163, 536.3651, 536.6942, 536.4520, 536.8054, 536.5049,\n",
            "        536.6671, 536.3167, 536.6462, 536.5840, 536.4874, 536.6315, 536.4604,\n",
            "        536.7482, 536.4774, 536.8338, 536.5024, 536.5062, 536.5042, 536.7295,\n",
            "        536.5690, 536.5961, 536.5748, 536.6064, 536.2492, 536.5659, 536.4716,\n",
            "        536.2191, 536.5825, 536.4302, 536.5735, 536.5226],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0280, 0.0080, 0.0122, 0.0112, 0.0131, 0.0121, 0.0148, 0.0119, 0.0144,\n",
            "        0.0135, 0.0111, 0.0122, 0.0127, 0.0128, 0.0133, 0.0127, 0.0137, 0.0136,\n",
            "        0.0134, 0.0119, 0.0135, 0.0127, 0.0127, 0.0128, 0.0138, 0.0129, 0.0128,\n",
            "        0.0136, 0.0124, 0.0125, 0.0127, 0.0122, 0.0120, 0.0133, 0.0117, 0.0121,\n",
            "        0.0113, 0.0129, 0.0127, 0.0122, 0.0113, 0.0111, 0.0124, 0.0126, 0.0133,\n",
            "        0.0118, 0.0137, 0.0123, 0.0129, 0.0124, 0.0132, 0.0124, 0.0141, 0.0132,\n",
            "        0.0129, 0.0132, 0.0106, 0.0135, 0.0120, 0.0115, 0.0141, 0.0123, 0.0132,\n",
            "        0.0121, 0.0131, 0.0129, 0.0128, 0.0118, 0.0132, 0.0116, 0.0130, 0.0127,\n",
            "        0.0128, 0.0128, 0.0129, 0.0130, 0.0136, 0.0123],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [69]\n",
            "DEBUGGING: logits looks like: tensor([536.7798, 536.1541, 536.3620, 536.3225, 536.3996, 536.3599, 536.4615,\n",
            "        536.3514, 536.4453, 536.4133, 536.3174, 536.3626, 536.3832, 536.3871,\n",
            "        536.4053, 536.3836, 536.4222, 536.4185, 536.4101, 536.3531, 536.4137,\n",
            "        536.3842, 536.3847, 536.3892, 536.4262, 536.3917, 536.3889, 536.4173,\n",
            "        536.3723, 536.3775, 536.3826, 536.3626, 536.3572, 536.4075, 536.3439,\n",
            "        536.3610, 536.3237, 536.3924, 536.3827, 536.3620, 536.3239, 536.3179,\n",
            "        536.3702, 536.3815, 536.4061, 536.3470, 536.4211, 536.3687, 536.3932,\n",
            "        536.3723, 536.4037, 536.3723, 536.4344, 536.4027, 536.3897, 536.4015,\n",
            "        536.2955, 536.4135, 536.3566, 536.3345, 536.4363, 536.3664, 536.4041,\n",
            "        536.3580, 536.3992, 536.3897, 536.3867, 536.3456, 536.4018, 536.3402,\n",
            "        536.3952, 536.3842, 536.3889, 536.3879, 536.3904, 536.3949, 536.4198,\n",
            "        536.3666], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0254, 0.0117, 0.0108, 0.0111, 0.0110, 0.0111, 0.0124, 0.0108, 0.0109,\n",
            "        0.0118, 0.0109, 0.0117, 0.0111, 0.0113, 0.0109, 0.0111, 0.0121, 0.0112,\n",
            "        0.0112, 0.0115, 0.0105, 0.0108, 0.0108, 0.0114, 0.0112, 0.0117, 0.0113,\n",
            "        0.0127, 0.0111, 0.0114, 0.0123, 0.0111, 0.0109, 0.0110, 0.0107, 0.0112,\n",
            "        0.0116, 0.0113, 0.0110, 0.0114, 0.0110, 0.0122, 0.0109, 0.0128, 0.0114,\n",
            "        0.0107, 0.0115, 0.0103, 0.0104, 0.0105, 0.0108, 0.0112, 0.0114, 0.0120,\n",
            "        0.0110, 0.0108, 0.0118, 0.0123, 0.0110, 0.0105, 0.0108, 0.0101, 0.0111,\n",
            "        0.0110, 0.0109, 0.0115, 0.0108, 0.0107, 0.0111, 0.0109, 0.0111, 0.0112,\n",
            "        0.0114, 0.0114, 0.0111, 0.0112, 0.0108, 0.0118, 0.0117, 0.0107, 0.0113,\n",
            "        0.0112, 0.0110, 0.0116, 0.0108, 0.0102, 0.0115, 0.0109],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [43]\n",
            "DEBUGGING: logits looks like: tensor([536.7379, 536.3520, 536.3116, 536.3237, 536.3223, 536.3264, 536.3801,\n",
            "        536.3110, 536.3148, 536.3562, 536.3171, 536.3513, 536.3231, 536.3341,\n",
            "        536.3135, 536.3235, 536.3698, 536.3273, 536.3295, 536.3437, 536.2987,\n",
            "        536.3088, 536.3120, 536.3372, 536.3308, 536.3520, 536.3347, 536.3922,\n",
            "        536.3243, 536.3390, 536.3743, 536.3237, 536.3151, 536.3198, 536.3071,\n",
            "        536.3291, 536.3466, 536.3333, 536.3204, 536.3401, 536.3183, 536.3718,\n",
            "        536.3175, 536.3959, 536.3394, 536.3081, 536.3440, 536.2877, 536.2931,\n",
            "        536.2975, 536.3094, 536.3283, 536.3367, 536.3623, 536.3216, 536.3105,\n",
            "        536.3556, 536.3774, 536.3213, 536.2969, 536.3125, 536.2751, 536.3248,\n",
            "        536.3205, 536.3159, 536.3438, 536.3123, 536.3060, 536.3233, 536.3140,\n",
            "        536.3270, 536.3315, 536.3376, 536.3397, 536.3226, 536.3309, 536.3131,\n",
            "        536.3561, 536.3524, 536.3083, 536.3347, 536.3311, 536.3187, 536.3480,\n",
            "        536.3102, 536.2804, 536.3445, 536.3168], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0130, 0.0132, 0.0093, 0.0067, 0.0025, 0.0039, 0.0139, 0.0106, 0.0037,\n",
            "        0.0082, 0.0311, 0.0049, 0.0027, 0.0060, 0.0090, 0.0049, 0.0126, 0.0177,\n",
            "        0.0072, 0.0061, 0.0066, 0.0034, 0.0105, 0.0021, 0.0055, 0.0086, 0.0065,\n",
            "        0.0080, 0.0172, 0.0220, 0.0168, 0.0083, 0.0364, 0.0118, 0.0061, 0.0601,\n",
            "        0.0289, 0.0097, 0.0071, 0.0247, 0.0087, 0.0084, 0.0081, 0.0108, 0.0037,\n",
            "        0.0049, 0.0195, 0.0043, 0.0068, 0.0073, 0.0134, 0.0050, 0.0088, 0.0061,\n",
            "        0.0011, 0.0028, 0.0075, 0.0071, 0.0071, 0.0065, 0.0106, 0.0065, 0.0162,\n",
            "        0.0097, 0.0093, 0.0187, 0.0103, 0.0065, 0.0037, 0.0108, 0.0085, 0.0133,\n",
            "        0.0043, 0.0198, 0.0303, 0.0042, 0.0065, 0.0136, 0.0058, 0.0091, 0.0096,\n",
            "        0.0060, 0.0081, 0.0015, 0.0081, 0.0067, 0.0055, 0.0067, 0.0036, 0.0069,\n",
            "        0.0074, 0.0106, 0.0131, 0.0148, 0.0045, 0.0185, 0.0070, 0.0088],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [42]\n",
            "DEBUGGING: logits looks like: tensor([537.0179, 537.0239, 536.8498, 536.6888, 536.2024, 536.4213, 537.0527,\n",
            "        536.9166, 536.3947, 536.7889, 537.4543, 536.5251, 536.2255, 536.6318,\n",
            "        536.8314, 536.5302, 537.0027, 537.1714, 536.7223, 536.6436, 536.6786,\n",
            "        536.3434, 536.9100, 536.0948, 536.5862, 536.8100, 536.6724, 536.7750,\n",
            "        537.1591, 537.2803, 537.1451, 536.7933, 537.5334, 536.9686, 536.6361,\n",
            "        537.7836, 537.4170, 536.8716, 536.7182, 537.3394, 536.8187, 536.7986,\n",
            "        536.7797, 536.9230, 536.3886, 536.5339, 537.2208, 536.4615, 536.6942,\n",
            "        536.7261, 537.0320, 536.5402, 536.8216, 536.6358, 535.7759, 536.2448,\n",
            "        536.7456, 536.7168, 536.7176, 536.6744, 536.9182, 536.6679, 537.1293,\n",
            "        536.8725, 536.8498, 537.2002, 536.8994, 536.6752, 536.3832, 536.9257,\n",
            "        536.8036, 537.0286, 536.4633, 537.2279, 537.4410, 536.4555, 536.6713,\n",
            "        537.0408, 536.6178, 536.8407, 536.8647, 536.6277, 536.7784, 535.9515,\n",
            "        536.7813, 536.6845, 536.5891, 536.6829, 536.3820, 536.7003, 536.7331,\n",
            "        536.9181, 537.0212, 537.0818, 536.4833, 537.1934, 536.7077, 536.8219],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0091, 0.0100, 0.0096, 0.0093, 0.0087, 0.0094, 0.0085, 0.0102, 0.0087,\n",
            "        0.0092, 0.0094, 0.0093, 0.0089, 0.0101, 0.0102, 0.0106, 0.0089, 0.0089,\n",
            "        0.0094, 0.0095, 0.0091, 0.0094, 0.0071, 0.0111, 0.0089, 0.0091, 0.0096,\n",
            "        0.0090, 0.0089, 0.0104, 0.0083, 0.0102, 0.0089, 0.0082, 0.0096, 0.0088,\n",
            "        0.0092, 0.0096, 0.0096, 0.0090, 0.0091, 0.0096, 0.0082, 0.0082, 0.0097,\n",
            "        0.0080, 0.0091, 0.0112, 0.0110, 0.0097, 0.0095, 0.0104, 0.0100, 0.0101,\n",
            "        0.0086, 0.0092, 0.0093, 0.0096, 0.0102, 0.0084, 0.0101, 0.0110, 0.0088,\n",
            "        0.0105, 0.0092, 0.0080, 0.0088, 0.0105, 0.0087, 0.0109, 0.0114, 0.0085,\n",
            "        0.0089, 0.0106, 0.0088, 0.0082, 0.0094, 0.0092, 0.0094, 0.0109, 0.0099,\n",
            "        0.0099, 0.0103, 0.0084, 0.0103, 0.0098, 0.0102, 0.0099, 0.0102, 0.0094,\n",
            "        0.0096, 0.0084, 0.0093, 0.0073, 0.0087, 0.0092, 0.0100, 0.0098, 0.0090,\n",
            "        0.0090, 0.0097, 0.0092, 0.0109, 0.0107, 0.0086, 0.0092],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [105]\n",
            "DEBUGGING: logits looks like: tensor([536.5952, 536.6403, 536.6202, 536.6039, 536.5717, 536.6063, 536.5592,\n",
            "        536.6490, 536.5706, 536.5955, 536.6108, 536.6057, 536.5836, 536.6469,\n",
            "        536.6497, 536.6666, 536.5813, 536.5836, 536.6072, 536.6155, 536.5898,\n",
            "        536.6103, 536.4672, 536.6914, 536.5791, 536.5916, 536.6194, 536.5869,\n",
            "        536.5789, 536.6576, 536.5466, 536.6519, 536.5813, 536.5388, 536.6177,\n",
            "        536.5761, 536.5975, 536.6199, 536.6213, 536.5869, 536.5940, 536.6199,\n",
            "        536.5397, 536.5390, 536.6221, 536.5310, 536.5942, 536.6950, 536.6860,\n",
            "        536.6228, 536.6115, 536.6580, 536.6381, 536.6464, 536.5654, 536.5968,\n",
            "        536.6057, 536.6210, 536.6503, 536.5541, 536.6454, 536.6890, 536.5751,\n",
            "        536.6626, 536.5957, 536.5284, 536.5778, 536.6663, 536.5706, 536.6809,\n",
            "        536.7071, 536.5593, 536.5839, 536.6697, 536.5784, 536.5420, 536.6089,\n",
            "        536.5959, 536.6102, 536.6816, 536.6345, 536.6349, 536.6536, 536.5527,\n",
            "        536.6551, 536.6282, 536.6498, 536.6356, 536.6479, 536.6104, 536.6174,\n",
            "        536.5536, 536.6052, 536.4826, 536.5681, 536.5983, 536.6385, 536.6293,\n",
            "        536.5884, 536.5866, 536.6265, 536.5976, 536.6821, 536.6729, 536.5636,\n",
            "        536.5975], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.7082653196239335 and immediate abs rewards look like: [0.03063765095475901, 0.017358033789150795, 0.03661709419793624, 0.02743415733175425, 1.6703719211363932e-05, 0.0011560300804376311, 0.0006214937634467788, 0.00017041931187122827, 0.00016141025253091357, 0.004804383729606343, 0.0029301385243343248, 0.0003128831485810224, 0.0032898170861699327, 0.0047756014100741595, 0.002103573339354625, 7.527292973463773e-05, 0.0007713142208558565, 4.136445249969256e-05, 0.0005348375957510143, 0.00029348897351155756, 3.466619091341272e-06, 1.7911473150888924e-05, 0.00031628502165403916, 0.00025518857773931813, 0.0009993250164370693, 0.0005823081528433249, 0.0007546502497461915, 7.036350643829792e-05, 0.0005886913363610802, 2.2853574591863435e-05, 0.00013833131833962398, 0.0003533985945978202, 4.9056096031563357e-05, 0.00015554572973996983, 0.0003843656077151536, 9.7904426183959e-05, 0.00020018881104988395, 0.00015973752124409657, 0.5690100791757686, 4.547473508864641e-13, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13]\n",
            "DEBUGGING: the total relative reward of the trajectory = 64.12412319966157 and immediate relative rewards look like: [0.08261989991023588, 0.09439799432143971, 0.3001180064635655, 0.302834303496673, 0.00023224005650932284, 0.019287518055286473, 0.012101254805140325, 0.0037929705451603324, 0.004041707623581495, 0.13367446613874048, 0.08979921445178156, 0.010469110970526906, 0.1192612559646207, 0.18661174935298008, 0.08818831988796999, 0.0033680331747347105, 0.03666966650492991, 0.0020826686267512735, 0.028425030751358344, 0.016421475511606512, 0.0002036814469149518, 0.0011025047284243113, 0.020353313002954655, 0.017137187825336627, 0.06991089523526586, 0.04237851932450816, 0.05704266898248223, 0.005516804842510944, 0.0478053294361396, 0.0019201610870204125, 0.012010117604293968, 0.03167354492358345, 0.004534524867949457, 0.014813846568200985, 0.03768446207760722, 0.00987418694201932, 0.020751521970029954, 0.017006828251432925, 62.17800621337195, 6.063298011820441e-11, 0.0, 0.0, 0.0, 6.669627813001473e-11, 6.821210263295928e-11, 6.972792713592449e-11, 7.124375163889018e-11, 7.275957614183426e-11, 7.427540064477789e-11, 7.579122514774402e-11]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([0.0195, 0.0069, 0.0024, 0.4134, 0.0067, 0.0092, 0.0048, 0.0133, 0.0040,\n",
            "        0.0059, 0.0036, 0.0028, 0.0189, 0.0035, 0.0078, 0.0073, 0.0069, 0.0033,\n",
            "        0.0198, 0.0066, 0.0027, 0.0077, 0.0156, 0.0621, 0.0036, 0.0104, 0.0059,\n",
            "        0.0097, 0.0012, 0.0013, 0.0033, 0.0022, 0.0072, 0.0089, 0.0121, 0.0354,\n",
            "        0.0054, 0.0051, 0.0074, 0.0009, 0.0031, 0.0126, 0.0004, 0.0059, 0.0137,\n",
            "        0.0121, 0.0085, 0.0026, 0.0037, 0.0331, 0.0070, 0.0030, 0.0079, 0.0036,\n",
            "        0.0093, 0.0067, 0.0012, 0.0051, 0.0070, 0.0106, 0.0109, 0.0067, 0.0012,\n",
            "        0.0142, 0.0118, 0.0020, 0.0211], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [3]\n",
            "DEBUGGING: logits looks like: tensor([539.4371, 538.9183, 538.3925, 540.9641, 538.9008, 539.0613, 538.7336,\n",
            "        539.2464, 538.6445, 538.8419, 538.5957, 538.4630, 539.4203, 538.5831,\n",
            "        538.9808, 538.9469, 538.9200, 538.5472, 539.4440, 538.8925, 538.4485,\n",
            "        538.9727, 539.3260, 540.0161, 538.5986, 539.1235, 538.8415, 539.0891,\n",
            "        538.0309, 538.1003, 538.5532, 538.3459, 538.9404, 539.0469, 539.1973,\n",
            "        539.7350, 538.7989, 538.7619, 538.9540, 537.9221, 538.5131, 539.2191,\n",
            "        537.5154, 538.8383, 539.2595, 539.1981, 539.0245, 538.4243, 538.6114,\n",
            "        539.7022, 538.9273, 538.5076, 538.9844, 538.5875, 539.0651, 538.9009,\n",
            "        538.0430, 538.7645, 538.9273, 539.1311, 539.1483, 538.9027, 538.0386,\n",
            "        539.2801, 539.1865, 538.2917, 539.4756], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.8136e-02, 1.9324e-03, 1.3740e-02, 2.3970e-03, 7.9598e-03, 8.5553e-03,\n",
            "        4.0754e-03, 6.8377e-02, 8.6538e-04, 3.1580e-04, 1.0868e-03, 2.6802e-03,\n",
            "        6.6928e-04, 7.7667e-04, 1.4790e-04, 2.1226e-03, 5.6864e-04, 3.3717e-02,\n",
            "        5.7177e-04, 6.2636e-04, 4.6748e-03, 3.4593e-02, 1.0855e-02, 3.3647e-02,\n",
            "        6.9122e-03, 1.8835e-03, 7.0307e-02, 2.0636e-03, 3.0830e-03, 3.6256e-03,\n",
            "        2.6691e-03, 3.1762e-04, 1.7715e-04, 3.2235e-03, 3.4407e-02, 6.9144e-05,\n",
            "        2.0470e-03, 1.9821e-03, 7.9295e-04, 4.7443e-03, 7.4441e-02, 3.8863e-04,\n",
            "        6.1810e-03, 4.4017e-03, 4.4016e-04, 1.7327e-01, 2.5848e-03, 2.3740e-02,\n",
            "        1.9017e-03, 4.0975e-02, 9.2448e-03, 2.3807e-03, 2.5197e-03, 8.5126e-03,\n",
            "        1.6298e-03, 7.1386e-03, 4.6578e-02, 7.6954e-02, 2.7065e-03, 2.7993e-03,\n",
            "        4.3187e-03, 4.1094e-03, 3.8652e-02, 8.7740e-04, 8.1533e-04, 1.8012e-03,\n",
            "        8.9678e-04, 1.9428e-03, 3.1243e-03, 1.3226e-03, 1.8010e-02, 4.9014e-04,\n",
            "        1.1030e-02, 9.3870e-03, 7.1290e-03, 6.9342e-03, 6.6264e-03, 2.3492e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [56]\n",
            "DEBUGGING: logits looks like: tensor([540.3600, 539.2405, 540.2213, 539.3482, 539.9483, 539.9844, 539.6136,\n",
            "        541.0236, 538.8388, 538.3348, 538.9527, 539.4041, 538.7103, 538.7847,\n",
            "        537.9555, 539.2874, 538.6288, 540.6701, 538.6316, 538.6772, 539.6822,\n",
            "        540.6829, 540.1034, 540.6691, 539.8777, 539.2277, 541.0375, 539.2733,\n",
            "        539.4741, 539.5551, 539.4020, 538.3376, 538.0457, 539.4963, 540.6802,\n",
            "        537.5753, 539.2693, 539.2532, 538.7951, 539.6896, 541.0661, 538.4385,\n",
            "        539.8218, 539.6521, 538.5008, 541.4885, 539.3859, 540.4947, 539.2325,\n",
            "        540.7676, 540.0231, 539.3448, 539.3732, 539.9819, 539.1553, 539.8939,\n",
            "        540.8317, 541.0827, 539.4089, 539.4258, 539.6426, 539.6177, 540.7384,\n",
            "        538.8457, 538.8090, 539.2053, 538.8566, 539.2432, 539.4807, 539.0509,\n",
            "        540.3566, 538.5546, 540.1114, 540.0308, 539.8932, 539.8793, 539.8566,\n",
            "        539.3381], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0169, 0.0102, 0.0396, 0.0083, 0.0020, 0.0040, 0.0093, 0.0016, 0.0213,\n",
            "        0.0006, 0.0086, 0.0111, 0.0053, 0.0172, 0.0119, 0.0175, 0.0058, 0.0035,\n",
            "        0.0110, 0.0073, 0.0061, 0.0196, 0.0106, 0.0115, 0.0106, 0.0097, 0.0073,\n",
            "        0.0031, 0.0027, 0.0056, 0.0005, 0.0074, 0.0048, 0.0084, 0.0217, 0.0081,\n",
            "        0.0177, 0.0043, 0.0102, 0.0188, 0.0139, 0.0069, 0.0081, 0.0138, 0.0153,\n",
            "        0.0053, 0.0458, 0.0051, 0.0005, 0.0135, 0.0131, 0.0104, 0.0199, 0.0060,\n",
            "        0.0095, 0.0170, 0.0082, 0.0129, 0.0126, 0.0070, 0.0067, 0.0080, 0.0147,\n",
            "        0.0088, 0.0027, 0.0051, 0.0053, 0.0045, 0.0501, 0.0219, 0.0257, 0.0127,\n",
            "        0.0164, 0.0014, 0.0814, 0.0120, 0.0178, 0.0027, 0.0136, 0.0084, 0.0091,\n",
            "        0.0097, 0.0110, 0.0040], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [74]\n",
            "DEBUGGING: logits looks like: tensor([540.0546, 539.8035, 540.4799, 539.6978, 538.9816, 539.3379, 539.7566,\n",
            "        538.8671, 540.1691, 538.3859, 539.7180, 539.8445, 539.4779, 540.0632,\n",
            "        539.8792, 540.0707, 539.5156, 539.2659, 539.8407, 539.6317, 539.5426,\n",
            "        540.1296, 539.8215, 539.8604, 539.8204, 539.7751, 539.6316, 539.2057,\n",
            "        539.1328, 539.4987, 538.3332, 539.6417, 539.4200, 539.7034, 540.1794,\n",
            "        539.6837, 540.0764, 539.3666, 539.8011, 540.1068, 539.9581, 539.6086,\n",
            "        539.6884, 539.9532, 540.0060, 539.4724, 540.5531, 539.4589, 538.2774,\n",
            "        539.9415, 539.9274, 539.8104, 540.1365, 539.5327, 539.7645, 540.0562,\n",
            "        539.6953, 539.9200, 539.9085, 539.6111, 539.5933, 539.6774, 539.9852,\n",
            "        539.7255, 539.1372, 539.4541, 539.4705, 539.3929, 540.5977, 540.1841,\n",
            "        540.2636, 539.9118, 540.0399, 538.8005, 540.8405, 539.8844, 540.0795,\n",
            "        539.1320, 539.9451, 539.7037, 539.7434, 539.7772, 539.8400, 539.3375],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.5509e-02, 2.3957e-02, 1.0461e-03, 2.2720e-03, 1.2330e-02, 6.1797e-03,\n",
            "        5.6902e-03, 5.9126e-03, 4.2519e-03, 9.0520e-03, 8.2178e-03, 5.5051e-03,\n",
            "        1.0748e-02, 6.7962e-03, 1.4571e-03, 7.4278e-03, 1.1220e-02, 1.0154e-02,\n",
            "        7.6067e-03, 2.0657e-03, 3.5087e-02, 4.7724e-03, 1.1461e-01, 2.1762e-03,\n",
            "        1.5059e-03, 1.5579e-02, 1.6779e-03, 2.4888e-04, 1.6994e-02, 5.5408e-03,\n",
            "        4.6744e-03, 2.7001e-02, 2.0730e-02, 1.7551e-02, 1.5509e-02, 3.3723e-02,\n",
            "        2.1343e-03, 2.6679e-03, 1.4803e-02, 6.4896e-04, 3.7308e-03, 3.5726e-03,\n",
            "        2.5250e-03, 4.7666e-03, 7.2930e-03, 8.4984e-03, 1.5646e-02, 2.6192e-03,\n",
            "        2.4590e-03, 4.3810e-03, 1.1920e-02, 5.2408e-03, 8.8726e-03, 7.9630e-03,\n",
            "        2.7540e-03, 6.7631e-03, 5.8573e-03, 6.6648e-03, 8.9027e-04, 7.1631e-04,\n",
            "        3.0369e-03, 2.9223e-03, 3.0499e-03, 7.2206e-02, 8.7992e-03, 1.9533e-03,\n",
            "        8.3411e-03, 8.2048e-03, 6.4400e-03, 3.6788e-03, 1.1215e-02, 1.2152e-03,\n",
            "        1.0411e-02, 8.0398e-05, 3.7304e-03, 1.2200e-03, 4.0198e-02, 3.4378e-04,\n",
            "        2.5257e-02, 7.8310e-03, 1.6702e-02, 7.4767e-04, 8.0707e-03, 2.7489e-03,\n",
            "        1.5602e-02, 3.4641e-02, 3.2581e-03, 1.3715e-02, 3.4169e-03, 5.0796e-03,\n",
            "        4.6435e-04, 1.9861e-02, 5.0407e-03, 2.3683e-03, 2.3683e-03, 1.2338e-02,\n",
            "        7.5956e-03, 1.7675e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [8]\n",
            "DEBUGGING: logits looks like: tensor([540.4398, 540.6572, 539.0916, 539.4794, 540.3251, 539.9797, 539.9385,\n",
            "        539.9576, 539.7928, 540.1706, 540.1223, 539.9219, 540.2565, 540.0273,\n",
            "        539.2573, 540.0717, 540.2780, 540.2280, 540.0836, 539.4318, 540.8480,\n",
            "        539.8505, 541.4399, 539.4579, 539.2738, 540.4421, 539.3279, 538.3737,\n",
            "        540.4855, 539.9252, 539.8401, 540.7170, 540.5849, 540.5016, 540.4398,\n",
            "        540.8282, 539.4482, 539.5598, 540.4165, 538.8529, 539.7274, 539.7057,\n",
            "        539.5322, 539.8499, 540.0626, 540.1390, 540.4442, 539.5505, 539.5190,\n",
            "        539.8077, 540.3082, 539.8973, 540.1606, 540.1065, 539.5756, 540.0248,\n",
            "        539.9529, 540.0175, 539.0110, 538.9023, 539.6245, 539.6053, 539.6266,\n",
            "        541.2089, 540.1564, 539.4039, 540.1297, 540.1215, 540.0004, 539.7204,\n",
            "        540.2777, 539.1666, 540.2405, 537.8087, 539.7274, 539.1685, 540.9160,\n",
            "        538.5352, 540.6837, 540.0981, 540.4769, 538.9237, 540.1132, 539.5747,\n",
            "        540.4428, 540.8416, 539.6597, 540.3784, 539.6835, 539.8817, 538.6855,\n",
            "        540.5635, 539.8779, 539.5002, 539.5002, 540.3254, 540.0829, 540.5052],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0082, 0.0056, 0.0172, 0.0119, 0.0023, 0.0069, 0.0102, 0.0077, 0.0153,\n",
            "        0.0068, 0.0084, 0.0122, 0.0186, 0.0078, 0.0078, 0.0121, 0.0093, 0.0074,\n",
            "        0.0047, 0.0081, 0.0087, 0.0146, 0.0051, 0.0067, 0.0112, 0.0050, 0.0069,\n",
            "        0.0061, 0.0134, 0.0133, 0.0070, 0.0098, 0.0109, 0.0102, 0.0139, 0.0065,\n",
            "        0.0076, 0.0071, 0.0090, 0.0127, 0.0086, 0.0074, 0.0088, 0.0163, 0.0095,\n",
            "        0.0050, 0.0070, 0.0096, 0.0098, 0.0081, 0.0123, 0.0057, 0.0094, 0.0058,\n",
            "        0.0048, 0.0101, 0.0137, 0.0104, 0.0138, 0.0098, 0.0047, 0.0086, 0.0096,\n",
            "        0.0089, 0.0075, 0.0109, 0.0121, 0.0111, 0.0086, 0.0094, 0.0060, 0.0060,\n",
            "        0.0147, 0.0102, 0.0097, 0.0076, 0.0125, 0.0090, 0.0101, 0.0048, 0.0105,\n",
            "        0.0107, 0.0070, 0.0084, 0.0065, 0.0072, 0.0122, 0.0068, 0.0039, 0.0104,\n",
            "        0.0094, 0.0145, 0.0086, 0.0072, 0.0075, 0.0106, 0.0114, 0.0069, 0.0101,\n",
            "        0.0062, 0.0076, 0.0109, 0.0118, 0.0111, 0.0186, 0.0076, 0.0141],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [9]\n",
            "DEBUGGING: logits looks like: tensor([541.8903, 541.7028, 542.2615, 542.0794, 541.2584, 541.8019, 542.0011,\n",
            "        541.8627, 542.2028, 541.7965, 541.9046, 542.0906, 542.3015, 541.8693,\n",
            "        541.8646, 542.0853, 541.9551, 541.8412, 541.6171, 541.8856, 541.9233,\n",
            "        542.1790, 541.6581, 541.7933, 542.0476, 541.6403, 541.8040, 541.7413,\n",
            "        542.1358, 542.1339, 541.8153, 541.9786, 542.0341, 542.0016, 542.1559,\n",
            "        541.7756, 541.8509, 541.8218, 541.9384, 542.1125, 541.9167, 541.8401,\n",
            "        541.9278, 542.2344, 541.9670, 541.6465, 541.8116, 541.9723, 541.9816,\n",
            "        541.8871, 542.0940, 541.7068, 541.9584, 541.7219, 541.6280, 541.9978,\n",
            "        542.1469, 542.0122, 542.1511, 541.9827, 541.6188, 541.9134, 541.9697,\n",
            "        541.9314, 541.8503, 542.0360, 542.0868, 542.0441, 541.9181, 541.9625,\n",
            "        541.7320, 541.7353, 542.1847, 542.0013, 541.9767, 541.8571, 542.1011,\n",
            "        541.9388, 541.9976, 541.6208, 542.0165, 542.0259, 541.8101, 541.9014,\n",
            "        541.7748, 541.8242, 542.0898, 541.7990, 541.5187, 542.0103, 541.9616,\n",
            "        542.1765, 541.9184, 541.8287, 541.8500, 542.0200, 542.0560, 541.8064,\n",
            "        541.9949, 541.7482, 541.8528, 542.0351, 542.0751, 542.0450, 542.3005,\n",
            "        541.8540, 542.1624], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.8867413289890465 and immediate abs rewards look like: [0.013861296453796967, 0.02123473316851232, 0.8516452993503663, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 1.3642420526593924e-12, 4.547473508864641e-13, 9.094947017729282e-13, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13, 0.0, 4.547473508864641e-13, 9.094947017729282e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 9.094947017729282e-13, 9.094947017729282e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 9.094947017729282e-13, 0.0, 0.0, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13]\n",
            "DEBUGGING: the total relative reward of the trajectory = 9.155361048265627 and immediate relative rewards look like: [0.04801710605199906, 0.1478288889765729, 8.959515051304379, 0.0, 1.1368683772161603e-11, 1.3642420526590822e-11, 1.5916157281026244e-11, 1.818989403545443e-11, 0.0, 6.821210263296962e-11, 2.5011104298772587e-11, 5.456968210640051e-11, 0.0, 0.0, 3.410605131648481e-11, 3.63797880709254e-11, 7.730704965073406e-11, 0.0, 4.320099833421409e-11, 9.094947017727214e-11, 0.0, 5.002220859752243e-11, 5.2295945351943374e-11, 1.0913936421272657e-10, 5.684341886082094e-11, 0.0, 0.0, 6.366462912410498e-11, 1.318767317570446e-10, 1.3642420526597025e-10, 7.048583938738591e-11, 0.0, 0.0, 0.0, 7.958078640513122e-11, 8.185452315954493e-11, 0.0, 8.640199666842818e-11, 0.0, 0.0, 0.0, 0.0, 1.955413608811351e-10, 0.0, 0.0, 1.0459189070391053e-10, 0.0, 0.0, 1.1141310096718371e-10, 1.1368683772164188e-10]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([0.0117, 0.0044, 0.0203, 0.0064, 0.0219, 0.0105, 0.0042, 0.0217, 0.0354,\n",
            "        0.0013, 0.0037, 0.0054, 0.0023, 0.0050, 0.0006, 0.0141, 0.0115, 0.0217,\n",
            "        0.0067, 0.0195, 0.0012, 0.0140, 0.0474, 0.0479, 0.0023, 0.0070, 0.0219,\n",
            "        0.0092, 0.0041, 0.0138, 0.0340, 0.0022, 0.0107, 0.0426, 0.0048, 0.0199,\n",
            "        0.0153, 0.0395, 0.0020, 0.0019, 0.0071, 0.0114, 0.0039, 0.0173, 0.0114,\n",
            "        0.0074, 0.0040, 0.0158, 0.0126, 0.0104, 0.0294, 0.0017, 0.0107, 0.0156,\n",
            "        0.0039, 0.0116, 0.0789, 0.0135, 0.0089, 0.0037, 0.0025, 0.0421, 0.0037,\n",
            "        0.0208, 0.0146, 0.0076, 0.0011, 0.0533, 0.0052],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [0]\n",
            "DEBUGGING: logits looks like: tensor([534.4443, 533.9568, 534.7230, 534.1423, 534.7595, 534.3945, 533.9290,\n",
            "        534.7546, 534.9996, 533.3620, 533.8707, 534.0613, 533.6365, 534.0250,\n",
            "        533.0004, 534.5408, 534.4361, 534.7559, 534.1702, 534.7012, 533.3004,\n",
            "        534.5352, 535.1457, 535.1515, 533.6332, 534.1884, 534.7595, 534.3245,\n",
            "        533.9200, 534.5277, 534.9793, 533.6135, 534.4021, 535.0925, 533.9966,\n",
            "        534.7131, 534.5797, 535.0551, 533.5599, 533.5427, 534.1938, 534.4348,\n",
            "        533.8955, 534.6417, 534.4355, 534.2174, 533.9123, 534.5972, 534.4837,\n",
            "        534.3854, 534.9074, 533.4699, 534.4020, 534.5912, 533.8943, 534.4400,\n",
            "        535.4005, 534.5161, 534.3093, 533.8759, 533.6779, 535.0861, 533.8676,\n",
            "        534.7328, 534.5568, 534.2297, 533.2817, 535.2047, 534.0433],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0120, 0.0135, 0.0099, 0.0165, 0.0115, 0.0074, 0.0190, 0.0105, 0.0112,\n",
            "        0.0210, 0.0120, 0.0182, 0.0078, 0.0118, 0.0094, 0.0161, 0.0148, 0.0086,\n",
            "        0.0117, 0.0112, 0.0130, 0.0115, 0.0155, 0.0211, 0.0116, 0.0264, 0.0147,\n",
            "        0.0157, 0.0133, 0.0146, 0.0150, 0.0125, 0.0174, 0.0154, 0.0117, 0.0136,\n",
            "        0.0080, 0.0091, 0.0114, 0.0090, 0.0132, 0.0200, 0.0127, 0.0069, 0.0142,\n",
            "        0.0094, 0.0247, 0.0096, 0.0147, 0.0135, 0.0291, 0.0099, 0.0116, 0.0106,\n",
            "        0.0114, 0.0111, 0.0205, 0.0130, 0.0130, 0.0182, 0.0104, 0.0075, 0.0112,\n",
            "        0.0134, 0.0096, 0.0075, 0.0072, 0.0100, 0.0217, 0.0097, 0.0103, 0.0113,\n",
            "        0.0095, 0.0051, 0.0141, 0.0093, 0.0103], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [11]\n",
            "DEBUGGING: logits looks like: tensor([534.6420, 534.7000, 534.5439, 534.8018, 534.6214, 534.3981, 534.8718,\n",
            "        534.5745, 534.6055, 534.9222, 534.6405, 534.8504, 534.4244, 534.6339,\n",
            "        534.5200, 534.7885, 534.7463, 534.4736, 534.6299, 534.6050, 534.6825,\n",
            "        534.6201, 534.7687, 534.9238, 534.6255, 535.0352, 534.7412, 534.7770,\n",
            "        534.6946, 534.7381, 534.7517, 534.6605, 534.8283, 534.7650, 534.6279,\n",
            "        534.7050, 534.4404, 534.5053, 534.6162, 534.4979, 534.6906, 534.8967,\n",
            "        534.6697, 534.3635, 534.7259, 534.5181, 535.0016, 534.5319, 534.7434,\n",
            "        534.6996, 535.0847, 534.5437, 534.6262, 534.5815, 534.6162, 534.6019,\n",
            "        534.9087, 534.6799, 534.6807, 534.8510, 534.5684, 534.4080, 534.6071,\n",
            "        534.6968, 534.5273, 534.4076, 534.3829, 534.5504, 534.9374, 534.5350,\n",
            "        534.5656, 534.6105, 534.5267, 534.2095, 534.7219, 534.5151, 534.5627],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0128, 0.0217, 0.0160, 0.0071, 0.0154, 0.0110, 0.0161, 0.0105, 0.0154,\n",
            "        0.0030, 0.0186, 0.0109, 0.0062, 0.0167, 0.0075, 0.0097, 0.0120, 0.0123,\n",
            "        0.0206, 0.0134, 0.0093, 0.0121, 0.0011, 0.0181, 0.0080, 0.0126, 0.0106,\n",
            "        0.0088, 0.0052, 0.0103, 0.0106, 0.0090, 0.0125, 0.0070, 0.0085, 0.0108,\n",
            "        0.0111, 0.0167, 0.0146, 0.0262, 0.0099, 0.0108, 0.0134, 0.0072, 0.0096,\n",
            "        0.0089, 0.0432, 0.0127, 0.0174, 0.0070, 0.0096, 0.0027, 0.0167, 0.0045,\n",
            "        0.0146, 0.0173, 0.0082, 0.0088, 0.0185, 0.0133, 0.0175, 0.0126, 0.0131,\n",
            "        0.0082, 0.0082, 0.0048, 0.0048, 0.0179, 0.0044, 0.0112, 0.0157, 0.0158,\n",
            "        0.0047, 0.0013, 0.0038, 0.0177, 0.0122, 0.0098, 0.0160, 0.0139, 0.0023,\n",
            "        0.0149, 0.0092, 0.0162, 0.0090], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [34]\n",
            "DEBUGGING: logits looks like: tensor([534.4579, 534.7216, 534.5696, 534.1603, 534.5490, 534.3823, 534.5727,\n",
            "        534.3555, 534.5507, 533.7272, 534.6443, 534.3777, 534.0926, 534.5896,\n",
            "        534.1901, 534.3187, 534.4243, 534.4382, 534.6947, 534.4790, 534.2977,\n",
            "        534.4280, 533.2331, 534.6298, 534.2205, 534.4481, 534.3646, 534.2722,\n",
            "        534.0084, 534.3504, 534.3638, 534.2801, 534.4465, 534.1534, 534.2540,\n",
            "        534.3740, 534.3868, 534.5887, 534.5242, 534.8156, 534.3298, 534.3721,\n",
            "        534.4799, 534.1708, 534.3134, 534.2746, 535.0653, 534.4542, 534.6102,\n",
            "        534.1540, 534.3107, 533.6706, 534.5907, 533.9379, 534.5240, 534.6063,\n",
            "        534.2322, 534.2706, 534.6417, 534.4769, 534.6135, 534.4493, 534.4690,\n",
            "        534.2335, 534.2330, 533.9680, 533.9651, 534.6259, 533.9228, 534.3906,\n",
            "        534.5595, 534.5636, 533.9527, 533.3055, 533.8440, 534.6193, 534.4323,\n",
            "        534.3232, 534.5682, 534.4965, 533.5977, 534.5323, 534.2895, 534.5759,\n",
            "        534.2818], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0033, 0.0148, 0.0194, 0.0039, 0.0093, 0.0074, 0.0102, 0.0087, 0.0061,\n",
            "        0.0035, 0.0139, 0.0209, 0.0143, 0.0027, 0.0126, 0.0031, 0.0090, 0.0060,\n",
            "        0.0118, 0.0146, 0.0096, 0.0152, 0.0087, 0.0125, 0.0108, 0.0083, 0.0036,\n",
            "        0.0076, 0.0048, 0.0059, 0.0049, 0.0083, 0.0106, 0.0154, 0.0102, 0.0064,\n",
            "        0.0129, 0.0117, 0.0092, 0.0055, 0.0079, 0.0065, 0.0133, 0.0126, 0.0068,\n",
            "        0.0102, 0.0070, 0.0094, 0.0136, 0.0127, 0.0137, 0.0112, 0.0082, 0.0138,\n",
            "        0.0101, 0.0168, 0.0131, 0.0074, 0.0089, 0.0011, 0.0082, 0.0146, 0.0187,\n",
            "        0.0108, 0.0152, 0.0060, 0.0040, 0.0048, 0.0181, 0.0078, 0.0161, 0.0123,\n",
            "        0.0137, 0.0104, 0.0081, 0.0102, 0.0126, 0.0150, 0.0106, 0.0196, 0.0053,\n",
            "        0.0125, 0.0096, 0.0210, 0.0080, 0.0149, 0.0025, 0.0057, 0.0132, 0.0103,\n",
            "        0.0097, 0.0121, 0.0013, 0.0184, 0.0086, 0.0101, 0.0091, 0.0085],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [91]\n",
            "DEBUGGING: logits looks like: tensor([534.4339, 535.1811, 535.3163, 534.5070, 534.9497, 534.8330, 534.9930,\n",
            "        534.9161, 534.7333, 534.4651, 535.1497, 535.3531, 535.1638, 534.3259,\n",
            "        535.1012, 534.3959, 534.9309, 534.7300, 535.0667, 535.1741, 534.9608,\n",
            "        535.1918, 534.9169, 535.0952, 535.0204, 534.8910, 534.4711, 534.8466,\n",
            "        534.6161, 534.7166, 534.6257, 534.8909, 535.0127, 535.1984, 534.9932,\n",
            "        534.7625, 535.1102, 535.0640, 534.9424, 534.6812, 534.8656, 534.7673,\n",
            "        535.1262, 535.0987, 534.7933, 534.9959, 534.8063, 534.9546, 535.1370,\n",
            "        535.1028, 535.1395, 535.0414, 534.8845, 535.1445, 534.9879, 535.2443,\n",
            "        535.1172, 534.8314, 534.9271, 533.8712, 534.8856, 535.1744, 535.2976,\n",
            "        535.0237, 535.1920, 534.7271, 534.5243, 534.6182, 535.2805, 534.8622,\n",
            "        535.2229, 535.0867, 535.1417, 535.0023, 534.8776, 534.9944, 535.1002,\n",
            "        535.1879, 535.0106, 535.3211, 534.6627, 535.0939, 534.9657, 535.3542,\n",
            "        534.8748, 535.1840, 534.2988, 534.7012, 535.1223, 534.9970, 534.9706,\n",
            "        535.0782, 533.9809, 535.2892, 534.9095, 534.9906, 534.9365, 534.9022],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0081, 0.0080, 0.0232, 0.0083, 0.0057, 0.0180, 0.0053, 0.0143, 0.0079,\n",
            "        0.0073, 0.0101, 0.0132, 0.0095, 0.0075, 0.0066, 0.0055, 0.0047, 0.0081,\n",
            "        0.0090, 0.0038, 0.0113, 0.0076, 0.0070, 0.0078, 0.0173, 0.0066, 0.0141,\n",
            "        0.0082, 0.0109, 0.0043, 0.0082, 0.0092, 0.0073, 0.0091, 0.0047, 0.0096,\n",
            "        0.0076, 0.0095, 0.0064, 0.0159, 0.0057, 0.0059, 0.0076, 0.0053, 0.0149,\n",
            "        0.0102, 0.0080, 0.0103, 0.0046, 0.0118, 0.0076, 0.0047, 0.0163, 0.0071,\n",
            "        0.0069, 0.0069, 0.0143, 0.0056, 0.0067, 0.0079, 0.0213, 0.0052, 0.0180,\n",
            "        0.0141, 0.0073, 0.0101, 0.0060, 0.0085, 0.0103, 0.0059, 0.0066, 0.0082,\n",
            "        0.0096, 0.0171, 0.0104, 0.0061, 0.0083, 0.0095, 0.0079, 0.0071, 0.0140,\n",
            "        0.0075, 0.0115, 0.0094, 0.0072, 0.0095, 0.0111, 0.0112, 0.0094, 0.0067,\n",
            "        0.0167, 0.0062, 0.0059, 0.0101, 0.0121, 0.0044, 0.0040, 0.0055, 0.0048,\n",
            "        0.0080, 0.0092, 0.0074, 0.0104, 0.0071, 0.0100, 0.0383, 0.0095],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [99]\n",
            "DEBUGGING: logits looks like: tensor([535.1039, 535.0947, 535.6277, 535.1129, 534.9252, 535.5020, 534.8947,\n",
            "        535.3862, 535.0905, 535.0525, 535.2151, 535.3469, 535.1833, 535.0668,\n",
            "        534.9995, 534.9060, 534.8268, 535.1056, 535.1539, 534.7296, 535.2689,\n",
            "        535.0681, 535.0315, 535.0811, 535.4833, 535.0033, 535.3809, 535.1113,\n",
            "        535.2524, 534.7886, 535.1080, 535.1650, 535.0538, 535.1598, 534.8354,\n",
            "        535.1890, 535.0740, 535.1800, 534.9880, 535.4394, 534.9245, 534.9478,\n",
            "        535.0738, 534.8879, 535.4071, 535.2178, 535.0935, 535.2207, 534.8223,\n",
            "        535.2906, 535.0703, 534.8253, 535.4512, 535.0340, 535.0197, 535.0242,\n",
            "        535.3862, 534.9137, 535.0090, 535.0930, 535.5870, 534.8812, 535.5031,\n",
            "        535.3802, 535.0490, 535.2109, 534.9522, 535.1269, 535.2244, 534.9460,\n",
            "        534.9977, 535.1059, 535.1887, 535.4765, 535.2289, 534.9639, 535.1148,\n",
            "        535.1826, 535.0897, 535.0366, 535.3766, 535.0610, 535.2769, 535.1755,\n",
            "        535.0455, 535.1804, 535.2622, 535.2663, 535.1793, 535.0100, 535.4658,\n",
            "        534.9684, 534.9474, 535.2133, 535.3017, 534.7949, 534.7514, 534.9066,\n",
            "        534.8362, 535.0961, 535.1685, 535.0601, 535.2282, 535.0363, 535.2057,\n",
            "        535.8796, 535.1843], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.6072478073242564 and immediate abs rewards look like: [0.6072478073024286, 9.094947017729282e-13, 4.547473508864641e-13, 2.2737367544323206e-13, 0.0, 4.547473508864641e-13, 1.1368683772161603e-12, 1.3642420526593924e-12, 4.547473508864641e-13, 2.2737367544323206e-13, 4.547473508864641e-13, 2.2737367544323206e-13, 2.2737367544323206e-13, 4.547473508864641e-13, 6.821210263296962e-13, 2.2737367544323206e-13, 2.2737367544323206e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 2.2737367544323206e-13, 0.0, 2.2737367544323206e-13, 2.2737367544323206e-13, 4.547473508864641e-13, 2.2737367544323206e-13, 6.821210263296962e-13, 0.0, 2.2737367544323206e-13, 2.2737367544323206e-13, 6.821210263296962e-13, 2.2737367544323206e-13, 4.547473508864641e-13, 2.2737367544323206e-13, 6.821210263296962e-13, 4.547473508864641e-13, 2.2737367544323206e-13, 4.547473508864641e-13, 2.2737367544323206e-13, 4.547473508864641e-13, 4.547473508864641e-13, 2.2737367544323206e-13, 2.2737367544323206e-13, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13, 1.1368683772161603e-12, 1.5916157281026244e-12, 2.2737367544323206e-13]\n",
            "DEBUGGING: the total relative reward of the trajectory = 1.683410290784972 and immediate relative rewards look like: [1.683410288788631, 6.063298011818143e-12, 4.547473508864985e-12, 3.031649005909531e-12, 0.0, 9.094947017729282e-12, 2.652692880171443e-11, 3.637978807090886e-11, 1.3642420526597027e-11, 7.579122514774976e-12, 1.6674069532503683e-11, 9.094947017727904e-12, 9.852859269205977e-12, 2.1221543041368324e-11, 3.4106051316489985e-11, 1.2126596023638124e-11, 1.2884508275116483e-11, 2.728484105318578e-11, 0.0, 3.0316490059099904e-11, 1.591615728102504e-11, 0.0, 1.7431981783981122e-11, 1.8189894035457188e-11, 3.789561257387201e-11, 1.9705718538416435e-11, 6.139089236968661e-11, 0.0, 2.1979455292845764e-11, 2.2737367544324928e-11, 7.048583938740194e-11, 2.4253192047283603e-11, 5.002220859751864e-11, 2.5769016550232966e-11, 7.958078640512518e-11, 5.456968210638397e-11, 2.8042753304665286e-11, 5.760133111228982e-11, 2.9558577807617925e-11, 6.063298011819521e-11, 6.214880462114068e-11, 3.183231456205249e-11, 3.25902268135324e-11, 1.333925562600497e-10, 6.821210263295928e-11, 6.972792713592449e-11, 1.4248750327773716e-10, 1.8189894035461323e-10, 2.599639022568999e-10, 3.789561257387201e-11]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 3\n",
            "DEBUGGING: the action_prob is: tensor([0.0080, 0.0017, 0.0282, 0.0075, 0.0029, 0.0271, 0.0049, 0.0404, 0.0477,\n",
            "        0.0320, 0.0009, 0.0011, 0.0136, 0.0246, 0.0007, 0.0470, 0.0180, 0.0121,\n",
            "        0.0210, 0.0175, 0.0120, 0.0034, 0.0202, 0.0005, 0.0623, 0.0359, 0.0034,\n",
            "        0.0058, 0.0148, 0.0153, 0.0086, 0.0335, 0.0071, 0.0015, 0.0004, 0.0024,\n",
            "        0.0011, 0.0006, 0.0045, 0.0084, 0.0162, 0.0170, 0.0077, 0.0020, 0.0128,\n",
            "        0.0029, 0.0125, 0.0102, 0.0008, 0.0012, 0.0286, 0.0004, 0.0438, 0.0115,\n",
            "        0.0216, 0.0229, 0.0034, 0.0008, 0.0062, 0.0021, 0.0125, 0.0056, 0.0325,\n",
            "        0.0761, 0.0023, 0.0477], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [7]\n",
            "DEBUGGING: logits looks like: tensor([534.6424, 533.8621, 535.2736, 534.6138, 534.1303, 535.2543, 534.3989,\n",
            "        535.4542, 535.5371, 535.3379, 533.5291, 533.6584, 534.9116, 535.2060,\n",
            "        533.4283, 535.5303, 535.0506, 534.8529, 535.1262, 535.0372, 534.8455,\n",
            "        534.2238, 535.1078, 533.2302, 535.6710, 535.3957, 534.2131, 534.4858,\n",
            "        534.9514, 534.9686, 534.6787, 535.3610, 534.5872, 533.8127, 533.1805,\n",
            "        534.0500, 533.6656, 533.3492, 534.3558, 534.6686, 534.9983, 535.0203,\n",
            "        534.6254, 533.9526, 534.8779, 534.1414, 534.8683, 534.7677, 533.4898,\n",
            "        533.6842, 535.2817, 533.2047, 535.4943, 534.8281, 535.1411, 535.1702,\n",
            "        534.2136, 533.4837, 534.5156, 533.9715, 534.8657, 534.4641, 535.3451,\n",
            "        535.7711, 534.0185, 535.5371], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0104, 0.0143, 0.0060, 0.0127, 0.0198, 0.0066, 0.0114, 0.0161, 0.0110,\n",
            "        0.0162, 0.0081, 0.0141, 0.0098, 0.0107, 0.0153, 0.0095, 0.0169, 0.0128,\n",
            "        0.0111, 0.0172, 0.0129, 0.0125, 0.0191, 0.0075, 0.0156, 0.0099, 0.0096,\n",
            "        0.0151, 0.0095, 0.0104, 0.0088, 0.0110, 0.0151, 0.0115, 0.0155, 0.0139,\n",
            "        0.0124, 0.0134, 0.0081, 0.0156, 0.0167, 0.0110, 0.0132, 0.0096, 0.0138,\n",
            "        0.0133, 0.0214, 0.0074, 0.0127, 0.0099, 0.0133, 0.0175, 0.0115, 0.0099,\n",
            "        0.0166, 0.0258, 0.0116, 0.0212, 0.0207, 0.0145, 0.0147, 0.0082, 0.0086,\n",
            "        0.0076, 0.0152, 0.0073, 0.0109, 0.0095, 0.0103, 0.0137, 0.0117, 0.0094,\n",
            "        0.0099, 0.0131, 0.0210, 0.0095, 0.0102, 0.0089, 0.0115],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [74]\n",
            "DEBUGGING: logits looks like: tensor([534.7621, 534.9232, 534.4850, 534.8629, 535.0858, 534.5369, 534.8111,\n",
            "        534.9818, 534.7933, 534.9840, 534.6405, 534.9167, 534.7354, 534.7780,\n",
            "        534.9584, 534.7203, 535.0065, 534.8690, 534.7984, 535.0149, 534.8707,\n",
            "        534.8564, 535.0681, 534.5981, 534.9662, 534.7390, 534.7223, 534.9493,\n",
            "        534.7194, 534.7626, 534.6787, 534.7941, 534.9512, 534.8152, 534.9619,\n",
            "        534.9095, 534.8503, 534.8894, 534.6369, 534.9669, 534.9993, 534.7909,\n",
            "        534.8817, 534.7260, 534.9058, 534.8850, 535.1235, 534.5925, 534.8649,\n",
            "        534.7402, 534.8850, 535.0233, 534.8120, 534.7415, 534.9984, 535.2177,\n",
            "        534.8187, 535.1210, 535.1083, 534.9305, 534.9376, 534.6439, 534.6661,\n",
            "        534.6041, 534.9530, 534.5873, 534.7883, 534.7181, 534.7592, 534.9006,\n",
            "        534.8229, 534.7138, 534.7406, 534.8776, 535.1158, 534.7203, 534.7543,\n",
            "        534.6838, 534.8159], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0112, 0.0107, 0.0122, 0.0090, 0.0119, 0.0107, 0.0107, 0.0115, 0.0135,\n",
            "        0.0108, 0.0118, 0.0117, 0.0117, 0.0121, 0.0107, 0.0113, 0.0116, 0.0108,\n",
            "        0.0115, 0.0117, 0.0113, 0.0124, 0.0115, 0.0117, 0.0095, 0.0116, 0.0113,\n",
            "        0.0112, 0.0111, 0.0120, 0.0118, 0.0119, 0.0140, 0.0118, 0.0108, 0.0118,\n",
            "        0.0095, 0.0110, 0.0109, 0.0110, 0.0111, 0.0110, 0.0117, 0.0141, 0.0110,\n",
            "        0.0129, 0.0113, 0.0117, 0.0111, 0.0120, 0.0118, 0.0116, 0.0096, 0.0123,\n",
            "        0.0100, 0.0114, 0.0118, 0.0119, 0.0118, 0.0118, 0.0129, 0.0117, 0.0130,\n",
            "        0.0109, 0.0111, 0.0108, 0.0123, 0.0117, 0.0143, 0.0113, 0.0119, 0.0104,\n",
            "        0.0112, 0.0093, 0.0126, 0.0118, 0.0115, 0.0124, 0.0124, 0.0104, 0.0102,\n",
            "        0.0116, 0.0113, 0.0101, 0.0119, 0.0136, 0.0107],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [15]\n",
            "DEBUGGING: logits looks like: tensor([534.5774, 534.5517, 534.6168, 534.4655, 534.6049, 534.5539, 534.5522,\n",
            "        534.5881, 534.6678, 534.5557, 534.6011, 534.5956, 534.5996, 534.6138,\n",
            "        534.5549, 534.5818, 534.5953, 534.5565, 534.5889, 534.5996, 534.5806,\n",
            "        534.6282, 534.5898, 534.5960, 534.4947, 534.5915, 534.5799, 534.5742,\n",
            "        534.5720, 534.6122, 534.6001, 534.6044, 534.6888, 534.6002, 534.5579,\n",
            "        534.6027, 534.4958, 534.5690, 534.5635, 534.5677, 534.5707, 534.5673,\n",
            "        534.5981, 534.6910, 534.5651, 534.6472, 534.5792, 534.5966, 534.5724,\n",
            "        534.6087, 534.6019, 534.5915, 534.4982, 534.6221, 534.5192, 534.5859,\n",
            "        534.6013, 534.6060, 534.6004, 534.6036, 534.6456, 534.5956, 534.6512,\n",
            "        534.5612, 534.5715, 534.5571, 534.6245, 534.5994, 534.6968, 534.5820,\n",
            "        534.6044, 534.5381, 534.5773, 534.4833, 534.6339, 534.6008, 534.5871,\n",
            "        534.6255, 534.6258, 534.5378, 534.5310, 534.5925, 534.5791, 534.5250,\n",
            "        534.6065, 534.6724, 534.5539], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0105, 0.0105, 0.0105, 0.0103, 0.0099, 0.0099, 0.0102, 0.0099, 0.0104,\n",
            "        0.0103, 0.0110, 0.0107, 0.0100, 0.0098, 0.0107, 0.0100, 0.0104, 0.0101,\n",
            "        0.0106, 0.0101, 0.0106, 0.0103, 0.0104, 0.0101, 0.0095, 0.0104, 0.0100,\n",
            "        0.0109, 0.0103, 0.0102, 0.0106, 0.0107, 0.0102, 0.0098, 0.0108, 0.0103,\n",
            "        0.0104, 0.0099, 0.0102, 0.0100, 0.0101, 0.0102, 0.0102, 0.0104, 0.0111,\n",
            "        0.0105, 0.0103, 0.0108, 0.0103, 0.0107, 0.0102, 0.0104, 0.0107, 0.0103,\n",
            "        0.0102, 0.0102, 0.0100, 0.0104, 0.0099, 0.0101, 0.0103, 0.0095, 0.0108,\n",
            "        0.0102, 0.0103, 0.0101, 0.0105, 0.0108, 0.0105, 0.0105, 0.0105, 0.0097,\n",
            "        0.0106, 0.0105, 0.0105, 0.0097, 0.0103, 0.0101, 0.0108, 0.0106, 0.0102,\n",
            "        0.0102, 0.0102, 0.0105, 0.0109, 0.0099, 0.0100, 0.0099, 0.0102, 0.0106,\n",
            "        0.0103, 0.0105, 0.0104, 0.0103, 0.0104, 0.0099, 0.0101],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [71]\n",
            "DEBUGGING: logits looks like: tensor([534.5074, 534.5090, 534.5076, 534.4980, 534.4814, 534.4782, 534.4926,\n",
            "        534.4796, 534.5016, 534.4980, 534.5294, 534.5165, 534.4862, 534.4755,\n",
            "        534.5177, 534.4853, 534.5016, 534.4894, 534.5109, 534.4904, 534.5121,\n",
            "        534.5007, 534.5057, 534.4888, 534.4562, 534.5050, 534.4862, 534.5292,\n",
            "        534.4990, 534.4943, 534.5119, 534.5191, 534.4931, 534.4714, 534.5211,\n",
            "        534.4976, 534.5060, 534.4794, 534.4922, 534.4863, 534.4884, 534.4917,\n",
            "        534.4941, 534.5048, 534.5380, 534.5078, 534.5012, 534.5204, 534.4997,\n",
            "        534.5164, 534.4941, 534.5046, 534.5168, 534.5003, 534.4960, 534.4943,\n",
            "        534.4841, 534.5046, 534.4810, 534.4872, 534.4987, 534.4561, 534.5236,\n",
            "        534.4950, 534.4998, 534.4909, 534.5066, 534.5219, 534.5092, 534.5071,\n",
            "        534.5065, 534.4704, 534.5109, 534.5081, 534.5095, 534.4706, 534.4998,\n",
            "        534.4913, 534.5217, 534.5134, 534.4941, 534.4922, 534.4948, 534.5090,\n",
            "        534.5281, 534.4777, 534.4827, 534.4810, 534.4949, 534.5122, 534.4994,\n",
            "        534.5085, 534.5028, 534.4996, 534.5056, 534.4788, 534.4913],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0092, 0.0093, 0.0092, 0.0094, 0.0095, 0.0094, 0.0094, 0.0093, 0.0093,\n",
            "        0.0093, 0.0095, 0.0090, 0.0093, 0.0097, 0.0093, 0.0093, 0.0094, 0.0092,\n",
            "        0.0093, 0.0090, 0.0095, 0.0095, 0.0091, 0.0093, 0.0092, 0.0092, 0.0093,\n",
            "        0.0092, 0.0096, 0.0094, 0.0091, 0.0094, 0.0094, 0.0096, 0.0092, 0.0094,\n",
            "        0.0094, 0.0092, 0.0092, 0.0097, 0.0095, 0.0095, 0.0094, 0.0101, 0.0093,\n",
            "        0.0094, 0.0095, 0.0094, 0.0094, 0.0095, 0.0095, 0.0096, 0.0094, 0.0094,\n",
            "        0.0091, 0.0095, 0.0090, 0.0093, 0.0094, 0.0096, 0.0096, 0.0095, 0.0095,\n",
            "        0.0094, 0.0096, 0.0092, 0.0098, 0.0094, 0.0091, 0.0094, 0.0092, 0.0094,\n",
            "        0.0091, 0.0092, 0.0092, 0.0095, 0.0092, 0.0094, 0.0090, 0.0093, 0.0091,\n",
            "        0.0095, 0.0093, 0.0092, 0.0091, 0.0096, 0.0094, 0.0095, 0.0093, 0.0094,\n",
            "        0.0093, 0.0095, 0.0091, 0.0094, 0.0091, 0.0090, 0.0092, 0.0093, 0.0093,\n",
            "        0.0093, 0.0093, 0.0094, 0.0093, 0.0097, 0.0092, 0.0088, 0.0093],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [78]\n",
            "DEBUGGING: logits looks like: tensor([534.4372, 534.4421, 534.4341, 534.4446, 534.4531, 534.4433, 534.4456,\n",
            "        534.4423, 534.4428, 534.4404, 534.4522, 534.4267, 534.4423, 534.4601,\n",
            "        534.4427, 534.4410, 534.4444, 534.4363, 534.4393, 534.4239, 534.4498,\n",
            "        534.4506, 534.4294, 534.4412, 534.4359, 534.4339, 534.4428, 534.4361,\n",
            "        534.4545, 534.4481, 534.4301, 534.4482, 534.4483, 534.4567, 534.4337,\n",
            "        534.4442, 534.4456, 534.4356, 534.4374, 534.4607, 534.4532, 534.4518,\n",
            "        534.4472, 534.4801, 534.4399, 534.4440, 534.4489, 534.4442, 534.4461,\n",
            "        534.4504, 534.4507, 534.4547, 534.4473, 534.4466, 534.4321, 534.4492,\n",
            "        534.4228, 534.4398, 534.4442, 534.4540, 534.4573, 534.4487, 534.4518,\n",
            "        534.4484, 534.4540, 534.4360, 534.4664, 534.4485, 534.4308, 534.4469,\n",
            "        534.4368, 534.4441, 534.4297, 534.4325, 534.4361, 534.4500, 534.4355,\n",
            "        534.4440, 534.4234, 534.4409, 534.4290, 534.4520, 534.4420, 534.4337,\n",
            "        534.4297, 534.4565, 534.4451, 534.4504, 534.4412, 534.4467, 534.4386,\n",
            "        534.4501, 534.4272, 534.4446, 534.4315, 534.4249, 534.4361, 534.4421,\n",
            "        534.4417, 534.4424, 534.4425, 534.4471, 534.4380, 534.4599, 534.4371,\n",
            "        534.4137, 534.4410], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.10455122058510824 and immediate abs rewards look like: [0.0011477767807264172, 0.013573219247973611, 0.0008757837440498406, 0.0001798492407942831, 0.0013010943171138933, 0.0011647232495306525, 0.014266391472574469, 0.0009400461017321504, 0.004301480645153788, 0.00013035676784056704, 0.0023792131923983106, 0.010861064383789198, 0.0012330458480391826, 0.0016428696394541475, 0.0023167359463514003, 0.0007066628295433475, 0.0010346222861699061, 0.0013319775684976776, 0.011852354671191279, 0.0007586347860524256, 0.005472905928854743, 0.008334703143646038, 0.001051479576744896, 0.0005956188792879402, 0.0004513126568781445, 0.0003449281261964643, 0.004390987559872883, 0.00017984794249059632, 0.0003051677435905731, 0.0007696726529502484, 0.0009705997176752135, 0.0022668510487164895, 0.0020743072541336005, 0.00019153290804752032, 7.786904006934492e-05, 0.00028137073923062417, 2.260894780192757e-05, 0.0004800501833415183, 3.356738307047635e-05, 0.0005030960228395998, 1.0533756267250283e-05, 0.0003404480657991371, 6.395149102900177e-05, 0.00041809303638729034, 0.0001429050748811278, 0.0010249858223687625, 0.0007932420367069426, 3.3984080801019445e-05, 8.009103612494073e-05, 0.0008466060103273776]\n",
            "DEBUGGING: the total relative reward of the trajectory = 5.389979963215367 and immediate relative rewards look like: [0.0037009404966609704, 0.08756454337921823, 0.008512148201755653, 0.002331379028498522, 0.021083775491564826, 0.022658270842157918, 0.32391345067093896, 0.024505876219512068, 0.12618991077034322, 0.0042550737366024655, 0.08543149987188778, 0.4257778324437601, 0.05255277718715307, 0.07543620526525924, 0.11403825529844341, 0.037131739832574416, 0.05777562050813613, 0.07878270843468563, 0.7403035895631981, 0.0500737164329494, 0.379396309938246, 0.6063927062079998, 0.08019892397666929, 0.04742103423444514, 0.03743645063693582, 0.029760768401283992, 0.39347565598496337, 0.0167374298095257, 0.029416286690080874, 0.0767578127680702, 0.10004796679396588, 0.24127901992289535, 0.2278563854484374, 0.021691843874867642, 0.009078931184793308, 0.03374384418423477, 0.002786993202640867, 0.060775332292526796, 0.004362231020915444, 0.06705671946223433, 0.0014393664043143327, 0.04765472041539742, 0.009165880142467341, 0.06131827262050287, 0.021438035922888198, 0.1571886590096223, 0.12433618218574245, 0.005441587535327731, 0.013091631438340235, 0.14121366782973224]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 200 number of matrices\n",
            "DEBUGGING: ACT_MAT has 200 number of matrices\n",
            "DEBUGGING: VAL looks like: [[44.183519078002085, 44.54636280615338, 44.900974557406, 45.05137025347721, 45.2005413636167, 45.65687790258605, 46.09857614599067, 46.55199483958135, 47.01838572629918, 47.48923638250061, 47.833900925618046, 48.22636536481441, 48.70292550893322, 49.07440833633191, 49.38161271412014, 49.79133777195169, 50.290878524017124, 50.7618271288002, 51.27246915169035, 51.76166072822121, 52.267918437080404, 52.79567147033686, 53.327847440008526, 53.84595366364199, 54.3725418947643, 54.8511424237667, 55.36238778226485, 55.86398496291148, 56.42269510916057, 56.944333110832765, 57.51758883812702, 58.08644315204316, 58.6411814213329, 59.22893625905551, 59.81224486109829, 60.37834383739463, 60.97825217217435, 61.57323298000437, 62.178006213891855, 5.251560789463425e-10, 4.692152513415537e-10, 4.739547993349027e-10, 4.787422215504068e-10, 4.835780015660674e-10, 4.210926499354067e-10, 3.5644499727519944e-10, 2.8961320216088376e-10, 2.2057520254746828e-10, 1.4930871354104447e-10, 7.579122514774402e-11], [8.975588409372316, 9.017748791232643, 8.95951505278391, 1.494476689648159e-09, 1.5095724137860193e-09, 1.5133371010240986e-09, 1.5148431116136442e-09, 1.514067630639008e-09, 1.5109876127308622e-09, 1.5262501138695578e-09, 1.4727656679157456e-09, 1.4623783470878515e-09, 1.4220289545267182e-09, 1.4363928833603214e-09, 1.450901902384163e-09, 1.4311069202703821e-09, 1.4088152850499562e-09, 1.3449578135345678e-09, 1.3585432459945129e-09, 1.3286285329902007e-09, 1.2501808715282107e-09, 1.2628089611396068e-09, 1.2250371237798832e-09, 1.184587048917111e-09, 1.0863107926306913e-09, 1.03986603411098e-09, 1.0503697314252324e-09, 1.060979526692154e-09, 1.0073887854222716e-09, 8.843556097628556e-10, 7.554862671685711e-10, 6.919196240213991e-10, 6.989087111327264e-10, 7.059683950835621e-10, 7.130993889732951e-10, 6.399177803718827e-10, 5.637002598104421e-10, 5.693942018287294e-10, 4.878709143033346e-10, 4.927989033367016e-10, 4.977766700370723e-10, 5.02804717209164e-10, 5.078835527365293e-10, 3.1549716349029714e-10, 3.1868400352555266e-10, 3.219030338641946e-10, 2.1950620521240814e-10, 2.2172343960849307e-10, 2.2396307031160917e-10, 1.1368683772164188e-10], [1.68341029019169, 1.4172314073313343e-09, 1.425422332645976e-09, 1.4352271304415261e-09, 1.4466621024602189e-09, 1.461274850969918e-09, 1.4668483878304937e-09, 1.4548701606351306e-09, 1.4328185581456786e-09, 1.4335112501202844e-09, 1.4403354824298076e-09, 1.438041831209398e-09, 1.4433806911026971e-09, 1.4480079109429204e-09, 1.4411983514157093e-09, 1.4213053536355751e-09, 1.423412886476704e-09, 1.424776139597563e-09, 1.4116073722670478e-09, 1.4258660325929776e-09, 1.4096460025594725e-09, 1.4078079245236845e-09, 1.4220282065895802e-09, 1.418784065460201e-09, 1.4147415872977212e-09, 1.3907535098220698e-09, 1.3848967588723771e-09, 1.3368746126289802e-09, 1.3503783965949296e-09, 1.3418171124263472e-09, 1.3324037827091134e-09, 1.27466458921385e-09, 1.2630418153197642e-09, 1.2252723300224702e-09, 1.2116195085578154e-09, 1.1434734567198892e-09, 1.0999028026399043e-09, 1.0826869185204436e-09, 1.0354399872809635e-09, 1.0160418277508542e-09, 9.650594420531909e-10, 9.120309469010608e-10, 8.890895276151599e-10, 8.651508088905328e-10, 7.391497501318011e-10, 6.777147954533756e-10, 6.141281498156072e-10, 4.764046934725961e-10, 2.974805587050332e-10, 3.789561257387201e-11], [4.341036092409484, 4.38114661809376, 4.33695159062075, 4.372161052948479, 4.41396936759594, 4.437258173842803, 4.459191821212773, 4.177048859133166, 4.194487861528943, 4.109391869453131, 4.14660282395609, 4.102193256650709, 3.713550933542373, 3.697977935712343, 3.6591330610576605, 3.580903844201229, 3.5795677821905603, 3.557365819881236, 3.5137203145924754, 2.8014310353831084, 2.7791488070203627, 2.4239924212950674, 1.835959308168755, 1.7734953375677633, 1.743509397306382, 1.7233060067368144, 1.7106517558944754, 1.3304809089995069, 1.3270136153434153, 1.3107043723771055, 1.246410666271753, 1.1579421206846332, 0.9259223240017553, 0.7051171096498162, 0.6903285512878268, 0.6881309293970035, 0.6609970557704734, 0.6648586490584167, 0.6101851684503938, 0.6119423610398771, 0.5503895369471139, 0.5544951217604036, 0.5119600013585921, 0.5078728497132573, 0.4510652293866207, 0.4339668620845783, 0.27957394249995554, 0.15680581849920514, 0.15289316258977517, 0.14121366782973224]]\n",
            "DEBUGGING: traj_returns = [44.183519078002085, 8.975588409372316, 1.68341029019169, 4.341036092409484]\n",
            "DEBUGGING: actions = [[12], [22], [5], [2], [29], [12], [58], [27], [23], [39], [20], [2], [45], [28], [54], [2], [1], [2], [6], [69], [76], [14], [24], [54], [76], [35], [18], [70], [50], [43], [17], [23], [22], [57], [18], [3], [17], [61], [0], [42], [52], [30], [3], [86], [91], [47], [16], [88], [35], [105], [7], [38], [0], [59], [50], [31], [34], [46], [18], [3], [45], [68], [52], [53], [4], [17], [0], [11], [70], [56], [60], [36], [14], [76], [49], [28], [14], [34], [14], [74], [85], [12], [21], [33], [26], [23], [86], [66], [0], [8], [94], [9], [41], [97], [102], [90], [76], [42], [29], [9], [0], [39], [17], [57], [16], [15], [38], [56], [31], [0], [38], [17], [39], [12], [70], [68], [30], [57], [6], [11], [75], [64], [24], [42], [10], [24], [12], [70], [66], [34], [12], [20], [87], [80], [61], [87], [51], [16], [91], [91], [7], [60], [16], [49], [77], [44], [55], [94], [8], [99], [8], [13], [54], [22], [36], [4], [30], [5], [8], [7], [67], [16], [46], [50], [38], [53], [17], [56], [55], [74], [40], [24], [49], [63], [25], [71], [35], [83], [5], [15], [35], [55], [67], [32], [31], [80], [88], [64], [36], [71], [39], [68], [79], [4], [62], [0], [75], [66], [60], [78]]\n",
            "DEBUGGING: actions length = 200\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[ 8.0375,  7.3366,  6.8424,  ..., -6.0717, -6.5408, -9.5747],\n",
            "        [ 8.0424,  7.3550,  6.8490,  ..., -6.0887, -6.5532, -9.5931],\n",
            "        [ 8.0149,  7.3575,  6.8282,  ..., -6.0759, -6.5231, -9.5626],\n",
            "        ...,\n",
            "        [ 7.9703,  7.2912,  6.7812,  ..., -6.0277, -6.4781, -9.5009],\n",
            "        [ 7.9708,  7.2917,  6.7816,  ..., -6.0281, -6.4785, -9.5014],\n",
            "        [ 7.9706,  7.2915,  6.7815,  ..., -6.0280, -6.4784, -9.5013]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[ 7.9705,  7.2914,  6.7813,  ..., -6.0279, -6.4782, -9.5010],\n",
            "        [ 7.9705,  7.2914,  6.7814,  ..., -6.0279, -6.4783, -9.5011],\n",
            "        [ 7.9704,  7.2913,  6.7813,  ..., -6.0278, -6.4782, -9.5010],\n",
            "        ...,\n",
            "        [ 7.9705,  7.2914,  6.7813,  ..., -6.0279, -6.4782, -9.5010],\n",
            "        [ 7.9701,  7.2911,  6.7810,  ..., -6.0276, -6.4779, -9.5006],\n",
            "        [ 7.9705,  7.2914,  6.7814,  ..., -6.0279, -6.4783, -9.5011]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([534.4372, 534.4421, 534.4341, 534.4446, 534.4531, 534.4433, 534.4456,\n",
            "        534.4423, 534.4428, 534.4404, 534.4522, 534.4267, 534.4423, 534.4601,\n",
            "        534.4427, 534.4410, 534.4444, 534.4363, 534.4393, 534.4239, 534.4498,\n",
            "        534.4506, 534.4294, 534.4412, 534.4359, 534.4339, 534.4428, 534.4361,\n",
            "        534.4545, 534.4481, 534.4301, 534.4482, 534.4483, 534.4567, 534.4337,\n",
            "        534.4442, 534.4456, 534.4356, 534.4374, 534.4607, 534.4532, 534.4518,\n",
            "        534.4472, 534.4801, 534.4399, 534.4440, 534.4489, 534.4442, 534.4461,\n",
            "        534.4504, 534.4507, 534.4547, 534.4473, 534.4466, 534.4321, 534.4492,\n",
            "        534.4228, 534.4398, 534.4442, 534.4540, 534.4573, 534.4487, 534.4518,\n",
            "        534.4484, 534.4540, 534.4360, 534.4664, 534.4485, 534.4308, 534.4469,\n",
            "        534.4368, 534.4441, 534.4297, 534.4325, 534.4361, 534.4500, 534.4355,\n",
            "        534.4440, 534.4234, 534.4409, 534.4290, 534.4520, 534.4420, 534.4337,\n",
            "        534.4297, 534.4565, 534.4451, 534.4504, 534.4412, 534.4467, 534.4386,\n",
            "        534.4501, 534.4272, 534.4446, 534.4315, 534.4249, 534.4361, 534.4421,\n",
            "        534.4417, 534.4424, 534.4425, 534.4471, 534.4380, 534.4599, 534.4371,\n",
            "        534.4137, 534.4410], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[14.79588847 14.48631455 14.5493603  12.35588283 12.40362768 12.52353402\n",
            "  12.63944199 12.68226093 12.8032184  12.89965706 12.99512594 13.08213966\n",
            "  13.10411911 13.19309657 13.26018644 13.3430604  13.46761158 13.57979824\n",
            "  13.69654737 13.64077294 13.76176681 13.80491597 13.79095169 13.90486225\n",
            "  14.02901282 14.14361211 14.26825989 14.29861647 14.43742718 14.56375937\n",
            "  14.69099988 14.81109632 14.89177594 14.98351334 15.12564335 15.26661869\n",
            "  15.40981231 15.55952291 15.69704785  0.15298559  0.13759738  0.13862378\n",
            "   0.12799     0.12696821  0.11276631  0.10849172  0.06989349  0.03920145\n",
            "   0.03822329  0.03530342]]\n",
            "DEBUGGING: baseline2 looks like: 14.795888467493892\n",
            "DEBUGGING: ADS looks like: [ 2.93876306e+01  3.00600483e+01  3.03516143e+01  3.26954874e+01\n",
            "  3.27969137e+01  3.31333439e+01  3.34591342e+01  3.38697339e+01\n",
            "  3.42151673e+01  3.45895793e+01  3.48387750e+01  3.51442257e+01\n",
            "  3.55988064e+01  3.58813118e+01  3.61214263e+01  3.64482774e+01\n",
            "  3.68232669e+01  3.71820289e+01  3.75759218e+01  3.81208878e+01\n",
            "  3.85061516e+01  3.89907555e+01  3.95368958e+01  3.99410914e+01\n",
            "  4.03435291e+01  4.07075303e+01  4.10941279e+01  4.15653685e+01\n",
            "  4.19852679e+01  4.23805737e+01  4.28265890e+01  4.32753468e+01\n",
            "  4.37494055e+01  4.42454229e+01  4.46866015e+01  4.51117251e+01\n",
            "  4.55684399e+01  4.60137101e+01  4.64809584e+01 -1.52985590e-01\n",
            " -1.37597384e-01 -1.38623780e-01 -1.27990000e-01 -1.26968212e-01\n",
            " -1.12766307e-01 -1.08491716e-01 -6.98934856e-02 -3.92014546e-02\n",
            " -3.82232907e-02 -3.53034169e-02 -5.82030006e+00 -5.46856576e+00\n",
            " -5.58984525e+00 -1.23558828e+01 -1.24036277e+01 -1.25235340e+01\n",
            " -1.26394420e+01 -1.26822609e+01 -1.28032184e+01 -1.28996571e+01\n",
            " -1.29951259e+01 -1.30821397e+01 -1.31041191e+01 -1.31930966e+01\n",
            " -1.32601864e+01 -1.33430604e+01 -1.34676116e+01 -1.35797982e+01\n",
            " -1.36965474e+01 -1.36407729e+01 -1.37617668e+01 -1.38049160e+01\n",
            " -1.37909517e+01 -1.39048622e+01 -1.40290128e+01 -1.41436121e+01\n",
            " -1.42682599e+01 -1.42986165e+01 -1.44374272e+01 -1.45637594e+01\n",
            " -1.46909999e+01 -1.48110963e+01 -1.48917759e+01 -1.49835133e+01\n",
            " -1.51256434e+01 -1.52666187e+01 -1.54098123e+01 -1.55595229e+01\n",
            " -1.56970478e+01 -1.52985590e-01 -1.37597384e-01 -1.38623780e-01\n",
            " -1.27990000e-01 -1.26968213e-01 -1.12766307e-01 -1.08491716e-01\n",
            " -6.98934857e-02 -3.92014546e-02 -3.82232906e-02 -3.53034169e-02\n",
            " -1.31124782e+01 -1.44863146e+01 -1.45493603e+01 -1.23558828e+01\n",
            " -1.24036277e+01 -1.25235340e+01 -1.26394420e+01 -1.26822609e+01\n",
            " -1.28032184e+01 -1.28996571e+01 -1.29951259e+01 -1.30821397e+01\n",
            " -1.31041191e+01 -1.31930966e+01 -1.32601864e+01 -1.33430604e+01\n",
            " -1.34676116e+01 -1.35797982e+01 -1.36965474e+01 -1.36407729e+01\n",
            " -1.37617668e+01 -1.38049160e+01 -1.37909517e+01 -1.39048622e+01\n",
            " -1.40290128e+01 -1.41436121e+01 -1.42682599e+01 -1.42986165e+01\n",
            " -1.44374272e+01 -1.45637594e+01 -1.46909999e+01 -1.48110963e+01\n",
            " -1.48917759e+01 -1.49835133e+01 -1.51256434e+01 -1.52666187e+01\n",
            " -1.54098123e+01 -1.55595229e+01 -1.56970478e+01 -1.52985590e-01\n",
            " -1.37597384e-01 -1.38623780e-01 -1.27990000e-01 -1.26968212e-01\n",
            " -1.12766307e-01 -1.08491715e-01 -6.98934853e-02 -3.92014544e-02\n",
            " -3.82232905e-02 -3.53034170e-02 -1.04548524e+01 -1.01051679e+01\n",
            " -1.02124087e+01 -7.98372177e+00 -7.98965832e+00 -8.08627585e+00\n",
            " -8.18025017e+00 -8.50521207e+00 -8.60873054e+00 -8.79026519e+00\n",
            " -8.84852311e+00 -8.97994640e+00 -9.39056818e+00 -9.49511863e+00\n",
            " -9.60105338e+00 -9.76215656e+00 -9.88804380e+00 -1.00224324e+01\n",
            " -1.01828271e+01 -1.08393419e+01 -1.09826180e+01 -1.13809236e+01\n",
            " -1.19549924e+01 -1.21313669e+01 -1.22855034e+01 -1.24203061e+01\n",
            " -1.25576081e+01 -1.29681356e+01 -1.31104136e+01 -1.32530550e+01\n",
            " -1.34445892e+01 -1.36531542e+01 -1.39658536e+01 -1.42783962e+01\n",
            " -1.44353148e+01 -1.45784878e+01 -1.47488153e+01 -1.48946643e+01\n",
            " -1.50868627e+01  4.58956770e-01  4.12792152e-01  4.15871341e-01\n",
            "  3.83970001e-01  3.80904637e-01  3.38298922e-01  3.25475146e-01\n",
            "  2.09680457e-01  1.17604364e-01  1.14669872e-01  1.05910251e-01]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(2.2209, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-0.0063, -0.0092, -0.0065,  ...,  0.0192,  0.0161,  0.0562],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0083, -0.0121, -0.0087,  ...,  0.0253,  0.0213,  0.0743],\n",
            "        [-0.0053, -0.0077, -0.0055,  ...,  0.0161,  0.0136,  0.0467]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0173,  0.0105,  0.0000,  0.0232,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0254,\n",
            "          0.0000,  0.0249,  0.0291,  0.0052],\n",
            "        [ 0.0163,  0.0098,  0.0000,  0.0218,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0240,\n",
            "          0.0000,  0.0235,  0.0275,  0.0049],\n",
            "        [ 0.0151,  0.0092,  0.0000,  0.0202,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0222,\n",
            "          0.0000,  0.0218,  0.0255,  0.0045],\n",
            "        [-0.0058, -0.0034,  0.0000, -0.0077,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0085,\n",
            "          0.0000, -0.0085, -0.0099, -0.0018],\n",
            "        [-0.0036, -0.0022,  0.0000, -0.0049,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0054,\n",
            "          0.0000, -0.0052, -0.0061, -0.0011],\n",
            "        [ 0.0146,  0.0087,  0.0000,  0.0194,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0214,\n",
            "          0.0000,  0.0210,  0.0246,  0.0044],\n",
            "        [-0.0283, -0.0171,  0.0000, -0.0378,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0416,\n",
            "          0.0000, -0.0409, -0.0478, -0.0085],\n",
            "        [-0.0146, -0.0087,  0.0000, -0.0194,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0214,\n",
            "          0.0000, -0.0212, -0.0247, -0.0044],\n",
            "        [-0.0148, -0.0089,  0.0000, -0.0197,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0217,\n",
            "          0.0000, -0.0214, -0.0250, -0.0045],\n",
            "        [-0.0216, -0.0130,  0.0000, -0.0289,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0318,\n",
            "          0.0000, -0.0312, -0.0365, -0.0065]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-0.0147, -0.0849,  0.0639,  ..., -0.1631,  0.0928,  0.0785],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0197, -0.1133,  0.0853,  ..., -0.2175,  0.1238,  0.1054],\n",
            "        [-0.0119, -0.0686,  0.0517,  ..., -0.1317,  0.0750,  0.0696]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0364,  0.0089,  0.0000,  0.0160,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0500,\n",
            "          0.0000,  0.0490,  0.0700,  0.0267],\n",
            "        [ 0.0236,  0.0035,  0.0000,  0.0029,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0317,\n",
            "          0.0000,  0.0298,  0.0470,  0.0212],\n",
            "        [ 0.0340,  0.0090,  0.0000,  0.0173,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0468,\n",
            "          0.0000,  0.0464,  0.0648,  0.0237],\n",
            "        [-0.0036,  0.0007,  0.0000,  0.0037,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0046,\n",
            "          0.0000, -0.0035, -0.0082, -0.0054],\n",
            "        [-0.0074, -0.0015,  0.0000, -0.0024,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0100,\n",
            "          0.0000, -0.0097, -0.0143, -0.0058],\n",
            "        [ 0.0243,  0.0049,  0.0000,  0.0071,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0331,\n",
            "          0.0000,  0.0318,  0.0475,  0.0197],\n",
            "        [-0.0476, -0.0096,  0.0000, -0.0139,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0647,\n",
            "          0.0000, -0.0622, -0.0930, -0.0386],\n",
            "        [-0.0176, -0.0020,  0.0000, -0.0001,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0235,\n",
            "          0.0000, -0.0217, -0.0356, -0.0169],\n",
            "        [-0.0253, -0.0052,  0.0000, -0.0079,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0345,\n",
            "          0.0000, -0.0332, -0.0494, -0.0203],\n",
            "        [-0.0328, -0.0056,  0.0000, -0.0063,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0444,\n",
            "          0.0000, -0.0420, -0.0650, -0.0283]])\n",
            "DEBUGGING: training for one iteration takes 0.007243 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 20\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([0.0225, 0.0199, 0.0174, 0.0003, 0.0130, 0.0164, 0.0109, 0.0108, 0.0124,\n",
            "        0.0107, 0.0232, 0.0103, 0.0141, 0.0190, 0.0133, 0.0223, 0.0154, 0.0095,\n",
            "        0.0165, 0.0160, 0.0131, 0.0169, 0.0166, 0.0192, 0.0169, 0.0167, 0.0149,\n",
            "        0.0225, 0.0132, 0.0167, 0.0171, 0.0145, 0.0214, 0.0039, 0.0087, 0.0026,\n",
            "        0.0099, 0.0218, 0.0107, 0.0173, 0.0113, 0.0182, 0.0152, 0.0171, 0.0113,\n",
            "        0.0148, 0.0124, 0.0206, 0.0119, 0.0142, 0.0179, 0.0099, 0.0102, 0.0133,\n",
            "        0.0169, 0.0096, 0.0145, 0.0150, 0.0162, 0.0137, 0.0118, 0.0067, 0.0151,\n",
            "        0.0197, 0.0083, 0.0143, 0.0155, 0.0177, 0.0053, 0.0130],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [26]\n",
            "DEBUGGING: logits looks like: tensor([559.5876, 559.5278, 559.4590, 557.3746, 559.3140, 559.4302, 559.2252,\n",
            "        559.2233, 559.2892, 559.2166, 559.6035, 559.1954, 559.3553, 559.5028,\n",
            "        559.3254, 559.5840, 559.3986, 559.1561, 559.4335, 559.4185, 559.3159,\n",
            "        559.4451, 559.4373, 559.5084, 559.4455, 559.4399, 559.3815, 559.5872,\n",
            "        559.3232, 559.4396, 559.4515, 559.3670, 559.5634, 558.7076, 559.1136,\n",
            "        558.5086, 559.1788, 559.5727, 559.2157, 559.4564, 559.2421, 559.4834,\n",
            "        559.3932, 559.4518, 559.2424, 559.3804, 559.2911, 559.5438, 559.2714,\n",
            "        559.3595, 559.4729, 559.1769, 559.1942, 559.3245, 559.4452, 559.1628,\n",
            "        559.3679, 559.3856, 559.4250, 559.3407, 559.2670, 558.9789, 559.3879,\n",
            "        559.5226, 559.0894, 559.3603, 559.4019, 559.4670, 558.8636, 559.3121],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.7310e-04, 1.4934e-02, 2.8994e-02, 1.0927e-02, 5.3170e-03, 9.3157e-03,\n",
            "        1.6300e-02, 2.3245e-04, 4.2712e-04, 1.4072e-06, 4.8862e-04, 3.3042e-03,\n",
            "        3.7698e-03, 1.1746e-03, 5.4908e-05, 1.8307e-05, 1.7971e-03, 4.6091e-05,\n",
            "        7.3039e-03, 1.5191e-03, 9.9065e-04, 3.8861e-04, 2.9760e-03, 4.3961e-03,\n",
            "        3.0343e-03, 4.6078e-02, 2.9385e-03, 5.5749e-03, 1.1744e-04, 1.0734e-03,\n",
            "        6.6847e-02, 7.8436e-03, 3.7146e-03, 6.4314e-04, 5.1737e-02, 8.2977e-03,\n",
            "        1.4395e-03, 2.0750e-04, 2.9620e-01, 2.8922e-03, 8.2419e-04, 2.0950e-02,\n",
            "        6.8897e-04, 4.9707e-02, 1.1796e-03, 9.1755e-04, 1.5600e-03, 3.1641e-03,\n",
            "        1.1165e-03, 4.5807e-03, 1.1202e-05, 3.7635e-02, 1.6210e-04, 1.4381e-01,\n",
            "        5.1027e-03, 2.4358e-03, 6.0017e-06, 6.2970e-04, 2.9851e-03, 2.0697e-03,\n",
            "        2.6154e-04, 5.6420e-03, 1.3774e-03, 1.5654e-03, 3.9764e-03, 6.6649e-03,\n",
            "        2.2776e-03, 2.2508e-03, 1.8134e-03, 4.0189e-03, 1.5447e-03, 2.7487e-03,\n",
            "        1.1794e-04, 5.9364e-04, 6.7264e-02, 2.8125e-03, 1.7873e-03, 2.5377e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [74]\n",
            "DEBUGGING: logits looks like: tensor([557.3110, 559.5397, 559.8715, 559.3835, 559.0234, 559.3038, 559.5835,\n",
            "        557.4584, 557.7626, 554.9048, 557.8298, 558.7855, 558.8514, 558.2684,\n",
            "        556.7369, 556.1877, 558.4810, 556.6494, 559.1821, 558.3970, 558.1832,\n",
            "        557.7153, 558.7332, 558.9283, 558.7429, 560.1031, 558.7269, 559.0471,\n",
            "        557.1170, 558.2233, 560.2891, 559.2178, 558.8441, 557.9672, 560.1610,\n",
            "        559.2459, 558.3701, 557.4016, 561.0334, 558.7189, 558.0912, 559.7090,\n",
            "        558.0016, 560.1410, 558.2705, 558.1449, 558.4103, 558.7639, 558.2430,\n",
            "        558.9489, 555.9421, 560.0019, 557.2781, 560.6722, 559.0028, 558.6331,\n",
            "        555.6301, 557.9567, 558.7347, 558.5516, 557.5173, 559.0530, 558.3480,\n",
            "        558.4120, 558.8781, 559.1364, 558.5995, 558.5936, 558.4855, 558.8834,\n",
            "        558.4053, 558.6935, 557.1191, 557.9272, 560.2922, 558.7050, 558.4783,\n",
            "        557.5023], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0145, 0.0150, 0.0152, 0.0127, 0.0124, 0.0133, 0.0095, 0.0009, 0.0122,\n",
            "        0.0102, 0.0076, 0.0094, 0.0171, 0.0081, 0.0124, 0.0128, 0.0119, 0.0061,\n",
            "        0.0050, 0.0135, 0.0109, 0.0129, 0.0142, 0.0134, 0.0118, 0.0180, 0.0122,\n",
            "        0.0142, 0.0152, 0.0127, 0.0145, 0.0081, 0.0118, 0.0078, 0.0134, 0.0093,\n",
            "        0.0068, 0.0151, 0.0148, 0.0157, 0.0075, 0.0026, 0.0067, 0.0117, 0.0154,\n",
            "        0.0115, 0.0104, 0.0100, 0.0079, 0.0102, 0.0074, 0.0079, 0.0115, 0.0054,\n",
            "        0.0202, 0.0113, 0.0091, 0.0118, 0.0098, 0.0106, 0.0094, 0.0143, 0.0116,\n",
            "        0.0089, 0.0094, 0.0093, 0.0154, 0.0127, 0.0093, 0.0121, 0.0134, 0.0084,\n",
            "        0.0075, 0.0161, 0.0140, 0.0098, 0.0109, 0.0138, 0.0127, 0.0084, 0.0133,\n",
            "        0.0139, 0.0109, 0.0105, 0.0112, 0.0109, 0.0116, 0.0090, 0.0098],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [1]\n",
            "DEBUGGING: logits looks like: tensor([559.9288, 559.9465, 559.9523, 559.8618, 559.8525, 559.8870, 559.7191,\n",
            "        558.5601, 559.8415, 559.7546, 559.6077, 559.7118, 560.0122, 559.6351,\n",
            "        559.8529, 559.8661, 559.8303, 559.4972, 559.3934, 559.8952, 559.7881,\n",
            "        559.8698, 559.9185, 559.8884, 559.8245, 560.0367, 559.8423, 559.9196,\n",
            "        559.9540, 559.8642, 559.9277, 559.6379, 559.8256, 559.6165, 559.8899,\n",
            "        559.7073, 559.5499, 559.9498, 559.9411, 559.9681, 559.5973, 559.0722,\n",
            "        559.5403, 559.8223, 559.9589, 559.8151, 559.7643, 559.7417, 559.6265,\n",
            "        559.7544, 559.5958, 559.6271, 559.8154, 559.4312, 560.0947, 559.8047,\n",
            "        559.6955, 559.8266, 559.7324, 559.7713, 559.7118, 559.9233, 559.8185,\n",
            "        559.6832, 559.7126, 559.7084, 559.9601, 559.8636, 559.7084, 559.8381,\n",
            "        559.8892, 559.6548, 559.5964, 559.9802, 559.9107, 559.7358, 559.7846,\n",
            "        559.9037, 559.8647, 559.6537, 559.8849, 559.9078, 559.7854, 559.7670,\n",
            "        559.8019, 559.7872, 559.8197, 559.6890, 559.7356],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0108, 0.0156, 0.0107, 0.0152, 0.0121, 0.0024, 0.0049, 0.0103, 0.0053,\n",
            "        0.0074, 0.0176, 0.0166, 0.0108, 0.0100, 0.0117, 0.0118, 0.0067, 0.0106,\n",
            "        0.0170, 0.0134, 0.0111, 0.0152, 0.0061, 0.0181, 0.0098, 0.0153, 0.0164,\n",
            "        0.0034, 0.0078, 0.0014, 0.0069, 0.0048, 0.0091, 0.0056, 0.0066, 0.0134,\n",
            "        0.0165, 0.0098, 0.0046, 0.0126, 0.0100, 0.0061, 0.0022, 0.0092, 0.0109,\n",
            "        0.0114, 0.0131, 0.0160, 0.0176, 0.0156, 0.0091, 0.0056, 0.0059, 0.0169,\n",
            "        0.0205, 0.0289, 0.0059, 0.0153, 0.0089, 0.0182, 0.0056, 0.0056, 0.0009,\n",
            "        0.0112, 0.0096, 0.0028, 0.0109, 0.0096, 0.0025, 0.0072, 0.0135, 0.0059,\n",
            "        0.0156, 0.0061, 0.0114, 0.0156, 0.0107, 0.0112, 0.0079, 0.0115, 0.0154,\n",
            "        0.0152, 0.0023, 0.0093, 0.0081, 0.0043, 0.0054, 0.0149, 0.0111, 0.0082,\n",
            "        0.0086, 0.0095, 0.0067, 0.0065, 0.0078, 0.0093, 0.0084, 0.0107],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [1]\n",
            "DEBUGGING: logits looks like: tensor([560.7363, 560.9199, 560.7308, 560.9069, 560.7913, 559.9803, 560.3426,\n",
            "        560.7125, 560.3828, 560.5452, 560.9794, 560.9492, 560.7327, 560.6945,\n",
            "        560.7743, 560.7789, 560.4967, 560.7244, 560.9619, 560.8408, 560.7485,\n",
            "        560.9069, 560.4517, 560.9916, 560.6837, 560.9082, 560.9421, 560.1580,\n",
            "        560.5704, 559.7119, 560.5081, 560.3340, 560.6490, 560.4102, 560.4881,\n",
            "        560.8429, 560.9453, 560.6857, 560.3071, 560.8129, 560.6951, 560.4510,\n",
            "        559.9387, 560.6548, 560.7415, 560.7626, 560.8317, 560.9327, 560.9794,\n",
            "        560.9197, 560.6511, 560.4066, 560.4294, 560.9591, 561.0546, 561.2276,\n",
            "        560.4329, 560.9084, 560.6395, 560.9965, 560.4044, 560.4088, 559.4715,\n",
            "        560.7540, 560.6774, 560.0615, 560.7405, 560.6749, 560.0010, 560.5305,\n",
            "        560.8472, 560.4365, 560.9194, 560.4451, 560.7626, 560.9193, 560.7297,\n",
            "        560.7512, 560.5770, 560.7657, 560.9110, 560.9060, 559.9696, 560.6597,\n",
            "        560.5916, 560.2744, 560.3878, 560.8959, 560.7490, 560.5984, 560.6192,\n",
            "        560.6726, 560.4923, 560.4785, 560.5716, 560.6611, 560.6112, 560.7283],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0120, 0.0088, 0.0110, 0.0075, 0.0096, 0.0098, 0.0076, 0.0100, 0.0069,\n",
            "        0.0096, 0.0095, 0.0104, 0.0092, 0.0078, 0.0088, 0.0131, 0.0097, 0.0104,\n",
            "        0.0094, 0.0082, 0.0095, 0.0078, 0.0085, 0.0079, 0.0102, 0.0104, 0.0094,\n",
            "        0.0079, 0.0108, 0.0099, 0.0095, 0.0092, 0.0122, 0.0082, 0.0075, 0.0083,\n",
            "        0.0095, 0.0091, 0.0025, 0.0103, 0.0088, 0.0092, 0.0098, 0.0096, 0.0096,\n",
            "        0.0108, 0.0094, 0.0075, 0.0094, 0.0136, 0.0101, 0.0096, 0.0086, 0.0094,\n",
            "        0.0095, 0.0087, 0.0111, 0.0098, 0.0091, 0.0097, 0.0090, 0.0097, 0.0086,\n",
            "        0.0092, 0.0082, 0.0102, 0.0099, 0.0072, 0.0065, 0.0087, 0.0108, 0.0075,\n",
            "        0.0059, 0.0091, 0.0088, 0.0079, 0.0098, 0.0101, 0.0106, 0.0093, 0.0091,\n",
            "        0.0092, 0.0084, 0.0108, 0.0104, 0.0136, 0.0077, 0.0101, 0.0122, 0.0095,\n",
            "        0.0101, 0.0098, 0.0092, 0.0085, 0.0095, 0.0096, 0.0107, 0.0100, 0.0101,\n",
            "        0.0084, 0.0093, 0.0080, 0.0109, 0.0098, 0.0095, 0.0080, 0.0095],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [45]\n",
            "DEBUGGING: logits looks like: tensor([560.3083, 560.1569, 560.2678, 560.0768, 560.1995, 560.2091, 560.0821,\n",
            "        560.2204, 560.0311, 560.1964, 560.1951, 560.2379, 560.1747, 560.0927,\n",
            "        560.1518, 560.3548, 560.2045, 560.2379, 560.1880, 560.1179, 560.1906,\n",
            "        560.0944, 560.1353, 560.0985, 560.2275, 560.2385, 560.1896, 560.1019,\n",
            "        560.2557, 560.2133, 560.1913, 560.1789, 560.3181, 560.1177, 560.0750,\n",
            "        560.1261, 560.1953, 560.1689, 559.5292, 560.2319, 560.1534, 560.1761,\n",
            "        560.2069, 560.1956, 560.1984, 560.2560, 560.1895, 560.0738, 560.1863,\n",
            "        560.3728, 560.2219, 560.1985, 560.1418, 560.1892, 560.1946, 560.1503,\n",
            "        560.2698, 560.2065, 560.1732, 560.2010, 560.1672, 560.2057, 560.1407,\n",
            "        560.1786, 560.1163, 560.2283, 560.2109, 560.0535, 560.0008, 560.1501,\n",
            "        560.2551, 560.0776, 559.9561, 560.1712, 560.1545, 560.0990, 560.2104,\n",
            "        560.2221, 560.2478, 560.1816, 560.1725, 560.1792, 560.1324, 560.2556,\n",
            "        560.2404, 560.3728, 560.0862, 560.2213, 560.3168, 560.1917, 560.2235,\n",
            "        560.2075, 560.1771, 560.1384, 560.1906, 560.1985, 560.2508, 560.2177,\n",
            "        560.2254, 560.1332, 560.1796, 560.1076, 560.2632, 560.2067, 560.1902,\n",
            "        560.1039, 560.1940], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.607247807314252 and immediate abs rewards look like: [0.04188488521799627, 0.0017925928923432366, 0.025916408209241126, 0.006005192746670218, 0.012270916993202263, 0.008814148013698286, 0.012243481236055231, 0.003182855530667439, 0.005431174799468863, 0.023350985188926643, 0.003029269891385411, 0.0012684903124409175, 0.00031138892313720135, 0.0003171091611875454, 4.121382630728476e-05, 0.0009739225577050092, 0.0007702631851316255, 1.784036862773064e-05, 0.45962566825005524, 1.3642420526593924e-12, 6.821210263296962e-13, 2.2737367544323206e-13, 2.2737367544323206e-13, 6.821210263296962e-13, 6.821210263296962e-13, 2.2737367544323206e-13, 0.0, 4.547473508864641e-13, 0.0, 2.2737367544323206e-13, 2.2737367544323206e-13, 2.2737367544323206e-13, 2.2737367544323206e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 2.2737367544323206e-13, 0.0, 2.2737367544323206e-13, 2.2737367544323206e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 2.2737367544323206e-13, 4.547473508864641e-13, 2.2737367544323206e-13, 2.2737367544323206e-13, 2.2737367544323206e-13, 2.2737367544323206e-13]\n",
            "DEBUGGING: the total relative reward of the trajectory = 27.354616344759567 and immediate relative rewards look like: [0.11611313515305924, 0.010055598442667839, 0.2181778874708931, 0.06790028511325572, 0.17372788090576033, 0.15026772037157773, 0.2441327857120606, 0.07278591701353848, 0.13985308338279942, 0.669139009821607, 0.09612970167487704, 0.04395163551979697, 0.01169263107379777, 0.012824534886088666, 0.0017859889976279382, 0.045018825682742916, 0.037840775730169876, 0.000928207297946348, 25.242290739423208, 9.094947017732731e-11, 4.7748471843075114e-11, 1.6674069532506213e-11, 1.7431981783982444e-11, 5.4569682106375694e-11, 5.684341886079509e-11, 1.9705718538413443e-11, 0.0, 4.244308608273987e-11, 0.0, 2.2737367544321484e-11, 2.3495279795797084e-11, 2.425319204727625e-11, 2.5011104298755523e-11, 0.0, 5.3053857603416796e-11, 5.4569682106363287e-11, 0.0, 2.8800665556140544e-11, 0.0, 3.0316490059097604e-11, 3.10744023105774e-11, 6.366462912410498e-11, 6.518045362704997e-11, 6.669627813001473e-11, 3.410605131648998e-11, 6.972792713592978e-11, 3.562187581943699e-11, 3.637978807091162e-11, 3.7137700322391754e-11, 3.789561257387201e-11]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([0.0231, 0.0528, 0.0049, 0.0136, 0.0071, 0.0166, 0.0015, 0.0361, 0.0227,\n",
            "        0.0360, 0.0085, 0.0174, 0.0197, 0.0098, 0.0335, 0.0019, 0.0431, 0.0080,\n",
            "        0.0012, 0.0236, 0.0238, 0.0016, 0.0101, 0.0046, 0.0125, 0.0135, 0.0062,\n",
            "        0.0040, 0.0065, 0.0099, 0.0459, 0.0102, 0.0078, 0.0101, 0.0177, 0.0025,\n",
            "        0.0707, 0.0026, 0.0129, 0.0211, 0.0020, 0.0009, 0.0028, 0.0003, 0.0063,\n",
            "        0.0002, 0.0128, 0.0021, 0.0542, 0.0065, 0.0148, 0.0250, 0.0023, 0.0004,\n",
            "        0.0188, 0.0119, 0.0020, 0.0134, 0.0206, 0.0119, 0.0069, 0.0693, 0.0137,\n",
            "        0.0001, 0.0047, 0.0032, 0.0176], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [54]\n",
            "DEBUGGING: logits looks like: tensor([560.3410, 560.7529, 559.5649, 560.0735, 559.7490, 560.1758, 558.9721,\n",
            "        560.5637, 560.3323, 560.5612, 559.8403, 560.1987, 560.2614, 559.9114,\n",
            "        560.5262, 559.0824, 560.6522, 559.8068, 558.8562, 560.3503, 560.3547,\n",
            "        559.0114, 559.9263, 559.5371, 560.0314, 560.0726, 559.6799, 559.4660,\n",
            "        559.7029, 559.9178, 560.6829, 559.9293, 559.7993, 559.9276, 560.2063,\n",
            "        559.2299, 560.8992, 559.2465, 560.0469, 560.2937, 559.1219, 558.7128,\n",
            "        559.2846, 558.2089, 559.6926, 557.9218, 560.0452, 559.1423, 560.7664,\n",
            "        559.7057, 560.1164, 560.3793, 559.1946, 558.3372, 560.2360, 560.0078,\n",
            "        559.1147, 560.0663, 560.2838, 560.0068, 559.7337, 560.8895, 560.0785,\n",
            "        557.7376, 559.5483, 559.3569, 560.2044], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0284, 0.0003, 0.0014, 0.0135, 0.0135, 0.0093, 0.0035, 0.0200, 0.0155,\n",
            "        0.0267, 0.0089, 0.0179, 0.0025, 0.0023, 0.0155, 0.0264, 0.0007, 0.0071,\n",
            "        0.0254, 0.0259, 0.0074, 0.0033, 0.0039, 0.0067, 0.0117, 0.0090, 0.0116,\n",
            "        0.0025, 0.0029, 0.0216, 0.0218, 0.0133, 0.0133, 0.0052, 0.0353, 0.0222,\n",
            "        0.0070, 0.0099, 0.0014, 0.0068, 0.0100, 0.0059, 0.0294, 0.0123, 0.0017,\n",
            "        0.0160, 0.0025, 0.0186, 0.0084, 0.0105, 0.0103, 0.0148, 0.0105, 0.0010,\n",
            "        0.0141, 0.0191, 0.0126, 0.0118, 0.0165, 0.0053, 0.0252, 0.0034, 0.0098,\n",
            "        0.0007, 0.0079, 0.0162, 0.0140, 0.0050, 0.0349, 0.0266, 0.0104, 0.0142,\n",
            "        0.0191, 0.0295, 0.0301, 0.0115, 0.0047, 0.0047, 0.0190],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [21]\n",
            "DEBUGGING: logits looks like: tensor([561.5279, 559.1744, 560.0282, 561.1570, 561.1544, 560.9711, 560.4828,\n",
            "        561.3516, 561.2261, 561.4977, 560.9463, 561.2966, 560.3110, 560.2742,\n",
            "        561.2253, 561.4913, 559.6667, 560.8336, 561.4725, 561.4822, 560.8558,\n",
            "        560.4561, 560.5345, 560.8091, 561.0852, 560.9531, 561.0820, 560.3127,\n",
            "        560.3897, 561.3920, 561.3965, 561.1492, 561.1496, 560.6836, 561.6371,\n",
            "        561.4043, 560.8304, 560.9998, 560.0353, 560.8161, 561.0042, 560.7388,\n",
            "        561.5451, 561.1100, 560.1103, 561.2402, 560.3218, 561.3176, 560.9174,\n",
            "        561.0291, 561.0231, 561.2035, 561.0314, 559.8317, 561.1771, 561.3286,\n",
            "        561.1235, 561.0876, 561.2555, 560.6873, 561.4684, 560.4652, 560.9949,\n",
            "        559.6448, 560.8878, 561.2480, 561.1738, 560.6561, 561.6313, 561.4943,\n",
            "        561.0259, 561.1806, 561.3292, 561.5470, 561.5568, 561.0751, 560.6285,\n",
            "        560.6291, 561.3281], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0059, 0.0184, 0.0068, 0.0139, 0.0138, 0.0176, 0.0074, 0.0053, 0.0023,\n",
            "        0.0160, 0.0143, 0.0073, 0.0186, 0.0083, 0.0032, 0.0136, 0.0082, 0.0102,\n",
            "        0.0084, 0.0151, 0.0046, 0.0128, 0.0030, 0.0049, 0.0103, 0.0038, 0.0044,\n",
            "        0.0072, 0.0121, 0.0263, 0.0311, 0.0033, 0.0259, 0.0070, 0.0104, 0.0076,\n",
            "        0.0220, 0.0280, 0.0095, 0.0072, 0.0042, 0.0127, 0.0169, 0.0135, 0.0122,\n",
            "        0.0117, 0.0084, 0.0555, 0.0076, 0.0098, 0.0050, 0.0041, 0.0088, 0.0070,\n",
            "        0.0075, 0.0367, 0.0080, 0.0137, 0.0262, 0.0053, 0.0312, 0.0019, 0.0041,\n",
            "        0.0158, 0.0085, 0.0131, 0.0254, 0.0068, 0.0087, 0.0113, 0.0039, 0.0227,\n",
            "        0.0092, 0.0062, 0.0038, 0.0127, 0.0043, 0.0069, 0.0084, 0.0122, 0.0019,\n",
            "        0.0134, 0.0044, 0.0075, 0.0080, 0.0057, 0.0114],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [57]\n",
            "DEBUGGING: logits looks like: tensor([561.4398, 562.0085, 561.5085, 561.8660, 561.8636, 561.9848, 561.5519,\n",
            "        561.3814, 560.9587, 561.9388, 561.8817, 561.5457, 562.0137, 561.6108,\n",
            "        561.1279, 561.8574, 561.6030, 561.7109, 561.6186, 561.9105, 561.3140,\n",
            "        561.8273, 561.1006, 561.3430, 561.7197, 561.2148, 561.2917, 561.5372,\n",
            "        561.7993, 562.1868, 562.2708, 561.1416, 562.1786, 561.5228, 561.7238,\n",
            "        561.5662, 562.0969, 562.2183, 561.6759, 561.5393, 561.2731, 561.8233,\n",
            "        561.9658, 561.8513, 561.8015, 561.7802, 561.6186, 562.5598, 561.5665,\n",
            "        561.6939, 561.3582, 561.2624, 561.6376, 561.5274, 561.5612, 562.3530,\n",
            "        561.5904, 561.8594, 562.1851, 561.3868, 562.2723, 560.8627, 561.2521,\n",
            "        561.9319, 561.6240, 561.8362, 562.1697, 561.5110, 561.6317, 561.7643,\n",
            "        561.2316, 562.1124, 561.6610, 561.4624, 561.2126, 561.8227, 561.2797,\n",
            "        561.5157, 561.6186, 561.8011, 560.8837, 561.8507, 561.2893, 561.5574,\n",
            "        561.5909, 561.4250, 561.7679], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0114, 0.0268, 0.0084, 0.0194, 0.0030, 0.0129, 0.0171, 0.0029, 0.0280,\n",
            "        0.0354, 0.0162, 0.0138, 0.0062, 0.0046, 0.0227, 0.0082, 0.0011, 0.0074,\n",
            "        0.0101, 0.0025, 0.0048, 0.0155, 0.0032, 0.0045, 0.0174, 0.0105, 0.0056,\n",
            "        0.0209, 0.0107, 0.0090, 0.0010, 0.0053, 0.0121, 0.0047, 0.0147, 0.0031,\n",
            "        0.0022, 0.0036, 0.0031, 0.0063, 0.0369, 0.0171, 0.0101, 0.0117, 0.0061,\n",
            "        0.0075, 0.0187, 0.0121, 0.0018, 0.0042, 0.0015, 0.0090, 0.0048, 0.0043,\n",
            "        0.0079, 0.0103, 0.0065, 0.0036, 0.0134, 0.0028, 0.0180, 0.0100, 0.0022,\n",
            "        0.0039, 0.0151, 0.0139, 0.0063, 0.0075, 0.0110, 0.0049, 0.0120, 0.0086,\n",
            "        0.0066, 0.0219, 0.0165, 0.0061, 0.0099, 0.0107, 0.0078, 0.0058, 0.0161,\n",
            "        0.0032, 0.0034, 0.0211, 0.0043, 0.0168, 0.0064, 0.0207, 0.0115, 0.0077,\n",
            "        0.0148, 0.0069, 0.0024, 0.0167, 0.0066, 0.0048, 0.0161, 0.0154],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [78]\n",
            "DEBUGGING: logits looks like: tensor([560.2704, 560.6959, 560.1152, 560.5345, 559.5965, 560.3313, 560.4727,\n",
            "        559.5898, 560.7175, 560.8360, 560.4459, 560.3650, 559.9666, 559.8136,\n",
            "        560.6124, 560.1058, 559.1093, 560.0505, 560.2085, 559.5125, 559.8317,\n",
            "        560.4215, 559.6348, 559.8057, 560.4791, 560.2265, 559.9122, 560.5714,\n",
            "        560.2385, 560.1511, 559.0316, 559.8835, 560.2979, 559.8294, 560.3975,\n",
            "        559.6118, 559.4378, 559.6947, 559.6116, 559.9703, 560.8560, 560.4707,\n",
            "        560.2064, 560.2817, 559.9560, 560.0563, 560.5177, 560.2974, 559.3591,\n",
            "        559.7753, 559.2421, 560.1491, 559.8407, 559.7868, 560.0860, 560.2176,\n",
            "        559.9843, 559.6924, 560.3514, 559.5707, 560.4961, 560.2051, 559.4446,\n",
            "        559.7335, 560.4109, 560.3691, 559.9729, 560.0616, 560.2507, 559.8467,\n",
            "        560.2957, 560.1302, 559.9935, 560.5957, 560.4529, 559.9575, 560.1960,\n",
            "        560.2363, 560.0785, 559.9337, 560.4401, 559.6409, 559.6682, 560.5762,\n",
            "        559.7806, 560.4633, 559.9807, 560.5676, 560.2729, 560.0720, 560.4009,\n",
            "        560.0144, 559.4908, 560.4600, 559.9952, 559.8367, 560.4409, 560.4203],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0116, 0.0078, 0.0061, 0.0074, 0.0111, 0.0087, 0.0144, 0.0125, 0.0081,\n",
            "        0.0040, 0.0068, 0.0059, 0.0077, 0.0101, 0.0110, 0.0060, 0.0060, 0.0064,\n",
            "        0.0109, 0.0121, 0.0083, 0.0144, 0.0253, 0.0061, 0.0054, 0.0095, 0.0094,\n",
            "        0.0095, 0.0074, 0.0062, 0.0083, 0.0083, 0.0275, 0.0091, 0.0099, 0.0108,\n",
            "        0.0142, 0.0090, 0.0126, 0.0104, 0.0101, 0.0113, 0.0093, 0.0098, 0.0064,\n",
            "        0.0101, 0.0056, 0.0057, 0.0100, 0.0057, 0.0145, 0.0047, 0.0087, 0.0121,\n",
            "        0.0050, 0.0058, 0.0045, 0.0121, 0.0124, 0.0067, 0.0107, 0.0103, 0.0123,\n",
            "        0.0201, 0.0073, 0.0073, 0.0105, 0.0091, 0.0106, 0.0078, 0.0072, 0.0135,\n",
            "        0.0098, 0.0042, 0.0123, 0.0174, 0.0103, 0.0099, 0.0091, 0.0121, 0.0060,\n",
            "        0.0109, 0.0127, 0.0075, 0.0087, 0.0051, 0.0041, 0.0046, 0.0132, 0.0090,\n",
            "        0.0088, 0.0042, 0.0049, 0.0078, 0.0127, 0.0037, 0.0097, 0.0074, 0.0099,\n",
            "        0.0074, 0.0084, 0.0197, 0.0145, 0.0080, 0.0128],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [11]\n",
            "DEBUGGING: logits looks like: tensor([562.4324, 562.2354, 562.1074, 562.2054, 562.4086, 562.2855, 562.5400,\n",
            "        562.4694, 562.2545, 561.8929, 562.1643, 562.0932, 562.2234, 562.3599,\n",
            "        562.4035, 562.0981, 562.0993, 562.1374, 562.3990, 562.4512, 562.2643,\n",
            "        562.5386, 562.8216, 562.1119, 562.0527, 562.3334, 562.3245, 562.3287,\n",
            "        562.2084, 562.1205, 562.2640, 562.2639, 562.8624, 562.3087, 562.3505,\n",
            "        562.3939, 562.5308, 562.3067, 562.4711, 562.3771, 562.3612, 562.4185,\n",
            "        562.3220, 562.3451, 562.1374, 562.3608, 562.0679, 562.0737, 562.3547,\n",
            "        562.0760, 562.5414, 561.9769, 562.2848, 562.4521, 562.0091, 562.0858,\n",
            "        561.9620, 562.4503, 562.4644, 562.1603, 562.3895, 562.3708, 562.4619,\n",
            "        562.7062, 562.1975, 562.1975, 562.3813, 562.3075, 562.3881, 562.2321,\n",
            "        562.1923, 562.5078, 562.3479, 561.9182, 562.4622, 562.6342, 562.3712,\n",
            "        562.3503, 562.3101, 562.4541, 562.0991, 562.3990, 562.4768, 562.2140,\n",
            "        562.2870, 562.0195, 561.9110, 561.9670, 562.4959, 562.3035, 562.2922,\n",
            "        561.9195, 562.0018, 562.2339, 562.4756, 561.8626, 562.3409, 562.2082,\n",
            "        562.3500, 562.2051, 562.2706, 562.6948, 562.5438, 562.2470, 562.4814],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.7058461509332119 and immediate abs rewards look like: [0.0001455381298001157, 0.0023031639466353226, 0.003064934571284539, 0.0030929863542041858, 0.0022143282049000845, 0.007177622635481384, 2.5339272724522743e-06, 0.6878450431518104, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 0.0, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13]\n",
            "DEBUGGING: the total relative reward of the trajectory = 20.77106086706686 and immediate relative rewards look like: [0.0005378655018895195, 0.017024529142261963, 0.034012030742213525, 0.04581637761801542, 0.04104804526960427, 0.1597971544661233, 6.599143142797357e-05, 20.472758871403755, 0.0, 2.2737367544323206e-11, 2.5011104298761213e-11, 0.0, 2.955857780762017e-11, 6.36646291240905e-11, 3.4106051316492564e-11, 0.0, 7.73070496506989e-11, 4.092726157980038e-11, 4.3200998334223914e-11, 4.547473508864641e-11, 9.549694368617918e-11, 5.002220859749968e-11, 5.2295945351943374e-11, 5.4569682106363287e-11, 5.6843418860808015e-11, 0.0, 0.0, 6.366462912411945e-11, 6.59383658785373e-11, 6.821210263298513e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 8.185452315956354e-11, 8.412825991401499e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0459189070388675e-10, 1.0686562745829477e-10, 0.0, 1.1141310096718371e-10, 1.1368683772159018e-10]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([0.0122, 0.0006, 0.0101, 0.0054, 0.0025, 0.0126, 0.0136, 0.0004, 0.0448,\n",
            "        0.0368, 0.0079, 0.0005, 0.0078, 0.0004, 0.0103, 0.0500, 0.0032, 0.0175,\n",
            "        0.0122, 0.0330, 0.0177, 0.0102, 0.0150, 0.0148, 0.0077, 0.0224, 0.0124,\n",
            "        0.0396, 0.0103, 0.0120, 0.0021, 0.0060, 0.0036, 0.0272, 0.0531, 0.0003,\n",
            "        0.0238, 0.0043, 0.0018, 0.0024, 0.0323, 0.0105, 0.0182, 0.0099, 0.0306,\n",
            "        0.0315, 0.0071, 0.0179, 0.0817, 0.0110, 0.0071, 0.0017, 0.0128, 0.0069,\n",
            "        0.0088, 0.0179, 0.0078, 0.0012, 0.0081, 0.0070, 0.0232, 0.0044, 0.0076,\n",
            "        0.0571, 0.0051, 0.0041], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [29]\n",
            "DEBUGGING: logits looks like: tensor([559.6017, 558.1263, 559.5093, 559.1957, 558.8105, 559.6165, 559.6562,\n",
            "        557.8308, 560.2524, 560.1541, 559.3838, 558.0207, 559.3773, 557.9269,\n",
            "        559.5149, 560.3069, 558.9376, 559.7825, 559.6035, 560.0997, 559.7888,\n",
            "        559.5118, 559.7040, 559.6972, 559.3705, 559.9059, 559.6080, 560.1902,\n",
            "        559.5193, 559.5931, 558.7136, 559.2444, 558.9894, 560.0020, 560.3371,\n",
            "        557.6624, 559.9359, 559.0839, 558.6477, 558.7786, 560.0887, 559.5262,\n",
            "        559.8018, 559.4974, 560.0616, 560.0762, 559.3290, 559.7943, 560.5527,\n",
            "        559.5481, 559.3306, 558.6063, 559.6241, 559.3141, 559.4391, 559.7933,\n",
            "        559.3748, 558.4624, 559.3978, 559.3264, 559.9238, 559.0890, 559.3641,\n",
            "        560.3736, 559.1616, 559.0507], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0106, 0.0111, 0.0116, 0.0154, 0.0104, 0.0169, 0.0093, 0.0127, 0.0161,\n",
            "        0.0096, 0.0158, 0.0250, 0.0095, 0.0127, 0.0280, 0.0154, 0.0061, 0.0120,\n",
            "        0.0129, 0.0106, 0.0113, 0.0130, 0.0127, 0.0083, 0.0102, 0.0103, 0.0138,\n",
            "        0.0132, 0.0081, 0.0088, 0.0120, 0.0074, 0.0154, 0.0114, 0.0104, 0.0136,\n",
            "        0.0189, 0.0116, 0.0132, 0.0100, 0.0135, 0.0111, 0.0092, 0.0159, 0.0089,\n",
            "        0.0105, 0.0202, 0.0122, 0.0209, 0.0117, 0.0064, 0.0121, 0.0109, 0.0115,\n",
            "        0.0065, 0.0128, 0.0181, 0.0106, 0.0135, 0.0120, 0.0189, 0.0120, 0.0125,\n",
            "        0.0165, 0.0085, 0.0106, 0.0094, 0.0150, 0.0168, 0.0136, 0.0126, 0.0090,\n",
            "        0.0108, 0.0416, 0.0113, 0.0123, 0.0146], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [30]\n",
            "DEBUGGING: logits looks like: tensor([559.5568, 559.5791, 559.6025, 559.7442, 559.5475, 559.7918, 559.4911,\n",
            "        559.6467, 559.7670, 559.5095, 559.7578, 559.9874, 559.5051, 559.6479,\n",
            "        560.0439, 559.7463, 559.2858, 559.6208, 559.6552, 559.5572, 559.5920,\n",
            "        559.6616, 559.6479, 559.4335, 559.5376, 559.5451, 559.6910, 559.6681,\n",
            "        559.4238, 559.4644, 559.6187, 559.3804, 559.7433, 559.5929, 559.5504,\n",
            "        559.6840, 559.8460, 559.6046, 559.6663, 559.5311, 559.6806, 559.5789,\n",
            "        559.4892, 559.7608, 559.4696, 559.5547, 559.8815, 559.6290, 559.8968,\n",
            "        559.6085, 559.3043, 559.6250, 559.5734, 559.5983, 559.3122, 559.6535,\n",
            "        559.8252, 559.5572, 559.6802, 559.6220, 559.8465, 559.6207, 559.6423,\n",
            "        559.7808, 559.4497, 559.5574, 559.4968, 559.7305, 559.7892, 559.6843,\n",
            "        559.6426, 559.4771, 559.5657, 560.2413, 559.5916, 559.6330, 559.7190],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0111, 0.0057, 0.0125, 0.0107, 0.0122, 0.0118, 0.0112, 0.0130, 0.0106,\n",
            "        0.0111, 0.0110, 0.0116, 0.0120, 0.0102, 0.0129, 0.0107, 0.0121, 0.0116,\n",
            "        0.0122, 0.0117, 0.0128, 0.0114, 0.0110, 0.0133, 0.0108, 0.0124, 0.0117,\n",
            "        0.0109, 0.0093, 0.0113, 0.0099, 0.0115, 0.0120, 0.0120, 0.0125, 0.0112,\n",
            "        0.0126, 0.0119, 0.0112, 0.0120, 0.0107, 0.0112, 0.0125, 0.0108, 0.0122,\n",
            "        0.0103, 0.0126, 0.0117, 0.0117, 0.0111, 0.0111, 0.0111, 0.0138, 0.0113,\n",
            "        0.0111, 0.0125, 0.0128, 0.0128, 0.0135, 0.0114, 0.0099, 0.0129, 0.0117,\n",
            "        0.0114, 0.0112, 0.0107, 0.0125, 0.0110, 0.0116, 0.0125, 0.0115, 0.0154,\n",
            "        0.0117, 0.0112, 0.0116, 0.0127, 0.0115, 0.0117, 0.0118, 0.0116, 0.0110,\n",
            "        0.0129, 0.0106, 0.0122, 0.0123, 0.0109], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [35]\n",
            "DEBUGGING: logits looks like: tensor([559.3304, 559.0001, 559.3894, 559.3108, 559.3772, 559.3599, 559.3343,\n",
            "        559.4063, 559.3066, 559.3293, 559.3259, 559.3497, 559.3673, 559.2854,\n",
            "        559.4048, 559.3086, 559.3738, 559.3504, 559.3770, 559.3554, 559.4008,\n",
            "        559.3432, 559.3260, 559.4191, 559.3167, 559.3854, 559.3575, 559.3223,\n",
            "        559.2428, 559.3387, 559.2706, 559.3483, 559.3677, 559.3671, 559.3897,\n",
            "        559.3321, 559.3914, 559.3644, 559.3338, 559.3663, 559.3112, 559.3328,\n",
            "        559.3873, 559.3140, 559.3770, 559.2917, 559.3911, 559.3572, 559.3572,\n",
            "        559.3301, 559.3278, 559.3307, 559.4385, 559.3363, 559.3281, 559.3875,\n",
            "        559.4016, 559.3998, 559.4252, 559.3434, 559.2713, 559.4028, 559.3540,\n",
            "        559.3433, 559.3343, 559.3101, 559.3902, 559.3268, 559.3508, 559.3899,\n",
            "        559.3449, 559.4929, 559.3548, 559.3320, 559.3516, 559.3946, 559.3480,\n",
            "        559.3543, 559.3604, 559.3500, 559.3260, 559.4048, 559.3076, 559.3782,\n",
            "        559.3809, 559.3218], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0111, 0.0095, 0.0101, 0.0100, 0.0099, 0.0106, 0.0099, 0.0104, 0.0098,\n",
            "        0.0098, 0.0093, 0.0098, 0.0109, 0.0102, 0.0107, 0.0101, 0.0104, 0.0101,\n",
            "        0.0098, 0.0099, 0.0102, 0.0107, 0.0102, 0.0092, 0.0112, 0.0098, 0.0102,\n",
            "        0.0108, 0.0095, 0.0104, 0.0092, 0.0101, 0.0103, 0.0108, 0.0098, 0.0108,\n",
            "        0.0102, 0.0094, 0.0095, 0.0102, 0.0099, 0.0094, 0.0103, 0.0106, 0.0104,\n",
            "        0.0100, 0.0096, 0.0099, 0.0104, 0.0102, 0.0103, 0.0102, 0.0103, 0.0101,\n",
            "        0.0106, 0.0099, 0.0105, 0.0098, 0.0100, 0.0104, 0.0101, 0.0096, 0.0099,\n",
            "        0.0101, 0.0103, 0.0102, 0.0106, 0.0108, 0.0105, 0.0100, 0.0098, 0.0096,\n",
            "        0.0106, 0.0097, 0.0099, 0.0105, 0.0100, 0.0105, 0.0098, 0.0100, 0.0099,\n",
            "        0.0102, 0.0100, 0.0098, 0.0101, 0.0107, 0.0105, 0.0103, 0.0100, 0.0098,\n",
            "        0.0098, 0.0102, 0.0098, 0.0091, 0.0101, 0.0096, 0.0094, 0.0106, 0.0103],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [20]\n",
            "DEBUGGING: logits looks like: tensor([559.3527, 559.2753, 559.3073, 559.3010, 559.2940, 559.3307, 559.2955,\n",
            "        559.3203, 559.2911, 559.2905, 559.2646, 559.2935, 559.3447, 559.3102,\n",
            "        559.3336, 559.3066, 559.3220, 559.3038, 559.2929, 559.2938, 559.3096,\n",
            "        559.3363, 559.3094, 559.2599, 559.3586, 559.2888, 559.3120, 559.3417,\n",
            "        559.2751, 559.3207, 559.2604, 559.3067, 559.3170, 559.3401, 559.2906,\n",
            "        559.3391, 559.3110, 559.2695, 559.2758, 559.3126, 559.2940, 559.2721,\n",
            "        559.3167, 559.3314, 559.3184, 559.3032, 559.2829, 559.2966, 559.3207,\n",
            "        559.3092, 559.3157, 559.3093, 559.3165, 559.3070, 559.3290, 559.2982,\n",
            "        559.3232, 559.2913, 559.2994, 559.3201, 559.3063, 559.2824, 559.2954,\n",
            "        559.3073, 559.3170, 559.3128, 559.3314, 559.3384, 559.3243, 559.3015,\n",
            "        559.2936, 559.2809, 559.3284, 559.2845, 559.2978, 559.3243, 559.3027,\n",
            "        559.3234, 559.2926, 559.3016, 559.2938, 559.3087, 559.3030, 559.2914,\n",
            "        559.3076, 559.3336, 559.3242, 559.3143, 559.3017, 559.2887, 559.2888,\n",
            "        559.3088, 559.2920, 559.2555, 559.3079, 559.2783, 559.2681, 559.3319,\n",
            "        559.3141], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0097, 0.0095, 0.0095, 0.0094, 0.0096, 0.0095, 0.0095, 0.0095, 0.0096,\n",
            "        0.0092, 0.0097, 0.0097, 0.0099, 0.0095, 0.0092, 0.0095, 0.0096, 0.0097,\n",
            "        0.0095, 0.0096, 0.0093, 0.0097, 0.0094, 0.0092, 0.0106, 0.0095, 0.0095,\n",
            "        0.0095, 0.0098, 0.0095, 0.0095, 0.0096, 0.0094, 0.0092, 0.0098, 0.0096,\n",
            "        0.0096, 0.0095, 0.0096, 0.0092, 0.0095, 0.0095, 0.0097, 0.0094, 0.0097,\n",
            "        0.0098, 0.0094, 0.0095, 0.0097, 0.0096, 0.0095, 0.0096, 0.0097, 0.0095,\n",
            "        0.0095, 0.0093, 0.0097, 0.0095, 0.0096, 0.0094, 0.0095, 0.0093, 0.0096,\n",
            "        0.0097, 0.0095, 0.0096, 0.0095, 0.0094, 0.0095, 0.0094, 0.0096, 0.0101,\n",
            "        0.0091, 0.0096, 0.0095, 0.0093, 0.0096, 0.0093, 0.0093, 0.0092, 0.0096,\n",
            "        0.0095, 0.0094, 0.0094, 0.0095, 0.0095, 0.0095, 0.0100, 0.0093, 0.0093,\n",
            "        0.0097, 0.0095, 0.0092, 0.0097, 0.0094, 0.0093, 0.0093, 0.0095, 0.0096,\n",
            "        0.0094, 0.0097, 0.0094, 0.0095, 0.0096, 0.0094],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [81]\n",
            "DEBUGGING: logits looks like: tensor([559.2681, 559.2583, 559.2544, 559.2513, 559.2608, 559.2539, 559.2565,\n",
            "        559.2580, 559.2618, 559.2408, 559.2663, 559.2655, 559.2750, 559.2547,\n",
            "        559.2409, 559.2581, 559.2620, 559.2665, 559.2571, 559.2590, 559.2474,\n",
            "        559.2640, 559.2504, 559.2413, 559.3125, 559.2558, 559.2587, 559.2584,\n",
            "        559.2706, 559.2587, 559.2565, 559.2588, 559.2488, 559.2408, 559.2729,\n",
            "        559.2601, 559.2589, 559.2538, 559.2628, 559.2408, 559.2560, 559.2535,\n",
            "        559.2670, 559.2493, 559.2651, 559.2723, 559.2532, 559.2549, 559.2667,\n",
            "        559.2637, 559.2550, 559.2619, 559.2648, 559.2556, 559.2537, 559.2474,\n",
            "        559.2669, 559.2561, 559.2631, 559.2507, 559.2556, 559.2454, 559.2626,\n",
            "        559.2688, 559.2537, 559.2604, 559.2565, 559.2517, 559.2567, 559.2510,\n",
            "        559.2634, 559.2844, 559.2352, 559.2635, 559.2560, 559.2454, 559.2623,\n",
            "        559.2451, 559.2444, 559.2419, 559.2628, 559.2547, 559.2517, 559.2532,\n",
            "        559.2535, 559.2546, 559.2550, 559.2796, 559.2480, 559.2456, 559.2660,\n",
            "        559.2546, 559.2415, 559.2639, 559.2520, 559.2476, 559.2468, 559.2578,\n",
            "        559.2602, 559.2526, 559.2651, 559.2511, 559.2561, 559.2597, 559.2505],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.10176630161777211 and immediate abs rewards look like: [0.0018197951239926624, 0.012901200906071608, 0.002134639473297284, 0.004979396019280102, 0.003215085424926656, 0.003330350476971944, 0.005169268338704569, 0.03195699143952879, 0.001905246167552832, 0.001344313492609217, 0.005750674731189065, 0.00033712141657815664, 0.006407351119833038, 0.00041566570371287526, 0.00034209950808872236, 0.0002383909823038266, 0.0011634636589406, 2.7237582798989024e-05, 0.0037819517033312877, 0.0004558578252726875, 0.0016456332496090909, 0.0023700195247329248, 0.0001754170862113824, 0.0020464866315705876, 6.84999340592185e-05, 0.0015393358876281127, 0.00023315633779930067, 0.00051009947901548, 0.0009528532741569506, 0.00012046008532706765, 4.540841018751962e-05, 2.6872148282564012e-05, 0.00034141987862312817, 0.0012277147498025442, 1.4740134702151408e-05, 6.595241029572207e-05, 5.917711541769677e-05, 0.0003085843991357251, 0.0005886904850740393, 1.1329781500535319e-05, 2.427883282507537e-05, 6.5524545789230615e-09, 8.325429189426359e-05, 0.00024899081927287625, 4.057901787746232e-05, 0.0010308879823242023, 0.0002266983697154501, 7.338340947171673e-05, 9.60735633270815e-06, 6.628874871239532e-07]\n",
            "DEBUGGING: the total relative reward of the trajectory = 3.583496207172899 and immediate relative rewards look like: [0.0058678251582577985, 0.08324721495858492, 0.020747550611076505, 0.06457406945332228, 0.052201825301445674, 0.06495581172784091, 0.1177536456573402, 0.8333631660379686, 0.056483269197974376, 0.04430976247879644, 0.20859448927012247, 0.013365440334960045, 0.2752237653806222, 0.01926889040045604, 0.016993700705566665, 0.012632906063940973, 0.06551330305371855, 0.001624561729888796, 0.23810507318494956, 0.03024844627389365, 0.11467313846650566, 0.17310960757222923, 0.013405658761786393, 0.16320516504756966, 0.005694286803555727, 0.13308398905272412, 0.020943651967021366, 0.04752126833875925, 0.09195447195535059, 0.01202959419987552, 0.0046859965211790535, 0.0028626147297380277, 0.037507417662829966, 0.13897611780988867, 0.0017183468754838037, 0.007908181819135001, 0.007293038885579256, 0.039058821591135925, 0.07648175396911266, 0.0015099859905063264, 0.003316688562699264, 9.169588669268981e-07, 0.01192810992612435, 0.03650434867246271, 0.006084973220359715, 0.1580228196997559, 0.03551779294819381, 0.011742799890788122, 0.0015694343028764138, 0.00011049799007903491]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 3\n",
            "DEBUGGING: the action_prob is: tensor([0.0318, 0.0128, 0.0148, 0.0201, 0.0112, 0.0140, 0.0119, 0.0166, 0.0130,\n",
            "        0.0108, 0.0085, 0.0112, 0.0136, 0.0161, 0.0085, 0.0161, 0.0231, 0.0149,\n",
            "        0.0184, 0.0195, 0.0139, 0.0093, 0.0033, 0.0213, 0.0114, 0.0164, 0.0125,\n",
            "        0.0146, 0.0211, 0.0116, 0.0115, 0.0143, 0.0075, 0.0133, 0.0148, 0.0098,\n",
            "        0.0165, 0.0159, 0.0176, 0.0074, 0.0130, 0.0098, 0.0157, 0.0155, 0.0159,\n",
            "        0.0174, 0.0148, 0.0148, 0.0153, 0.0065, 0.0089, 0.0130, 0.0132, 0.0140,\n",
            "        0.0109, 0.0169, 0.0192, 0.0165, 0.0173, 0.0122, 0.0132, 0.0153, 0.0076,\n",
            "        0.0160, 0.0151, 0.0132, 0.0157, 0.0174, 0.0142, 0.0205],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [63]\n",
            "DEBUGGING: logits looks like: tensor([561.7830, 561.3303, 561.4005, 561.5552, 561.2621, 561.3726, 561.2913,\n",
            "        561.4578, 561.3354, 561.2427, 561.1216, 561.2628, 561.3577, 561.4436,\n",
            "        561.1262, 561.4443, 561.6243, 561.4062, 561.5113, 561.5383, 561.3687,\n",
            "        561.1706, 560.6479, 561.5834, 561.2705, 561.4513, 561.3152, 561.3934,\n",
            "        561.5774, 561.2805, 561.2748, 561.3828, 561.0623, 561.3489, 561.4027,\n",
            "        561.1952, 561.4548, 561.4377, 561.4890, 561.0555, 561.3356, 561.1961,\n",
            "        561.4305, 561.4235, 561.4377, 561.4829, 561.4025, 561.3999, 561.4169,\n",
            "        560.9882, 561.1481, 561.3380, 561.3455, 561.3732, 561.2472, 561.4684,\n",
            "        561.5317, 561.4556, 561.4798, 561.3051, 561.3453, 561.4164, 561.0676,\n",
            "        561.4416, 561.4107, 561.3440, 561.4304, 561.4832, 561.3797, 561.5640],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0286, 0.0124, 0.0140, 0.0115, 0.0126, 0.0123, 0.0121, 0.0124, 0.0125,\n",
            "        0.0124, 0.0130, 0.0125, 0.0120, 0.0133, 0.0147, 0.0129, 0.0120, 0.0128,\n",
            "        0.0124, 0.0129, 0.0139, 0.0122, 0.0126, 0.0126, 0.0121, 0.0138, 0.0129,\n",
            "        0.0128, 0.0124, 0.0130, 0.0119, 0.0132, 0.0121, 0.0122, 0.0111, 0.0124,\n",
            "        0.0126, 0.0130, 0.0125, 0.0132, 0.0133, 0.0134, 0.0138, 0.0128, 0.0123,\n",
            "        0.0102, 0.0106, 0.0126, 0.0115, 0.0134, 0.0136, 0.0121, 0.0142, 0.0131,\n",
            "        0.0135, 0.0125, 0.0129, 0.0127, 0.0130, 0.0128, 0.0135, 0.0126, 0.0118,\n",
            "        0.0128, 0.0131, 0.0128, 0.0125, 0.0127, 0.0125, 0.0122, 0.0134, 0.0127,\n",
            "        0.0129, 0.0122, 0.0118, 0.0125, 0.0097, 0.0123],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [18]\n",
            "DEBUGGING: logits looks like: tensor([561.7202, 561.3009, 561.3613, 561.2648, 561.3120, 561.2979, 561.2919,\n",
            "        561.3030, 561.3079, 561.3030, 561.3249, 561.3066, 561.2871, 561.3383,\n",
            "        561.3871, 561.3212, 561.2847, 561.3168, 561.3016, 561.3226, 561.3586,\n",
            "        561.2948, 561.3118, 561.3109, 561.2921, 561.3547, 561.3212, 561.3163,\n",
            "        561.3016, 561.3268, 561.2831, 561.3347, 561.2908, 561.2947, 561.2452,\n",
            "        561.3026, 561.3099, 561.3245, 561.3054, 561.3351, 561.3362, 561.3427,\n",
            "        561.3571, 561.3178, 561.2988, 561.2052, 561.2229, 561.3119, 561.2627,\n",
            "        561.3423, 561.3467, 561.2881, 561.3710, 561.3290, 561.3445, 561.3055,\n",
            "        561.3203, 561.3150, 561.3276, 561.3177, 561.3447, 561.3110, 561.2770,\n",
            "        561.3201, 561.3299, 561.3172, 561.3079, 561.3143, 561.3066, 561.2923,\n",
            "        561.3398, 561.3135, 561.3227, 561.2930, 561.2783, 561.3075, 561.1780,\n",
            "        561.2994], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0289, 0.0111, 0.0111, 0.0113, 0.0112, 0.0112, 0.0112, 0.0111, 0.0112,\n",
            "        0.0111, 0.0111, 0.0114, 0.0112, 0.0112, 0.0111, 0.0112, 0.0112, 0.0112,\n",
            "        0.0111, 0.0112, 0.0112, 0.0112, 0.0112, 0.0110, 0.0112, 0.0113, 0.0111,\n",
            "        0.0112, 0.0111, 0.0113, 0.0113, 0.0111, 0.0111, 0.0113, 0.0112, 0.0114,\n",
            "        0.0112, 0.0112, 0.0112, 0.0111, 0.0112, 0.0112, 0.0112, 0.0112, 0.0111,\n",
            "        0.0111, 0.0111, 0.0112, 0.0112, 0.0113, 0.0111, 0.0111, 0.0111, 0.0111,\n",
            "        0.0111, 0.0112, 0.0111, 0.0112, 0.0112, 0.0112, 0.0110, 0.0112, 0.0112,\n",
            "        0.0112, 0.0110, 0.0113, 0.0112, 0.0111, 0.0111, 0.0111, 0.0111, 0.0111,\n",
            "        0.0111, 0.0112, 0.0111, 0.0112, 0.0111, 0.0110, 0.0113, 0.0112, 0.0113,\n",
            "        0.0112, 0.0110, 0.0113, 0.0110, 0.0112, 0.0112, 0.0111],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [24]\n",
            "DEBUGGING: logits looks like: tensor([561.6645, 561.1852, 561.1864, 561.1933, 561.1900, 561.1906, 561.1896,\n",
            "        561.1846, 561.1900, 561.1868, 561.1871, 561.1974, 561.1904, 561.1887,\n",
            "        561.1852, 561.1890, 561.1906, 561.1923, 561.1844, 561.1924, 561.1916,\n",
            "        561.1918, 561.1910, 561.1823, 561.1913, 561.1946, 561.1863, 561.1907,\n",
            "        561.1874, 561.1951, 561.1934, 561.1876, 561.1855, 561.1931, 561.1899,\n",
            "        561.1979, 561.1922, 561.1907, 561.1904, 561.1848, 561.1904, 561.1894,\n",
            "        561.1884, 561.1915, 561.1849, 561.1851, 561.1871, 561.1910, 561.1908,\n",
            "        561.1934, 561.1865, 561.1871, 561.1838, 561.1848, 561.1878, 561.1891,\n",
            "        561.1849, 561.1901, 561.1890, 561.1910, 561.1794, 561.1903, 561.1910,\n",
            "        561.1888, 561.1827, 561.1927, 561.1896, 561.1849, 561.1853, 561.1854,\n",
            "        561.1863, 561.1843, 561.1858, 561.1899, 561.1849, 561.1895, 561.1857,\n",
            "        561.1824, 561.1943, 561.1890, 561.1937, 561.1890, 561.1827, 561.1951,\n",
            "        561.1835, 561.1907, 561.1920, 561.1859], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0118, 0.0079, 0.0096, 0.0091, 0.0149, 0.0118, 0.0117, 0.0101, 0.0064,\n",
            "        0.0104, 0.0065, 0.0152, 0.0100, 0.0167, 0.0087, 0.0021, 0.0100, 0.0096,\n",
            "        0.0133, 0.0081, 0.0097, 0.0083, 0.0082, 0.0135, 0.0067, 0.0131, 0.0072,\n",
            "        0.0114, 0.0112, 0.0134, 0.0075, 0.0120, 0.0104, 0.0155, 0.0097, 0.0117,\n",
            "        0.0119, 0.0107, 0.0128, 0.0097, 0.0119, 0.0008, 0.0113, 0.0077, 0.0116,\n",
            "        0.0099, 0.0102, 0.0115, 0.0052, 0.0078, 0.0121, 0.0133, 0.0123, 0.0065,\n",
            "        0.0019, 0.0108, 0.0132, 0.0107, 0.0118, 0.0108, 0.0116, 0.0098, 0.0094,\n",
            "        0.0081, 0.0087, 0.0091, 0.0110, 0.0155, 0.0087, 0.0118, 0.0163, 0.0082,\n",
            "        0.0158, 0.0101, 0.0097, 0.0116, 0.0132, 0.0112, 0.0123, 0.0059, 0.0092,\n",
            "        0.0110, 0.0105, 0.0134, 0.0112, 0.0108, 0.0117, 0.0074, 0.0084, 0.0089,\n",
            "        0.0096, 0.0052, 0.0150, 0.0092, 0.0172, 0.0138],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [58]\n",
            "DEBUGGING: logits looks like: tensor([561.8542, 561.6560, 561.7504, 561.7242, 561.9725, 561.8571, 561.8525,\n",
            "        561.7781, 561.5516, 561.7952, 561.5568, 561.9814, 561.7716, 562.0292,\n",
            "        561.7026, 560.9866, 561.7737, 561.7507, 561.9150, 561.6653, 561.7564,\n",
            "        561.6797, 561.6755, 561.9238, 561.5747, 561.9081, 561.6105, 561.8389,\n",
            "        561.8286, 561.9191, 561.6299, 561.8641, 561.7938, 561.9918, 561.7587,\n",
            "        561.8503, 561.8604, 561.8057, 561.8969, 561.7571, 561.8615, 560.4870,\n",
            "        561.8351, 561.6457, 561.8478, 561.7671, 561.7845, 561.8418, 561.4468,\n",
            "        561.6519, 561.8705, 561.9143, 561.8785, 561.5569, 560.9537, 561.8119,\n",
            "        561.9135, 561.8059, 561.8561, 561.8101, 561.8458, 561.7654, 561.7399,\n",
            "        561.6682, 561.7014, 561.7280, 561.8232, 561.9921, 561.7037, 561.8552,\n",
            "        562.0186, 561.6740, 562.0010, 561.7767, 561.7604, 561.8458, 561.9106,\n",
            "        561.8288, 561.8788, 561.5119, 561.7302, 561.8226, 561.7996, 561.9214,\n",
            "        561.8285, 561.8129, 561.8527, 561.6253, 561.6879, 561.7132, 561.7531,\n",
            "        561.4420, 561.9744, 561.7301, 562.0450, 561.9343],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0111, 0.0095, 0.0117, 0.0100, 0.0091, 0.0098, 0.0091, 0.0090, 0.0093,\n",
            "        0.0060, 0.0157, 0.0106, 0.0127, 0.0165, 0.0071, 0.0068, 0.0070, 0.0049,\n",
            "        0.0171, 0.0051, 0.0086, 0.0092, 0.0155, 0.0075, 0.0092, 0.0167, 0.0072,\n",
            "        0.0042, 0.0049, 0.0127, 0.0072, 0.0067, 0.0087, 0.0058, 0.0145, 0.0124,\n",
            "        0.0086, 0.0082, 0.0096, 0.0073, 0.0073, 0.0072, 0.0152, 0.0088, 0.0109,\n",
            "        0.0076, 0.0181, 0.0172, 0.0082, 0.0079, 0.0078, 0.0128, 0.0087, 0.0052,\n",
            "        0.0098, 0.0072, 0.0048, 0.0086, 0.0104, 0.0139, 0.0075, 0.0119, 0.0085,\n",
            "        0.0106, 0.0078, 0.0087, 0.0112, 0.0083, 0.0090, 0.0078, 0.0070, 0.0102,\n",
            "        0.0101, 0.0059, 0.0081, 0.0063, 0.0111, 0.0137, 0.0066, 0.0092, 0.0065,\n",
            "        0.0113, 0.0143, 0.0059, 0.0073, 0.0071, 0.0045, 0.0103, 0.0152, 0.0085,\n",
            "        0.0111, 0.0082, 0.0102, 0.0073, 0.0050, 0.0095, 0.0050, 0.0106, 0.0056,\n",
            "        0.0104, 0.0155, 0.0115, 0.0156, 0.0071, 0.0094, 0.0072],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [85]\n",
            "DEBUGGING: logits looks like: tensor([561.8442, 561.7662, 561.8729, 561.7938, 561.7457, 561.7858, 561.7454,\n",
            "        561.7394, 561.7568, 561.5394, 562.0201, 561.8212, 561.9154, 562.0443,\n",
            "        561.6236, 561.6037, 561.6186, 561.4411, 562.0632, 561.4590, 561.7188,\n",
            "        561.7515, 562.0139, 561.6490, 561.7503, 562.0501, 561.6298, 561.3578,\n",
            "        561.4426, 561.9150, 561.6275, 561.5912, 561.7252, 561.5198, 561.9789,\n",
            "        561.9023, 561.7178, 561.6935, 561.7760, 561.6345, 561.6386, 561.6298,\n",
            "        562.0046, 561.7293, 561.8368, 561.6541, 562.0909, 562.0645, 561.6951,\n",
            "        561.6744, 561.6714, 561.9182, 561.7271, 561.4651, 561.7828, 561.6317,\n",
            "        561.4277, 561.7215, 561.8121, 561.9586, 561.6523, 561.8823, 561.7134,\n",
            "        561.8245, 561.6701, 561.7241, 561.8511, 561.6985, 561.7407, 561.6686,\n",
            "        561.6147, 561.8060, 561.7979, 561.5314, 561.6893, 561.5643, 561.8468,\n",
            "        561.9508, 561.5827, 561.7519, 561.5795, 561.8552, 561.9724, 561.5327,\n",
            "        561.6345, 561.6198, 561.3954, 561.8100, 562.0040, 561.7153, 561.8472,\n",
            "        561.6957, 561.8019, 561.6396, 561.4512, 561.7682, 561.4442, 561.8226,\n",
            "        561.5050, 561.8145, 562.0142, 561.8646, 562.0177, 561.6220, 561.7633,\n",
            "        561.6321], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.7082653196252977 and immediate abs rewards look like: [0.03063765095475901, 0.018337027771849534, 0.014364625375492324, 0.004012461366528441, 0.010781989170027373, 0.007508716179017938, 1.245090697921114e-05, 0.00025186222501361044, 0.009501110969722504, 0.001287526791657001, 3.240700380047201e-05, 0.0006887037834530929, 0.00012683571867455612, 8.495841711919638e-05, 0.0002033727064372215, 0.0006606503088733007, 0.0005618650629912736, 0.00028283148913033074, 0.00011737832164726569, 0.0007394951453534304, 3.20281787935528e-05, 0.00016018125552363927, 0.0001413818326909677, 0.0001408338207511406, 0.0005211307316130842, 0.0001180881522486743, 8.948393224272877e-05, 0.0001563999435347796, 3.1239357667800505e-05, 0.00015247024748532567, 0.00016594014141446678, 0.6063622223578022, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 0.0, 0.0, 4.547473508864641e-13, 9.094947017729282e-13, 0.0, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0]\n",
            "DEBUGGING: the total relative reward of the trajectory = 54.97771518550923 and immediate relative rewards look like: [0.08261989991023588, 0.09972204597049691, 0.1177656555751411, 0.044033391618331606, 0.14806708549471354, 0.12410651313223449, 0.0002405890772849748, 0.005562005236002142, 0.23606166503250983, 0.03563735404708787, 0.0009870417903626977, 0.022883454546019893, 0.004566417593143396, 0.0032941274783194743, 0.008448898636125964, 0.029277383421759368, 0.026460683678203395, 0.014105483598406767, 0.00617964099681497, 0.040982759521048386, 0.0018641309445087048, 0.009767043145620763, 0.009013001766908632, 0.009368784200146795, 0.03611342503362604, 0.008511858611069519, 0.006698348952238961, 0.012141276278126906, 0.0025118207511201853, 0.01268231898058823, 0.01426342496736357, 53.80377765483094, 0.0, 5.153803310047375e-11, 5.305385760342081e-11, 0.0, 5.6085506609322075e-11, 0.0, 0.0, 0.0, 6.214880462115009e-11, 1.2732925824819064e-10, 0.0, 1.333925562600497e-10, 6.821210263295928e-11, 6.972792713592449e-11, 7.124375163886858e-11, 0.0, 0.0, 0.0]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 200 number of matrices\n",
            "DEBUGGING: ACT_MAT has 200 number of matrices\n",
            "DEBUGGING: VAL looks like: [[23.039798599232487, 23.155237842504473, 23.378971963698792, 23.394741491139293, 23.562465864672763, 23.62498786239091, 23.711838527292254, 23.704753274323426, 23.870674098292817, 23.970526277686886, 23.536754816025535, 23.677399105404707, 23.872169161499908, 24.101491444874856, 24.33198677776643, 24.57596039269576, 24.778728855568705, 24.990796040240944, 25.242290740346462, 9.325807581757644e-10, 8.501326141398355e-10, 8.104890326229902e-10, 8.01833296050994e-10, 7.923245598656682e-10, 7.452069472316086e-10, 6.95316695324054e-10, 6.824353300865057e-10, 6.893286162489956e-10, 6.534197274406625e-10, 6.600199267077399e-10, 6.437197567307257e-10, 6.26489370641342e-10, 6.083193723172381e-10, 5.8920027072574e-10, 5.951517886118586e-10, 5.475736676852947e-10, 4.979838238171024e-10, 5.030139634516186e-10, 4.790033312075536e-10, 4.838417486944986e-10, 4.581063218539404e-10, 4.3134537327612426e-10, 3.7139469106264574e-10, 3.093073105410058e-10, 2.45061648899991e-10, 2.1308646220555658e-10, 1.448066010804311e-10, 1.1028760127373143e-10, 7.465435677052505e-11, 3.789561257387201e-11], [19.368590269302093, 19.563689296767883, 19.744105825884468, 19.90918565165884, 20.064009367718004, 20.225213457018587, 20.268097275305518, 20.472758872600092, 1.2084212906445183e-09, 1.2206275663075943e-09, 1.2099900997608798e-09, 1.1969484802647662e-09, 1.2090388689543092e-09, 1.1913942334815041e-09, 1.139120812482236e-09, 1.1161765264300438e-09, 1.1274510367980241e-09, 1.0607515021690154e-09, 1.0301254955446616e-09, 9.968934315256946e-10, 9.610289863000486e-10, 8.742747905190599e-10, 8.325783655773336e-10, 7.881640608337275e-10, 7.410044229569336e-10, 6.910717213092177e-10, 6.980522437466845e-10, 7.051032765118025e-10, 6.479178256441243e-10, 5.878580401672596e-10, 5.24894886398257e-10, 5.301968549477343e-10, 5.355523787350852e-10, 5.409619987223083e-10, 5.464262613356649e-10, 5.519457185208737e-10, 4.748395912740507e-10, 3.9465791046468247e-10, 3.9864435400472977e-10, 4.026710646512422e-10, 4.067384491426689e-10, 4.108469183259282e-10, 4.149968871979073e-10, 4.191887749473811e-10, 4.2342300499735464e-10, 4.2770000504783296e-10, 3.2637183267065276e-10, 2.217234396084424e-10, 2.23963070311558e-10, 1.1368683772159018e-10], [3.0377374351822133, 3.062494555579753, 3.00934074810219, 3.0187810075667816, 2.984047412235818, 2.961460188822598, 2.9257619970654116, 2.8363720721293655, 2.023241319284239, 1.9866242930164293, 1.9619338692299322, 1.7710498787472826, 1.7754388266791137, 1.515368748786355, 1.5112119781675746, 1.5093113913757654, 1.5117964498099237, 1.4608920674305104, 1.4740075815157794, 1.2483863720513433, 1.230442349270151, 1.1270396068723691, 0.9635656558587272, 0.9597575728251928, 0.8045983916945688, 0.8069738433242556, 0.6806968224964964, 0.6664173439691667, 0.6251475511418257, 0.5385788678651264, 0.5318679531972231, 0.532507026945499, 0.534994355773496, 0.5025120586976424, 0.3672080210987411, 0.36918148911440135, 0.36492253262148117, 0.3612419128645474, 0.3254374659327388, 0.25147041612487486, 0.25248528296400863, 0.2516854488902115, 0.25422679993065106, 0.24474615151972395, 0.21034525540127397, 0.20632351735445884, 0.04878858348959892, 0.013404838930712233, 0.0016788273130546583, 0.00011049799007903491], [40.48592689879954, 40.8114212109993, 41.122928449524046, 41.419356357524144, 41.79325552111698, 42.06584690466896, 42.36539433488558, 42.793084591725545, 43.219719784332874, 43.41783648414178, 43.82040316171181, 44.26203648476914, 44.68601316184154, 45.13277448913979, 45.58533369864795, 46.03725737374932, 46.47270706093693, 46.915400381069425, 47.37504535098083, 47.847339100993956, 48.289248829770614, 48.775136059420305, 49.25794850128756, 49.7463994944653, 50.23942495986379, 50.71041569174764, 51.214044275895525, 51.724591845397256, 52.23479855466579, 52.7598855898128, 53.28000330387092, 53.80377765545814, 6.335352728914673e-10, 6.399346190822902e-10, 5.943399858402187e-10, 5.467536648856544e-10, 5.522764291774286e-10, 5.012029520889966e-10, 5.062656081707036e-10, 5.113794021926298e-10, 5.165448506996261e-10, 4.589859051297737e-10, 3.3500671402180114e-10, 3.3839062022404154e-10, 2.070687514787796e-10, 1.4025924125840438e-10, 7.124375163886858e-11, 0.0, 0.0, 0.0]]\n",
            "DEBUGGING: traj_returns = [23.039798599232487, 19.368590269302093, 3.0377374351822133, 40.48592689879954]\n",
            "DEBUGGING: actions = [[59], [35], [32], [10], [26], [17], [20], [55], [23], [26], [50], [68], [64], [8], [36], [1], [15], [65], [0], [74], [62], [32], [10], [16], [27], [48], [42], [77], [81], [1], [7], [36], [71], [3], [61], [89], [20], [39], [3], [1], [52], [88], [36], [38], [4], [71], [65], [50], [46], [45], [5], [28], [41], [46], [6], [10], [19], [0], [28], [54], [0], [13], [41], [43], [65], [23], [13], [51], [47], [21], [21], [61], [61], [67], [32], [26], [16], [19], [78], [57], [65], [75], [53], [10], [65], [21], [49], [32], [60], [78], [83], [72], [69], [39], [91], [96], [5], [66], [96], [11], [6], [13], [23], [29], [42], [49], [7], [39], [42], [29], [14], [33], [7], [31], [18], [23], [57], [16], [39], [30], [78], [15], [15], [82], [39], [25], [6], [23], [58], [35], [23], [84], [10], [62], [80], [45], [30], [33], [62], [20], [13], [88], [16], [23], [36], [60], [20], [71], [78], [81], [12], [47], [22], [49], [56], [33], [17], [62], [57], [63], [1], [7], [11], [12], [50], [74], [59], [11], [54], [18], [47], [9], [71], [49], [9], [37], [40], [30], [15], [24], [9], [0], [90], [60], [19], [79], [31], [52], [25], [58], [90], [68], [98], [83], [95], [86], [20], [0], [84], [85]]\n",
            "DEBUGGING: actions length = 200\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[ 7.9708,  7.3719,  6.7599,  ..., -6.0841, -6.5309, -9.5543],\n",
            "        [ 8.1444,  7.5212,  6.9230,  ..., -6.2073, -6.6727, -9.7421],\n",
            "        [ 8.1486,  7.5338,  6.9306,  ..., -6.2236, -6.6854, -9.7599],\n",
            "        ...,\n",
            "        [ 8.1386,  7.5247,  6.9107,  ..., -6.2160, -6.6748, -9.7522],\n",
            "        [ 8.1370,  7.5224,  6.9096,  ..., -6.2145, -6.6734, -9.7501],\n",
            "        [ 8.1320,  7.5172,  6.9051,  ..., -6.2097, -6.6683, -9.7434]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[ 8.1366,  7.5226,  6.9092,  ..., -6.2143, -6.6732, -9.7498],\n",
            "        [ 8.1356,  7.5212,  6.9085,  ..., -6.2134, -6.6723, -9.7485],\n",
            "        [ 8.1371,  7.5227,  6.9096,  ..., -6.2147, -6.6735, -9.7504],\n",
            "        ...,\n",
            "        [ 8.1337,  7.5194,  6.9068,  ..., -6.2117, -6.6704, -9.7460],\n",
            "        [ 8.1357,  7.5212,  6.9082,  ..., -6.2134, -6.6724, -9.7486],\n",
            "        [ 8.1341,  7.5193,  6.9070,  ..., -6.2117, -6.6705, -9.7462]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([561.8442, 561.7662, 561.8729, 561.7938, 561.7457, 561.7858, 561.7454,\n",
            "        561.7394, 561.7568, 561.5394, 562.0201, 561.8212, 561.9154, 562.0443,\n",
            "        561.6236, 561.6037, 561.6186, 561.4411, 562.0632, 561.4590, 561.7188,\n",
            "        561.7515, 562.0139, 561.6490, 561.7503, 562.0501, 561.6298, 561.3578,\n",
            "        561.4426, 561.9150, 561.6275, 561.5912, 561.7252, 561.5198, 561.9789,\n",
            "        561.9023, 561.7178, 561.6935, 561.7760, 561.6345, 561.6386, 561.6298,\n",
            "        562.0046, 561.7293, 561.8368, 561.6541, 562.0909, 562.0645, 561.6951,\n",
            "        561.6744, 561.6714, 561.9182, 561.7271, 561.4651, 561.7828, 561.6317,\n",
            "        561.4277, 561.7215, 561.8121, 561.9586, 561.6523, 561.8823, 561.7134,\n",
            "        561.8245, 561.6701, 561.7241, 561.8511, 561.6985, 561.7407, 561.6686,\n",
            "        561.6147, 561.8060, 561.7979, 561.5314, 561.6893, 561.5643, 561.8468,\n",
            "        561.9508, 561.5827, 561.7519, 561.5795, 561.8552, 561.9724, 561.5327,\n",
            "        561.6345, 561.6198, 561.3954, 561.8100, 562.0040, 561.7153, 561.8472,\n",
            "        561.6957, 561.8019, 561.6396, 561.4512, 561.7682, 561.4442, 561.8226,\n",
            "        561.5050, 561.8145, 562.0142, 561.8646, 562.0177, 561.6220, 561.7633,\n",
            "        561.6321], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[2.14830133e+01 2.16482107e+01 2.18138367e+01 2.19355161e+01\n",
            "  2.21009445e+01 2.22193771e+01 2.23177730e+01 2.24517422e+01\n",
            "  1.72784088e+01 1.73437468e+01 1.73297730e+01 1.74276214e+01\n",
            "  1.75834053e+01 1.76874087e+01 1.78571331e+01 1.80306323e+01\n",
            "  1.81908081e+01 1.83417721e+01 1.85228359e+01 1.22739314e+01\n",
            "  1.23799228e+01 1.24755439e+01 1.25553785e+01 1.26765393e+01\n",
            "  1.27610058e+01 1.28793474e+01 1.29736853e+01 1.30977523e+01\n",
            "  1.32149865e+01 1.33246161e+01 1.34529678e+01 1.35840712e+01\n",
            "  1.33748589e-01 1.25628015e-01 9.18020057e-02 9.22953727e-02\n",
            "  9.12306335e-02 9.03104786e-02 8.13593668e-02 6.28676044e-02\n",
            "  6.31213211e-02 6.29213625e-02 6.35567003e-02 6.11865381e-02\n",
            "  5.25863141e-02 5.15808795e-02 1.21971460e-02 3.35120982e-03\n",
            "  4.19706903e-04 2.76245354e-05]]\n",
            "DEBUGGING: baseline2 looks like: 21.483013300629082\n",
            "DEBUGGING: ADS looks like: [ 1.55678530e+00  1.50702712e+00  1.56513522e+00  1.45922536e+00\n",
            "  1.46152132e+00  1.40561076e+00  1.39406549e+00  1.25301107e+00\n",
            "  6.59226530e+00  6.62677951e+00  6.20698185e+00  6.24977774e+00\n",
            "  6.28876387e+00  6.41408277e+00  6.47485366e+00  6.54532810e+00\n",
            "  6.58792076e+00  6.64902392e+00  6.71945482e+00 -1.22739314e+01\n",
            " -1.23799228e+01 -1.24755439e+01 -1.25553785e+01 -1.26765393e+01\n",
            " -1.27610058e+01 -1.28793474e+01 -1.29736853e+01 -1.30977523e+01\n",
            " -1.32149865e+01 -1.33246161e+01 -1.34529678e+01 -1.35840712e+01\n",
            " -1.33748589e-01 -1.25628015e-01 -9.18020051e-02 -9.22953721e-02\n",
            " -9.12306330e-02 -9.03104781e-02 -8.13593664e-02 -6.28676039e-02\n",
            " -6.31213206e-02 -6.29213621e-02 -6.35566999e-02 -6.11865378e-02\n",
            " -5.25863138e-02 -5.15808793e-02 -1.21971459e-02 -3.35120971e-03\n",
            " -4.19706828e-04 -2.76244975e-05 -2.11442303e+00 -2.08452143e+00\n",
            " -2.06973092e+00 -2.02633048e+00 -2.03693517e+00 -1.99416365e+00\n",
            " -2.04967576e+00 -1.97898333e+00 -1.72784088e+01 -1.73437468e+01\n",
            " -1.73297730e+01 -1.74276214e+01 -1.75834053e+01 -1.76874087e+01\n",
            " -1.78571331e+01 -1.80306323e+01 -1.81908081e+01 -1.83417721e+01\n",
            " -1.85228359e+01 -1.22739314e+01 -1.23799228e+01 -1.24755439e+01\n",
            " -1.25553785e+01 -1.26765393e+01 -1.27610058e+01 -1.28793474e+01\n",
            " -1.29736853e+01 -1.30977523e+01 -1.32149865e+01 -1.33246161e+01\n",
            " -1.34529678e+01 -1.35840712e+01 -1.33748589e-01 -1.25628015e-01\n",
            " -9.18020052e-02 -9.22953721e-02 -9.12306331e-02 -9.03104782e-02\n",
            " -8.13593664e-02 -6.28676040e-02 -6.31213207e-02 -6.29213621e-02\n",
            " -6.35566998e-02 -6.11865377e-02 -5.25863136e-02 -5.15808791e-02\n",
            " -1.21971457e-02 -3.35120959e-03 -4.19706679e-04 -2.76244217e-05\n",
            " -1.84452759e+01 -1.85857162e+01 -1.88044960e+01 -1.89167351e+01\n",
            " -1.91168971e+01 -1.92579169e+01 -1.93920110e+01 -1.96153701e+01\n",
            " -1.52551675e+01 -1.53571225e+01 -1.53678391e+01 -1.56565715e+01\n",
            " -1.58079665e+01 -1.61720399e+01 -1.63459211e+01 -1.65213209e+01\n",
            " -1.66790116e+01 -1.68808801e+01 -1.70488283e+01 -1.10255450e+01\n",
            " -1.11494804e+01 -1.13485043e+01 -1.15918129e+01 -1.17167817e+01\n",
            " -1.19564074e+01 -1.20723735e+01 -1.22929885e+01 -1.24313350e+01\n",
            " -1.25898390e+01 -1.27860372e+01 -1.29210999e+01 -1.30515641e+01\n",
            "  4.01245766e-01  3.76884044e-01  2.75406015e-01  2.76886116e-01\n",
            "  2.73691899e-01  2.70931434e-01  2.44078099e-01  1.88602812e-01\n",
            "  1.89363962e-01  1.88764086e-01  1.90670100e-01  1.83559613e-01\n",
            "  1.57758941e-01  1.54742638e-01  3.65914375e-02  1.00536291e-02\n",
            "  1.25912041e-03  8.28734547e-05  1.90029136e+01  1.91632105e+01\n",
            "  1.93090917e+01  1.94838402e+01  1.96923110e+01  1.98464698e+01\n",
            "  2.00476213e+01  2.03413424e+01  2.59413110e+01  2.60740897e+01\n",
            "  2.64906302e+01  2.68344151e+01  2.71026079e+01  2.74453658e+01\n",
            "  2.77282006e+01  2.80066251e+01  2.82818990e+01  2.85736283e+01\n",
            "  2.88522094e+01  3.55734077e+01  3.59093260e+01  3.62995921e+01\n",
            "  3.67025700e+01  3.70698602e+01  3.74784191e+01  3.78310683e+01\n",
            "  3.82403590e+01  3.86268395e+01  3.90198120e+01  3.94352695e+01\n",
            "  3.98270355e+01  4.02197065e+01 -1.33748589e-01 -1.25628014e-01\n",
            " -9.18020051e-02 -9.22953721e-02 -9.12306330e-02 -9.03104781e-02\n",
            " -8.13593663e-02 -6.28676039e-02 -6.31213206e-02 -6.29213621e-02\n",
            " -6.35566999e-02 -6.11865378e-02 -5.25863139e-02 -5.15808794e-02\n",
            " -1.21971459e-02 -3.35120982e-03 -4.19706903e-04 -2.76245354e-05]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(2.6433, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-0.0147, -0.0849,  0.0639,  ..., -0.1631,  0.0928,  0.0785],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0197, -0.1133,  0.0853,  ..., -0.2175,  0.1238,  0.1054],\n",
            "        [-0.0119, -0.0686,  0.0517,  ..., -0.1317,  0.0750,  0.0696]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0364,  0.0089,  0.0000,  0.0160,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0500,\n",
            "          0.0000,  0.0490,  0.0700,  0.0267],\n",
            "        [ 0.0236,  0.0035,  0.0000,  0.0029,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0317,\n",
            "          0.0000,  0.0298,  0.0470,  0.0212],\n",
            "        [ 0.0340,  0.0090,  0.0000,  0.0173,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0468,\n",
            "          0.0000,  0.0464,  0.0648,  0.0237],\n",
            "        [-0.0036,  0.0007,  0.0000,  0.0037,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0046,\n",
            "          0.0000, -0.0035, -0.0082, -0.0054],\n",
            "        [-0.0074, -0.0015,  0.0000, -0.0024,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0100,\n",
            "          0.0000, -0.0097, -0.0143, -0.0058],\n",
            "        [ 0.0243,  0.0049,  0.0000,  0.0071,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0331,\n",
            "          0.0000,  0.0318,  0.0475,  0.0197],\n",
            "        [-0.0476, -0.0096,  0.0000, -0.0139,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0647,\n",
            "          0.0000, -0.0622, -0.0930, -0.0386],\n",
            "        [-0.0176, -0.0020,  0.0000, -0.0001,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0235,\n",
            "          0.0000, -0.0217, -0.0356, -0.0169],\n",
            "        [-0.0253, -0.0052,  0.0000, -0.0079,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0345,\n",
            "          0.0000, -0.0332, -0.0494, -0.0203],\n",
            "        [-0.0328, -0.0056,  0.0000, -0.0063,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0444,\n",
            "          0.0000, -0.0420, -0.0650, -0.0283]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-0.0337,  0.0858,  0.0355,  ...,  0.0335,  0.0401,  0.5722],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0439,  0.1120,  0.0464,  ...,  0.0437,  0.0524,  0.7479],\n",
            "        [-0.0251,  0.0641,  0.0265,  ...,  0.0250,  0.0299,  0.4261]])\n",
            "   Last layer:\n",
            "tensor([[ 0.1692,  0.0733,  0.0000,  0.2183,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2516,\n",
            "          0.0000,  0.2477,  0.2912,  0.0509],\n",
            "        [ 0.1621,  0.0705,  0.0000,  0.2087,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2408,\n",
            "          0.0000,  0.2378,  0.2792,  0.0490],\n",
            "        [ 0.1468,  0.0637,  0.0000,  0.1891,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2180,\n",
            "          0.0000,  0.2151,  0.2526,  0.0443],\n",
            "        [-0.0522, -0.0227,  0.0000, -0.0672,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0775,\n",
            "          0.0000, -0.0766, -0.0899, -0.0158],\n",
            "        [-0.0430, -0.0187,  0.0000, -0.0553,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0638,\n",
            "          0.0000, -0.0632, -0.0741, -0.0130],\n",
            "        [ 0.1357,  0.0588,  0.0000,  0.1749,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2016,\n",
            "          0.0000,  0.1987,  0.2336,  0.0409],\n",
            "        [-0.2728, -0.1185,  0.0000, -0.3512,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.4051,\n",
            "          0.0000, -0.4000, -0.4696, -0.0823],\n",
            "        [-0.1347, -0.0585,  0.0000, -0.1733,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2000,\n",
            "          0.0000, -0.1976, -0.2319, -0.0407],\n",
            "        [-0.1482, -0.0645,  0.0000, -0.1904,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2198,\n",
            "          0.0000, -0.2176, -0.2552, -0.0448],\n",
            "        [-0.2052, -0.0890,  0.0000, -0.2646,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.3051,\n",
            "          0.0000, -0.3006, -0.3533, -0.0619]])\n",
            "DEBUGGING: training for one iteration takes 0.005148 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 21\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([0.2895, 0.0082, 0.0186, 0.0218, 0.0098, 0.0114, 0.0112, 0.0039, 0.0046,\n",
            "        0.0125, 0.0244, 0.0046, 0.0123, 0.0066, 0.0105, 0.0107, 0.0087, 0.0143,\n",
            "        0.0117, 0.0069, 0.0052, 0.0194, 0.0126, 0.0153, 0.0085, 0.0188, 0.0072,\n",
            "        0.0199, 0.0052, 0.0137, 0.0145, 0.0135, 0.0117, 0.0122, 0.0109, 0.0083,\n",
            "        0.0059, 0.0048, 0.0047, 0.0093, 0.0214, 0.0096, 0.0095, 0.0112, 0.0060,\n",
            "        0.0093, 0.0132, 0.0108, 0.0026, 0.0059, 0.0063, 0.0102, 0.0182, 0.0014,\n",
            "        0.0096, 0.0108, 0.0115, 0.0036, 0.0106, 0.0131, 0.0065, 0.0067, 0.0066,\n",
            "        0.0212, 0.0133, 0.0046, 0.0114, 0.0114], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [0]\n",
            "DEBUGGING: logits looks like: tensor([452.3894, 450.6090, 451.0182, 451.0970, 450.6943, 450.7727, 450.7652,\n",
            "        450.2412, 450.3228, 450.8182, 451.1531, 450.3151, 450.8088, 450.5001,\n",
            "        450.7287, 450.7397, 450.6348, 450.8848, 450.7862, 450.5197, 450.3823,\n",
            "        451.0384, 450.8209, 450.9180, 450.6234, 451.0221, 450.5394, 451.0498,\n",
            "        450.3836, 450.8658, 450.8910, 450.8569, 450.7837, 450.8041, 450.7479,\n",
            "        450.6107, 450.4392, 450.3447, 450.3271, 450.6715, 451.0864, 450.6837,\n",
            "        450.6800, 450.7617, 450.4496, 450.6678, 450.8455, 450.7437, 450.0312,\n",
            "        450.4449, 450.4779, 450.7170, 451.0051, 449.7328, 450.6837, 450.7449,\n",
            "        450.7777, 450.1959, 450.7365, 450.8426, 450.4889, 450.5063, 450.4973,\n",
            "        451.0826, 450.8474, 450.3228, 450.7705, 450.7726],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0049, 0.0072, 0.0074, 0.0188, 0.0070, 0.0132, 0.0059, 0.0056, 0.0032,\n",
            "        0.0189, 0.0012, 0.0233, 0.0005, 0.0175, 0.0065, 0.0127, 0.0098, 0.0136,\n",
            "        0.0087, 0.0093, 0.0061, 0.0314, 0.0138, 0.0056, 0.0168, 0.0079, 0.0041,\n",
            "        0.0086, 0.0207, 0.0140, 0.0503, 0.0097, 0.0121, 0.0075, 0.0164, 0.0019,\n",
            "        0.0145, 0.0239, 0.0214, 0.0058, 0.0101, 0.0052, 0.0114, 0.0054, 0.0075,\n",
            "        0.0046, 0.0075, 0.0188, 0.0199, 0.0272, 0.0226, 0.0127, 0.0116, 0.0171,\n",
            "        0.0090, 0.0037, 0.0394, 0.0085, 0.0083, 0.0097, 0.0087, 0.0155, 0.0161,\n",
            "        0.0086, 0.0193, 0.0089, 0.0240, 0.0003, 0.0260, 0.0130, 0.0123, 0.0046,\n",
            "        0.0108, 0.0071, 0.0084, 0.0122, 0.0060, 0.0503],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [6]\n",
            "DEBUGGING: logits looks like: tensor([450.7646, 450.9568, 450.9724, 451.4380, 450.9456, 451.2636, 450.8555,\n",
            "        450.8326, 450.5586, 451.4408, 450.0700, 451.5464, 449.6566, 451.4031,\n",
            "        450.9040, 451.2428, 451.1114, 451.2773, 451.0529, 451.0885, 450.8730,\n",
            "        451.6945, 451.2823, 450.8294, 451.3824, 451.0049, 450.6830, 451.0484,\n",
            "        451.4870, 451.2921, 451.9310, 451.1103, 451.2202, 450.9778, 451.3705,\n",
            "        450.2795, 451.3099, 451.5587, 451.5034, 450.8515, 451.1298, 450.8003,\n",
            "        451.1885, 450.8104, 450.9765, 450.7306, 450.9774, 451.4391, 451.4673,\n",
            "        451.6234, 451.5307, 451.2430, 451.1982, 451.3922, 451.0717, 450.6303,\n",
            "        451.8085, 451.0389, 451.0327, 451.1092, 451.0536, 451.3423, 451.3602,\n",
            "        451.0497, 451.4525, 451.0675, 451.5605, 449.3489, 451.6006, 451.2545,\n",
            "        451.2262, 450.7331, 451.1602, 450.9538, 451.0388, 451.2222, 450.8649,\n",
            "        451.9310], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0167, 0.0082, 0.0194, 0.0364, 0.0028, 0.0091, 0.0088, 0.0074, 0.0172,\n",
            "        0.0057, 0.0185, 0.0239, 0.0033, 0.0136, 0.0112, 0.0202, 0.0058, 0.0058,\n",
            "        0.0122, 0.0164, 0.0053, 0.0366, 0.0012, 0.0330, 0.0073, 0.0151, 0.0040,\n",
            "        0.0072, 0.0190, 0.0090, 0.0083, 0.0143, 0.0155, 0.0090, 0.0055, 0.0109,\n",
            "        0.0038, 0.0005, 0.0453, 0.0039, 0.0163, 0.0021, 0.0054, 0.0046, 0.0231,\n",
            "        0.0046, 0.0035, 0.0146, 0.0309, 0.0187, 0.0082, 0.0027, 0.0028, 0.0126,\n",
            "        0.0179, 0.0225, 0.0132, 0.0103, 0.0048, 0.0222, 0.0161, 0.0082, 0.0058,\n",
            "        0.0107, 0.0143, 0.0107, 0.0011, 0.0060, 0.0086, 0.0061, 0.0082, 0.0061,\n",
            "        0.0113, 0.0118, 0.0017, 0.0072, 0.0089, 0.0072, 0.0219, 0.0059, 0.0111,\n",
            "        0.0197, 0.0100, 0.0127, 0.0088, 0.0018], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [35]\n",
            "DEBUGGING: logits looks like: tensor([451.9162, 451.5613, 451.9900, 452.3046, 451.0177, 451.6113, 451.5923,\n",
            "        451.5072, 451.9284, 451.3736, 451.9662, 452.0937, 451.1096, 451.8109,\n",
            "        451.7144, 452.0104, 451.3875, 451.3877, 451.7573, 451.9063, 451.3408,\n",
            "        452.3079, 450.6013, 452.2562, 451.5028, 451.8639, 451.2005, 451.4927,\n",
            "        451.9786, 451.6032, 451.5645, 451.8389, 451.8775, 451.6082, 451.3589,\n",
            "        451.7003, 451.1758, 450.1371, 452.4135, 451.1914, 451.9040, 450.8866,\n",
            "        451.3507, 451.2675, 452.0764, 451.2755, 451.1385, 451.8486, 452.2228,\n",
            "        451.9710, 451.5565, 451.0078, 451.0285, 451.7754, 451.9492, 452.0629,\n",
            "        451.7957, 451.6722, 451.2885, 452.0565, 451.8963, 451.5571, 451.3870,\n",
            "        451.6928, 451.8389, 451.6927, 450.5382, 451.4017, 451.5814, 451.4107,\n",
            "        451.5568, 451.4148, 451.7177, 451.7421, 450.7817, 451.4933, 451.5976,\n",
            "        451.4956, 452.0509, 451.3917, 451.7094, 451.9987, 451.6590, 451.7796,\n",
            "        451.5941, 450.7881], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0080, 0.0127, 0.0229, 0.0116, 0.0060, 0.0122, 0.0107, 0.0158, 0.0088,\n",
            "        0.0107, 0.0112, 0.0072, 0.0076, 0.0048, 0.0135, 0.0067, 0.0067, 0.0075,\n",
            "        0.0056, 0.0075, 0.0153, 0.0083, 0.0060, 0.0111, 0.0119, 0.0072, 0.0116,\n",
            "        0.0135, 0.0088, 0.0085, 0.0081, 0.0060, 0.0124, 0.0066, 0.0129, 0.0266,\n",
            "        0.0114, 0.0104, 0.0101, 0.0119, 0.0089, 0.0125, 0.0131, 0.0105, 0.0141,\n",
            "        0.0102, 0.0073, 0.0087, 0.0110, 0.0078, 0.0119, 0.0055, 0.0073, 0.0115,\n",
            "        0.0174, 0.0104, 0.0068, 0.0079, 0.0152, 0.0119, 0.0125, 0.0088, 0.0123,\n",
            "        0.0094, 0.0150, 0.0126, 0.0086, 0.0063, 0.0075, 0.0092, 0.0170, 0.0084,\n",
            "        0.0075, 0.0114, 0.0076, 0.0074, 0.0118, 0.0072, 0.0142, 0.0102, 0.0121,\n",
            "        0.0081, 0.0158, 0.0099, 0.0159, 0.0062, 0.0041, 0.0091, 0.0083, 0.0125,\n",
            "        0.0066, 0.0125, 0.0080, 0.0071, 0.0107, 0.0117, 0.0105],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [10]\n",
            "DEBUGGING: logits looks like: tensor([451.6785, 451.9106, 452.2055, 451.8645, 451.5362, 451.8927, 451.8237,\n",
            "        452.0219, 451.7275, 451.8275, 451.8504, 451.6277, 451.6522, 451.4261,\n",
            "        451.9411, 451.5907, 451.5881, 451.6449, 451.5041, 451.6492, 452.0041,\n",
            "        451.6960, 451.5395, 451.8448, 451.8770, 451.6259, 451.8659, 451.9436,\n",
            "        451.7264, 451.7079, 451.6851, 451.5370, 451.9003, 451.5827, 451.9177,\n",
            "        452.2807, 451.8571, 451.8094, 451.7975, 451.8780, 451.7341, 451.9026,\n",
            "        451.9288, 451.8184, 451.9650, 451.8017, 451.6377, 451.7223, 451.8380,\n",
            "        451.6685, 451.8802, 451.4971, 451.6331, 451.8632, 452.0685, 451.8103,\n",
            "        451.6017, 451.6770, 452.0009, 451.8781, 451.9028, 451.7293, 451.8952,\n",
            "        451.7619, 451.9941, 451.9060, 451.7175, 451.5648, 451.6498, 451.7487,\n",
            "        452.0568, 451.7047, 451.6469, 451.8590, 451.6544, 451.6429, 451.8762,\n",
            "        451.6312, 451.9691, 451.8030, 451.8890, 451.6893, 452.0214, 451.7867,\n",
            "        452.0239, 451.5552, 451.3416, 451.7474, 451.6963, 451.9030, 451.5827,\n",
            "        451.9030, 451.6804, 451.6194, 451.8236, 451.8706, 451.8175],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0068, 0.0063, 0.0259, 0.0054, 0.0246, 0.0078, 0.0094, 0.0072, 0.0152,\n",
            "        0.0057, 0.0073, 0.0061, 0.0047, 0.0021, 0.0035, 0.0109, 0.0108, 0.0057,\n",
            "        0.0061, 0.0106, 0.0178, 0.0078, 0.0114, 0.0107, 0.0118, 0.0081, 0.0118,\n",
            "        0.0101, 0.0200, 0.0176, 0.0059, 0.0070, 0.0131, 0.0076, 0.0063, 0.0091,\n",
            "        0.0052, 0.0076, 0.0204, 0.0113, 0.0131, 0.0069, 0.0048, 0.0102, 0.0090,\n",
            "        0.0064, 0.0056, 0.0080, 0.0129, 0.0073, 0.0150, 0.0100, 0.0078, 0.0082,\n",
            "        0.0123, 0.0152, 0.0201, 0.0244, 0.0038, 0.0057, 0.0239, 0.0060, 0.0004,\n",
            "        0.0082, 0.0048, 0.0080, 0.0066, 0.0137, 0.0033, 0.0051, 0.0071, 0.0111,\n",
            "        0.0081, 0.0044, 0.0034, 0.0118, 0.0078, 0.0099, 0.0105, 0.0139, 0.0139,\n",
            "        0.0173, 0.0090, 0.0013, 0.0174, 0.0039, 0.0070, 0.0056, 0.0043, 0.0067,\n",
            "        0.0077, 0.0073, 0.0077, 0.0068, 0.0114, 0.0066, 0.0039, 0.0081, 0.0044,\n",
            "        0.0064, 0.0157, 0.0081, 0.0007, 0.0099, 0.0060, 0.0051, 0.0140, 0.0066],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [95]\n",
            "DEBUGGING: logits looks like: tensor([452.3736, 452.3360, 453.0453, 452.2636, 453.0187, 452.4420, 452.5400,\n",
            "        452.4058, 452.7773, 452.2903, 452.4100, 452.3183, 452.1930, 451.8000,\n",
            "        452.0383, 452.6123, 452.6065, 452.2861, 452.3244, 452.5979, 452.8590,\n",
            "        452.4431, 452.6361, 452.6048, 452.6515, 452.4626, 452.6529, 452.5729,\n",
            "        452.9153, 452.8533, 452.3047, 452.3903, 452.7027, 452.4292, 452.3391,\n",
            "        452.5237, 452.2446, 452.4307, 452.9263, 452.6293, 452.7049, 452.3824,\n",
            "        452.2025, 452.5814, 452.5154, 452.3446, 452.2759, 452.4566, 452.6969,\n",
            "        452.4124, 452.7726, 452.5673, 452.4424, 452.4704, 452.6726, 452.7784,\n",
            "        452.9189, 453.0158, 452.0843, 452.2913, 453.0049, 452.3110, 450.9256,\n",
            "        452.4702, 452.2060, 452.4592, 452.3647, 452.7257, 452.0134, 452.2348,\n",
            "        452.3993, 452.6194, 452.4619, 452.1555, 452.0343, 452.6527, 452.4456,\n",
            "        452.5668, 452.5956, 452.7342, 452.7345, 452.8423, 452.5166, 451.5436,\n",
            "        452.8452, 452.0989, 452.3931, 452.2805, 452.1499, 452.3694, 452.4377,\n",
            "        452.4096, 452.4377, 452.3757, 452.6329, 452.3616, 452.1044, 452.4624,\n",
            "        452.1640, 452.3433, 452.7948, 452.4657, 451.2623, 452.5634, 452.3125,\n",
            "        452.2319, 452.7380, 452.3640], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.8867413289890465 and immediate abs rewards look like: [0.016846865432398772, 0.0015901832225608814, 0.0015934622033455526, 0.0019343438611940655, 0.03153990328019063, 0.011572186330340628, 0.00031544807825412136, 0.00043874720677195, 0.012416396247772354, 0.8084937931098466, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 9.094947017729282e-13, 9.094947017729282e-13, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 1.3642420526593924e-12, 9.094947017729282e-13, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 0.0, 0.0, 9.094947017729282e-13, 1.3642420526593924e-12, 4.547473508864641e-13, 0.0, 0.0, 0.0]\n",
            "DEBUGGING: the total relative reward of the trajectory = 30.112500149602194 and immediate relative rewards look like: [0.05835945626064869, 0.011081823689079113, 0.01666624647475387, 0.026990428877181474, 0.5504775601805517, 0.2450664328330308, 0.007825652688523066, 0.012440778269878824, 0.39614010630873175, 28.787451661575545, 0.0, 0.0, 2.955857780762017e-11, 3.1832314562059726e-11, 3.410605131648481e-11, 3.63797880709254e-11, 0.0, 4.092726157978177e-11, 0.0, 9.094947017727214e-11, 9.549694368617918e-11, 1.0004441719499936e-10, 5.2295945351955264e-11, 5.4569682106375694e-11, 5.684341886079509e-11, 0.0, 6.139089236967266e-11, 6.366462912411945e-11, 1.3187673175713457e-10, 6.821210263296962e-11, 2.114575181622539e-10, 1.4551915228360234e-10, 0.0, 0.0, 7.958078640513122e-11, 8.185452315954493e-11, 8.412825991399586e-11, 8.640199666844783e-11, 8.86757334228605e-11, 0.0, 9.322320693170395e-11, 0.0, 0.0, 0.0, 2.0463630789890885e-10, 3.1377567211180293e-10, 1.0686562745829477e-10, 0.0, 0.0, 0.0]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([0.0059, 0.0171, 0.0164, 0.0200, 0.0126, 0.0126, 0.0200, 0.0087, 0.0196,\n",
            "        0.0153, 0.0132, 0.0193, 0.0068, 0.0209, 0.0210, 0.0144, 0.0094, 0.0222,\n",
            "        0.0119, 0.0265, 0.0103, 0.0214, 0.0097, 0.0260, 0.0142, 0.0110, 0.0174,\n",
            "        0.0146, 0.0113, 0.0101, 0.0092, 0.0142, 0.0153, 0.0168, 0.0073, 0.0132,\n",
            "        0.0173, 0.0209, 0.0053, 0.0139, 0.0118, 0.0102, 0.0109, 0.0100, 0.0186,\n",
            "        0.0241, 0.0131, 0.0143, 0.0164, 0.0083, 0.0199, 0.0104, 0.0197, 0.0132,\n",
            "        0.0074, 0.0195, 0.0181, 0.0212, 0.0212, 0.0142, 0.0201, 0.0065, 0.0118,\n",
            "        0.0203, 0.0130, 0.0204, 0.0124], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [11]\n",
            "DEBUGGING: logits looks like: tensor([446.8233, 447.3565, 447.3346, 447.4343, 447.2023, 447.2049, 447.4355,\n",
            "        447.0188, 447.4261, 447.3007, 447.2256, 447.4170, 446.8959, 447.4564,\n",
            "        447.4583, 447.2709, 447.0580, 447.4870, 447.1772, 447.5764, 447.1043,\n",
            "        447.4691, 447.0745, 447.5655, 447.2642, 447.1382, 447.3648, 447.2787,\n",
            "        447.1498, 447.0949, 447.0442, 447.2631, 447.3004, 447.3492, 446.9278,\n",
            "        447.2286, 447.3623, 447.4561, 446.7679, 447.2542, 447.1723, 447.0969,\n",
            "        447.1310, 447.0908, 447.3994, 447.5283, 447.2239, 447.2657, 447.3358,\n",
            "        446.9964, 447.4328, 447.1075, 447.4268, 447.2256, 446.9365, 447.4220,\n",
            "        447.3843, 447.4648, 447.4633, 447.2635, 447.4381, 446.8698, 447.1718,\n",
            "        447.4414, 447.2202, 447.4453, 447.1974], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0135, 0.0133, 0.0120, 0.0177, 0.0114, 0.0139, 0.0150, 0.0137, 0.0133,\n",
            "        0.0129, 0.0121, 0.0115, 0.0125, 0.0125, 0.0122, 0.0129, 0.0123, 0.0122,\n",
            "        0.0134, 0.0120, 0.0118, 0.0120, 0.0135, 0.0134, 0.0143, 0.0110, 0.0120,\n",
            "        0.0123, 0.0119, 0.0118, 0.0121, 0.0134, 0.0123, 0.0127, 0.0126, 0.0105,\n",
            "        0.0114, 0.0129, 0.0126, 0.0146, 0.0133, 0.0150, 0.0112, 0.0116, 0.0135,\n",
            "        0.0127, 0.0120, 0.0141, 0.0114, 0.0129, 0.0132, 0.0120, 0.0132, 0.0124,\n",
            "        0.0118, 0.0116, 0.0122, 0.0126, 0.0113, 0.0106, 0.0119, 0.0131, 0.0120,\n",
            "        0.0123, 0.0119, 0.0116, 0.0123, 0.0120, 0.0123, 0.0128, 0.0110, 0.0129,\n",
            "        0.0103, 0.0117, 0.0126, 0.0119, 0.0130, 0.0133, 0.0119, 0.0114],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [67]\n",
            "DEBUGGING: logits looks like: tensor([446.8604, 446.8545, 446.8040, 446.9990, 446.7769, 446.8776, 446.9149,\n",
            "        446.8699, 446.8548, 446.8379, 446.8083, 446.7808, 446.8232, 446.8243,\n",
            "        446.8130, 446.8406, 446.8153, 446.8110, 446.8592, 446.8014, 446.7940,\n",
            "        446.8014, 446.8622, 446.8580, 446.8911, 446.7603, 446.8054, 446.8152,\n",
            "        446.7975, 446.7951, 446.8092, 446.8585, 446.8172, 446.8335, 446.8270,\n",
            "        446.7365, 446.7773, 446.8397, 446.8290, 446.9007, 446.8542, 446.9133,\n",
            "        446.7675, 446.7844, 446.8611, 446.8329, 446.8031, 446.8856, 446.7764,\n",
            "        446.8383, 446.8497, 446.8027, 446.8511, 446.8182, 446.7954, 446.7852,\n",
            "        446.8134, 446.8266, 446.7719, 446.7404, 446.7997, 446.8457, 446.8053,\n",
            "        446.8154, 446.8010, 446.7850, 446.8150, 446.8053, 446.8157, 446.8340,\n",
            "        446.7615, 446.8376, 446.7254, 446.7927, 446.8290, 446.8007, 446.8420,\n",
            "        446.8564, 446.8011, 446.7766], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0235, 0.0116, 0.0114, 0.0116, 0.0110, 0.0114, 0.0111, 0.0113, 0.0112,\n",
            "        0.0113, 0.0115, 0.0115, 0.0113, 0.0112, 0.0117, 0.0111, 0.0110, 0.0116,\n",
            "        0.0118, 0.0112, 0.0114, 0.0115, 0.0110, 0.0118, 0.0112, 0.0115, 0.0114,\n",
            "        0.0111, 0.0117, 0.0118, 0.0119, 0.0119, 0.0110, 0.0113, 0.0114, 0.0103,\n",
            "        0.0109, 0.0122, 0.0118, 0.0112, 0.0114, 0.0121, 0.0117, 0.0114, 0.0105,\n",
            "        0.0113, 0.0105, 0.0121, 0.0114, 0.0115, 0.0112, 0.0116, 0.0115, 0.0116,\n",
            "        0.0114, 0.0108, 0.0112, 0.0110, 0.0114, 0.0119, 0.0113, 0.0107, 0.0108,\n",
            "        0.0114, 0.0116, 0.0113, 0.0120, 0.0110, 0.0113, 0.0117, 0.0115, 0.0111,\n",
            "        0.0116, 0.0114, 0.0120, 0.0114, 0.0109, 0.0110, 0.0111, 0.0109, 0.0111,\n",
            "        0.0114, 0.0119, 0.0110, 0.0107, 0.0117, 0.0111],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [50]\n",
            "DEBUGGING: logits looks like: tensor([447.1200, 446.7653, 446.7582, 446.7661, 446.7414, 446.7587, 446.7458,\n",
            "        446.7536, 446.7478, 446.7543, 446.7611, 446.7646, 446.7541, 446.7483,\n",
            "        446.7715, 446.7445, 446.7413, 446.7654, 446.7762, 446.7488, 446.7599,\n",
            "        446.7631, 446.7385, 446.7767, 446.7505, 446.7628, 446.7589, 446.7470,\n",
            "        446.7717, 446.7761, 446.7788, 446.7798, 446.7392, 446.7542, 446.7563,\n",
            "        446.7096, 446.7346, 446.7903, 446.7755, 446.7503, 446.7592, 446.7884,\n",
            "        446.7698, 446.7567, 446.7148, 446.7543, 446.7155, 446.7862, 446.7582,\n",
            "        446.7636, 446.7493, 446.7689, 446.7635, 446.7686, 446.7572, 446.7307,\n",
            "        446.7515, 446.7395, 446.7592, 446.7785, 446.7555, 446.7285, 446.7293,\n",
            "        446.7603, 446.7666, 446.7535, 446.7834, 446.7421, 446.7532, 446.7723,\n",
            "        446.7623, 446.7469, 446.7661, 446.7602, 446.7827, 446.7589, 446.7350,\n",
            "        446.7404, 446.7459, 446.7346, 446.7436, 446.7599, 446.7788, 446.7416,\n",
            "        446.7271, 446.7705, 446.7457], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0209, 0.0100, 0.0100, 0.0101, 0.0099, 0.0099, 0.0100, 0.0100, 0.0097,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0101, 0.0100, 0.0101, 0.0100, 0.0101,\n",
            "        0.0100, 0.0095, 0.0100, 0.0100, 0.0100, 0.0100, 0.0099, 0.0101, 0.0101,\n",
            "        0.0100, 0.0100, 0.0100, 0.0101, 0.0101, 0.0099, 0.0101, 0.0100, 0.0100,\n",
            "        0.0100, 0.0099, 0.0100, 0.0101, 0.0099, 0.0100, 0.0101, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0098, 0.0100, 0.0099, 0.0100, 0.0101, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0100, 0.0101, 0.0100, 0.0101,\n",
            "        0.0100, 0.0101, 0.0100, 0.0100, 0.0100, 0.0099, 0.0100, 0.0101, 0.0101,\n",
            "        0.0100, 0.0100, 0.0100, 0.0101, 0.0100, 0.0099, 0.0099, 0.0098, 0.0100,\n",
            "        0.0100, 0.0098, 0.0100, 0.0099, 0.0098, 0.0100, 0.0099, 0.0101, 0.0100,\n",
            "        0.0100, 0.0100, 0.0100, 0.0100, 0.0099, 0.0100, 0.0099, 0.0100, 0.0100],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [78]\n",
            "DEBUGGING: logits looks like: tensor([447.1193, 446.7535, 446.7530, 446.7574, 446.7486, 446.7464, 446.7531,\n",
            "        446.7503, 446.7363, 446.7508, 446.7511, 446.7524, 446.7513, 446.7552,\n",
            "        446.7530, 446.7570, 446.7524, 446.7561, 446.7523, 446.7255, 446.7513,\n",
            "        446.7497, 446.7512, 446.7534, 446.7448, 446.7545, 446.7558, 446.7492,\n",
            "        446.7506, 446.7492, 446.7550, 446.7559, 446.7475, 446.7570, 446.7498,\n",
            "        446.7524, 446.7509, 446.7476, 446.7526, 446.7562, 446.7476, 446.7509,\n",
            "        446.7545, 446.7505, 446.7525, 446.7526, 446.7504, 446.7537, 446.7433,\n",
            "        446.7507, 446.7465, 446.7521, 446.7568, 446.7524, 446.7522, 446.7525,\n",
            "        446.7502, 446.7509, 446.7503, 446.7509, 446.7552, 446.7523, 446.7554,\n",
            "        446.7517, 446.7571, 446.7527, 446.7520, 446.7504, 446.7463, 446.7523,\n",
            "        446.7552, 446.7540, 446.7516, 446.7525, 446.7512, 446.7573, 446.7531,\n",
            "        446.7477, 446.7458, 446.7437, 446.7512, 446.7496, 446.7430, 446.7514,\n",
            "        446.7488, 446.7431, 446.7515, 446.7475, 446.7549, 446.7494, 446.7504,\n",
            "        446.7510, 446.7507, 446.7531, 446.7440, 446.7516, 446.7485, 446.7523,\n",
            "        446.7513], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0189, 0.0090, 0.0091, 0.0090, 0.0091, 0.0091, 0.0091, 0.0090, 0.0091,\n",
            "        0.0091, 0.0090, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0090, 0.0091,\n",
            "        0.0090, 0.0091, 0.0090, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0090, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0090, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0091, 0.0090, 0.0092, 0.0091, 0.0091, 0.0090,\n",
            "        0.0091, 0.0091, 0.0090, 0.0091, 0.0091, 0.0090, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0090, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0090, 0.0091, 0.0091, 0.0090, 0.0091, 0.0091, 0.0090, 0.0091,\n",
            "        0.0091], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [34]\n",
            "DEBUGGING: logits looks like: tensor([447.1200, 446.7496, 446.7538, 446.7507, 446.7535, 446.7516, 446.7510,\n",
            "        446.7494, 446.7537, 446.7525, 446.7505, 446.7548, 446.7545, 446.7552,\n",
            "        446.7546, 446.7539, 446.7507, 446.7550, 446.7493, 446.7526, 446.7509,\n",
            "        446.7551, 446.7531, 446.7549, 446.7532, 446.7541, 446.7556, 446.7523,\n",
            "        446.7527, 446.7526, 446.7501, 446.7557, 446.7521, 446.7554, 446.7514,\n",
            "        446.7542, 446.7536, 446.7526, 446.7533, 446.7525, 446.7520, 446.7553,\n",
            "        446.7546, 446.7531, 446.7523, 446.7552, 446.7525, 446.7534, 446.7518,\n",
            "        446.7532, 446.7513, 446.7525, 446.7522, 446.7529, 446.7525, 446.7543,\n",
            "        446.7525, 446.7527, 446.7529, 446.7523, 446.7559, 446.7523, 446.7549,\n",
            "        446.7563, 446.7498, 446.7534, 446.7538, 446.7512, 446.7525, 446.7529,\n",
            "        446.7533, 446.7548, 446.7523, 446.7515, 446.7542, 446.7518, 446.7509,\n",
            "        446.7572, 446.7527, 446.7513, 446.7504, 446.7535, 446.7535, 446.7501,\n",
            "        446.7533, 446.7525, 446.7482, 446.7533, 446.7557, 446.7547, 446.7531,\n",
            "        446.7538, 446.7527, 446.7538, 446.7540, 446.7506, 446.7516, 446.7513,\n",
            "        446.7523, 446.7532, 446.7509, 446.7511, 446.7535, 446.7491, 446.7544,\n",
            "        446.7532, 446.7499, 446.7542, 446.7527], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.30821806326434853 and immediate abs rewards look like: [0.023442453944653607, 0.028699107045213168, 0.055071806815703894, 0.04446072392897804, 0.005220336462116393, 0.07105859327612052, 0.008825931959563604, 0.012017932889193617, 0.004749194340092799, 0.0029603020011563785, 0.00313560037852767, 0.01794975333950788, 0.0014403258685433684, 0.0011900814301952778, 0.004978603097470113, 0.00036617142109207634, 0.000555879704961626, 0.003027672672033077, 0.0001252403269518254, 0.0011834068313874013, 0.0025896471993291925, 0.0004931116448005923, 0.0014411563349767675, 0.003910802859309115, 0.002157520907530852, 0.00017998583530243195, 0.0011838613618238014, 0.0005805289304134931, 0.0006553440766765561, 7.673405320929305e-05, 0.0005033027211993613, 0.0006094346113059146, 0.0009453756867969787, 0.00015352826903836103, 0.0006821793165272538, 3.7643882706106524e-05, 5.021646984459949e-06, 0.00032223684524979035, 0.0002718281743909756, 0.00033542113374096516, 5.581783671004814e-05, 0.00021268369573590462, 3.46810454630031e-05, 1.846347868195153e-05, 0.00011105776184194838, 1.5625208334313356e-05, 7.360063000305672e-05, 1.1331454061291879e-05, 1.5289053862943547e-06, 8.949002335612022e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 6.013932933221261 and immediate relative rewards look like: [0.06498709042720274, 0.16015996526328447, 0.46472709674554796, 0.5081175593844814, 0.07553501808682248, 1.2356750535712877, 0.18282371806094128, 0.28525248943669806, 0.1272692383080675, 0.08826968652698097, 0.10293723028033065, 0.6434360894971665, 0.05623474584832227, 0.050060276433386286, 0.2244618888232949, 0.017635941426264564, 0.028449316174058808, 0.16409532294733095, 0.007171478020687601, 0.07133313946015571, 0.163961579334043, 0.03273326691282308, 0.10002877864665673, 0.2833688579159222, 0.16303582734016436, 0.014154124800964068, 0.09668511064505088, 0.049184972439221895, 0.05751673236527525, 0.006968228219509359, 0.047229574436789004, 0.059042715706858095, 0.09446865639893286, 0.015811059863009395, 0.07232367749510094, 0.004105826304632071, 0.0005629327516303882, 0.037099500986819064, 0.03212260461539105, 0.04065723715906115, 0.006935670492760857, 0.027072130188489564, 0.0045198869447618225, 0.0024622815245571757, 0.015147304697698264, 0.002178573407502691, 0.010485037702657081, 0.0016486450962715194, 0.00022707978674002026, 0.013562714319653965]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([1.0005e-02, 1.7675e-02, 8.4031e-03, 1.5643e-02, 2.0111e-02, 3.4604e-03,\n",
            "        5.4225e-03, 2.6506e-03, 9.1198e-03, 6.5909e-03, 8.8506e-05, 5.6371e-03,\n",
            "        7.5334e-03, 1.1973e-02, 2.4058e-02, 2.3138e-02, 2.2259e-03, 1.4042e-02,\n",
            "        4.5512e-03, 2.6257e-03, 2.5592e-03, 1.7313e-02, 1.8841e-02, 1.4176e-02,\n",
            "        1.1913e-02, 1.6995e-03, 2.4555e-02, 1.2056e-03, 3.1422e-02, 2.7018e-02,\n",
            "        4.5152e-03, 1.4518e-02, 1.0730e-02, 2.9038e-02, 4.1954e-02, 1.1627e-02,\n",
            "        8.6250e-03, 7.0692e-03, 4.6642e-03, 1.9881e-02, 1.4442e-02, 9.1282e-03,\n",
            "        3.3274e-02, 2.9256e-02, 2.2424e-02, 4.4938e-03, 8.5095e-03, 8.8021e-03,\n",
            "        6.4628e-02, 5.6886e-03, 2.7751e-03, 1.5476e-02, 5.8538e-03, 1.1353e-02,\n",
            "        6.2278e-04, 6.7661e-03, 1.2149e-02, 2.5255e-03, 1.2745e-03, 3.9125e-02,\n",
            "        7.1865e-02, 1.7111e-02, 1.1910e-02, 1.5207e-02, 1.9135e-02, 3.4025e-02,\n",
            "        2.0770e-02, 1.3132e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [48]\n",
            "DEBUGGING: logits looks like: tensor([451.5537, 451.8383, 451.4665, 451.7772, 451.9029, 451.0229, 451.2475,\n",
            "        450.8896, 451.5074, 451.3451, 449.1899, 451.2669, 451.4119, 451.6436,\n",
            "        451.9925, 451.9730, 450.8023, 451.7232, 451.1599, 450.8849, 450.8721,\n",
            "        451.8279, 451.8702, 451.7280, 451.6410, 450.6674, 452.0027, 450.4957,\n",
            "        452.1260, 452.0505, 451.1559, 451.7399, 451.5887, 452.0865, 452.2705,\n",
            "        451.6289, 451.4796, 451.3801, 451.1722, 451.8971, 451.7373, 451.5079,\n",
            "        452.1546, 452.0903, 451.9573, 451.1536, 451.4728, 451.4897, 452.4865,\n",
            "        451.2715, 450.9126, 451.7719, 451.2858, 451.6170, 450.1654, 451.3582,\n",
            "        451.6508, 450.8654, 450.5235, 452.2356, 452.5396, 451.8221, 451.6409,\n",
            "        451.7631, 451.8780, 452.1658, 451.9190, 451.6898],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0108, 0.0015, 0.0031, 0.0248, 0.1159, 0.0138, 0.0083, 0.0040, 0.0148,\n",
            "        0.0048, 0.0128, 0.0197, 0.0019, 0.0077, 0.0158, 0.0030, 0.0092, 0.0073,\n",
            "        0.0152, 0.0193, 0.0129, 0.0187, 0.0114, 0.0104, 0.0080, 0.0054, 0.0049,\n",
            "        0.0100, 0.0072, 0.0082, 0.0216, 0.0030, 0.0046, 0.0061, 0.0149, 0.0070,\n",
            "        0.0141, 0.0060, 0.0031, 0.0371, 0.0132, 0.0157, 0.0097, 0.0120, 0.0038,\n",
            "        0.0539, 0.0164, 0.0090, 0.0173, 0.0113, 0.0098, 0.0232, 0.0212, 0.0036,\n",
            "        0.0097, 0.0080, 0.0064, 0.0317, 0.0088, 0.0208, 0.0124, 0.0114, 0.0144,\n",
            "        0.0006, 0.0114, 0.0006, 0.0113, 0.0091, 0.0056, 0.0025, 0.0239, 0.0158,\n",
            "        0.0094, 0.0064, 0.0075, 0.0049, 0.0040, 0.0149],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [70]\n",
            "DEBUGGING: logits looks like: tensor([450.6346, 449.6437, 450.0116, 451.0507, 451.8214, 450.7559, 450.5046,\n",
            "        450.1350, 450.7917, 450.2258, 450.7205, 450.9355, 449.7555, 450.4656,\n",
            "        450.8264, 450.0015, 450.5531, 450.4421, 450.8061, 450.9239, 450.7245,\n",
            "        450.9089, 450.6637, 450.6170, 450.4854, 450.2840, 450.2437, 450.5978,\n",
            "        450.4288, 450.4963, 450.9805, 449.9955, 450.2110, 450.3454, 450.7968,\n",
            "        450.4178, 450.7676, 450.3379, 450.0168, 451.2511, 450.7354, 450.8216,\n",
            "        450.5802, 450.6866, 450.1081, 451.4387, 450.8427, 450.5420, 450.8706,\n",
            "        450.6589, 450.5878, 451.0171, 450.9727, 450.0820, 450.5808, 450.4821,\n",
            "        450.3700, 451.1734, 450.5336, 450.9623, 450.7036, 450.6609, 450.7792,\n",
            "        449.2203, 450.6611, 449.2028, 450.6574, 450.5511, 450.3077, 449.9060,\n",
            "        451.0308, 450.8235, 450.5632, 450.3746, 450.4519, 450.2382, 450.1363,\n",
            "        450.7968], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0099, 0.0060, 0.0187, 0.0423, 0.0127, 0.0090, 0.0078, 0.0094, 0.0092,\n",
            "        0.0238, 0.0012, 0.0083, 0.0123, 0.0161, 0.0048, 0.0152, 0.0141, 0.0045,\n",
            "        0.0302, 0.0068, 0.0086, 0.0076, 0.0173, 0.0228, 0.0120, 0.0149, 0.0072,\n",
            "        0.0108, 0.0057, 0.0110, 0.0104, 0.0119, 0.0110, 0.0070, 0.0255, 0.0110,\n",
            "        0.0118, 0.0098, 0.0089, 0.0161, 0.0139, 0.0066, 0.0073, 0.0063, 0.0146,\n",
            "        0.0125, 0.0134, 0.0092, 0.0167, 0.0213, 0.0024, 0.0088, 0.0056, 0.0079,\n",
            "        0.0066, 0.0158, 0.0059, 0.0151, 0.0176, 0.0089, 0.0145, 0.0039, 0.0133,\n",
            "        0.0120, 0.0154, 0.0113, 0.0088, 0.0081, 0.0045, 0.0111, 0.0098, 0.0064,\n",
            "        0.0040, 0.0195, 0.0215, 0.0090, 0.0107, 0.0050, 0.0097, 0.0112, 0.0231,\n",
            "        0.0139, 0.0099, 0.0135, 0.0097], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [59]\n",
            "DEBUGGING: logits looks like: tensor([451.5344, 451.2790, 451.8514, 452.2586, 451.6551, 451.4849, 451.4134,\n",
            "        451.5078, 451.4946, 451.9702, 450.4698, 451.4451, 451.6407, 451.7751,\n",
            "        451.1735, 451.7454, 451.7101, 451.1346, 452.0906, 451.3420, 451.4607,\n",
            "        451.3968, 451.8114, 451.9499, 451.6291, 451.7360, 451.3723, 451.5766,\n",
            "        451.2604, 451.5842, 451.5583, 451.6259, 451.5851, 451.3568, 452.0058,\n",
            "        451.5861, 451.6184, 451.5282, 451.4796, 451.7745, 451.7009, 451.3289,\n",
            "        451.3825, 451.3093, 451.7260, 451.6483, 451.6839, 451.4977, 451.7937,\n",
            "        451.9153, 450.8139, 451.4728, 451.2503, 451.4214, 451.3296, 451.7646,\n",
            "        451.2708, 451.7418, 451.8186, 451.4792, 451.7224, 451.0696, 451.6809,\n",
            "        451.6267, 451.7525, 451.5999, 451.4733, 451.4340, 451.1360, 451.5909,\n",
            "        451.5252, 451.3124, 451.0767, 451.8723, 451.9197, 451.4868, 451.5724,\n",
            "        451.1868, 451.5236, 451.5918, 451.9567, 451.7034, 451.5338, 451.6868,\n",
            "        451.5207], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0015, 0.0238, 0.0131, 0.0079, 0.0091, 0.0073, 0.0393, 0.0124, 0.0076,\n",
            "        0.0090, 0.0039, 0.0017, 0.0119, 0.0046, 0.0079, 0.0146, 0.0222, 0.0018,\n",
            "        0.0065, 0.0104, 0.0037, 0.0180, 0.0061, 0.0075, 0.0055, 0.0257, 0.0036,\n",
            "        0.0208, 0.0053, 0.0159, 0.0051, 0.0075, 0.0083, 0.0047, 0.0040, 0.0022,\n",
            "        0.0025, 0.0038, 0.0270, 0.0111, 0.0030, 0.0084, 0.0149, 0.0214, 0.0055,\n",
            "        0.0334, 0.0037, 0.0073, 0.0109, 0.0098, 0.0033, 0.0035, 0.0066, 0.0410,\n",
            "        0.0128, 0.0139, 0.0106, 0.0255, 0.0124, 0.0070, 0.0113, 0.0079, 0.0017,\n",
            "        0.0091, 0.0320, 0.0072, 0.0057, 0.0235, 0.0057, 0.0029, 0.0046, 0.0038,\n",
            "        0.0039, 0.0101, 0.0164, 0.0197, 0.0072, 0.0172, 0.0035, 0.0106, 0.0081,\n",
            "        0.0114, 0.0029, 0.0132, 0.0025, 0.0135, 0.0045, 0.0091, 0.0072, 0.0064,\n",
            "        0.0081, 0.0091, 0.0111, 0.0094, 0.0011, 0.0134, 0.0051],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [21]\n",
            "DEBUGGING: logits looks like: tensor([451.1742, 452.5468, 452.2502, 451.9956, 452.0666, 451.9573, 452.7977,\n",
            "        452.2227, 451.9775, 452.0598, 451.6383, 451.2388, 452.1998, 451.7302,\n",
            "        451.9979, 452.3032, 452.5124, 451.2452, 451.8982, 452.1324, 451.6205,\n",
            "        452.4083, 451.8622, 451.9709, 451.8185, 452.5859, 451.6039, 452.4789,\n",
            "        451.7974, 452.3467, 451.7749, 451.9691, 452.0230, 451.7360, 451.6535,\n",
            "        451.3649, 451.4231, 451.6313, 452.6097, 452.1649, 451.5042, 452.0233,\n",
            "        452.3142, 452.4940, 451.8137, 452.7162, 451.6226, 451.9539, 452.1576,\n",
            "        452.1046, 451.5561, 451.5814, 451.9086, 452.8187, 452.2376, 452.2791,\n",
            "        452.1418, 452.5817, 452.2190, 451.9336, 452.1739, 451.9937, 451.2232,\n",
            "        452.0664, 452.6950, 451.9467, 451.8348, 452.5414, 451.8335, 451.4874,\n",
            "        451.7242, 451.6299, 451.6364, 452.1181, 452.3605, 452.4513, 451.9495,\n",
            "        452.3851, 451.5898, 452.1430, 452.0093, 452.1798, 451.4966, 452.2537,\n",
            "        451.4257, 452.2642, 451.7190, 452.0654, 451.9493, 451.8885, 452.0075,\n",
            "        452.0654, 452.1656, 452.0800, 451.0221, 452.2596, 451.7749],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0051, 0.0032, 0.0237, 0.0008, 0.0173, 0.0016, 0.0052, 0.0028, 0.0010,\n",
            "        0.0055, 0.0066, 0.0061, 0.0048, 0.0033, 0.0095, 0.0197, 0.0025, 0.0057,\n",
            "        0.0159, 0.0215, 0.0073, 0.0125, 0.0086, 0.0073, 0.0034, 0.0038, 0.0012,\n",
            "        0.0038, 0.0188, 0.0088, 0.0109, 0.0046, 0.0054, 0.0076, 0.0046, 0.0155,\n",
            "        0.0067, 0.0061, 0.0028, 0.0014, 0.0063, 0.0080, 0.0080, 0.0436, 0.1123,\n",
            "        0.0057, 0.0131, 0.0033, 0.0066, 0.0026, 0.0071, 0.0080, 0.0050, 0.0053,\n",
            "        0.0013, 0.0021, 0.0035, 0.0031, 0.0040, 0.0283, 0.0035, 0.0040, 0.0190,\n",
            "        0.0131, 0.0354, 0.0026, 0.0078, 0.0044, 0.0124, 0.0067, 0.0092, 0.0233,\n",
            "        0.0115, 0.0032, 0.0090, 0.0081, 0.0181, 0.0030, 0.0075, 0.0056, 0.0074,\n",
            "        0.0006, 0.0120, 0.0008, 0.0018, 0.0085, 0.0026, 0.0047, 0.0030, 0.0021,\n",
            "        0.0064, 0.0102, 0.0091, 0.0167, 0.0023, 0.0037, 0.0064, 0.0038, 0.0087,\n",
            "        0.0125, 0.0081, 0.0128, 0.0056, 0.0076, 0.0315, 0.0238],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [72]\n",
            "DEBUGGING: logits looks like: tensor([451.2753, 451.0338, 452.0414, 450.3360, 451.8836, 450.6927, 451.2873,\n",
            "        450.9749, 450.4591, 451.3092, 451.4034, 451.3643, 451.2470, 451.0513,\n",
            "        451.5851, 451.9493, 450.9186, 451.3325, 451.8428, 451.9922, 451.4553,\n",
            "        451.7228, 451.5335, 451.4502, 451.0688, 451.1310, 450.5630, 451.1266,\n",
            "        451.9260, 451.5457, 451.6515, 451.2228, 451.3024, 451.4759, 451.2214,\n",
            "        451.8304, 451.4091, 451.3653, 450.9698, 450.6238, 451.3813, 451.4973,\n",
            "        451.4993, 452.3470, 452.8198, 451.3278, 451.7446, 451.0504, 451.4056,\n",
            "        450.9287, 451.4418, 451.4991, 451.2650, 451.2945, 450.5830, 450.8278,\n",
            "        451.0834, 451.0222, 451.1485, 452.1299, 451.0864, 451.1534, 451.9312,\n",
            "        451.7468, 452.2420, 450.9463, 451.4866, 451.2009, 451.7175, 451.4120,\n",
            "        451.5707, 452.0333, 451.6817, 451.0482, 451.5584, 451.5058, 451.9064,\n",
            "        451.0052, 451.4642, 451.3161, 451.4566, 450.1775, 451.6994, 450.3479,\n",
            "        450.7416, 451.5277, 450.9277, 451.2329, 451.0106, 450.8323, 451.3869,\n",
            "        451.6219, 451.5623, 451.8662, 450.8682, 451.1118, 451.3847, 451.1276,\n",
            "        451.5399, 451.7228, 451.5024, 451.7335, 451.3189, 451.4703, 452.1841,\n",
            "        452.0443], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.8867413289867727 and immediate abs rewards look like: [0.013861296453796967, 0.0006388484584931575, 0.8722411840603854, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 1.3642420526593924e-12, 9.094947017729282e-13, 9.094947017729282e-13, 1.3642420526593924e-12, 0.0, 0.0, 0.0]\n",
            "DEBUGGING: the total relative reward of the trajectory = 9.162853910551176 and immediate relative rewards look like: [0.04801710605199906, 0.004447442644745796, 9.110389359719392, 9.094947017729282e-12, 2.2737367544328376e-11, 1.3642420526590822e-11, 0.0, 0.0, 2.0463630789890885e-11, 2.2737367544328376e-11, 2.5011104298755527e-11, 0.0, 2.955857780762689e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.774847184307873e-11, 5.002220859749968e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 6.366462912410498e-11, 1.3187673175710458e-10, 6.821210263295411e-11, 0.0, 7.275957614183426e-11, 0.0, 7.730704965068132e-11, 0.0, 0.0, 8.412825991399586e-11, 8.640199666840854e-11, 8.86757334228605e-11, 9.094947017727214e-11, 0.0, 9.549694368615746e-11, 0.0, 3.001332515849981e-10, 2.046363078990019e-10, 2.091837814077735e-10, 3.20596882375103e-10, 0.0, 0.0, 0.0]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 3\n",
            "DEBUGGING: the action_prob is: tensor([1.9370e-02, 3.2929e-03, 1.5401e-02, 1.1763e-02, 4.1621e-03, 2.8008e-02,\n",
            "        6.4126e-03, 1.4857e-02, 2.9820e-02, 2.5502e-02, 7.1115e-03, 1.2781e-03,\n",
            "        1.4976e-03, 1.4258e-02, 2.7075e-02, 4.5286e-03, 2.0558e-02, 2.8094e-02,\n",
            "        1.5000e-02, 2.2956e-02, 8.4580e-03, 1.6461e-02, 2.1299e-02, 1.6747e-02,\n",
            "        2.3528e-02, 2.6690e-02, 9.7929e-03, 1.2702e-02, 5.3344e-03, 1.3845e-02,\n",
            "        1.0298e-02, 4.3799e-03, 8.1891e-04, 2.9650e-02, 7.1211e-03, 1.1576e-03,\n",
            "        2.7227e-03, 1.8929e-03, 1.3580e-02, 4.7806e-05, 1.2231e-02, 4.0075e-03,\n",
            "        1.4331e-02, 2.1748e-02, 3.1112e-02, 1.3832e-02, 9.2571e-03, 2.5949e-02,\n",
            "        2.2261e-02, 2.1034e-02, 1.3113e-02, 7.3292e-03, 4.8408e-03, 5.9160e-02,\n",
            "        2.4882e-02, 1.5021e-02, 5.4244e-03, 2.2095e-03, 6.6129e-03, 1.2865e-02,\n",
            "        1.0796e-02, 7.3274e-03, 9.2418e-03, 1.2759e-02, 7.2931e-03, 2.4800e-02,\n",
            "        1.4258e-02, 5.8832e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [19]\n",
            "DEBUGGING: logits looks like: tensor([446.7094, 445.8234, 446.5948, 446.4600, 445.9406, 446.8938, 446.1567,\n",
            "        446.5768, 446.9251, 446.8469, 446.2084, 445.3503, 445.4295, 446.5562,\n",
            "        446.8769, 445.9828, 446.7392, 446.8953, 446.5816, 446.7943, 446.2951,\n",
            "        446.6281, 446.7569, 446.6367, 446.8066, 446.8697, 446.3684, 446.4984,\n",
            "        446.0646, 446.5415, 446.3935, 445.9661, 445.1277, 446.9223, 446.2091,\n",
            "        445.3007, 445.7284, 445.5466, 446.5319, 443.7072, 446.4795, 445.9216,\n",
            "        446.5588, 446.7673, 446.9464, 446.5410, 446.3402, 446.8556, 446.7790,\n",
            "        446.7506, 446.5143, 446.2235, 446.0161, 447.2677, 446.8346, 446.5823,\n",
            "        446.0730, 445.6239, 446.1721, 446.5048, 446.4171, 446.2234, 446.3394,\n",
            "        446.5007, 446.2210, 446.8330, 446.5562, 447.2649],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0134, 0.0113, 0.0120, 0.0133, 0.0125, 0.0120, 0.0145, 0.0123, 0.0122,\n",
            "        0.0132, 0.0128, 0.0131, 0.0118, 0.0149, 0.0136, 0.0152, 0.0131, 0.0130,\n",
            "        0.0122, 0.0123, 0.0139, 0.0125, 0.0132, 0.0132, 0.0121, 0.0140, 0.0144,\n",
            "        0.0134, 0.0106, 0.0186, 0.0122, 0.0139, 0.0130, 0.0136, 0.0126, 0.0134,\n",
            "        0.0090, 0.0137, 0.0130, 0.0145, 0.0126, 0.0119, 0.0122, 0.0119, 0.0132,\n",
            "        0.0133, 0.0135, 0.0140, 0.0136, 0.0111, 0.0138, 0.0111, 0.0124, 0.0126,\n",
            "        0.0115, 0.0120, 0.0140, 0.0132, 0.0132, 0.0111, 0.0130, 0.0107, 0.0126,\n",
            "        0.0136, 0.0110, 0.0095, 0.0123, 0.0126, 0.0160, 0.0144, 0.0109, 0.0143,\n",
            "        0.0114, 0.0132, 0.0124, 0.0083, 0.0150, 0.0132],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [53]\n",
            "DEBUGGING: logits looks like: tensor([446.7116, 446.6234, 446.6555, 446.7047, 446.6766, 446.6551, 446.7483,\n",
            "        446.6662, 446.6617, 446.7014, 446.6880, 446.7003, 446.6485, 446.7624,\n",
            "        446.7173, 446.7736, 446.6976, 446.6946, 446.6639, 446.6686, 446.7300,\n",
            "        446.6753, 446.7030, 446.7020, 446.6588, 446.7319, 446.7461, 446.7084,\n",
            "        446.5915, 446.8737, 446.6639, 446.7275, 446.6948, 446.7183, 446.6805,\n",
            "        446.7085, 446.5091, 446.7228, 446.6965, 446.7495, 446.6789, 446.6525,\n",
            "        446.6612, 446.6500, 446.7016, 446.7078, 446.7151, 446.7308, 446.7168,\n",
            "        446.6166, 446.7239, 446.6162, 446.6701, 446.6792, 446.6356, 446.6530,\n",
            "        446.7308, 446.7008, 446.7018, 446.6148, 446.6948, 446.5987, 446.6807,\n",
            "        446.7173, 446.6111, 446.5377, 446.6674, 446.6802, 446.7997, 446.7454,\n",
            "        446.6063, 446.7409, 446.6313, 446.7038, 446.6702, 446.4695, 446.7669,\n",
            "        446.7014], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0114, 0.0107, 0.0109, 0.0120, 0.0113, 0.0116, 0.0109, 0.0110, 0.0114,\n",
            "        0.0116, 0.0106, 0.0119, 0.0102, 0.0104, 0.0106, 0.0095, 0.0106, 0.0108,\n",
            "        0.0121, 0.0112, 0.0115, 0.0111, 0.0114, 0.0114, 0.0115, 0.0118, 0.0118,\n",
            "        0.0120, 0.0113, 0.0121, 0.0101, 0.0117, 0.0115, 0.0125, 0.0116, 0.0120,\n",
            "        0.0115, 0.0117, 0.0112, 0.0106, 0.0118, 0.0131, 0.0111, 0.0120, 0.0111,\n",
            "        0.0110, 0.0084, 0.0115, 0.0108, 0.0107, 0.0113, 0.0118, 0.0119, 0.0116,\n",
            "        0.0118, 0.0117, 0.0119, 0.0083, 0.0116, 0.0125, 0.0121, 0.0121, 0.0126,\n",
            "        0.0105, 0.0123, 0.0118, 0.0113, 0.0105, 0.0127, 0.0111, 0.0118, 0.0112,\n",
            "        0.0119, 0.0109, 0.0117, 0.0129, 0.0118, 0.0109, 0.0120, 0.0109, 0.0120,\n",
            "        0.0113, 0.0113, 0.0113, 0.0112, 0.0118, 0.0123, 0.0090],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [51]\n",
            "DEBUGGING: logits looks like: tensor([446.5346, 446.5029, 446.5105, 446.5600, 446.5308, 446.5414, 446.5114,\n",
            "        446.5137, 446.5331, 446.5403, 446.4949, 446.5529, 446.4785, 446.4856,\n",
            "        446.4989, 446.4401, 446.4950, 446.5050, 446.5612, 446.5238, 446.5359,\n",
            "        446.5198, 446.5339, 446.5353, 446.5359, 446.5515, 446.5511, 446.5602,\n",
            "        446.5275, 446.5613, 446.4734, 446.5482, 446.5358, 446.5786, 446.5430,\n",
            "        446.5579, 446.5370, 446.5473, 446.5230, 446.4983, 446.5525, 446.6044,\n",
            "        446.5215, 446.5572, 446.5211, 446.5164, 446.3820, 446.5359, 446.5067,\n",
            "        446.5036, 446.5297, 446.5491, 446.5563, 446.5430, 446.5519, 446.5469,\n",
            "        446.5558, 446.3721, 446.5402, 446.5777, 446.5639, 446.5651, 446.5849,\n",
            "        446.4907, 446.5710, 446.5526, 446.5281, 446.4921, 446.5880, 446.5211,\n",
            "        446.5487, 446.5263, 446.5549, 446.5114, 446.5470, 446.5940, 446.5514,\n",
            "        446.5117, 446.5591, 446.5109, 446.5582, 446.5286, 446.5312, 446.5278,\n",
            "        446.5250, 446.5522, 446.5727, 446.4135], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0101, 0.0102, 0.0102, 0.0103, 0.0104, 0.0101, 0.0102, 0.0099, 0.0101,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0101, 0.0103, 0.0102, 0.0102, 0.0102,\n",
            "        0.0104, 0.0102, 0.0103, 0.0104, 0.0099, 0.0097, 0.0101, 0.0102, 0.0103,\n",
            "        0.0103, 0.0100, 0.0102, 0.0103, 0.0106, 0.0103, 0.0104, 0.0098, 0.0103,\n",
            "        0.0103, 0.0101, 0.0101, 0.0102, 0.0102, 0.0102, 0.0103, 0.0103, 0.0103,\n",
            "        0.0101, 0.0101, 0.0103, 0.0101, 0.0103, 0.0103, 0.0103, 0.0103, 0.0104,\n",
            "        0.0100, 0.0101, 0.0104, 0.0103, 0.0102, 0.0101, 0.0099, 0.0102, 0.0100,\n",
            "        0.0102, 0.0105, 0.0103, 0.0098, 0.0102, 0.0101, 0.0105, 0.0102, 0.0103,\n",
            "        0.0106, 0.0102, 0.0099, 0.0102, 0.0102, 0.0101, 0.0103, 0.0104, 0.0102,\n",
            "        0.0104, 0.0103, 0.0104, 0.0100, 0.0101, 0.0105, 0.0102, 0.0103, 0.0104,\n",
            "        0.0102, 0.0104, 0.0103, 0.0103, 0.0101, 0.0100, 0.0104, 0.0098],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [3]\n",
            "DEBUGGING: logits looks like: tensor([446.4728, 446.4767, 446.4783, 446.4833, 446.4884, 446.4717, 446.4771,\n",
            "        446.4653, 446.4731, 446.4800, 446.4786, 446.4767, 446.4810, 446.4724,\n",
            "        446.4825, 446.4815, 446.4800, 446.4782, 446.4869, 446.4784, 446.4839,\n",
            "        446.4878, 446.4644, 446.4561, 446.4717, 446.4812, 446.4822, 446.4839,\n",
            "        446.4674, 446.4799, 446.4827, 446.4992, 446.4825, 446.4886, 446.4565,\n",
            "        446.4837, 446.4850, 446.4766, 446.4765, 446.4794, 446.4768, 446.4799,\n",
            "        446.4826, 446.4821, 446.4849, 446.4754, 446.4735, 446.4864, 446.4742,\n",
            "        446.4818, 446.4828, 446.4832, 446.4826, 446.4866, 446.4684, 446.4724,\n",
            "        446.4877, 446.4835, 446.4810, 446.4744, 446.4653, 446.4774, 446.4696,\n",
            "        446.4810, 446.4936, 446.4821, 446.4610, 446.4791, 446.4736, 446.4913,\n",
            "        446.4780, 446.4850, 446.4967, 446.4806, 446.4651, 446.4778, 446.4814,\n",
            "        446.4739, 446.4824, 446.4900, 446.4805, 446.4875, 446.4825, 446.4885,\n",
            "        446.4710, 446.4760, 446.4918, 446.4806, 446.4853, 446.4866, 446.4790,\n",
            "        446.4865, 446.4817, 446.4845, 446.4717, 446.4669, 446.4883, 446.4583],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0091, 0.0091, 0.0092, 0.0091, 0.0092, 0.0093, 0.0091, 0.0093, 0.0092,\n",
            "        0.0089, 0.0091, 0.0091, 0.0091, 0.0094, 0.0091, 0.0091, 0.0092, 0.0093,\n",
            "        0.0087, 0.0091, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0091,\n",
            "        0.0092, 0.0094, 0.0092, 0.0092, 0.0091, 0.0091, 0.0092, 0.0094, 0.0091,\n",
            "        0.0093, 0.0091, 0.0091, 0.0091, 0.0091, 0.0093, 0.0098, 0.0091, 0.0092,\n",
            "        0.0091, 0.0093, 0.0092, 0.0091, 0.0091, 0.0093, 0.0091, 0.0091, 0.0092,\n",
            "        0.0092, 0.0091, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092,\n",
            "        0.0092, 0.0092, 0.0091, 0.0092, 0.0092, 0.0092, 0.0083, 0.0092, 0.0093,\n",
            "        0.0091, 0.0093, 0.0095, 0.0091, 0.0094, 0.0091, 0.0093, 0.0092, 0.0093,\n",
            "        0.0091, 0.0091, 0.0092, 0.0093, 0.0092, 0.0091, 0.0093, 0.0091, 0.0090,\n",
            "        0.0094, 0.0092, 0.0091, 0.0091, 0.0091, 0.0091, 0.0092, 0.0092, 0.0092,\n",
            "        0.0091, 0.0091, 0.0092, 0.0091, 0.0093, 0.0092, 0.0092, 0.0091, 0.0092,\n",
            "        0.0092], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [65]\n",
            "DEBUGGING: logits looks like: tensor([446.4701, 446.4685, 446.4710, 446.4687, 446.4706, 446.4803, 446.4658,\n",
            "        446.4766, 446.4714, 446.4542, 446.4698, 446.4686, 446.4649, 446.4858,\n",
            "        446.4685, 446.4673, 446.4751, 446.4779, 446.4470, 446.4663, 446.4722,\n",
            "        446.4718, 446.4711, 446.4710, 446.4725, 446.4707, 446.4680, 446.4715,\n",
            "        446.4816, 446.4708, 446.4713, 446.4692, 446.4701, 446.4718, 446.4828,\n",
            "        446.4680, 446.4803, 446.4698, 446.4669, 446.4700, 446.4675, 446.4763,\n",
            "        446.5064, 446.4647, 446.4717, 446.4682, 446.4778, 446.4738, 446.4683,\n",
            "        446.4649, 446.4807, 446.4685, 446.4662, 446.4723, 446.4706, 446.4683,\n",
            "        446.4719, 446.4743, 446.4728, 446.4721, 446.4730, 446.4753, 446.4752,\n",
            "        446.4713, 446.4755, 446.4677, 446.4739, 446.4702, 446.4703, 446.4238,\n",
            "        446.4708, 446.4759, 446.4688, 446.4790, 446.4866, 446.4685, 446.4822,\n",
            "        446.4687, 446.4809, 446.4725, 446.4765, 446.4649, 446.4696, 446.4708,\n",
            "        446.4809, 446.4727, 446.4677, 446.4777, 446.4671, 446.4630, 446.4830,\n",
            "        446.4737, 446.4689, 446.4689, 446.4690, 446.4673, 446.4749, 446.4710,\n",
            "        446.4721, 446.4678, 446.4657, 446.4712, 446.4695, 446.4757, 446.4725,\n",
            "        446.4750, 446.4688, 446.4721, 446.4702], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.09518550995881014 and immediate abs rewards look like: [0.01472099603006427, 0.0005253255621937569, 0.0007521928805545031, 0.003071092427944677, 0.00074553054628268, 0.01992855754087941, 0.0072205439787467185, 0.0025006313790072454, 0.005141694630310667, 0.011213299331757298, 0.003137982685075258, 0.0016387035398111038, 0.009448866713682946, 0.0018383089827693766, 6.487099881269387e-05, 0.003950107219679921, 5.3675489652960096e-06, 0.0001094255962925672, 0.0001483629853282764, 0.0007827719314263959, 0.00020766893248946872, 0.0009861562903097365, 0.0007889884323049046, 0.0022327525784930913, 9.545871444061049e-05, 3.202516518285847e-05, 8.120061011140933e-06, 0.0004171529831182852, 0.00017931786760527757, 0.001333449370577, 0.0002934691437985748, 2.573994743215735e-05, 4.583997406371054e-05, 0.0003233872098462598, 3.6260084925743286e-06, 0.0003378670144229545, 1.2129250535508618e-05, 8.956671217674739e-05, 1.1076797363784863e-05, 0.0001741075434438244, 4.84127258459921e-05, 0.00015377912313851994, 2.8742424092342844e-05, 0.00013162955974621582, 4.2208425838907715e-06, 9.163190497929463e-06, 4.80368830722e-05, 0.00011168899163749302, 0.00010556534971328801, 1.7383617887389846e-06]\n",
            "DEBUGGING: the total relative reward of the trajectory = 2.972248160027496 and immediate relative rewards look like: [0.04746700863243581, 0.0034039217785948165, 0.007312155805866789, 0.03981564074759445, 0.012093967170807591, 0.388030187513548, 0.16509127947569044, 0.06549698513305915, 0.15163035204221537, 0.3680468269281224, 0.1137140810651692, 0.06484878541239693, 0.405301342839789, 0.08518392138540753, 0.0032226805444364602, 0.2093213903844514, 0.000302606478751093, 0.00653198961611043, 0.009348651781325564, 0.051922599629903435, 0.014467542825923767, 0.07197841887487322, 0.060224673973794635, 0.177885914319367, 0.00792806721954421, 0.0027662423942006143, 0.0007283719014715124, 0.03880473157368045, 0.01727877918487189, 0.13292759682670127, 0.03024363455909489, 0.0027384817356420855, 0.005029377499537036, 0.036556474574256315, 0.00042199383766730174, 0.040444369208660846, 0.0014924309811878626, 0.011318543542663493, 0.001436653617638806, 0.023160740035941107, 0.006601511627705342, 0.021480958852004697, 0.004110749890381654, 0.019263689179544935, 0.0006317773336313272, 0.0014020307154467915, 0.007509775991502473, 0.017832525407971093, 0.01720659155580224, 0.0002891364211117258]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 200 number of matrices\n",
            "DEBUGGING: ACT_MAT has 200 number of matrices\n",
            "DEBUGGING: VAL looks like: [[27.556029225187157, 27.775424009016675, 28.04479008618949, 28.311236201732058, 28.569945225105936, 28.30249259083372, 28.340834503030997, 28.61920085893179, 28.895717253193848, 28.78745166352032, 1.9644160255983755e-09, 1.984258611715531e-09, 2.004301627995486e-09, 1.994689949684713e-09, 1.9826844799218717e-09, 1.9682610389953404e-09, 1.9513952029539544e-09, 1.971106265610055e-09, 1.9496757616467404e-09, 1.969369456208829e-09, 1.8973939252844006e-09, 1.8200979612103246e-09, 1.7374278222377023e-09, 1.702153410995704e-09, 1.6642259887770994e-09, 1.6236187574912165e-09, 1.6400189469608249e-09, 1.5945737925163154e-09, 1.5463728923153494e-09, 1.4287840005638534e-09, 1.3743150484150342e-09, 1.1746035659118991e-09, 1.0394792056851482e-09, 1.0499789956415639e-09, 1.0605848440823877e-09, 9.909131895729864e-10, 9.182410771852944e-10, 8.425381992639379e-10, 7.637739420156465e-10, 6.819173824169556e-10, 6.888054367848037e-10, 6.015982119728281e-10, 6.076749615887152e-10, 6.138130925138538e-10, 6.200132247614684e-10, 4.1957264329551476e-10, 1.0686562745829477e-10, 0.0, 0.0, 0.0], [5.3637052474885225, 5.352240562688202, 5.244525855984765, 4.828079554787088, 4.363597975154148, 4.33137672431043, 3.126971384584992, 2.9738865318424756, 2.715791962026038, 2.61466941789694, 2.5519189205757162, 2.473718879086248, 1.8487704945344259, 1.8106421703900035, 1.7783655494511283, 1.5695996571998316, 1.567640116942997, 1.554738182594887, 1.4046897572197534, 1.4116346254536019, 1.3538398848418647, 1.201897278290729, 1.1809737488665715, 1.0918636062827423, 0.8166613619866869, 0.6602278127742652, 0.6525996848215163, 0.5615298729055206, 0.5175201014811097, 0.4646498677937722, 0.4623046864386493, 0.419267789900869, 0.3638637113070817, 0.27211621707893824, 0.25889409819790793, 0.18845497040687575, 0.186211256668933, 0.18752355951242689, 0.1519434934602099, 0.12103120085335238, 0.08118582191342548, 0.0750001529501663, 0.048412144203713876, 0.04433561339288086, 0.04229629481648857, 0.027423222342212433, 0.0254996453885957, 0.01516627038983699, 0.013654166963197446, 0.013562714319653965], [8.98151268721545, 9.023732910266112, 9.110389361233702, 1.529605753422422e-09, 1.5358695014188816e-09, 1.528416296842983e-09, 1.5300746225418102e-09, 1.5455299217594043e-09, 1.5611413351105094e-09, 1.556240105374362e-09, 1.5489926644747815e-09, 1.5393753133091171e-09, 1.5549245588980981e-09, 1.5407737182732033e-09, 1.5563370891648519e-09, 1.5720576658230826e-09, 1.587937036184932e-09, 1.603976804227204e-09, 1.6201785901284889e-09, 1.636544030432817e-09, 1.6530747782149667e-09, 1.6215417236079676e-09, 1.5873934495055231e-09, 1.6034277267732556e-09, 1.6196239664376319e-09, 1.6359838044824565e-09, 1.6525088934166227e-09, 1.669200902441033e-09, 1.6217538114312405e-09, 1.504926343105188e-09, 1.451226505527509e-09, 1.465885359118696e-09, 1.4071977605826886e-09, 1.4214118793764531e-09, 1.3576816461876483e-09, 1.3713956022097459e-09, 1.3852480830401473e-09, 1.3142624476021731e-09, 1.2402630817512773e-09, 1.1632195437660775e-09, 1.0831010844331367e-09, 1.0940414994274108e-09, 1.0086308643851044e-09, 1.0188190549344489e-09, 7.25945255908536e-10, 5.265746949591254e-10, 3.20596882375103e-10, 0.0, 0.0, 0.0], [2.5847973187528064, 2.5629599092124957, 2.5854100883170714, 2.6041393257688936, 2.5902259444659586, 2.6041737144395465, 2.238528815076766, 2.0943813490919956, 2.0493781454130673, 1.9169169630008605, 1.5645152889623615, 1.4654557655527196, 1.4147545253942653, 1.019649679347956, 0.9439048060227762, 0.9501839651296361, 0.7483460350961462, 0.7555994228458536, 0.7566337709391344, 0.7548334536947564, 0.7100109637018717, 0.702569111995907, 0.6369602960818523, 0.5825612344525836, 0.40876294962951165, 0.40488371960602776, 0.40617926991093656, 0.4095463616257223, 0.37448649500206244, 0.3608158745628187, 0.23019017953143178, 0.20196620704276452, 0.20124012657285095, 0.19819267583163022, 0.16326889015896354, 0.1644918144659558, 0.1253004497548434, 0.12505860482187428, 0.1148889507870816, 0.11459827996913413, 0.09236115144766972, 0.08662589880804483, 0.0658029696525658, 0.06231537349715569, 0.04348654981576844, 0.04328764897185567, 0.04230870530950392, 0.03515043365454691, 0.01749283661270285, 0.0002891364211117258]]\n",
            "DEBUGGING: traj_returns = [27.556029225187157, 5.3637052474885225, 8.98151268721545, 2.5847973187528064]\n",
            "DEBUGGING: actions = [[52], [5], [5], [22], [33], [54], [42], [47], [8], [0], [28], [67], [70], [7], [38], [61], [42], [55], [31], [6], [28], [48], [47], [14], [33], [59], [49], [21], [64], [35], [84], [35], [37], [78], [61], [51], [20], [44], [34], [10], [42], [55], [15], [12], [42], [93], [75], [104], [38], [95], [13], [13], [17], [2], [28], [55], [27], [14], [56], [11], [21], [45], [27], [9], [6], [71], [67], [68], [31], [67], [5], [41], [35], [64], [2], [76], [79], [26], [49], [50], [85], [19], [13], [57], [48], [37], [10], [29], [43], [78], [27], [65], [24], [69], [10], [93], [105], [30], [3], [34], [7], [19], [0], [16], [47], [42], [45], [2], [52], [48], [59], [22], [22], [7], [51], [25], [32], [39], [35], [70], [72], [29], [6], [65], [69], [52], [6], [44], [68], [59], [53], [15], [85], [54], [56], [15], [28], [66], [29], [21], [61], [48], [66], [12], [63], [24], [90], [70], [42], [72], [12], [5], [49], [9], [1], [21], [23], [13], [18], [19], [60], [64], [13], [22], [60], [36], [11], [7], [8], [53], [48], [7], [74], [47], [32], [15], [76], [64], [53], [51], [57], [59], [47], [89], [25], [31], [56], [22], [81], [3], [70], [33], [93], [76], [37], [57], [97], [27], [59], [65]]\n",
            "DEBUGGING: actions length = 200\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[ 7.3448,  6.7605,  6.2318,  ..., -5.4659, -5.9294, -8.7293],\n",
            "        [ 7.3669,  6.7963,  6.2529,  ..., -5.4984, -5.9578, -8.7705],\n",
            "        [ 7.3316,  6.7907,  6.2250,  ..., -5.4780, -5.9206, -8.7296],\n",
            "        ...,\n",
            "        [ 7.2956,  6.7318,  6.1856,  ..., -5.4383, -5.8839, -8.6791],\n",
            "        [ 7.2956,  6.7319,  6.1856,  ..., -5.4383, -5.8839, -8.6791],\n",
            "        [ 7.2956,  6.7318,  6.1856,  ..., -5.4383, -5.8839, -8.6791]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[ 7.2956,  6.7319,  6.1856,  ..., -5.4383, -5.8839, -8.6792],\n",
            "        [ 7.2956,  6.7319,  6.1856,  ..., -5.4383, -5.8839, -8.6791],\n",
            "        [ 7.2956,  6.7319,  6.1857,  ..., -5.4383, -5.8839, -8.6792],\n",
            "        ...,\n",
            "        [ 7.2956,  6.7319,  6.1856,  ..., -5.4383, -5.8839, -8.6791],\n",
            "        [ 7.2957,  6.7319,  6.1857,  ..., -5.4383, -5.8839, -8.6792],\n",
            "        [ 7.2956,  6.7319,  6.1857,  ..., -5.4383, -5.8839, -8.6792]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([446.4701, 446.4685, 446.4710, 446.4687, 446.4706, 446.4803, 446.4658,\n",
            "        446.4766, 446.4714, 446.4542, 446.4698, 446.4686, 446.4649, 446.4858,\n",
            "        446.4685, 446.4673, 446.4751, 446.4779, 446.4470, 446.4663, 446.4722,\n",
            "        446.4718, 446.4711, 446.4710, 446.4725, 446.4707, 446.4680, 446.4715,\n",
            "        446.4816, 446.4708, 446.4713, 446.4692, 446.4701, 446.4718, 446.4828,\n",
            "        446.4680, 446.4803, 446.4698, 446.4669, 446.4700, 446.4675, 446.4763,\n",
            "        446.5064, 446.4647, 446.4717, 446.4682, 446.4778, 446.4738, 446.4683,\n",
            "        446.4649, 446.4807, 446.4685, 446.4662, 446.4723, 446.4706, 446.4683,\n",
            "        446.4719, 446.4743, 446.4728, 446.4721, 446.4730, 446.4753, 446.4752,\n",
            "        446.4713, 446.4755, 446.4677, 446.4739, 446.4702, 446.4703, 446.4238,\n",
            "        446.4708, 446.4759, 446.4688, 446.4790, 446.4866, 446.4685, 446.4822,\n",
            "        446.4687, 446.4809, 446.4725, 446.4765, 446.4649, 446.4696, 446.4708,\n",
            "        446.4809, 446.4727, 446.4677, 446.4777, 446.4671, 446.4630, 446.4830,\n",
            "        446.4737, 446.4689, 446.4689, 446.4690, 446.4673, 446.4749, 446.4710,\n",
            "        446.4721, 446.4678, 446.4657, 446.4712, 446.4695, 446.4757, 446.4725,\n",
            "        446.4750, 446.4688, 446.4721, 446.4702], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[1.11215111e+01 1.11785893e+01 1.12462788e+01 8.93586377e+00\n",
            "  8.88094229e+00 8.80951076e+00 8.42658368e+00 8.42186719e+00\n",
            "  8.41522184e+00 8.32975951e+00 1.02910855e+00 9.84793662e-01\n",
            "  8.15881256e-01 7.07572963e-01 6.80567590e-01 6.29945906e-01\n",
            "  5.78996539e-01 5.77584402e-01 5.40330883e-01 5.41617021e-01\n",
            "  5.15962713e-01 4.76116598e-01 4.54483512e-01 4.18606211e-01\n",
            "  3.06356079e-01 2.66277884e-01 2.64694740e-01 2.42769059e-01\n",
            "  2.23001650e-01 2.06366436e-01 1.73123717e-01 1.55308500e-01\n",
            "  1.41275960e-01 1.17577224e-01 1.05540748e-01 8.82366968e-02\n",
            "  7.78779272e-02 7.81455416e-02 6.67081116e-02 5.89073707e-02\n",
            "  4.33867438e-02 4.04065134e-02 2.85537789e-02 2.66627471e-02\n",
            "  2.14457115e-02 1.76777181e-02 1.69520878e-02 1.25791760e-02\n",
            "  7.78675089e-03 3.46296269e-03]]\n",
            "DEBUGGING: baseline2 looks like: 11.121511119660983\n",
            "DEBUGGING: ADS looks like: [ 1.64345181e+01  1.65968347e+01  1.67985112e+01  1.93753724e+01\n",
            "  1.96890029e+01  1.94929818e+01  1.99142508e+01  2.01973337e+01\n",
            "  2.04804954e+01  2.04576922e+01 -1.02910855e+00 -9.84793660e-01\n",
            " -8.15881254e-01 -7.07572961e-01 -6.80567588e-01 -6.29945904e-01\n",
            " -5.78996537e-01 -5.77584400e-01 -5.40330881e-01 -5.41617019e-01\n",
            " -5.15962711e-01 -4.76116597e-01 -4.54483510e-01 -4.18606209e-01\n",
            " -3.06356077e-01 -2.66277882e-01 -2.64694738e-01 -2.42769058e-01\n",
            " -2.23001648e-01 -2.06366435e-01 -1.73123716e-01 -1.55308499e-01\n",
            " -1.41275959e-01 -1.17577223e-01 -1.05540747e-01 -8.82366958e-02\n",
            " -7.78779263e-02 -7.81455408e-02 -6.67081108e-02 -5.89073700e-02\n",
            " -4.33867431e-02 -4.04065128e-02 -2.85537783e-02 -2.66627465e-02\n",
            " -2.14457109e-02 -1.76777176e-02 -1.69520877e-02 -1.25791760e-02\n",
            " -7.78675089e-03 -3.46296269e-03 -5.75780587e+00 -5.82634879e+00\n",
            " -6.00175299e+00 -4.10778422e+00 -4.51734431e+00 -4.47813403e+00\n",
            " -5.29961229e+00 -5.44798065e+00 -5.69942988e+00 -5.71509009e+00\n",
            "  1.52281037e+00  1.48892522e+00  1.03288924e+00  1.10306921e+00\n",
            "  1.09779796e+00  9.39653751e-01  9.88643578e-01  9.77153780e-01\n",
            "  8.64358874e-01  8.70017605e-01  8.37877172e-01  7.25780680e-01\n",
            "  7.26490237e-01  6.73257395e-01  5.10305283e-01  3.93949929e-01\n",
            "  3.87904945e-01  3.18760813e-01  2.94518452e-01  2.58283431e-01\n",
            "  2.89180969e-01  2.63959290e-01  2.22587751e-01  1.54538993e-01\n",
            "  1.53353351e-01  1.00218274e-01  1.08333329e-01  1.09378018e-01\n",
            "  8.52353819e-02  6.21238302e-02  3.77990781e-02  3.45936396e-02\n",
            "  1.98583653e-02  1.76728663e-02  2.08505833e-02  9.74550428e-03\n",
            "  8.54755761e-03  2.58709438e-03  5.86741607e-03  1.00997516e-02\n",
            " -2.13999843e+00 -2.15485644e+00 -2.13588949e+00 -8.93586377e+00\n",
            " -8.88094229e+00 -8.80951076e+00 -8.42658367e+00 -8.42186718e+00\n",
            " -8.41522184e+00 -8.32975951e+00 -1.02910855e+00 -9.84793661e-01\n",
            " -8.15881254e-01 -7.07572962e-01 -6.80567588e-01 -6.29945905e-01\n",
            " -5.78996537e-01 -5.77584401e-01 -5.40330881e-01 -5.41617019e-01\n",
            " -5.15962711e-01 -4.76116597e-01 -4.54483510e-01 -4.18606209e-01\n",
            " -3.06356077e-01 -2.66277882e-01 -2.64694738e-01 -2.42769058e-01\n",
            " -2.23001648e-01 -2.06366435e-01 -1.73123716e-01 -1.55308498e-01\n",
            " -1.41275959e-01 -1.17577222e-01 -1.05540746e-01 -8.82366954e-02\n",
            " -7.78779258e-02 -7.81455403e-02 -6.67081103e-02 -5.89073695e-02\n",
            " -4.33867427e-02 -4.04065123e-02 -2.85537779e-02 -2.66627461e-02\n",
            " -2.14457108e-02 -1.76777175e-02 -1.69520875e-02 -1.25791760e-02\n",
            " -7.78675089e-03 -3.46296269e-03 -8.53671380e+00 -8.61562944e+00\n",
            " -8.66086876e+00 -6.33172445e+00 -6.29071634e+00 -6.20533704e+00\n",
            " -6.18805486e+00 -6.32748584e+00 -6.36584370e+00 -6.41284255e+00\n",
            "  5.35406736e-01  4.80662104e-01  5.98873270e-01  3.12076716e-01\n",
            "  2.63337216e-01  3.20238059e-01  1.69349496e-01  1.78015021e-01\n",
            "  2.16302888e-01  2.13216433e-01  1.94048251e-01  2.26452514e-01\n",
            "  1.82476784e-01  1.63955023e-01  1.02406871e-01  1.38605836e-01\n",
            "  1.41484530e-01  1.66777302e-01  1.51484845e-01  1.54449438e-01\n",
            "  5.70664623e-02  4.66577071e-02  5.99641665e-02  8.06154520e-02\n",
            "  5.77281425e-02  7.62551177e-02  4.74225226e-02  4.69130632e-02\n",
            "  4.81808392e-02  5.56909093e-02  4.89744077e-02  4.62193854e-02\n",
            "  3.72491908e-02  3.56526264e-02  2.20408383e-02  2.56099309e-02\n",
            "  2.53566175e-02  2.25712576e-02  9.70608572e-03 -3.17382626e-03]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(0.8950, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-0.0337,  0.0858,  0.0355,  ...,  0.0335,  0.0401,  0.5722],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0439,  0.1120,  0.0464,  ...,  0.0437,  0.0524,  0.7479],\n",
            "        [-0.0251,  0.0641,  0.0265,  ...,  0.0250,  0.0299,  0.4261]])\n",
            "   Last layer:\n",
            "tensor([[ 0.1692,  0.0733,  0.0000,  0.2183,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2516,\n",
            "          0.0000,  0.2477,  0.2912,  0.0509],\n",
            "        [ 0.1621,  0.0705,  0.0000,  0.2087,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2408,\n",
            "          0.0000,  0.2378,  0.2792,  0.0490],\n",
            "        [ 0.1468,  0.0637,  0.0000,  0.1891,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2180,\n",
            "          0.0000,  0.2151,  0.2526,  0.0443],\n",
            "        [-0.0522, -0.0227,  0.0000, -0.0672,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0775,\n",
            "          0.0000, -0.0766, -0.0899, -0.0158],\n",
            "        [-0.0430, -0.0187,  0.0000, -0.0553,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0638,\n",
            "          0.0000, -0.0632, -0.0741, -0.0130],\n",
            "        [ 0.1357,  0.0588,  0.0000,  0.1749,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2016,\n",
            "          0.0000,  0.1987,  0.2336,  0.0409],\n",
            "        [-0.2728, -0.1185,  0.0000, -0.3512,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.4051,\n",
            "          0.0000, -0.4000, -0.4696, -0.0823],\n",
            "        [-0.1347, -0.0585,  0.0000, -0.1733,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2000,\n",
            "          0.0000, -0.1976, -0.2319, -0.0407],\n",
            "        [-0.1482, -0.0645,  0.0000, -0.1904,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2198,\n",
            "          0.0000, -0.2176, -0.2552, -0.0448],\n",
            "        [-0.2052, -0.0890,  0.0000, -0.2646,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.3051,\n",
            "          0.0000, -0.3006, -0.3533, -0.0619]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.0463,  0.0400, -0.0258,  ...,  0.0587,  0.0116,  0.6820],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0610,  0.0526, -0.0339,  ...,  0.0773,  0.0153,  0.8997],\n",
            "        [ 0.0329,  0.0284, -0.0183,  ...,  0.0417,  0.0082,  0.4837]])\n",
            "   Last layer:\n",
            "tensor([[ 0.2139,  0.0972,  0.0000,  0.2561,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2878,\n",
            "          0.0000,  0.2863,  0.3347,  0.0608],\n",
            "        [ 0.1970,  0.0896,  0.0000,  0.2359,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2650,\n",
            "          0.0000,  0.2636,  0.3081,  0.0560],\n",
            "        [ 0.1861,  0.0846,  0.0000,  0.2228,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2509,\n",
            "          0.0000,  0.2502,  0.2923,  0.0532],\n",
            "        [-0.0617, -0.0280,  0.0000, -0.0739,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0835,\n",
            "          0.0000, -0.0837, -0.0976, -0.0178],\n",
            "        [-0.0482, -0.0219,  0.0000, -0.0577,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0650,\n",
            "          0.0000, -0.0648, -0.0757, -0.0138],\n",
            "        [ 0.1727,  0.0785,  0.0000,  0.2068,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2330,\n",
            "          0.0000,  0.2326,  0.2716,  0.0494],\n",
            "        [-0.3452, -0.1569,  0.0000, -0.4132,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.4654,\n",
            "          0.0000, -0.4642, -0.5423, -0.0987],\n",
            "        [-0.1716, -0.0780,  0.0000, -0.2054,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2323,\n",
            "          0.0000, -0.2326, -0.2714, -0.0495],\n",
            "        [-0.1846, -0.0839,  0.0000, -0.2210,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2498,\n",
            "          0.0000, -0.2500, -0.2918, -0.0532],\n",
            "        [-0.2619, -0.1190,  0.0000, -0.3135,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.3532,\n",
            "          0.0000, -0.3523, -0.4115, -0.0749]])\n",
            "DEBUGGING: training for one iteration takes 0.004138 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 22\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([0.0083, 0.0126, 0.0212, 0.0138, 0.0165, 0.0108, 0.0073, 0.0099, 0.0339,\n",
            "        0.0106, 0.0242, 0.0332, 0.0172, 0.0069, 0.0197, 0.0094, 0.0177, 0.0266,\n",
            "        0.0113, 0.0136, 0.0123, 0.0135, 0.0081, 0.0136, 0.0032, 0.0107, 0.0059,\n",
            "        0.0147, 0.0075, 0.0118, 0.0168, 0.0087, 0.0137, 0.0081, 0.0169, 0.0060,\n",
            "        0.0197, 0.0165, 0.0255, 0.0149, 0.0074, 0.0030, 0.0083, 0.0072, 0.0098,\n",
            "        0.0187, 0.0161, 0.0295, 0.0081, 0.0136, 0.0081, 0.0468, 0.0151, 0.0312,\n",
            "        0.0134, 0.0048, 0.0139, 0.0129, 0.0096, 0.0285, 0.0068, 0.0050, 0.0372,\n",
            "        0.0072, 0.0047, 0.0050, 0.0154, 0.0296, 0.0097],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [9]\n",
            "DEBUGGING: logits looks like: tensor([286.6667, 286.8776, 287.1368, 286.9225, 287.0116, 286.7997, 286.6061,\n",
            "        286.7575, 287.3700, 286.7875, 287.2024, 287.3594, 287.0322, 286.5745,\n",
            "        287.0991, 286.7291, 287.0451, 287.2492, 286.8213, 286.9150, 286.8648,\n",
            "        286.9094, 286.6554, 286.9146, 286.1868, 286.7948, 286.4998, 286.9541,\n",
            "        286.6154, 286.8415, 287.0202, 286.6900, 286.9168, 286.6552, 287.0236,\n",
            "        286.5006, 287.0997, 287.0119, 287.2289, 286.9595, 286.6122, 286.1631,\n",
            "        286.6645, 286.5984, 286.7525, 287.0737, 286.9978, 287.3016, 286.6576,\n",
            "        286.9128, 286.6576, 287.5316, 286.9677, 287.3283, 286.9069, 286.3968,\n",
            "        286.9232, 286.8886, 286.7392, 287.2845, 286.5643, 286.4164, 287.4174,\n",
            "        286.5966, 286.3826, 286.4092, 286.9761, 287.3027, 286.7453],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0188, 0.0189, 0.0172, 0.0089, 0.0126, 0.0064, 0.0066, 0.0075, 0.0064,\n",
            "        0.0077, 0.0385, 0.0202, 0.0173, 0.0069, 0.0235, 0.0132, 0.0157, 0.0070,\n",
            "        0.0076, 0.0125, 0.0174, 0.0104, 0.0113, 0.0055, 0.0069, 0.0525, 0.0142,\n",
            "        0.0161, 0.0038, 0.0067, 0.0164, 0.0092, 0.0102, 0.0063, 0.0047, 0.0065,\n",
            "        0.0109, 0.0066, 0.0112, 0.0079, 0.0063, 0.0096, 0.0697, 0.0109, 0.0304,\n",
            "        0.0152, 0.0068, 0.0196, 0.0082, 0.0083, 0.0076, 0.0173, 0.0084, 0.0091,\n",
            "        0.0087, 0.0143, 0.0115, 0.0089, 0.0036, 0.0127, 0.0053, 0.0033, 0.0106,\n",
            "        0.0181, 0.0176, 0.0241, 0.0098, 0.0134, 0.0115, 0.0197, 0.0105, 0.0141,\n",
            "        0.0037, 0.0083, 0.0110, 0.0062, 0.0176], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [74]\n",
            "DEBUGGING: logits looks like: tensor([287.5853, 287.5860, 287.5400, 287.2097, 287.3856, 287.0445, 287.0571,\n",
            "        287.1240, 287.0464, 287.1392, 287.9427, 287.6201, 287.5421, 287.0817,\n",
            "        287.6951, 287.4062, 287.4952, 287.0887, 287.1299, 287.3809, 287.5459,\n",
            "        287.2892, 287.3285, 286.9716, 287.0819, 288.0973, 287.4452, 287.5073,\n",
            "        286.7814, 287.0702, 287.5165, 287.2262, 287.2779, 287.0348, 286.8889,\n",
            "        287.0550, 287.3098, 287.0624, 287.3252, 287.1493, 287.0403, 287.2469,\n",
            "        288.2394, 287.3132, 287.8250, 287.4770, 287.0784, 287.6061, 287.1689,\n",
            "        287.1770, 287.1341, 287.5417, 287.1810, 287.2226, 287.2018, 287.4463,\n",
            "        287.3402, 287.2108, 286.7644, 287.3882, 286.9544, 286.7105, 287.2988,\n",
            "        287.5645, 287.5499, 287.7086, 287.2594, 287.4154, 287.3395, 287.6080,\n",
            "        287.2944, 287.4396, 286.7661, 287.1731, 287.3160, 287.0303, 287.5499],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0086, 0.0098, 0.0101, 0.0110, 0.0153, 0.0116, 0.0155, 0.0144, 0.0133,\n",
            "        0.0091, 0.0126, 0.0102, 0.0113, 0.0104, 0.0118, 0.0131, 0.0127, 0.0099,\n",
            "        0.0101, 0.0087, 0.0111, 0.0113, 0.0124, 0.0123, 0.0112, 0.0130, 0.0107,\n",
            "        0.0099, 0.0101, 0.0138, 0.0084, 0.0115, 0.0130, 0.0070, 0.0101, 0.0135,\n",
            "        0.0124, 0.0115, 0.0119, 0.0109, 0.0103, 0.0087, 0.0103, 0.0134, 0.0128,\n",
            "        0.0096, 0.0108, 0.0121, 0.0111, 0.0091, 0.0121, 0.0100, 0.0101, 0.0109,\n",
            "        0.0140, 0.0105, 0.0102, 0.0102, 0.0098, 0.0112, 0.0096, 0.0112, 0.0120,\n",
            "        0.0125, 0.0135, 0.0086, 0.0116, 0.0120, 0.0109, 0.0118, 0.0103, 0.0123,\n",
            "        0.0117, 0.0118, 0.0117, 0.0127, 0.0092, 0.0128, 0.0126, 0.0105, 0.0091,\n",
            "        0.0099, 0.0151, 0.0107, 0.0108, 0.0108, 0.0111, 0.0119, 0.0089],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [0]\n",
            "DEBUGGING: logits looks like: tensor([287.0692, 287.1336, 287.1498, 287.1909, 287.3570, 287.2213, 287.3631,\n",
            "        287.3278, 287.2892, 287.0988, 287.2606, 287.1541, 287.2061, 287.1653,\n",
            "        287.2268, 287.2787, 287.2653, 287.1397, 287.1518, 287.0737, 287.1960,\n",
            "        287.2080, 287.2516, 287.2484, 287.2025, 287.2762, 287.1792, 287.1389,\n",
            "        287.1509, 287.3048, 287.0572, 287.2168, 287.2753, 286.9635, 287.1500,\n",
            "        287.2940, 287.2534, 287.2143, 287.2325, 287.1902, 287.1579, 287.0768,\n",
            "        287.1591, 287.2896, 287.2684, 287.1245, 287.1838, 287.2397, 287.1950,\n",
            "        287.1003, 287.2397, 287.1453, 287.1498, 287.1902, 287.3124, 287.1672,\n",
            "        287.1540, 287.1546, 287.1364, 287.2025, 287.1248, 287.1999, 287.2381,\n",
            "        287.2582, 287.2968, 287.0703, 287.2173, 287.2342, 287.1901, 287.2258,\n",
            "        287.1590, 287.2476, 287.2254, 287.2270, 287.2232, 287.2644, 287.1038,\n",
            "        287.2668, 287.2604, 287.1713, 287.0996, 287.1424, 287.3515, 287.1769,\n",
            "        287.1822, 287.1826, 287.1979, 287.2306, 287.0888],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0035, 0.0123, 0.0062, 0.0078, 0.0041, 0.0105, 0.0115, 0.0092, 0.0095,\n",
            "        0.0077, 0.0068, 0.0148, 0.0083, 0.0188, 0.0058, 0.0137, 0.0139, 0.0084,\n",
            "        0.0096, 0.0146, 0.0027, 0.0102, 0.0131, 0.0071, 0.0065, 0.0083, 0.0100,\n",
            "        0.0177, 0.0114, 0.0131, 0.0163, 0.0067, 0.0054, 0.0055, 0.0118, 0.0078,\n",
            "        0.0089, 0.0094, 0.0129, 0.0072, 0.0075, 0.0110, 0.0092, 0.0036, 0.0058,\n",
            "        0.0091, 0.0115, 0.0129, 0.0103, 0.0131, 0.0079, 0.0090, 0.0069, 0.0131,\n",
            "        0.0076, 0.0150, 0.0082, 0.0166, 0.0100, 0.0149, 0.0092, 0.0062, 0.0260,\n",
            "        0.0155, 0.0088, 0.0142, 0.0093, 0.0183, 0.0078, 0.0074, 0.0111, 0.0082,\n",
            "        0.0139, 0.0107, 0.0113, 0.0049, 0.0093, 0.0078, 0.0117, 0.0109, 0.0103,\n",
            "        0.0098, 0.0087, 0.0193, 0.0186, 0.0147, 0.0125, 0.0155, 0.0225, 0.0082,\n",
            "        0.0092, 0.0134, 0.0144, 0.0085], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [18]\n",
            "DEBUGGING: logits looks like: tensor([286.4348, 287.0623, 286.7151, 286.8326, 286.5164, 286.9844, 287.0289,\n",
            "        286.9163, 286.9305, 286.8280, 286.7614, 287.1522, 286.8650, 287.2737,\n",
            "        286.6879, 287.1144, 287.1221, 286.8703, 286.9355, 287.1485, 286.2997,\n",
            "        286.9675, 287.0920, 286.7859, 286.7420, 286.8651, 286.9566, 287.2433,\n",
            "        287.0248, 287.0943, 287.2015, 286.7552, 286.6467, 286.6569, 287.0383,\n",
            "        286.8324, 286.8994, 286.9273, 287.0836, 286.7968, 286.8122, 287.0036,\n",
            "        286.9179, 286.4440, 286.6874, 286.9078, 287.0272, 287.0844, 286.9723,\n",
            "        287.0935, 286.8424, 286.9073, 286.7721, 287.0936, 286.8221, 287.1592,\n",
            "        286.8597, 287.2110, 286.9574, 287.1575, 286.9136, 286.7148, 287.4358,\n",
            "        287.1756, 286.8936, 287.1342, 286.9189, 287.2591, 286.8350, 286.8082,\n",
            "        287.0082, 286.8564, 287.1239, 286.9914, 287.0187, 286.5982, 286.9215,\n",
            "        286.8341, 287.0382, 287.0010, 286.9709, 286.9489, 286.8899, 287.2856,\n",
            "        287.2668, 287.1496, 287.0703, 287.1766, 287.3623, 286.8575, 286.9163,\n",
            "        287.1028, 287.1393, 286.8736], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0102, 0.0085, 0.0052, 0.0092, 0.0089, 0.0064, 0.0092, 0.0089, 0.0087,\n",
            "        0.0093, 0.0092, 0.0087, 0.0087, 0.0112, 0.0079, 0.0083, 0.0095, 0.0091,\n",
            "        0.0089, 0.0066, 0.0047, 0.0112, 0.0059, 0.0041, 0.0055, 0.0136, 0.0114,\n",
            "        0.0084, 0.0071, 0.0090, 0.0105, 0.0091, 0.0124, 0.0061, 0.0080, 0.0087,\n",
            "        0.0108, 0.0084, 0.0086, 0.0031, 0.0097, 0.0190, 0.0038, 0.0076, 0.0095,\n",
            "        0.0112, 0.0091, 0.0090, 0.0096, 0.0107, 0.0089, 0.0116, 0.0104, 0.0136,\n",
            "        0.0087, 0.0081, 0.0088, 0.0083, 0.0096, 0.0072, 0.0114, 0.0110, 0.0112,\n",
            "        0.0102, 0.0116, 0.0096, 0.0096, 0.0136, 0.0092, 0.0129, 0.0094, 0.0082,\n",
            "        0.0076, 0.0087, 0.0078, 0.0118, 0.0099, 0.0084, 0.0093, 0.0096, 0.0086,\n",
            "        0.0092, 0.0144, 0.0067, 0.0073, 0.0120, 0.0074, 0.0098, 0.0102, 0.0067,\n",
            "        0.0105, 0.0085, 0.0084, 0.0090, 0.0060, 0.0174, 0.0038, 0.0094, 0.0094,\n",
            "        0.0070, 0.0103, 0.0074, 0.0075, 0.0092, 0.0112, 0.0093, 0.0127, 0.0160],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [88]\n",
            "DEBUGGING: logits looks like: tensor([287.0446, 286.9516, 286.7107, 286.9894, 286.9727, 286.8117, 286.9901,\n",
            "        286.9724, 286.9615, 286.9965, 286.9902, 286.9615, 286.9660, 287.0899,\n",
            "        286.9154, 286.9426, 287.0078, 286.9866, 286.9751, 286.8268, 286.6548,\n",
            "        287.0903, 286.7721, 286.5883, 286.7370, 287.1850, 287.0977, 286.9433,\n",
            "        286.8647, 286.9775, 287.0595, 286.9837, 287.1419, 286.7864, 286.9223,\n",
            "        286.9651, 287.0706, 286.9477, 286.9594, 286.4532, 287.0169, 287.3546,\n",
            "        286.5509, 286.8961, 287.0079, 287.0883, 286.9864, 286.9778, 287.0141,\n",
            "        287.0685, 286.9742, 287.1054, 287.0540, 287.1879, 286.9613, 286.9264,\n",
            "        286.9662, 286.9420, 287.0136, 286.8683, 287.0984, 287.0813, 287.0899,\n",
            "        287.0444, 287.1083, 287.0121, 287.0103, 287.1856, 286.9918, 287.1611,\n",
            "        287.0039, 286.9358, 286.8961, 286.9615, 286.9079, 287.1164, 287.0255,\n",
            "        286.9465, 286.9976, 287.0138, 286.9553, 286.9921, 287.2137, 286.8307,\n",
            "        286.8782, 287.1227, 286.8834, 287.0215, 287.0431, 286.8334, 287.0592,\n",
            "        286.9502, 286.9447, 286.9829, 286.7813, 287.3085, 286.5456, 287.0021,\n",
            "        287.0018, 286.8557, 287.0462, 286.8833, 286.8864, 286.9901, 287.0907,\n",
            "        286.9965, 287.1505, 287.2670], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.7082653196348474 and immediate abs rewards look like: [0.0202288254904488, 0.017470288805270684, 0.012208153250867326, 0.0350149505788977, 0.6233431014957205, 4.547473508864641e-13, 1.3642420526593924e-12, 9.094947017729282e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 9.094947017729282e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 9.094947017729282e-13, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 0.0, 0.0, 0.0, 4.547473508864641e-13, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0]\n",
            "DEBUGGING: the total relative reward of the trajectory = 9.233686091379 and immediate relative rewards look like: [0.05455064227314402, 0.09474032501077388, 0.09977877445577348, 0.3828488090065884, 8.601767539467053, 9.094947017733418e-12, 3.1832314562062137e-11, 2.425319204727441e-11, 1.3642420526595993e-11, 0.0, 0.0, 0.0, 0.0, 2.1221543041368324e-11, 4.547473508865331e-11, 0.0, 2.5769016550229062e-11, 2.7284841053187844e-11, 0.0, 0.0, 6.366462912409532e-11, 3.3348139065012427e-11, 0.0, 0.0, 3.789561257387201e-11, 0.0, 0.0, 0.0, 4.395891058568487e-11, 0.0, 0.0, 0.0, 5.0022208597511047e-11, 5.153803310047375e-11, 1.0610771520684162e-10, 5.456968210639224e-11, 5.6085506609339083e-11, 5.760133111228545e-11, 5.91171556152493e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 6.821210263296962e-11, 1.3945585427187015e-10, 7.124375163886858e-11, 0.0, 7.427540064478913e-11, 0.0]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([0.1215, 0.0114, 0.0112, 0.0135, 0.0123, 0.0208, 0.0116, 0.0171, 0.0115,\n",
            "        0.0146, 0.0167, 0.0116, 0.0116, 0.0134, 0.0138, 0.0125, 0.0137, 0.0125,\n",
            "        0.0128, 0.0136, 0.0147, 0.0130, 0.0110, 0.0108, 0.0101, 0.0150, 0.0104,\n",
            "        0.0127, 0.0117, 0.0137, 0.0123, 0.0129, 0.0110, 0.0154, 0.0089, 0.0137,\n",
            "        0.0093, 0.0110, 0.0174, 0.0125, 0.0106, 0.0122, 0.0172, 0.0086, 0.0210,\n",
            "        0.0139, 0.0117, 0.0122, 0.0118, 0.0103, 0.0151, 0.0284, 0.0113, 0.0135,\n",
            "        0.0126, 0.0115, 0.0139, 0.0102, 0.0139, 0.0113, 0.0134, 0.0096, 0.0167,\n",
            "        0.0119, 0.0127, 0.0131, 0.0128, 0.0134], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [4]\n",
            "DEBUGGING: logits looks like: tensor([287.4822, 286.2987, 286.2882, 286.3830, 286.3385, 286.6001, 286.3058,\n",
            "        286.5006, 286.3020, 286.4234, 286.4904, 286.3083, 286.3096, 286.3810,\n",
            "        286.3928, 286.3463, 286.3896, 286.3449, 286.3561, 286.3865, 286.4268,\n",
            "        286.3635, 286.2803, 286.2714, 286.2380, 286.4373, 286.2548, 286.3546,\n",
            "        286.3105, 286.3902, 286.3360, 286.3616, 286.2815, 286.4489, 286.1748,\n",
            "        286.3892, 286.1979, 286.2806, 286.5100, 286.3446, 286.2605, 286.3330,\n",
            "        286.5055, 286.1603, 286.6053, 286.3986, 286.3138, 286.3311, 286.3155,\n",
            "        286.2495, 286.4393, 286.7552, 286.2942, 286.3846, 286.3481, 286.3014,\n",
            "        286.3970, 286.2424, 286.3991, 286.2960, 286.3795, 286.2125, 286.4890,\n",
            "        286.3184, 286.3512, 286.3693, 286.3564, 286.3794],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0088, 0.0022, 0.0253, 0.0058, 0.0167, 0.0238, 0.0320, 0.0135, 0.0131,\n",
            "        0.0298, 0.0037, 0.0076, 0.0072, 0.0094, 0.0305, 0.0065, 0.0110, 0.0129,\n",
            "        0.0054, 0.0099, 0.0173, 0.0248, 0.0112, 0.0103, 0.0073, 0.0721, 0.0049,\n",
            "        0.0014, 0.0076, 0.0119, 0.0021, 0.0721, 0.0206, 0.0055, 0.0019, 0.0041,\n",
            "        0.0025, 0.0149, 0.0118, 0.0071, 0.0102, 0.0068, 0.0135, 0.0057, 0.0100,\n",
            "        0.0330, 0.0102, 0.0114, 0.0168, 0.0075, 0.0038, 0.0187, 0.0183, 0.0124,\n",
            "        0.0029, 0.0052, 0.0051, 0.0048, 0.0070, 0.0036, 0.0098, 0.0143, 0.0093,\n",
            "        0.0081, 0.0136, 0.0080, 0.0076, 0.0173, 0.0395, 0.0073, 0.0064, 0.0041,\n",
            "        0.0075, 0.0379, 0.0031, 0.0060, 0.0066], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [52]\n",
            "DEBUGGING: logits looks like: tensor([286.6457, 285.9566, 287.1755, 286.4423, 286.9676, 287.1461, 287.2936,\n",
            "        286.8629, 286.8457, 287.2583, 286.2201, 286.5775, 286.5500, 286.6823,\n",
            "        287.2700, 286.4998, 286.7607, 286.8377, 286.4006, 286.7067, 286.9869,\n",
            "        287.1668, 286.7708, 286.7278, 286.5555, 287.7002, 286.3554, 285.7428,\n",
            "        286.5760, 286.8010, 285.9381, 287.7002, 287.0747, 286.4097, 285.8719,\n",
            "        286.2671, 286.0146, 286.9110, 286.7929, 286.5403, 286.7240, 286.5231,\n",
            "        286.8609, 286.4351, 286.7141, 287.3090, 286.7201, 286.7769, 286.9729,\n",
            "        286.5652, 286.2235, 287.0263, 287.0134, 286.8213, 286.1004, 286.3806,\n",
            "        286.3792, 286.3469, 286.5368, 286.1962, 286.7020, 286.8907, 286.6784,\n",
            "        286.6100, 286.8648, 286.5995, 286.5752, 286.9873, 287.3988, 286.5553,\n",
            "        286.4887, 286.2692, 286.5665, 287.3786, 286.1207, 286.4545, 286.5015],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0116, 0.0111, 0.0117, 0.0104, 0.0126, 0.0135, 0.0102, 0.0110, 0.0105,\n",
            "        0.0124, 0.0105, 0.0111, 0.0105, 0.0113, 0.0119, 0.0122, 0.0103, 0.0111,\n",
            "        0.0098, 0.0115, 0.0095, 0.0114, 0.0118, 0.0107, 0.0107, 0.0119, 0.0137,\n",
            "        0.0111, 0.0124, 0.0089, 0.0115, 0.0131, 0.0126, 0.0121, 0.0119, 0.0107,\n",
            "        0.0111, 0.0107, 0.0111, 0.0107, 0.0135, 0.0110, 0.0108, 0.0121, 0.0094,\n",
            "        0.0105, 0.0126, 0.0105, 0.0111, 0.0110, 0.0101, 0.0088, 0.0105, 0.0106,\n",
            "        0.0114, 0.0144, 0.0112, 0.0127, 0.0117, 0.0105, 0.0106, 0.0113, 0.0104,\n",
            "        0.0112, 0.0120, 0.0121, 0.0113, 0.0111, 0.0101, 0.0131, 0.0116, 0.0113,\n",
            "        0.0118, 0.0105, 0.0112, 0.0113, 0.0109, 0.0114, 0.0161, 0.0120, 0.0118,\n",
            "        0.0107, 0.0112, 0.0117, 0.0126, 0.0119, 0.0106, 0.0113],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [76]\n",
            "DEBUGGING: logits looks like: tensor([287.3011, 287.2784, 287.3080, 287.2472, 287.3443, 287.3778, 287.2362,\n",
            "        287.2743, 287.2501, 287.3354, 287.2543, 287.2779, 287.2516, 287.2873,\n",
            "        287.3164, 287.3255, 287.2439, 287.2787, 287.2198, 287.2964, 287.1995,\n",
            "        287.2922, 287.3087, 287.2610, 287.2596, 287.3146, 287.3843, 287.2813,\n",
            "        287.3342, 287.1691, 287.2971, 287.3618, 287.3426, 287.3212, 287.3127,\n",
            "        287.2596, 287.2808, 287.2599, 287.2802, 287.2629, 287.3761, 287.2767,\n",
            "        287.2640, 287.3225, 287.1967, 287.2532, 287.3412, 287.2523, 287.2780,\n",
            "        287.2740, 287.2346, 287.1631, 287.2530, 287.2569, 287.2909, 287.4102,\n",
            "        287.2836, 287.3470, 287.3050, 287.2513, 287.2586, 287.2896, 287.2458,\n",
            "        287.2859, 287.3202, 287.3249, 287.2883, 287.2806, 287.2318, 287.3615,\n",
            "        287.3007, 287.2877, 287.3116, 287.2513, 287.2854, 287.2897, 287.2707,\n",
            "        287.2943, 287.4645, 287.3207, 287.3083, 287.2608, 287.2859, 287.3075,\n",
            "        287.3412, 287.3155, 287.2557, 287.2892], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0151, 0.0073, 0.0031, 0.0126, 0.0136, 0.0037, 0.0021, 0.0094, 0.0056,\n",
            "        0.0060, 0.0099, 0.0014, 0.0133, 0.0104, 0.0121, 0.0116, 0.0256, 0.0101,\n",
            "        0.0064, 0.0100, 0.0093, 0.0125, 0.0105, 0.0117, 0.0134, 0.0128, 0.0076,\n",
            "        0.0124, 0.0064, 0.0137, 0.0114, 0.0095, 0.0122, 0.0109, 0.0091, 0.0130,\n",
            "        0.0144, 0.0115, 0.0342, 0.0137, 0.0098, 0.0102, 0.0093, 0.0096, 0.0074,\n",
            "        0.0143, 0.0109, 0.0080, 0.0146, 0.0103, 0.0018, 0.0080, 0.0080, 0.0110,\n",
            "        0.0127, 0.0083, 0.0063, 0.0081, 0.0058, 0.0094, 0.0113, 0.0104, 0.0097,\n",
            "        0.0100, 0.0109, 0.0080, 0.0082, 0.0098, 0.0092, 0.0079, 0.0054, 0.0095,\n",
            "        0.0090, 0.0147, 0.0138, 0.0106, 0.0076, 0.0034, 0.0112, 0.0094, 0.0077,\n",
            "        0.0185, 0.0105, 0.0119, 0.0150, 0.0089, 0.0133, 0.0066, 0.0109, 0.0066,\n",
            "        0.0067, 0.0151, 0.0111, 0.0091, 0.0098, 0.0128, 0.0121],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [96]\n",
            "DEBUGGING: logits looks like: tensor([287.2003, 286.8344, 286.4139, 287.1122, 287.1501, 286.4960, 286.2198,\n",
            "        286.9626, 286.7055, 286.7390, 286.9880, 286.0152, 287.1373, 287.0161,\n",
            "        287.0901, 287.0692, 287.4652, 287.0006, 286.7729, 286.9942, 286.9561,\n",
            "        287.1081, 287.0213, 287.0738, 287.1397, 287.1175, 286.8582, 287.1004,\n",
            "        286.7717, 287.1537, 287.0624, 286.9689, 287.0959, 287.0392, 286.9459,\n",
            "        287.1269, 287.1772, 287.0632, 287.6102, 287.1520, 286.9854, 287.0036,\n",
            "        286.9595, 286.9737, 286.8419, 287.1734, 287.0361, 286.8831, 287.1845,\n",
            "        287.0078, 286.1428, 286.8824, 286.8825, 287.0410, 287.1143, 286.9031,\n",
            "        286.7656, 286.8899, 286.7225, 286.9662, 287.0542, 287.0157, 286.9816,\n",
            "        286.9961, 287.0397, 286.8829, 286.8942, 286.9870, 286.9512, 286.8765,\n",
            "        286.6849, 286.9716, 286.9437, 287.1866, 287.1568, 287.0222, 286.8580,\n",
            "        286.4569, 287.0497, 286.9637, 286.8671, 287.3030, 287.0202, 287.0798,\n",
            "        287.1967, 286.9340, 287.1373, 286.7870, 287.0373, 286.7874, 286.7948,\n",
            "        287.2013, 287.0462, 286.9452, 286.9845, 287.1192, 287.0902],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0080, 0.0070, 0.0101, 0.0096, 0.0185, 0.0086, 0.0052, 0.0165, 0.0097,\n",
            "        0.0078, 0.0106, 0.0025, 0.0085, 0.0160, 0.0117, 0.0068, 0.0117, 0.0106,\n",
            "        0.0018, 0.0127, 0.0127, 0.0095, 0.0116, 0.0073, 0.0074, 0.0112, 0.0080,\n",
            "        0.0108, 0.0047, 0.0139, 0.0054, 0.0062, 0.0030, 0.0059, 0.0120, 0.0105,\n",
            "        0.0102, 0.0088, 0.0132, 0.0085, 0.0162, 0.0187, 0.0094, 0.0106, 0.0103,\n",
            "        0.0055, 0.0040, 0.0103, 0.0074, 0.0113, 0.0081, 0.0074, 0.0105, 0.0098,\n",
            "        0.0120, 0.0132, 0.0095, 0.0059, 0.0121, 0.0096, 0.0068, 0.0105, 0.0095,\n",
            "        0.0150, 0.0085, 0.0077, 0.0095, 0.0082, 0.0118, 0.0126, 0.0084, 0.0059,\n",
            "        0.0087, 0.0104, 0.0098, 0.0140, 0.0103, 0.0069, 0.0075, 0.0064, 0.0081,\n",
            "        0.0037, 0.0087, 0.0104, 0.0086, 0.0097, 0.0101, 0.0068, 0.0130, 0.0072,\n",
            "        0.0142, 0.0036, 0.0082, 0.0067, 0.0078, 0.0119, 0.0104, 0.0057, 0.0104,\n",
            "        0.0082, 0.0073, 0.0089, 0.0079, 0.0064, 0.0079, 0.0116, 0.0113],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [20]\n",
            "DEBUGGING: logits looks like: tensor([287.5742, 287.5045, 287.6896, 287.6659, 287.9925, 287.6108, 287.3598,\n",
            "        287.9363, 287.6681, 287.5616, 287.7163, 286.9908, 287.6029, 287.9193,\n",
            "        287.7621, 287.4923, 287.7640, 287.7160, 286.8366, 287.8041, 287.8038,\n",
            "        287.6572, 287.7608, 287.5294, 287.5348, 287.7421, 287.5764, 287.7231,\n",
            "        287.3120, 287.8515, 287.3817, 287.4449, 287.0848, 287.4208, 287.7762,\n",
            "        287.7095, 287.6969, 287.6219, 287.8249, 287.6017, 287.9256, 287.9980,\n",
            "        287.6537, 287.7156, 287.7022, 287.3845, 287.2293, 287.7014, 287.5360,\n",
            "        287.7470, 287.5784, 287.5321, 287.7108, 287.6761, 287.7755, 287.8227,\n",
            "        287.6606, 287.4231, 287.7807, 287.6666, 287.4916, 287.7095, 287.6585,\n",
            "        287.8881, 287.6040, 287.5545, 287.6613, 287.5876, 287.7676, 287.7993,\n",
            "        287.5991, 287.4240, 287.6164, 287.7044, 287.6769, 287.8550, 287.6993,\n",
            "        287.4985, 287.5381, 287.4646, 287.5829, 287.1913, 287.6139, 287.7031,\n",
            "        287.6115, 287.6691, 287.6880, 287.4904, 287.8166, 287.5208, 287.8588,\n",
            "        287.1703, 287.5842, 287.4882, 287.5594, 287.7731, 287.7069, 287.4046,\n",
            "        287.7063, 287.5864, 287.5259, 287.6279, 287.5678, 287.4659, 287.5675,\n",
            "        287.7596, 287.7467], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.7058461509327572 and immediate abs rewards look like: [0.0057782136041169, 0.0027352415213499626, 0.0018807676606229506, 0.0004309101714170538, 2.4859926270437427e-05, 0.0019372374581507756, 0.0004440645707290969, 0.00047844280015851837, 0.0001504307156210416, 0.00044360890751704574, 0.001051624545652885, 0.0005332506598278997, 0.001248944203780411, 0.00020181140507702366, 0.0013424077651507105, 0.0009996013382078672, 0.6861647336681926, 0.0, 0.0, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 1.3642420526593924e-12, 1.3642420526593924e-12, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 9.094947017729282e-13, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13]\n",
            "DEBUGGING: the total relative reward of the trajectory = 43.857313457212356 and immediate relative rewards look like: [0.021354553370114243, 0.020260538511246783, 0.020918083225932707, 0.0063946259537287385, 0.00046121952490781276, 0.04312965239018511, 0.01154245817404856, 0.01421496428546681, 0.005029003857110576, 0.016478871376077352, 0.04297859144150141, 0.023783794537180845, 0.06035885198529626, 0.010508240719098793, 0.07489702799296671, 0.059518583225355616, 43.42548439474129, 0.0, 0.0, 4.547473508865675e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 5.911715561524034e-11, 1.841726771089761e-10, 1.9099388737240178e-10, 6.59383658785223e-11, 6.821210263296962e-11, 0.0, 7.27595761418508e-11, 0.0, 1.546140993013978e-10, 1.5916157281033482e-10, 8.185452315956354e-11, 8.412825991397673e-11, 0.0, 8.86757334228605e-11, 9.09494701773135e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0686562745831907e-10, 1.0913936421272657e-10, 1.1141310096718371e-10, 2.2737367544328376e-10]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([0.0462, 0.0020, 0.0121, 0.0037, 0.0170, 0.0147, 0.0032, 0.0040, 0.0042,\n",
            "        0.0040, 0.0030, 0.0206, 0.0033, 0.0112, 0.0040, 0.0021, 0.0027, 0.1773,\n",
            "        0.0053, 0.0048, 0.0045, 0.0198, 0.0126, 0.0211, 0.0100, 0.0047, 0.0019,\n",
            "        0.0088, 0.0407, 0.0208, 0.0050, 0.0155, 0.0470, 0.0040, 0.0035, 0.0033,\n",
            "        0.0035, 0.0101, 0.0041, 0.0040, 0.0171, 0.0038, 0.0383, 0.0042, 0.0051,\n",
            "        0.0034, 0.0030, 0.0048, 0.0045, 0.1773, 0.0192, 0.0052, 0.0040, 0.0038,\n",
            "        0.0048, 0.0038, 0.0033, 0.0042, 0.0033, 0.0121, 0.0068, 0.0035, 0.0139,\n",
            "        0.0063, 0.0069, 0.0052, 0.0057, 0.0009, 0.0280, 0.0077],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [48]\n",
            "DEBUGGING: logits looks like: tensor([287.5007, 285.9284, 286.8290, 286.2336, 287.0006, 286.9279, 286.1600,\n",
            "        286.2721, 286.3044, 286.2832, 286.1389, 287.0974, 286.1799, 286.7903,\n",
            "        286.2724, 285.9530, 286.0880, 288.1733, 286.4188, 286.3708, 286.3337,\n",
            "        287.0761, 286.8500, 287.1083, 286.7354, 286.3629, 285.9159, 286.6710,\n",
            "        287.4372, 287.1012, 286.3863, 286.9541, 287.5096, 286.2776, 286.2072,\n",
            "        286.1763, 286.2078, 286.7419, 286.2845, 286.2788, 287.0036, 286.2575,\n",
            "        287.4076, 286.3078, 286.3958, 286.2013, 286.1319, 286.3652, 286.3368,\n",
            "        288.1733, 287.0612, 286.4046, 286.2804, 286.2457, 286.3725, 286.2570,\n",
            "        286.1806, 286.3037, 286.1795, 286.8318, 286.5464, 286.2112, 286.9006,\n",
            "        286.5038, 286.5466, 286.4072, 286.4546, 285.5346, 287.2508, 286.6062],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.1385, 0.0092, 0.0098, 0.0135, 0.0099, 0.0130, 0.0136, 0.0135, 0.0096,\n",
            "        0.0133, 0.0138, 0.0091, 0.0096, 0.0102, 0.0176, 0.0118, 0.0100, 0.0159,\n",
            "        0.0111, 0.0097, 0.0107, 0.0118, 0.0114, 0.0128, 0.0121, 0.0099, 0.0111,\n",
            "        0.0116, 0.0114, 0.0108, 0.0113, 0.0113, 0.0125, 0.0114, 0.0120, 0.0127,\n",
            "        0.0110, 0.0100, 0.0095, 0.0104, 0.0112, 0.0140, 0.0100, 0.0121, 0.0097,\n",
            "        0.0127, 0.0122, 0.0115, 0.0103, 0.0120, 0.0097, 0.0115, 0.0112, 0.0097,\n",
            "        0.0122, 0.0108, 0.0099, 0.0072, 0.0113, 0.0122, 0.0114, 0.0129, 0.0115,\n",
            "        0.0115, 0.0097, 0.0150, 0.0113, 0.0136, 0.0144, 0.0115, 0.0112, 0.0103,\n",
            "        0.0120, 0.0116, 0.0129, 0.0096], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [0]\n",
            "DEBUGGING: logits looks like: tensor([287.5435, 286.1852, 286.2209, 286.3799, 286.2224, 286.3615, 286.3818,\n",
            "        286.3793, 286.2112, 286.3710, 286.3904, 286.1849, 286.2114, 286.2413,\n",
            "        286.5130, 286.3131, 286.2309, 286.4598, 286.2821, 286.2140, 286.2624,\n",
            "        286.3101, 286.2943, 286.3510, 286.3247, 286.2263, 286.2823, 286.3033,\n",
            "        286.2948, 286.2665, 286.2926, 286.2892, 286.3407, 286.2942, 286.3188,\n",
            "        286.3500, 286.2764, 286.2311, 286.2037, 286.2498, 286.2850, 286.3985,\n",
            "        286.2307, 286.3261, 286.2123, 286.3481, 286.3284, 286.2972, 286.2422,\n",
            "        286.3199, 286.2133, 286.2994, 286.2859, 286.2155, 286.3306, 286.2672,\n",
            "        286.2259, 286.0644, 286.2904, 286.3278, 286.2945, 286.3564, 286.2981,\n",
            "        286.2974, 286.2126, 286.4310, 286.2896, 286.3818, 286.4126, 286.2986,\n",
            "        286.2841, 286.2448, 286.3225, 286.3057, 286.3554, 286.2114],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0120, 0.0070, 0.0170, 0.0057, 0.0205, 0.0102, 0.0077, 0.0102, 0.0077,\n",
            "        0.0156, 0.0124, 0.0106, 0.0173, 0.0073, 0.0077, 0.0068, 0.0075, 0.0065,\n",
            "        0.0119, 0.0099, 0.0138, 0.0101, 0.0210, 0.0087, 0.0165, 0.0080, 0.0127,\n",
            "        0.0059, 0.0137, 0.0094, 0.0181, 0.0136, 0.0074, 0.0084, 0.0114, 0.0118,\n",
            "        0.0016, 0.0147, 0.0125, 0.0086, 0.0119, 0.0060, 0.0112, 0.0093, 0.0306,\n",
            "        0.0142, 0.0085, 0.0098, 0.0066, 0.0175, 0.0156, 0.0106, 0.0141, 0.0105,\n",
            "        0.0171, 0.0103, 0.0125, 0.0126, 0.0067, 0.0099, 0.0112, 0.0086, 0.0199,\n",
            "        0.0105, 0.0077, 0.0094, 0.0087, 0.0112, 0.0126, 0.0194, 0.0132, 0.0147,\n",
            "        0.0105, 0.0100, 0.0096, 0.0175, 0.0091, 0.0088, 0.0058, 0.0175, 0.0117,\n",
            "        0.0093, 0.0065, 0.0075, 0.0205, 0.0093, 0.0145],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [31]\n",
            "DEBUGGING: logits looks like: tensor([286.7076, 286.4335, 286.8811, 286.3383, 286.9731, 286.6228, 286.4814,\n",
            "        286.6248, 286.4833, 286.8376, 286.7241, 286.6419, 286.8899, 286.4582,\n",
            "        286.4839, 286.4209, 286.4682, 286.3987, 286.7032, 286.6123, 286.7762,\n",
            "        286.6203, 286.9862, 286.5451, 286.8665, 286.5064, 286.7335, 286.3546,\n",
            "        286.7735, 286.5858, 286.9121, 286.7692, 286.4656, 286.5249, 286.6802,\n",
            "        286.6959, 285.7021, 286.8092, 286.7263, 286.5381, 286.7021, 286.3564,\n",
            "        286.6713, 286.5779, 287.1736, 286.7919, 286.5327, 286.6057, 286.4047,\n",
            "        286.8960, 286.8385, 286.6427, 286.7866, 286.6397, 286.8831, 286.6311,\n",
            "        286.7257, 286.7289, 286.4168, 286.6091, 286.6715, 286.5424, 286.9582,\n",
            "        286.6374, 286.4858, 286.5836, 286.5457, 286.6708, 286.7311, 286.9461,\n",
            "        286.7543, 286.8093, 286.6390, 286.6143, 286.5966, 286.8940, 286.5669,\n",
            "        286.5502, 286.3404, 286.8942, 286.6954, 286.5799, 286.3976, 286.4709,\n",
            "        286.9727, 286.5760, 286.7993], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0166, 0.0062, 0.0179, 0.0043, 0.0137, 0.0065, 0.0104, 0.0084, 0.0044,\n",
            "        0.0110, 0.0103, 0.0063, 0.0126, 0.0047, 0.0055, 0.0176, 0.0118, 0.0093,\n",
            "        0.0123, 0.0060, 0.0093, 0.0058, 0.0047, 0.0164, 0.0122, 0.0078, 0.0023,\n",
            "        0.0064, 0.0047, 0.0062, 0.0118, 0.0037, 0.0169, 0.0040, 0.0093, 0.0079,\n",
            "        0.0100, 0.0049, 0.0150, 0.0127, 0.0043, 0.0095, 0.0035, 0.0033, 0.0035,\n",
            "        0.0116, 0.0153, 0.0216, 0.0037, 0.0032, 0.0168, 0.0108, 0.0029, 0.0253,\n",
            "        0.0175, 0.0341, 0.0102, 0.0167, 0.0044, 0.0051, 0.0051, 0.0110, 0.0115,\n",
            "        0.0037, 0.0123, 0.0077, 0.0111, 0.0067, 0.0136, 0.0123, 0.0098, 0.0077,\n",
            "        0.0101, 0.0076, 0.0074, 0.0206, 0.0096, 0.0138, 0.0158, 0.0131, 0.0119,\n",
            "        0.0194, 0.0603, 0.0231, 0.0067, 0.0104, 0.0094, 0.0028, 0.0116, 0.0044,\n",
            "        0.0030, 0.0043, 0.0127, 0.0055, 0.0053, 0.0073],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [23]\n",
            "DEBUGGING: logits looks like: tensor([286.7813, 286.2862, 286.8188, 286.1048, 286.6869, 286.3086, 286.5489,\n",
            "        286.4394, 286.1144, 286.5767, 286.5420, 286.2944, 286.6426, 286.1502,\n",
            "        286.2289, 286.8114, 286.6120, 286.4917, 286.6321, 286.2738, 286.4915,\n",
            "        286.2558, 286.1520, 286.7765, 286.6261, 286.4052, 285.7965, 286.3074,\n",
            "        286.1539, 286.2857, 286.6092, 286.0373, 286.7914, 286.0737, 286.4919,\n",
            "        286.4092, 286.5272, 286.1753, 286.7296, 286.6477, 286.1097, 286.5045,\n",
            "        285.9960, 285.9718, 286.0033, 286.6035, 286.7399, 286.9130, 286.0323,\n",
            "        285.9629, 286.7858, 286.5639, 285.9119, 286.9922, 286.8082, 287.1416,\n",
            "        286.5367, 286.7828, 286.1169, 286.1904, 286.1898, 286.5758, 286.5997,\n",
            "        286.0352, 286.6304, 286.3941, 286.5789, 286.3295, 286.6828, 286.6303,\n",
            "        286.5151, 286.3970, 286.5350, 286.3899, 286.3773, 286.8901, 286.5064,\n",
            "        286.6877, 286.7564, 286.6641, 286.6136, 286.8584, 287.4259, 286.9469,\n",
            "        286.3302, 286.5485, 286.4949, 285.8841, 286.6001, 286.1218, 285.9255,\n",
            "        286.1000, 286.6459, 286.2321, 286.2114, 286.3692],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0137, 0.0106, 0.0090, 0.0144, 0.0094, 0.0056, 0.0058, 0.0062, 0.0104,\n",
            "        0.0063, 0.0104, 0.0064, 0.0075, 0.0089, 0.0128, 0.0111, 0.0057, 0.0062,\n",
            "        0.0145, 0.0054, 0.0062, 0.0109, 0.0112, 0.0107, 0.0081, 0.0076, 0.0098,\n",
            "        0.0043, 0.0029, 0.0160, 0.0081, 0.0264, 0.0116, 0.0048, 0.0066, 0.0078,\n",
            "        0.0065, 0.0061, 0.0075, 0.0064, 0.0085, 0.0065, 0.0132, 0.0079, 0.0076,\n",
            "        0.0129, 0.0103, 0.0097, 0.0150, 0.0067, 0.0116, 0.0068, 0.0092, 0.0047,\n",
            "        0.0082, 0.0101, 0.0053, 0.0147, 0.0058, 0.0146, 0.0085, 0.0149, 0.0067,\n",
            "        0.0091, 0.0100, 0.0063, 0.0088, 0.0057, 0.0095, 0.0065, 0.0068, 0.0049,\n",
            "        0.0102, 0.0140, 0.0069, 0.0070, 0.0097, 0.0124, 0.0055, 0.0090, 0.0071,\n",
            "        0.0069, 0.0091, 0.0111, 0.0112, 0.0076, 0.0264, 0.0078, 0.0105, 0.0118,\n",
            "        0.0064, 0.0085, 0.0208, 0.0049, 0.0076, 0.0048, 0.0080, 0.0182, 0.0095,\n",
            "        0.0095, 0.0093, 0.0122, 0.0115, 0.0123, 0.0056, 0.0045, 0.0075, 0.0082],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [14]\n",
            "DEBUGGING: logits looks like: tensor([287.1094, 286.9821, 286.8976, 287.1341, 286.9206, 286.6634, 286.6788,\n",
            "        286.7107, 286.9700, 286.7173, 286.9706, 286.7297, 286.8074, 286.8910,\n",
            "        287.0743, 287.0033, 286.6708, 286.7146, 287.1385, 286.6429, 286.7144,\n",
            "        286.9947, 287.0067, 286.9843, 286.8466, 286.8148, 286.9418, 286.5293,\n",
            "        286.3354, 287.1863, 286.8448, 287.4370, 287.0243, 286.5890, 286.7480,\n",
            "        286.8249, 286.7393, 286.7080, 286.8053, 286.7314, 286.8724, 286.7371,\n",
            "        287.0892, 286.8355, 286.8166, 287.0795, 286.9659, 286.9380, 287.1559,\n",
            "        286.7505, 287.0242, 286.7561, 286.9091, 286.5791, 286.8553, 286.9570,\n",
            "        286.6379, 287.1456, 286.6759, 287.1411, 286.8693, 287.1505, 286.7550,\n",
            "        286.9063, 286.9508, 286.7239, 286.8880, 286.6681, 286.9285, 286.7394,\n",
            "        286.7555, 286.5937, 286.9597, 287.1193, 286.7630, 286.7739, 286.9388,\n",
            "        287.0615, 286.6497, 286.8995, 286.7787, 286.7654, 286.9075, 287.0021,\n",
            "        287.0101, 286.8119, 287.4366, 286.8257, 286.9781, 287.0327, 286.7290,\n",
            "        286.8703, 287.3190, 286.5960, 286.8168, 286.5823, 286.8389, 287.2512,\n",
            "        286.9254, 286.9280, 286.9133, 287.0508, 287.0232, 287.0558, 286.6645,\n",
            "        286.5571, 286.8080, 286.8554], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.7058461509291192 and immediate abs rewards look like: [0.009993862921874097, 0.0017838502158156189, 0.0023159150923675043, 0.0005434825529846421, 0.0011893307087120775, 0.0015332583839153813, 0.0033970725371545996, 0.00015649609531465103, 2.233586656075204e-06, 0.00020191012845316436, 0.00014046975866222056, 0.0003370212943991646, 1.7513028979010414e-05, 3.7744846849818714e-05, 0.001061371277046419, 0.0004667648258873669, 0.0018364970246693701, 0.00012334469920460833, 7.558262495876988e-06, 0.6807004536799468, 0.0, 0.0, 0.0, 0.0, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0]\n",
            "DEBUGGING: the total relative reward of the trajectory = 51.262283096231236 and immediate relative rewards look like: [0.03693433537775609, 0.013234035290111119, 0.025789045221205075, 0.008076263302857347, 0.022096587276827402, 0.034198821187978845, 0.08844942384155544, 0.00466267071978295, 7.487069802135488e-05, 0.007520124534367619, 0.005755394662455535, 0.01506471431608997, 0.0008481671636620157, 0.001968635775203972, 0.059312245515518086, 0.02783400118177697, 0.11637836333973027, 0.008281776398140398, 0.0005357054434197967, 50.78526791350457, 0.0, 0.0, 0.0, 0.0, 1.1368683772161603e-10, 5.911715561526722e-11, 6.139089236968661e-11, 0.0, 0.0, 0.0, 0.0, 7.275957614183426e-11, 7.503331289628364e-11, 0.0, 0.0, 0.0, 8.412825991399586e-11, 8.640199666844783e-11, 0.0, 0.0, 9.322320693172514e-11, 9.549694368617918e-11, 9.777068044058979e-11, 0.0, 1.0231815394947769e-10, 1.0459189070388675e-10, 2.1373125491658954e-10, 1.091393642127762e-10, 1.1141310096718371e-10, 0.0]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 3\n",
            "DEBUGGING: the action_prob is: tensor([0.0245, 0.0015, 0.0090, 0.0062, 0.1320, 0.0039, 0.0064, 0.0228, 0.0019,\n",
            "        0.0146, 0.0060, 0.0006, 0.0183, 0.0110, 0.0107, 0.0023, 0.0178, 0.0120,\n",
            "        0.0060, 0.0018, 0.0054, 0.0184, 0.0081, 0.0209, 0.0114, 0.0231, 0.0058,\n",
            "        0.0196, 0.0178, 0.0117, 0.0429, 0.0103, 0.0214, 0.0035, 0.0037, 0.0053,\n",
            "        0.0102, 0.0117, 0.0020, 0.0064, 0.0063, 0.0171, 0.0082, 0.0053, 0.0082,\n",
            "        0.0151, 0.0059, 0.0277, 0.0091, 0.0326, 0.0549, 0.0092, 0.0091, 0.0067,\n",
            "        0.0208, 0.0122, 0.0273, 0.0239, 0.0091, 0.0409, 0.0131, 0.0108, 0.0235,\n",
            "        0.0158, 0.0113, 0.0067], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [30]\n",
            "DEBUGGING: logits looks like: tensor([289.0632, 287.6621, 288.5622, 288.3760, 289.9048, 288.1400, 288.3932,\n",
            "        289.0275, 287.7730, 288.8054, 288.3590, 287.1766, 288.9179, 288.6626,\n",
            "        288.6505, 287.8774, 288.9031, 288.7068, 288.3631, 287.7537, 288.3031,\n",
            "        288.9195, 288.5078, 288.9836, 288.6787, 289.0334, 288.3393, 288.9513,\n",
            "        288.9036, 288.6952, 289.3430, 288.6310, 288.9957, 288.0920, 288.1215,\n",
            "        288.2994, 288.6227, 288.6950, 287.8206, 288.3884, 288.3849, 288.8832,\n",
            "        288.5160, 288.2964, 288.5130, 288.8220, 288.3489, 289.1235, 288.5681,\n",
            "        289.2061, 289.4657, 288.5720, 288.5659, 288.4142, 288.9817, 288.7131,\n",
            "        289.1170, 289.0504, 288.5672, 289.3185, 288.7515, 288.6519, 289.0423,\n",
            "        288.8448, 288.6759, 288.4131], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0173, 0.0022, 0.0765, 0.0207, 0.0048, 0.0016, 0.0161, 0.0018, 0.0938,\n",
            "        0.0070, 0.0061, 0.0116, 0.0510, 0.0333, 0.0234, 0.0282, 0.0040, 0.0013,\n",
            "        0.0149, 0.0314, 0.0053, 0.0196, 0.0087, 0.0047, 0.0072, 0.0174, 0.0054,\n",
            "        0.0006, 0.0084, 0.0035, 0.0039, 0.0029, 0.0030, 0.0149, 0.0180, 0.0093,\n",
            "        0.0034, 0.0054, 0.0106, 0.0043, 0.0137, 0.0070, 0.0100, 0.0077, 0.0043,\n",
            "        0.0037, 0.0214, 0.0116, 0.0025, 0.0011, 0.0353, 0.0065, 0.0098, 0.0031,\n",
            "        0.0107, 0.0016, 0.0054, 0.0052, 0.0224, 0.0095, 0.0069, 0.0261, 0.0090,\n",
            "        0.0191, 0.0049, 0.0472, 0.0022, 0.0054, 0.0051, 0.0046, 0.0275, 0.0059,\n",
            "        0.0076, 0.0050, 0.0047, 0.0116, 0.0090, 0.0020],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [2]\n",
            "DEBUGGING: logits looks like: tensor([290.0135, 288.9902, 290.7584, 290.1047, 289.3723, 288.8308, 289.9798,\n",
            "        288.8890, 290.8601, 289.5619, 289.4971, 289.8131, 290.5551, 290.3429,\n",
            "        290.1668, 290.2583, 289.2803, 288.7305, 289.9413, 290.3137, 289.4189,\n",
            "        290.0771, 289.6727, 289.3615, 289.5751, 290.0178, 289.4318, 288.3397,\n",
            "        289.6515, 289.2216, 289.2753, 289.1291, 289.1370, 289.9396, 290.0336,\n",
            "        289.7055, 289.2068, 289.4367, 289.7693, 289.3216, 289.8982, 289.5612,\n",
            "        289.7412, 289.6086, 289.3237, 289.2501, 290.1220, 289.8131, 289.0569,\n",
            "        288.6452, 290.3712, 289.5221, 289.7291, 289.1616, 289.7764, 288.8360,\n",
            "        289.4294, 289.4108, 290.1448, 289.7131, 289.5552, 290.2196, 289.6870,\n",
            "        290.0636, 289.3876, 290.5169, 288.9946, 289.4336, 289.4014, 289.3486,\n",
            "        290.2461, 289.4738, 289.6018, 289.3928, 289.3680, 289.8129, 289.6904,\n",
            "        288.9328], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0212, 0.0124, 0.0116, 0.0054, 0.0280, 0.0125, 0.0075, 0.0084, 0.0097,\n",
            "        0.0241, 0.0077, 0.0183, 0.0081, 0.0075, 0.0205, 0.0054, 0.0130, 0.0066,\n",
            "        0.0042, 0.0092, 0.0090, 0.0027, 0.0039, 0.0290, 0.0057, 0.0099, 0.0111,\n",
            "        0.0181, 0.0091, 0.0059, 0.0074, 0.0037, 0.0181, 0.0052, 0.0039, 0.0236,\n",
            "        0.0125, 0.0109, 0.0290, 0.0056, 0.0158, 0.0092, 0.0122, 0.0136, 0.0046,\n",
            "        0.0108, 0.0046, 0.0163, 0.0166, 0.0129, 0.0164, 0.0065, 0.0138, 0.0089,\n",
            "        0.0170, 0.0066, 0.0048, 0.0067, 0.0195, 0.0054, 0.0057, 0.0079, 0.0123,\n",
            "        0.0122, 0.0126, 0.0084, 0.0110, 0.0107, 0.0063, 0.0231, 0.0071, 0.0176,\n",
            "        0.0107, 0.0087, 0.0264, 0.0045, 0.0032, 0.0143, 0.0059, 0.0216, 0.0113,\n",
            "        0.0109, 0.0193, 0.0071, 0.0082, 0.0060, 0.0195],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [47]\n",
            "DEBUGGING: logits looks like: tensor([289.4382, 289.1714, 289.1362, 288.7552, 289.5777, 289.1743, 288.9208,\n",
            "        288.9742, 289.0454, 289.5027, 288.9321, 289.3667, 288.9582, 288.9190,\n",
            "        289.4225, 288.7574, 289.1957, 288.8542, 288.6322, 289.0230, 289.0088,\n",
            "        288.4029, 288.5965, 289.5949, 288.7816, 289.0572, 289.1167, 289.3602,\n",
            "        289.0139, 288.8027, 288.9095, 288.5710, 289.3594, 288.7359, 288.5920,\n",
            "        289.4915, 289.1741, 289.1059, 289.5962, 288.7705, 289.2905, 289.0230,\n",
            "        289.1618, 289.2180, 288.6696, 289.1021, 288.6711, 289.3062, 289.3178,\n",
            "        289.1901, 289.3114, 288.8475, 289.2230, 289.0062, 289.3295, 288.8582,\n",
            "        288.6946, 288.8631, 289.3966, 288.7525, 288.7829, 288.9454, 289.1650,\n",
            "        289.1623, 289.1778, 288.9767, 289.1094, 289.0955, 288.8299, 289.4821,\n",
            "        288.8954, 289.3457, 289.0959, 288.9918, 289.5490, 288.6650, 288.4911,\n",
            "        289.2420, 288.7995, 289.4482, 289.1241, 289.1060, 289.3932, 288.8952,\n",
            "        288.9636, 288.8047, 289.3959], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0252, 0.0043, 0.0041, 0.0116, 0.0073, 0.0167, 0.0178, 0.0232, 0.0131,\n",
            "        0.0026, 0.0238, 0.0028, 0.0027, 0.0126, 0.0081, 0.0056, 0.0067, 0.0132,\n",
            "        0.0105, 0.0128, 0.0072, 0.0120, 0.0086, 0.0141, 0.0148, 0.0113, 0.0266,\n",
            "        0.0081, 0.0095, 0.0139, 0.0082, 0.0110, 0.0051, 0.0055, 0.0144, 0.0070,\n",
            "        0.0109, 0.0105, 0.0085, 0.0107, 0.0210, 0.0152, 0.0137, 0.0112, 0.0056,\n",
            "        0.0113, 0.0077, 0.0206, 0.0052, 0.0079, 0.0081, 0.0062, 0.0042, 0.0047,\n",
            "        0.0116, 0.0042, 0.0096, 0.0078, 0.0037, 0.0179, 0.0122, 0.0117, 0.0193,\n",
            "        0.0110, 0.0191, 0.0133, 0.0061, 0.0119, 0.0088, 0.0049, 0.0075, 0.0040,\n",
            "        0.0039, 0.0072, 0.0037, 0.0081, 0.0132, 0.0106, 0.0146, 0.0052, 0.0185,\n",
            "        0.0139, 0.0079, 0.0119, 0.0059, 0.0112, 0.0047, 0.0030, 0.0049, 0.0084,\n",
            "        0.0056, 0.0041, 0.0052, 0.0065, 0.0071, 0.0275, 0.0174],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [41]\n",
            "DEBUGGING: logits looks like: tensor([290.4420, 289.5571, 289.5323, 290.0530, 289.8247, 290.2347, 290.2688,\n",
            "        290.3996, 290.1158, 289.3020, 290.4142, 289.3399, 289.3313, 290.0969,\n",
            "        289.8737, 289.6921, 289.7828, 290.1172, 290.0034, 290.1046, 289.8146,\n",
            "        290.0703, 289.9042, 290.1522, 290.1763, 290.0388, 290.4684, 289.8738,\n",
            "        289.9546, 290.1454, 289.8804, 290.0259, 289.6406, 289.6764, 290.1615,\n",
            "        289.8020, 290.0240, 290.0021, 289.8993, 290.0154, 290.3509, 290.1892,\n",
            "        290.1357, 290.0350, 289.6927, 290.0418, 289.8501, 290.3412, 289.6517,\n",
            "        289.8597, 289.8737, 289.7447, 289.5418, 289.5981, 290.0533, 289.5474,\n",
            "        289.9606, 289.8557, 289.4893, 290.2701, 290.0775, 290.0566, 290.3073,\n",
            "        290.0265, 290.3022, 290.1241, 289.7347, 290.0675, 289.9156, 289.6259,\n",
            "        289.8378, 289.5274, 289.5139, 289.8130, 289.4817, 289.8742, 290.1187,\n",
            "        290.0079, 290.1694, 289.6516, 290.2864, 290.1447, 289.8600, 290.0666,\n",
            "        289.7169, 290.0386, 289.6006, 289.3743, 289.6187, 289.8940, 289.6908,\n",
            "        289.5395, 289.6527, 289.7652, 289.8102, 290.4852, 290.2572],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0104, 0.0032, 0.0067, 0.0134, 0.0146, 0.0217, 0.0084, 0.0082, 0.0128,\n",
            "        0.0139, 0.0013, 0.0059, 0.0122, 0.0026, 0.0093, 0.0052, 0.0103, 0.0089,\n",
            "        0.0050, 0.0074, 0.0061, 0.0057, 0.0069, 0.0067, 0.0089, 0.0043, 0.0061,\n",
            "        0.0079, 0.0295, 0.0226, 0.0041, 0.0076, 0.0081, 0.0149, 0.0155, 0.0057,\n",
            "        0.0169, 0.0103, 0.0091, 0.0066, 0.0086, 0.0144, 0.0137, 0.0124, 0.0123,\n",
            "        0.0019, 0.0131, 0.0095, 0.0096, 0.0094, 0.0133, 0.0106, 0.0225, 0.0097,\n",
            "        0.0060, 0.0068, 0.0144, 0.0126, 0.0222, 0.0132, 0.0085, 0.0032, 0.0072,\n",
            "        0.0104, 0.0058, 0.0056, 0.0067, 0.0112, 0.0062, 0.0080, 0.0151, 0.0025,\n",
            "        0.0166, 0.0066, 0.0141, 0.0102, 0.0133, 0.0070, 0.0117, 0.0137, 0.0111,\n",
            "        0.0026, 0.0072, 0.0036, 0.0021, 0.0129, 0.0102, 0.0057, 0.0090, 0.0083,\n",
            "        0.0127, 0.0122, 0.0122, 0.0126, 0.0026, 0.0046, 0.0063, 0.0168, 0.0120,\n",
            "        0.0077, 0.0047, 0.0076, 0.0106], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [60]\n",
            "DEBUGGING: logits looks like: tensor([289.8430, 289.2554, 289.6234, 289.9695, 290.0138, 290.2114, 289.7384,\n",
            "        289.7247, 289.9472, 289.9901, 288.8207, 289.5602, 289.9224, 289.1484,\n",
            "        289.7862, 289.4966, 289.8395, 289.7673, 289.4732, 289.6721, 289.5806,\n",
            "        289.5400, 289.6416, 289.6230, 289.7681, 289.3987, 289.5769, 289.7093,\n",
            "        290.3651, 290.2317, 289.3794, 289.6871, 289.7166, 290.0241, 290.0431,\n",
            "        289.5435, 290.0871, 289.8392, 289.7782, 289.6143, 289.7464, 290.0083,\n",
            "        289.9813, 289.9327, 289.9276, 288.9899, 289.9585, 289.7983, 289.8044,\n",
            "        289.7952, 289.9683, 289.8553, 290.2288, 289.8085, 289.5716, 289.6328,\n",
            "        290.0069, 289.9391, 290.2225, 289.9637, 289.7403, 289.2591, 289.6614,\n",
            "        289.8420, 289.5555, 289.5310, 289.6222, 289.8808, 289.5820, 289.7130,\n",
            "        290.0293, 289.1273, 290.0768, 289.6174, 289.9953, 289.8337, 289.9669,\n",
            "        289.6451, 289.9044, 289.9803, 289.8783, 289.1532, 289.6623, 289.3116,\n",
            "        289.0458, 289.9529, 289.8344, 289.5461, 289.7690, 289.7297, 289.9430,\n",
            "        289.9221, 289.9217, 289.9414, 289.1587, 289.4326, 289.5945, 290.0844,\n",
            "        289.9175, 289.6959, 289.4452, 289.6888, 289.8531],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.886741328989956 and immediate abs rewards look like: [0.004442844588083972, 0.004651945139357849, 0.02913625602832326, 0.0024509241466148524, 0.0002833660696524021, 0.8457759930006432, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 4.547473508864641e-13, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 9.094947017729282e-13, 9.094947017729282e-13, 0.0, 0.0, 0.0, 9.094947017729282e-13, 9.094947017729282e-13, 0.0, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 9.094947017729282e-13, 9.094947017729282e-13, 0.0, 9.094947017729282e-13, 0.0, 1.3642420526593924e-12, 9.094947017729282e-13]\n",
            "DEBUGGING: the total relative reward of the trajectory = 18.223055640674563 and immediate relative rewards look like: [0.01539051851821125, 0.0322794128683109, 0.30375088424826446, 0.03441692538103739, 0.004978217842669442, 17.832239679037563, 1.5916157281026244e-11, 1.818989403545443e-11, 2.0463630789890885e-11, 4.547473508863607e-11, 2.5011104298761213e-11, 2.7284841053187847e-11, 0.0, 0.0, 0.0, 3.637978807090886e-11, 0.0, 0.0, 0.0, 4.547473508864641e-11, 4.7748471843067876e-11, 0.0, 5.2295945351943374e-11, 5.4569682106363287e-11, 0.0, 0.0, 0.0, 0.0, 1.318767317570746e-10, 1.3642420526600127e-10, 0.0, 0.0, 0.0, 1.546140993013978e-10, 1.5916157281033482e-10, 0.0, 8.412825991399586e-11, 1.7280399333681707e-10, 8.867573342288067e-11, 9.094947017729282e-11, 9.322320693170395e-11, 0.0, 9.777068044058979e-11, 2.000888343900897e-10, 2.0463630789886232e-10, 0.0, 2.1373125491668673e-10, 0.0, 3.3423930290147513e-10, 2.2737367544333546e-10]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 200 number of matrices\n",
            "DEBUGGING: ACT_MAT has 200 number of matrices\n",
            "DEBUGGING: VAL looks like: [[8.880438135616107, 8.915037872063598, 8.90939146166952, 8.89859867395328, 8.601767540350194, 8.920611301184305e-10, 8.918850334350476e-10, 8.687401200737227e-10, 8.530170990166144e-10, 8.478532105959782e-10, 8.564173844403821e-10, 8.65068065091295e-10, 8.738061263548435e-10, 8.826324508634783e-10, 8.701120281031413e-10, 8.329669626408969e-10, 8.413807703443404e-10, 8.238502563576881e-10, 8.046115306106064e-10, 8.127389198086934e-10, 8.209484038471651e-10, 7.649331057808785e-10, 7.389747138544102e-10, 7.464391049034447e-10, 7.539788938418633e-10, 7.233164457252439e-10, 7.306226724497413e-10, 7.380026994441831e-10, 7.454572721658415e-10, 7.085842036163198e-10, 7.157416198144645e-10, 7.229713331459237e-10, 7.302740738847714e-10, 6.871230962497579e-10, 6.420051142922062e-10, 5.413105041266309e-10, 4.916573959800391e-10, 4.3997160542494946e-10, 3.8623260031582223e-10, 3.304196411116898e-10, 3.337572132441311e-10, 3.3712849822639504e-10, 3.405338365923182e-10, 3.4397357231547296e-10, 3.4744805284391206e-10, 2.820565153645883e-10, 1.4404107181082643e-10, 7.353264663834124e-11, 7.427540064478913e-11, 0.0], [37.36749647689339, 37.72337568032654, 38.08395468870232, 38.447511722703425, 38.829411208838074, 39.22116160536684, 39.573769649471366, 39.96184564777507, 40.35114210453496, 40.75364959664429, 41.14865729825071, 41.52088758263557, 41.91626645262463, 42.27869454610034, 42.695137682203274, 43.05074813556597, 43.42548439630365, 1.5781476506808828e-09, 1.5940885360412957e-09, 1.6101904404457533e-09, 1.5805209145021178e-09, 1.5964857722243614e-09, 1.6126118911357186e-09, 1.6289009001370896e-09, 1.6453544445829187e-09, 1.6619741864473927e-09, 1.619047505891063e-09, 1.4493685139212999e-09, 1.2710854813625234e-09, 1.217320318670708e-09, 1.1607153697350894e-09, 1.1724397674091811e-09, 1.1107880719872023e-09, 1.1220081535224266e-09, 9.771657113343726e-10, 8.262668065899371e-10, 7.519315994246198e-10, 6.745488277885284e-10, 6.813624523116448e-10, 5.986734534230144e-10, 5.128525083289909e-10, 5.180328366959503e-10, 5.232654916120711e-10, 5.285510016283546e-10, 5.338899006347015e-10, 5.392827279138399e-10, 5.447300281957979e-10, 4.4228727347220086e-10, 3.3651303965603463e-10, 2.2737367544328376e-10], [42.39180786605562, 42.78270053603825, 43.20148131388701, 43.611810372389705, 44.044175867764494, 44.46674674796734, 44.881361542201375, 45.245365776121034, 45.69767990444571, 46.15919700378554, 46.617855433587046, 47.08292933224706, 47.54329759386967, 48.02267618859193, 48.50576520486538, 48.93581107005036, 49.4019970392612, 49.78345320800148, 50.27795094101347, 50.785267914717224, 1.224904576261551e-09, 1.2372773497591425e-09, 1.2497751007668106e-09, 1.2623990916836471e-09, 1.2751505976602496e-09, 1.1731957171097309e-09, 1.125331880297438e-09, 1.0746878665936884e-09, 1.0855432995895842e-09, 1.0965083834238223e-09, 1.1075842256806287e-09, 1.1187719451319483e-09, 1.0565781504950646e-09, 9.914594319179605e-10, 1.0014741736545055e-09, 1.0115900743984904e-09, 1.0218081559580712e-09, 9.471514101455307e-10, 8.694438519970534e-10, 8.782261131283368e-10, 8.87097083968017e-10, 8.018928050871635e-10, 7.135311731323074e-10, 6.219802956481996e-10, 6.282629248971714e-10, 5.312573443916097e-10, 4.3097520574517474e-10, 2.1943833417028808e-10, 1.1141310096718371e-10, 0.0], [17.34151264750865, 17.501133463626708, 17.64530712197818, 17.516723472454462, 17.658895502094367, 17.832239681062322, 2.0452119955478542e-09, 2.049793776027099e-09, 2.052125133324894e-09, 2.0521833358939423e-09, 2.0269783846518245e-09, 2.022189172073801e-09, 2.0150548798188013e-09, 2.0354089695139407e-09, 2.0559686560746877e-09, 2.0767360162370583e-09, 2.0609658870365145e-09, 2.0817837242793075e-09, 2.1028118427063712e-09, 2.124052366370072e-09, 2.099573364930733e-09, 2.0725503970582475e-09, 2.0934852495537854e-09, 2.0618073779816585e-09, 2.0275128241164597e-09, 2.0479927516327877e-09, 2.068679547103826e-09, 2.0895753001048744e-09, 2.110682121318055e-09, 1.9987933227888694e-09, 1.881180926790776e-09, 1.900182754334117e-09, 1.919376519529411e-09, 1.9387641611408193e-09, 1.8021717796357794e-09, 1.659606269520651e-09, 1.6763699692127788e-09, 1.6083249588876595e-09, 1.4500211773240833e-09, 1.3750964079810129e-09, 1.2971181189936567e-09, 1.2160554667292453e-09, 1.228338855282066e-09, 1.1419880553954306e-09, 9.514133545508495e-10, 7.543202491434213e-10, 7.619396455994154e-10, 5.537458491744734e-10, 5.593392415903772e-10, 2.2737367544333546e-10]]\n",
            "DEBUGGING: traj_returns = [8.880438135616107, 37.36749647689339, 42.39180786605562, 17.34151264750865]\n",
            "DEBUGGING: actions = [[13], [9], [20], [28], [0], [59], [16], [42], [18], [9], [1], [9], [44], [52], [22], [40], [59], [1], [63], [74], [40], [31], [41], [80], [41], [17], [69], [58], [57], [0], [57], [38], [33], [64], [25], [14], [48], [79], [6], [18], [90], [26], [70], [99], [42], [85], [22], [55], [6], [88], [4], [42], [25], [56], [26], [1], [26], [3], [1], [4], [32], [45], [53], [70], [71], [31], [0], [59], [25], [52], [23], [44], [5], [66], [46], [78], [76], [43], [50], [76], [45], [31], [6], [18], [60], [40], [19], [1], [14], [96], [66], [85], [68], [45], [31], [48], [47], [53], [100], [20], [47], [27], [4], [1], [34], [45], [65], [17], [40], [48], [3], [62], [63], [66], [21], [65], [12], [58], [6], [0], [36], [57], [56], [69], [19], [15], [80], [52], [43], [31], [39], [14], [17], [14], [57], [42], [63], [90], [85], [23], [4], [72], [99], [75], [38], [85], [0], [51], [43], [14], [2], [44], [5], [46], [7], [0], [9], [34], [44], [30], [17], [37], [39], [32], [67], [41], [10], [12], [59], [2], [21], [79], [3], [4], [21], [55], [51], [23], [19], [47], [1], [83], [71], [28], [13], [42], [66], [8], [72], [41], [34], [30], [62], [26], [50], [70], [30], [21], [64], [60]]\n",
            "DEBUGGING: actions length = 200\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[ 5.9828,  5.4737,  5.0736,  ..., -4.2006, -4.6593, -6.9834],\n",
            "        [ 5.9439,  5.4139,  5.0411,  ..., -4.1568, -4.6210, -6.9231],\n",
            "        [ 5.8719,  5.3762,  4.9677,  ..., -4.1053, -4.5533, -6.8420],\n",
            "        ...,\n",
            "        [ 5.9800,  5.4694,  5.0675,  ..., -4.1985, -4.6521, -6.9784],\n",
            "        [ 5.9808,  5.4697,  5.0682,  ..., -4.1981, -4.6519, -6.9784],\n",
            "        [ 5.9795,  5.4688,  5.0669,  ..., -4.1970, -4.6510, -6.9769]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[ 5.9798,  5.4681,  5.0668,  ..., -4.1970, -4.6507, -6.9772],\n",
            "        [ 5.9691,  5.4570,  5.0583,  ..., -4.1868, -4.6405, -6.9623],\n",
            "        [ 5.9761,  5.4641,  5.0641,  ..., -4.1929, -4.6467, -6.9712],\n",
            "        ...,\n",
            "        [ 5.9722,  5.4607,  5.0600,  ..., -4.1909, -4.6436, -6.9676],\n",
            "        [ 5.9769,  5.4652,  5.0644,  ..., -4.1946, -4.6478, -6.9734],\n",
            "        [ 5.9804,  5.4680,  5.0675,  ..., -4.1968, -4.6509, -6.9772]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([289.8430, 289.2554, 289.6234, 289.9695, 290.0138, 290.2114, 289.7384,\n",
            "        289.7247, 289.9472, 289.9901, 288.8207, 289.5602, 289.9224, 289.1484,\n",
            "        289.7862, 289.4966, 289.8395, 289.7673, 289.4732, 289.6721, 289.5806,\n",
            "        289.5400, 289.6416, 289.6230, 289.7681, 289.3987, 289.5769, 289.7093,\n",
            "        290.3651, 290.2317, 289.3794, 289.6871, 289.7166, 290.0241, 290.0431,\n",
            "        289.5435, 290.0871, 289.8392, 289.7782, 289.6143, 289.7464, 290.0083,\n",
            "        289.9813, 289.9327, 289.9276, 288.9899, 289.9585, 289.7983, 289.8044,\n",
            "        289.7952, 289.9683, 289.8553, 290.2288, 289.8085, 289.5716, 289.6328,\n",
            "        290.0069, 289.9391, 290.2225, 289.9637, 289.7403, 289.2591, 289.6614,\n",
            "        289.8420, 289.5555, 289.5310, 289.6222, 289.8808, 289.5820, 289.7130,\n",
            "        290.0293, 289.1273, 290.0768, 289.6174, 289.9953, 289.8337, 289.9669,\n",
            "        289.6451, 289.9044, 289.9803, 289.8783, 289.1532, 289.6623, 289.3116,\n",
            "        289.0458, 289.9529, 289.8344, 289.5461, 289.7690, 289.7297, 289.9430,\n",
            "        289.9221, 289.9217, 289.9414, 289.1587, 289.4326, 289.5945, 290.0844,\n",
            "        289.9175, 289.6959, 289.4452, 289.6888, 289.8531],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[2.64953138e+01 2.67305619e+01 2.69600336e+01 2.71186611e+01\n",
            "  2.72835625e+01 2.53800370e+01 2.11137828e+01 2.13018029e+01\n",
            "  2.15122055e+01 2.17282117e+01 2.19416282e+01 2.21509542e+01\n",
            "  2.23648910e+01 2.25753427e+01 2.28002257e+01 2.29966398e+01\n",
            "  2.32068704e+01 1.24458633e+01 1.25694877e+01 1.26963170e+01\n",
            "  1.43148681e-09 1.41781166e-09 1.42371174e-09 1.42488662e-09\n",
            "  1.42549919e-09 1.40161978e-09 1.38592040e-09 1.33790860e-09\n",
            "  1.30319204e-09 1.25530156e-09 1.21630554e-09 1.22859145e-09\n",
            "  1.20425420e-09 1.18483871e-09 1.10570419e-09 1.00969341e-09\n",
            "  9.85441780e-10 9.17499201e-10 8.46765020e-10 7.95603904e-10\n",
            "  7.57706231e-10 7.18277402e-10 7.01417339e-10 6.59123231e-10\n",
            "  6.15253558e-10 5.26729209e-10 4.70421488e-10 3.22251026e-10\n",
            "  2.70385196e-10 1.13686838e-10]]\n",
            "DEBUGGING: baseline2 looks like: 26.495313781518444\n",
            "DEBUGGING: ADS looks like: [-1.76148756e+01 -1.78155240e+01 -1.80506422e+01 -1.82200624e+01\n",
            " -1.86817950e+01 -2.53800370e+01 -2.11137828e+01 -2.13018029e+01\n",
            " -2.15122055e+01 -2.17282116e+01 -2.19416282e+01 -2.21509542e+01\n",
            " -2.23648910e+01 -2.25753427e+01 -2.28002257e+01 -2.29966398e+01\n",
            " -2.32068704e+01 -1.24458633e+01 -1.25694877e+01 -1.26963170e+01\n",
            " -6.10538411e-10 -6.52878550e-10 -6.84737025e-10 -6.78447514e-10\n",
            " -6.71520296e-10 -6.78303330e-10 -6.55297729e-10 -5.99905896e-10\n",
            " -5.57734771e-10 -5.46717354e-10 -5.00563916e-10 -5.05620117e-10\n",
            " -4.73980130e-10 -4.97715614e-10 -4.63699080e-10 -4.68382910e-10\n",
            " -4.93784384e-10 -4.77527595e-10 -4.60532420e-10 -4.65184263e-10\n",
            " -4.23949018e-10 -3.81148903e-10 -3.60883503e-10 -3.15149659e-10\n",
            " -2.67805505e-10 -2.44672694e-10 -3.26380416e-10 -2.48718379e-10\n",
            " -1.96109795e-10 -1.13686838e-10  1.08721827e+01  1.09928138e+01\n",
            "  1.11239210e+01  1.13288507e+01  1.15458487e+01  1.38411246e+01\n",
            "  1.84599869e+01  1.86600428e+01  1.88389366e+01  1.90254379e+01\n",
            "  1.92070291e+01  1.93699334e+01  1.95513754e+01  1.97033519e+01\n",
            "  1.98949120e+01  2.00541083e+01  2.02186140e+01 -1.24458633e+01\n",
            " -1.25694877e+01 -1.26963170e+01  1.49034100e-10  1.78674116e-10\n",
            "  1.88900152e-10  2.04014281e-10  2.19855255e-10  2.60354411e-10\n",
            "  2.33127104e-10  1.11459919e-10 -3.21065622e-11 -3.79812385e-11\n",
            " -5.55901658e-11 -5.61516826e-11 -9.34661320e-11 -6.28305572e-11\n",
            " -1.28538483e-10 -1.83426607e-10 -2.33510181e-10 -2.42950373e-10\n",
            " -1.65402568e-10 -1.96930450e-10 -2.44853723e-10 -2.00244565e-10\n",
            " -1.78151848e-10 -1.30572230e-10 -8.13636576e-11  1.25535187e-11\n",
            "  7.43085404e-11  1.20036248e-10  6.61278439e-11  1.13686838e-10\n",
            "  1.58964941e+01  1.60521386e+01  1.62414477e+01  1.64931493e+01\n",
            "  1.67606133e+01  1.90867097e+01  2.37675787e+01  2.39435629e+01\n",
            "  2.41854744e+01  2.44309854e+01  2.46762272e+01  2.49319751e+01\n",
            "  2.51784066e+01  2.54473335e+01  2.57055395e+01  2.59391713e+01\n",
            "  2.61951267e+01  3.73375899e+01  3.77084632e+01  3.80889509e+01\n",
            " -2.06582239e-10 -1.80534306e-10 -1.73936638e-10 -1.62487527e-10\n",
            " -1.50348592e-10 -2.28424058e-10 -2.60588521e-10 -2.63220728e-10\n",
            " -2.17648744e-10 -1.58793174e-10 -1.08721310e-10 -1.09819505e-10\n",
            " -1.47676053e-10 -1.93379279e-10 -1.04230021e-10  1.89666074e-12\n",
            "  3.63663758e-11  2.96522096e-11  2.26788315e-11  8.26222092e-11\n",
            "  1.29390853e-10  8.36154034e-11  1.21138340e-11 -3.71429356e-11\n",
            "  1.30093667e-11  4.52813519e-12 -3.94462821e-11 -1.02812692e-10\n",
            " -1.58972095e-10 -1.13686838e-10 -9.15380113e+00 -9.22942842e+00\n",
            " -9.31472652e+00 -9.60193759e+00 -9.62466703e+00 -7.54779733e+00\n",
            " -2.11137828e+01 -2.13018029e+01 -2.15122055e+01 -2.17282116e+01\n",
            " -2.19416282e+01 -2.21509542e+01 -2.23648910e+01 -2.25753427e+01\n",
            " -2.28002257e+01 -2.29966398e+01 -2.32068704e+01 -1.24458633e+01\n",
            " -1.25694877e+01 -1.26963170e+01  6.68086550e-10  6.54738741e-10\n",
            "  6.69773511e-10  6.36920759e-10  6.02013634e-10  6.46372976e-10\n",
            "  6.82759146e-10  7.51666705e-10  8.07490078e-10  7.43491766e-10\n",
            "  6.64875391e-10  6.71591304e-10  7.15122316e-10  7.53925450e-10\n",
            "  6.96467585e-10  6.49912856e-10  6.90928189e-10  6.90825758e-10\n",
            "  6.03256157e-10  5.79492504e-10  5.39411888e-10  4.97778065e-10\n",
            "  5.26921516e-10  4.82864824e-10  3.36159796e-10  2.27591040e-10\n",
            "  2.91518158e-10  2.31494823e-10  2.88954046e-10  1.13686838e-10]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(0.5878, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.0463,  0.0400, -0.0258,  ...,  0.0587,  0.0116,  0.6820],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0610,  0.0526, -0.0339,  ...,  0.0773,  0.0153,  0.8997],\n",
            "        [ 0.0329,  0.0284, -0.0183,  ...,  0.0417,  0.0082,  0.4837]])\n",
            "   Last layer:\n",
            "tensor([[ 0.2139,  0.0972,  0.0000,  0.2561,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2878,\n",
            "          0.0000,  0.2863,  0.3347,  0.0608],\n",
            "        [ 0.1970,  0.0896,  0.0000,  0.2359,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2650,\n",
            "          0.0000,  0.2636,  0.3081,  0.0560],\n",
            "        [ 0.1861,  0.0846,  0.0000,  0.2228,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2509,\n",
            "          0.0000,  0.2502,  0.2923,  0.0532],\n",
            "        [-0.0617, -0.0280,  0.0000, -0.0739,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0835,\n",
            "          0.0000, -0.0837, -0.0976, -0.0178],\n",
            "        [-0.0482, -0.0219,  0.0000, -0.0577,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0650,\n",
            "          0.0000, -0.0648, -0.0757, -0.0138],\n",
            "        [ 0.1727,  0.0785,  0.0000,  0.2068,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2330,\n",
            "          0.0000,  0.2326,  0.2716,  0.0494],\n",
            "        [-0.3452, -0.1569,  0.0000, -0.4132,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.4654,\n",
            "          0.0000, -0.4642, -0.5423, -0.0987],\n",
            "        [-0.1716, -0.0780,  0.0000, -0.2054,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2323,\n",
            "          0.0000, -0.2326, -0.2714, -0.0495],\n",
            "        [-0.1846, -0.0839,  0.0000, -0.2210,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2498,\n",
            "          0.0000, -0.2500, -0.2918, -0.0532],\n",
            "        [-0.2619, -0.1190,  0.0000, -0.3135,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.3532,\n",
            "          0.0000, -0.3523, -0.4115, -0.0749]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-0.1534, -0.1249, -0.0758,  ..., -0.1676, -0.1825,  1.1551],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.2040, -0.1661, -0.1008,  ..., -0.2228, -0.2426,  1.5423],\n",
            "        [-0.1019, -0.0830, -0.0504,  ..., -0.1113, -0.1212,  0.7599]])\n",
            "   Last layer:\n",
            "tensor([[ 0.3566,  0.1187,  0.0000,  0.4225,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.4507,\n",
            "          0.0000,  0.4582,  0.5471,  0.0868],\n",
            "        [ 0.3345,  0.1118,  0.0000,  0.3959,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.4248,\n",
            "          0.0000,  0.4327,  0.5166,  0.0825],\n",
            "        [ 0.3087,  0.1031,  0.0000,  0.3655,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3918,\n",
            "          0.0000,  0.3990,  0.4764,  0.0760],\n",
            "        [-0.0828, -0.0280,  0.0000, -0.0977,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1065,\n",
            "          0.0000, -0.1091, -0.1302, -0.0212],\n",
            "        [-0.0750, -0.0254,  0.0000, -0.0885,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0966,\n",
            "          0.0000, -0.0989, -0.1180, -0.0192],\n",
            "        [ 0.2809,  0.0943,  0.0000,  0.3321,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3583,\n",
            "          0.0000,  0.3657,  0.4366,  0.0702],\n",
            "        [-0.5887, -0.1976,  0.0000, -0.6961,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.7507,\n",
            "          0.0000, -0.7660, -0.9145, -0.1470],\n",
            "        [-0.2797, -0.0949,  0.0000, -0.3299,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.3607,\n",
            "          0.0000, -0.3698, -0.4413, -0.0721],\n",
            "        [-0.3120, -0.1060,  0.0000, -0.3679,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.4028,\n",
            "          0.0000, -0.4130, -0.4929, -0.0807],\n",
            "        [-0.4405, -0.1481,  0.0000, -0.5207,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.5628,\n",
            "          0.0000, -0.5746, -0.6860, -0.1106]])\n",
            "DEBUGGING: training for one iteration takes 0.004309 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 23\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([0.0047, 0.0171, 0.0188, 0.0320, 0.0102, 0.0106, 0.0134, 0.0082, 0.0142,\n",
            "        0.0126, 0.0089, 0.0080, 0.0190, 0.0215, 0.0182, 0.0215, 0.0177, 0.0104,\n",
            "        0.0073, 0.0057, 0.0140, 0.0151, 0.0061, 0.0078, 0.0212, 0.0130, 0.0200,\n",
            "        0.0162, 0.0189, 0.0210, 0.0207, 0.0076, 0.0034, 0.0225, 0.0134, 0.0374,\n",
            "        0.0127, 0.0170, 0.0073, 0.0208, 0.0198, 0.0213, 0.0100, 0.0238, 0.0105,\n",
            "        0.0120, 0.0087, 0.0148, 0.0095, 0.0084, 0.0303, 0.0194, 0.0135, 0.0047,\n",
            "        0.0136, 0.0221, 0.0108, 0.0290, 0.0036, 0.0198, 0.0115, 0.0301, 0.0085,\n",
            "        0.0057, 0.0083, 0.0125, 0.0146, 0.0075], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [0]\n",
            "DEBUGGING: logits looks like: tensor([147.5138, 148.1587, 148.2054, 148.4721, 147.8995, 147.9202, 148.0378,\n",
            "        147.7940, 148.0650, 148.0047, 147.8339, 147.7794, 148.2103, 148.2726,\n",
            "        148.1893, 148.2721, 148.1752, 147.9117, 147.7308, 147.6096, 148.0575,\n",
            "        148.0969, 147.6393, 147.7653, 148.2672, 148.0197, 148.2380, 148.1323,\n",
            "        148.2097, 148.2607, 148.2552, 147.7498, 147.3470, 148.2959, 148.0361,\n",
            "        148.5498, 148.0083, 148.1550, 147.7361, 148.2553, 148.2316, 148.2676,\n",
            "        147.8890, 148.3230, 147.9155, 147.9806, 147.8185, 148.0858, 147.8667,\n",
            "        147.8035, 148.4441, 148.2227, 148.0391, 147.5084, 148.0452, 148.2879,\n",
            "        147.9267, 148.4225, 147.3827, 148.2315, 147.9582, 148.4411, 147.8084,\n",
            "        147.6054, 147.7980, 148.0000, 148.0802, 147.7447],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0148, 0.0139, 0.0099, 0.0119, 0.0121, 0.0139, 0.0134, 0.0130, 0.0142,\n",
            "        0.0134, 0.0113, 0.0134, 0.0130, 0.0128, 0.0140, 0.0100, 0.0152, 0.0125,\n",
            "        0.0123, 0.0147, 0.0112, 0.0129, 0.0137, 0.0139, 0.0119, 0.0138, 0.0160,\n",
            "        0.0124, 0.0147, 0.0141, 0.0124, 0.0123, 0.0141, 0.0122, 0.0103, 0.0144,\n",
            "        0.0140, 0.0108, 0.0122, 0.0141, 0.0103, 0.0138, 0.0111, 0.0104, 0.0138,\n",
            "        0.0111, 0.0135, 0.0140, 0.0116, 0.0120, 0.0142, 0.0126, 0.0149, 0.0126,\n",
            "        0.0138, 0.0151, 0.0124, 0.0097, 0.0140, 0.0109, 0.0111, 0.0146, 0.0124,\n",
            "        0.0142, 0.0100, 0.0100, 0.0118, 0.0117, 0.0117, 0.0142, 0.0116, 0.0147,\n",
            "        0.0131, 0.0132, 0.0136, 0.0132, 0.0123, 0.0136],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [16]\n",
            "DEBUGGING: logits looks like: tensor([148.1562, 148.1272, 147.9547, 148.0469, 148.0573, 148.1264, 148.1061,\n",
            "        148.0921, 148.1353, 148.1087, 148.0245, 148.1089, 148.0936, 148.0838,\n",
            "        148.1304, 147.9604, 148.1722, 148.0712, 148.0658, 148.1535, 148.0196,\n",
            "        148.0901, 148.1176, 148.1255, 148.0501, 148.1212, 148.1960, 148.0700,\n",
            "        148.1542, 148.1318, 148.0701, 148.0654, 148.1327, 148.0594, 147.9781,\n",
            "        148.1446, 148.1294, 147.9976, 148.0616, 148.1314, 147.9749, 148.1223,\n",
            "        148.0126, 147.9786, 148.1232, 148.0114, 148.1129, 148.1312, 148.0356,\n",
            "        148.0533, 148.1367, 148.0769, 148.1591, 148.0750, 148.1229, 148.1686,\n",
            "        148.0701, 147.9462, 148.1294, 148.0021, 148.0127, 148.1500, 148.0680,\n",
            "        148.1382, 147.9595, 147.9631, 148.0459, 148.0388, 148.0382, 148.1368,\n",
            "        148.0338, 148.1544, 148.0976, 148.0992, 148.1134, 148.0989, 148.0661,\n",
            "        148.1161], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0114, 0.0096, 0.0120, 0.0103, 0.0114, 0.0125, 0.0123, 0.0117, 0.0125,\n",
            "        0.0035, 0.0151, 0.0118, 0.0128, 0.0142, 0.0118, 0.0071, 0.0096, 0.0117,\n",
            "        0.0118, 0.0097, 0.0122, 0.0123, 0.0119, 0.0125, 0.0089, 0.0134, 0.0128,\n",
            "        0.0099, 0.0124, 0.0122, 0.0148, 0.0074, 0.0117, 0.0100, 0.0126, 0.0112,\n",
            "        0.0171, 0.0104, 0.0110, 0.0119, 0.0125, 0.0121, 0.0085, 0.0046, 0.0111,\n",
            "        0.0118, 0.0084, 0.0110, 0.0129, 0.0142, 0.0034, 0.0122, 0.0122, 0.0123,\n",
            "        0.0098, 0.0187, 0.0103, 0.0168, 0.0173, 0.0093, 0.0147, 0.0090, 0.0099,\n",
            "        0.0157, 0.0098, 0.0101, 0.0144, 0.0124, 0.0141, 0.0147, 0.0123, 0.0084,\n",
            "        0.0075, 0.0119, 0.0135, 0.0107, 0.0087, 0.0139, 0.0088, 0.0093, 0.0117,\n",
            "        0.0070, 0.0127, 0.0119, 0.0158, 0.0079, 0.0146],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [14]\n",
            "DEBUGGING: logits looks like: tensor([148.0742, 147.9867, 148.0984, 148.0253, 148.0723, 148.1193, 148.1139,\n",
            "        148.0868, 148.1187, 147.4901, 148.2135, 148.0901, 148.1331, 148.1842,\n",
            "        148.0924, 147.8402, 147.9863, 148.0875, 148.0928, 147.9940, 148.1098,\n",
            "        148.1105, 148.0964, 148.1190, 147.9504, 148.1546, 148.1310, 148.0023,\n",
            "        148.1147, 148.1099, 148.2042, 147.8573, 148.0875, 148.0099, 148.1235,\n",
            "        148.0668, 148.2761, 148.0304, 148.0586, 148.0957, 148.1205, 148.1039,\n",
            "        147.9265, 147.6199, 148.0612, 148.0931, 147.9196, 148.0572, 148.1345,\n",
            "        148.1853, 147.4690, 148.1101, 148.1068, 148.1128, 147.9998, 148.3220,\n",
            "        148.0261, 148.2676, 148.2844, 147.9742, 148.2001, 147.9536, 148.0057,\n",
            "        148.2347, 148.0006, 148.0139, 148.1897, 148.1169, 148.1813, 148.2031,\n",
            "        148.1137, 147.9199, 147.8639, 148.0976, 148.1604, 148.0414, 147.9379,\n",
            "        148.1730, 147.9460, 147.9720, 148.0876, 147.8280, 148.1290, 148.0957,\n",
            "        148.2365, 147.8943, 148.1991], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0102, 0.0105, 0.0120, 0.0099, 0.0089, 0.0109, 0.0109, 0.0132, 0.0097,\n",
            "        0.0109, 0.0104, 0.0096, 0.0088, 0.0094, 0.0075, 0.0144, 0.0093, 0.0094,\n",
            "        0.0072, 0.0124, 0.0086, 0.0071, 0.0117, 0.0102, 0.0115, 0.0121, 0.0116,\n",
            "        0.0092, 0.0075, 0.0110, 0.0120, 0.0089, 0.0074, 0.0113, 0.0084, 0.0091,\n",
            "        0.0128, 0.0083, 0.0088, 0.0092, 0.0115, 0.0104, 0.0066, 0.0113, 0.0092,\n",
            "        0.0118, 0.0093, 0.0115, 0.0131, 0.0144, 0.0105, 0.0093, 0.0106, 0.0121,\n",
            "        0.0099, 0.0113, 0.0063, 0.0121, 0.0071, 0.0097, 0.0096, 0.0101, 0.0107,\n",
            "        0.0086, 0.0108, 0.0087, 0.0077, 0.0115, 0.0074, 0.0089, 0.0099, 0.0111,\n",
            "        0.0116, 0.0107, 0.0118, 0.0126, 0.0107, 0.0101, 0.0112, 0.0098, 0.0079,\n",
            "        0.0110, 0.0098, 0.0097, 0.0109, 0.0111, 0.0086, 0.0125, 0.0082, 0.0108,\n",
            "        0.0110, 0.0084, 0.0089, 0.0079, 0.0104, 0.0087, 0.0112, 0.0095, 0.0099],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [57]\n",
            "DEBUGGING: logits looks like: tensor([148.2394, 148.2550, 148.3214, 148.2282, 148.1750, 148.2749, 148.2728,\n",
            "        148.3714, 148.2157, 148.2724, 148.2494, 148.2112, 148.1662, 148.1998,\n",
            "        148.0900, 148.4126, 148.1939, 148.2017, 148.0679, 148.3400, 148.1567,\n",
            "        148.0595, 148.3095, 148.2395, 148.3013, 148.3262, 148.3070, 148.1905,\n",
            "        148.0843, 148.2780, 148.3227, 148.1707, 148.0802, 148.2922, 148.1426,\n",
            "        148.1826, 148.3557, 148.1384, 148.1651, 148.1882, 148.2994, 148.2496,\n",
            "        148.0206, 148.2927, 148.1892, 148.3140, 148.1927, 148.3020, 148.3654,\n",
            "        148.4138, 148.2559, 148.1947, 148.2620, 148.3251, 148.2264, 148.2916,\n",
            "        147.9979, 148.3247, 148.0584, 148.2145, 148.2095, 148.2380, 148.2641,\n",
            "        148.1542, 148.2712, 148.1584, 148.0974, 148.3029, 148.0780, 148.1705,\n",
            "        148.2244, 148.2850, 148.3061, 148.2664, 148.3129, 148.3463, 148.2663,\n",
            "        148.2361, 148.2854, 148.2191, 148.1144, 148.2764, 148.2218, 148.2140,\n",
            "        148.2756, 148.2846, 148.1579, 148.3409, 148.1311, 148.2689, 148.2792,\n",
            "        148.1421, 148.1729, 148.1106, 148.2507, 148.1584, 148.2895, 148.2059,\n",
            "        148.2233], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0096, 0.0098, 0.0107, 0.0076, 0.0095, 0.0102, 0.0096, 0.0059, 0.0092,\n",
            "        0.0098, 0.0112, 0.0097, 0.0107, 0.0110, 0.0092, 0.0073, 0.0095, 0.0099,\n",
            "        0.0092, 0.0089, 0.0065, 0.0097, 0.0101, 0.0100, 0.0100, 0.0097, 0.0068,\n",
            "        0.0101, 0.0090, 0.0111, 0.0090, 0.0098, 0.0114, 0.0121, 0.0083, 0.0098,\n",
            "        0.0094, 0.0082, 0.0088, 0.0105, 0.0081, 0.0031, 0.0108, 0.0098, 0.0065,\n",
            "        0.0112, 0.0095, 0.0090, 0.0100, 0.0027, 0.0099, 0.0103, 0.0099, 0.0093,\n",
            "        0.0140, 0.0087, 0.0147, 0.0082, 0.0070, 0.0071, 0.0089, 0.0108, 0.0107,\n",
            "        0.0058, 0.0090, 0.0094, 0.0103, 0.0105, 0.0098, 0.0107, 0.0092, 0.0099,\n",
            "        0.0104, 0.0088, 0.0076, 0.0074, 0.0105, 0.0097, 0.0088, 0.0102, 0.0101,\n",
            "        0.0090, 0.0094, 0.0103, 0.0098, 0.0089, 0.0108, 0.0086, 0.0080, 0.0103,\n",
            "        0.0086, 0.0043, 0.0089, 0.0078, 0.0098, 0.0106, 0.0103, 0.0108, 0.0094,\n",
            "        0.0098, 0.0092, 0.0096, 0.0102, 0.0099, 0.0098, 0.0094, 0.0094],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [66]\n",
            "DEBUGGING: logits looks like: tensor([148.1688, 148.1799, 148.2213, 148.0486, 148.1648, 148.1996, 148.1669,\n",
            "        147.9225, 148.1489, 148.1765, 148.2454, 148.1720, 148.2198, 148.2338,\n",
            "        148.1482, 148.0286, 148.1621, 148.1855, 148.1471, 148.1287, 147.9733,\n",
            "        148.1734, 148.1949, 148.1901, 148.1884, 148.1736, 147.9924, 148.1940,\n",
            "        148.1333, 148.2405, 148.1363, 148.1786, 148.2546, 148.2836, 148.0924,\n",
            "        148.1784, 148.1557, 148.0891, 148.1232, 148.2132, 148.0846, 147.6044,\n",
            "        148.2262, 148.1795, 147.9749, 148.2447, 148.1639, 148.1378, 148.1859,\n",
            "        147.5257, 148.1851, 148.2026, 148.1856, 148.1520, 148.3550, 148.1211,\n",
            "        148.3802, 148.0912, 148.0102, 148.0199, 148.1327, 148.2286, 148.2202,\n",
            "        147.9177, 148.1364, 148.1581, 148.2007, 148.2128, 148.1793, 148.2203,\n",
            "        148.1443, 148.1839, 148.2080, 148.1225, 148.0515, 148.0386, 148.2108,\n",
            "        148.1750, 148.1233, 148.1959, 148.1930, 148.1369, 148.1568, 148.2029,\n",
            "        148.1770, 148.1314, 148.2253, 148.1146, 148.0750, 148.2042, 148.1114,\n",
            "        147.7654, 148.1294, 148.0620, 148.1799, 148.2189, 148.2052, 148.2271,\n",
            "        148.1560, 148.1762, 148.1445, 148.1667, 148.1966, 148.1833, 148.1761,\n",
            "        148.1573, 148.1575], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.6072478073144794 and immediate abs rewards look like: [0.034180376574113325, 0.01236382725551266, 0.5607036034734847, 2.2737367544323206e-13, 0.0, 2.2737367544323206e-13, 2.2737367544323206e-13, 2.2737367544323206e-13, 0.0, 2.2737367544323206e-13, 0.0, 2.2737367544323206e-13, 0.0, 0.0, 2.2737367544323206e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 2.2737367544323206e-13, 0.0, 2.2737367544323206e-13, 0.0, 0.0, 2.2737367544323206e-13, 2.2737367544323206e-13, 6.821210263296962e-13, 0.0, 2.2737367544323206e-13, 0.0, 4.547473508864641e-13, 2.2737367544323206e-13, 0.0, 2.2737367544323206e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 6.821210263296962e-13, 6.821210263296962e-13, 4.547473508864641e-13, 4.547473508864641e-13, 2.2737367544323206e-13, 4.547473508864641e-13, 0.0, 2.2737367544323206e-13, 2.2737367544323206e-13]\n",
            "DEBUGGING: the total relative reward of the trajectory = 4.88805708852098 and immediate relative rewards look like: [0.09475472271384545, 0.06920567548869416, 4.7240966891474665, 3.0316490059097605e-12, 0.0, 4.547473508864297e-12, 5.305385760342081e-12, 6.063298011819981e-12, 0.0, 7.579122514775551e-12, 0.0, 9.09494701772997e-12, 0.0, 0.0, 1.1368683772161601e-11, 2.4253192047279923e-11, 2.5769016550231014e-11, 2.7284841053189912e-11, 0.0, 3.031649005909531e-11, 0.0, 1.6674069532504947e-11, 0.0, 1.8189894035458565e-11, 0.0, 0.0, 2.0463630789892436e-11, 2.1221543041368324e-11, 6.593836587854229e-11, 0.0, 2.3495279795797084e-11, 0.0, 5.0022208597507266e-11, 2.5769016550234917e-11, 0.0, 2.7284841053187844e-11, 5.608550660933482e-11, 0.0, 5.911715561523585e-11, 6.063298011818143e-11, 6.214880462114539e-11, 9.549694368616469e-11, 9.777068044057497e-11, 6.669627813001979e-11, 6.821210263296445e-11, 3.486396356796489e-11, 7.124375163887937e-11, 0.0, 3.713770032238894e-11, 3.789561257386914e-11]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([0.0357, 0.0122, 0.0121, 0.0097, 0.0176, 0.0137, 0.0137, 0.0149, 0.0124,\n",
            "        0.0089, 0.0103, 0.0143, 0.0220, 0.0125, 0.0100, 0.0155, 0.0168, 0.0127,\n",
            "        0.0165, 0.0137, 0.0155, 0.0143, 0.0125, 0.0161, 0.0106, 0.0146, 0.0127,\n",
            "        0.0158, 0.0123, 0.0153, 0.0150, 0.0159, 0.0157, 0.0129, 0.0145, 0.0140,\n",
            "        0.0135, 0.0150, 0.0136, 0.0134, 0.0109, 0.0110, 0.0123, 0.0148, 0.0130,\n",
            "        0.0155, 0.0150, 0.0160, 0.0176, 0.0133, 0.0173, 0.0141, 0.0209, 0.0132,\n",
            "        0.0172, 0.0155, 0.0169, 0.0176, 0.0130, 0.0139, 0.0117, 0.0185, 0.0150,\n",
            "        0.0173, 0.0144, 0.0150, 0.0169, 0.0138], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [7]\n",
            "DEBUGGING: logits looks like: tensor([148.1685, 147.6332, 147.6285, 147.5152, 147.8143, 147.6909, 147.6906,\n",
            "        147.7324, 147.6396, 147.4727, 147.5457, 147.7099, 147.9270, 147.6438,\n",
            "        147.5302, 147.7517, 147.7930, 147.6532, 147.7813, 147.6883, 147.7518,\n",
            "        147.7117, 147.6418, 147.7697, 147.5605, 147.7201, 147.6527, 147.7597,\n",
            "        147.6366, 147.7446, 147.7352, 147.7654, 147.7580, 147.6584, 147.7162,\n",
            "        147.7014, 147.6807, 147.7359, 147.6860, 147.6776, 147.5770, 147.5803,\n",
            "        147.6345, 147.7282, 147.6622, 147.7519, 147.7352, 147.7670, 147.8143,\n",
            "        147.6742, 147.8055, 147.7034, 147.9003, 147.6724, 147.8033, 147.7523,\n",
            "        147.7957, 147.8158, 147.6644, 147.6960, 147.6105, 147.8394, 147.7340,\n",
            "        147.8062, 147.7156, 147.7338, 147.7951, 147.6929],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0370, 0.0125, 0.0139, 0.0130, 0.0136, 0.0132, 0.0118, 0.0107, 0.0115,\n",
            "        0.0132, 0.0126, 0.0118, 0.0119, 0.0115, 0.0119, 0.0118, 0.0129, 0.0129,\n",
            "        0.0153, 0.0122, 0.0110, 0.0109, 0.0126, 0.0118, 0.0133, 0.0128, 0.0119,\n",
            "        0.0121, 0.0121, 0.0128, 0.0129, 0.0120, 0.0139, 0.0120, 0.0122, 0.0120,\n",
            "        0.0116, 0.0132, 0.0129, 0.0134, 0.0112, 0.0117, 0.0107, 0.0093, 0.0138,\n",
            "        0.0143, 0.0123, 0.0129, 0.0115, 0.0130, 0.0123, 0.0128, 0.0117, 0.0124,\n",
            "        0.0118, 0.0134, 0.0129, 0.0126, 0.0129, 0.0122, 0.0130, 0.0133, 0.0107,\n",
            "        0.0130, 0.0135, 0.0124, 0.0141, 0.0137, 0.0128, 0.0121, 0.0117, 0.0062,\n",
            "        0.0106, 0.0136, 0.0127, 0.0113, 0.0128, 0.0116, 0.0126],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [13]\n",
            "DEBUGGING: logits looks like: tensor([148.1922, 147.6471, 147.7040, 147.6682, 147.6919, 147.6774, 147.6223,\n",
            "        147.5703, 147.6071, 147.6751, 147.6541, 147.6216, 147.6238, 147.6094,\n",
            "        147.6257, 147.6213, 147.6667, 147.6642, 147.7490, 147.6373, 147.5831,\n",
            "        147.5812, 147.6521, 147.6194, 147.6810, 147.6599, 147.6262, 147.6320,\n",
            "        147.6309, 147.6598, 147.6655, 147.6292, 147.7011, 147.6293, 147.6368,\n",
            "        147.6286, 147.6104, 147.6745, 147.6634, 147.6845, 147.5935, 147.6157,\n",
            "        147.5716, 147.5006, 147.6979, 147.7162, 147.6406, 147.6656, 147.6091,\n",
            "        147.6683, 147.6392, 147.6613, 147.6164, 147.6464, 147.6210, 147.6832,\n",
            "        147.6660, 147.6538, 147.6633, 147.6357, 147.6703, 147.6788, 147.5697,\n",
            "        147.6698, 147.6874, 147.6456, 147.7098, 147.6957, 147.6603, 147.6332,\n",
            "        147.6144, 147.3011, 147.5665, 147.6920, 147.6566, 147.5991, 147.6612,\n",
            "        147.6116, 147.6541], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0344, 0.0108, 0.0109, 0.0109, 0.0110, 0.0108, 0.0111, 0.0110, 0.0109,\n",
            "        0.0108, 0.0110, 0.0109, 0.0112, 0.0112, 0.0111, 0.0109, 0.0110, 0.0109,\n",
            "        0.0107, 0.0109, 0.0111, 0.0109, 0.0110, 0.0109, 0.0111, 0.0111, 0.0108,\n",
            "        0.0108, 0.0109, 0.0112, 0.0109, 0.0111, 0.0111, 0.0105, 0.0109, 0.0109,\n",
            "        0.0109, 0.0111, 0.0110, 0.0111, 0.0109, 0.0108, 0.0109, 0.0104, 0.0111,\n",
            "        0.0109, 0.0109, 0.0109, 0.0110, 0.0110, 0.0113, 0.0110, 0.0110, 0.0108,\n",
            "        0.0110, 0.0109, 0.0111, 0.0109, 0.0114, 0.0107, 0.0111, 0.0109, 0.0108,\n",
            "        0.0109, 0.0112, 0.0111, 0.0111, 0.0110, 0.0108, 0.0110, 0.0111, 0.0111,\n",
            "        0.0108, 0.0120, 0.0110, 0.0109, 0.0110, 0.0111, 0.0112, 0.0108, 0.0110,\n",
            "        0.0110, 0.0110, 0.0106, 0.0108, 0.0109, 0.0111, 0.0112, 0.0112],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [3]\n",
            "DEBUGGING: logits looks like: tensor([148.1486, 147.5693, 147.5725, 147.5745, 147.5767, 147.5676, 147.5833,\n",
            "        147.5773, 147.5756, 147.5670, 147.5772, 147.5727, 147.5891, 147.5851,\n",
            "        147.5813, 147.5721, 147.5763, 147.5741, 147.5639, 147.5729, 147.5821,\n",
            "        147.5743, 147.5792, 147.5741, 147.5831, 147.5828, 147.5675, 147.5708,\n",
            "        147.5731, 147.5861, 147.5714, 147.5805, 147.5817, 147.5541, 147.5720,\n",
            "        147.5724, 147.5746, 147.5815, 147.5786, 147.5829, 147.5750, 147.5677,\n",
            "        147.5743, 147.5525, 147.5836, 147.5722, 147.5758, 147.5742, 147.5787,\n",
            "        147.5781, 147.5896, 147.5799, 147.5803, 147.5712, 147.5795, 147.5721,\n",
            "        147.5844, 147.5748, 147.5948, 147.5643, 147.5825, 147.5729, 147.5710,\n",
            "        147.5717, 147.5892, 147.5813, 147.5840, 147.5779, 147.5687, 147.5778,\n",
            "        147.5848, 147.5829, 147.5690, 147.6201, 147.5760, 147.5744, 147.5761,\n",
            "        147.5828, 147.5882, 147.5694, 147.5766, 147.5762, 147.5801, 147.5586,\n",
            "        147.5690, 147.5746, 147.5806, 147.5860, 147.5862],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0307, 0.0101, 0.0100, 0.0099, 0.0092, 0.0100, 0.0104, 0.0100, 0.0100,\n",
            "        0.0100, 0.0101, 0.0099, 0.0096, 0.0102, 0.0098, 0.0100, 0.0096, 0.0101,\n",
            "        0.0098, 0.0097, 0.0104, 0.0100, 0.0103, 0.0098, 0.0103, 0.0100, 0.0100,\n",
            "        0.0100, 0.0100, 0.0098, 0.0103, 0.0102, 0.0099, 0.0102, 0.0098, 0.0098,\n",
            "        0.0100, 0.0100, 0.0103, 0.0098, 0.0099, 0.0097, 0.0101, 0.0102, 0.0102,\n",
            "        0.0097, 0.0100, 0.0097, 0.0098, 0.0097, 0.0102, 0.0104, 0.0096, 0.0098,\n",
            "        0.0101, 0.0103, 0.0101, 0.0100, 0.0105, 0.0102, 0.0099, 0.0103, 0.0094,\n",
            "        0.0105, 0.0104, 0.0098, 0.0104, 0.0101, 0.0101, 0.0101, 0.0101, 0.0099,\n",
            "        0.0100, 0.0104, 0.0101, 0.0099, 0.0095, 0.0093, 0.0100, 0.0098, 0.0099,\n",
            "        0.0100, 0.0099, 0.0098, 0.0101, 0.0104, 0.0100, 0.0101, 0.0098, 0.0101,\n",
            "        0.0097, 0.0103, 0.0101, 0.0100, 0.0100, 0.0102, 0.0101, 0.0097],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [94]\n",
            "DEBUGGING: logits looks like: tensor([148.1137, 147.5563, 147.5536, 147.5494, 147.5110, 147.5559, 147.5716,\n",
            "        147.5522, 147.5515, 147.5543, 147.5603, 147.5495, 147.5306, 147.5649,\n",
            "        147.5423, 147.5515, 147.5343, 147.5572, 147.5453, 147.5382, 147.5737,\n",
            "        147.5549, 147.5679, 147.5412, 147.5672, 147.5548, 147.5516, 147.5558,\n",
            "        147.5549, 147.5450, 147.5662, 147.5613, 147.5475, 147.5623, 147.5426,\n",
            "        147.5445, 147.5515, 147.5520, 147.5664, 147.5441, 147.5468, 147.5361,\n",
            "        147.5592, 147.5613, 147.5632, 147.5408, 147.5537, 147.5388, 147.5445,\n",
            "        147.5398, 147.5618, 147.5724, 147.5352, 147.5417, 147.5564, 147.5707,\n",
            "        147.5567, 147.5553, 147.5766, 147.5625, 147.5464, 147.5700, 147.5246,\n",
            "        147.5789, 147.5718, 147.5427, 147.5731, 147.5571, 147.5603, 147.5600,\n",
            "        147.5586, 147.5491, 147.5519, 147.5756, 147.5562, 147.5498, 147.5258,\n",
            "        147.5199, 147.5533, 147.5456, 147.5502, 147.5532, 147.5472, 147.5428,\n",
            "        147.5572, 147.5751, 147.5528, 147.5565, 147.5432, 147.5574, 147.5397,\n",
            "        147.5677, 147.5589, 147.5523, 147.5535, 147.5652, 147.5580, 147.5401],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0273, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0092, 0.0091, 0.0090,\n",
            "        0.0092, 0.0091, 0.0090, 0.0091, 0.0091, 0.0090, 0.0090, 0.0092, 0.0091,\n",
            "        0.0091, 0.0091, 0.0090, 0.0091, 0.0090, 0.0090, 0.0090, 0.0091, 0.0091,\n",
            "        0.0091, 0.0090, 0.0091, 0.0091, 0.0090, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0092, 0.0090, 0.0091, 0.0092, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0092, 0.0091, 0.0090, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0090, 0.0093, 0.0090, 0.0092, 0.0091, 0.0093, 0.0091, 0.0092, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0090, 0.0090, 0.0090, 0.0091,\n",
            "        0.0090, 0.0091, 0.0090, 0.0091, 0.0091, 0.0091, 0.0091, 0.0090, 0.0092,\n",
            "        0.0090, 0.0091, 0.0091, 0.0090, 0.0091, 0.0091, 0.0090, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0090, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0090, 0.0091, 0.0095, 0.0091, 0.0091, 0.0090, 0.0090, 0.0092, 0.0091],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [97]\n",
            "DEBUGGING: logits looks like: tensor([148.0862, 147.5375, 147.5361, 147.5354, 147.5347, 147.5348, 147.5421,\n",
            "        147.5368, 147.5333, 147.5399, 147.5346, 147.5337, 147.5363, 147.5350,\n",
            "        147.5320, 147.5314, 147.5410, 147.5379, 147.5357, 147.5352, 147.5338,\n",
            "        147.5353, 147.5313, 147.5320, 147.5330, 147.5363, 147.5340, 147.5361,\n",
            "        147.5334, 147.5350, 147.5339, 147.5338, 147.5356, 147.5367, 147.5342,\n",
            "        147.5350, 147.5410, 147.5337, 147.5360, 147.5431, 147.5360, 147.5366,\n",
            "        147.5381, 147.5381, 147.5343, 147.5402, 147.5365, 147.5326, 147.5382,\n",
            "        147.5371, 147.5368, 147.5393, 147.5339, 147.5352, 147.5332, 147.5480,\n",
            "        147.5337, 147.5396, 147.5355, 147.5466, 147.5352, 147.5396, 147.5343,\n",
            "        147.5345, 147.5353, 147.5369, 147.5372, 147.5360, 147.5326, 147.5329,\n",
            "        147.5308, 147.5368, 147.5336, 147.5346, 147.5327, 147.5367, 147.5389,\n",
            "        147.5370, 147.5370, 147.5318, 147.5410, 147.5338, 147.5362, 147.5347,\n",
            "        147.5334, 147.5372, 147.5365, 147.5338, 147.5374, 147.5366, 147.5369,\n",
            "        147.5350, 147.5357, 147.5336, 147.5361, 147.5381, 147.5359, 147.5348,\n",
            "        147.5347, 147.5336, 147.5348, 147.5571, 147.5351, 147.5364, 147.5328,\n",
            "        147.5333, 147.5404, 147.5350], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.0556204040672128 and immediate abs rewards look like: [0.0015702111491009418, 0.00024251755257864716, 0.00436014543129204, 0.0003838924239971675, 0.013309999036664522, 0.0003079183484260284, 0.011474142808765464, 0.0014082114844313764, 0.0008927548997235135, 0.0005087757162982598, 0.00041671055760161835, 0.0017673618299340887, 0.0006742891241628968, 0.0020307237869019445, 0.0012470119831959892, 0.004327588372689206, 0.0009409046474502247, 0.0008554885939702217, 0.00017797994496504543, 0.00011153466675750678, 0.0010721988460318244, 0.0031795138452253013, 8.227644411817892e-05, 6.0184610447322484e-05, 0.00010513465576877934, 3.1983208373276284e-05, 0.0003179360669491871, 3.2578391255810857e-06, 2.8260910767130554e-07, 2.933516043412965e-07, 0.00021978392032906413, 7.179558951975196e-05, 0.00042822552859433927, 0.0008192907971533714, 0.0012921542088406568, 8.477262781525496e-06, 2.231872258562362e-06, 4.245976697347942e-05, 0.0002663600612322625, 1.0323714377591386e-05, 2.633649364724988e-05, 4.771323801833205e-05, 3.897137730746181e-05, 5.2886700814269716e-05, 9.360254625789821e-05, 0.00027368621977075236, 1.1031163012376055e-05, 8.435331437794957e-07, 2.276597888339893e-05, 3.0240258638514206e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 2.0293857403127227 and immediate relative rewards look like: [0.005063055924809998, 0.0015647601656046013, 0.04220178482895407, 0.004961231417422036, 0.21504128670329678, 0.0059955978294779135, 0.2606797916917832, 0.03670010218648606, 0.02618686054305404, 0.016586755422299256, 0.014946320703022252, 0.06916284333453535, 0.02860263274636208, 0.09278781724615205, 0.06108884099135419, 0.22622616526537767, 0.05233424104525118, 0.0503978304912566, 0.011070606039283526, 0.007303178276470368, 0.0737195238881944, 0.22909930758175082, 0.006204348980058586, 0.004735886429212052, 0.008617852552159598, 0.0027266129935249045, 0.028147267503702545, 0.0002991338924244022, 2.6875815054145784e-05, 2.885939715302908e-05, 0.022342675795725943, 0.0075345378770677995, 0.046345289145651634, 0.09136862565087278, 0.14838131438435395, 0.0010017033500709371, 0.00027105239325925896, 0.005295947963646683, 0.0340974791114563, 0.0013555717281384324, 0.003544621057554032, 0.006578394863482573, 0.005501140914602029, 0.007639118865557026, 0.013827759978617685, 0.04133098579089224, 0.0017022493794974813, 0.00013293795261933237, 0.0036625884889036476, 0.004964373735264508]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([0.0264, 0.0127, 0.0126, 0.0149, 0.0133, 0.0136, 0.0146, 0.0169, 0.0124,\n",
            "        0.0192, 0.0113, 0.0149, 0.0153, 0.0135, 0.0159, 0.0134, 0.0114, 0.0140,\n",
            "        0.0128, 0.0168, 0.0132, 0.0150, 0.0105, 0.0146, 0.0191, 0.0159, 0.0144,\n",
            "        0.0136, 0.0152, 0.0133, 0.0158, 0.0163, 0.0114, 0.0134, 0.0121, 0.0170,\n",
            "        0.0151, 0.0149, 0.0134, 0.0144, 0.0155, 0.0134, 0.0193, 0.0164, 0.0170,\n",
            "        0.0137, 0.0137, 0.0182, 0.0135, 0.0130, 0.0192, 0.0149, 0.0156, 0.0136,\n",
            "        0.0150, 0.0157, 0.0133, 0.0156, 0.0169, 0.0140, 0.0150, 0.0163, 0.0155,\n",
            "        0.0131, 0.0154, 0.0169, 0.0158], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [22]\n",
            "DEBUGGING: logits looks like: tensor([148.9186, 148.5552, 148.5482, 148.6325, 148.5749, 148.5862, 148.6228,\n",
            "        148.6970, 148.5423, 148.7608, 148.4949, 148.6326, 148.6453, 148.5851,\n",
            "        148.6665, 148.5794, 148.5008, 148.6027, 148.5584, 148.6942, 148.5727,\n",
            "        148.6371, 148.4572, 148.6249, 148.7572, 148.6658, 148.6170, 148.5887,\n",
            "        148.6423, 148.5757, 148.6643, 148.6783, 148.5013, 148.5787, 148.5314,\n",
            "        148.6980, 148.6394, 148.6342, 148.5794, 148.6181, 148.6520, 148.5796,\n",
            "        148.7619, 148.6829, 148.6998, 148.5899, 148.5929, 148.7334, 148.5835,\n",
            "        148.5668, 148.7605, 148.6320, 148.6574, 148.5893, 148.6373, 148.6587,\n",
            "        148.5768, 148.6574, 148.6968, 148.6018, 148.6362, 148.6793, 148.6524,\n",
            "        148.5687, 148.6489, 148.6974, 148.6631], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0252, 0.0127, 0.0127, 0.0130, 0.0118, 0.0128, 0.0126, 0.0127, 0.0126,\n",
            "        0.0127, 0.0126, 0.0127, 0.0127, 0.0126, 0.0127, 0.0127, 0.0129, 0.0128,\n",
            "        0.0124, 0.0126, 0.0128, 0.0128, 0.0127, 0.0128, 0.0128, 0.0126, 0.0126,\n",
            "        0.0127, 0.0129, 0.0125, 0.0127, 0.0128, 0.0126, 0.0127, 0.0126, 0.0126,\n",
            "        0.0127, 0.0129, 0.0126, 0.0126, 0.0126, 0.0127, 0.0126, 0.0128, 0.0126,\n",
            "        0.0125, 0.0126, 0.0126, 0.0125, 0.0125, 0.0128, 0.0128, 0.0129, 0.0126,\n",
            "        0.0126, 0.0130, 0.0128, 0.0126, 0.0125, 0.0127, 0.0125, 0.0127, 0.0124,\n",
            "        0.0127, 0.0125, 0.0127, 0.0125, 0.0130, 0.0129, 0.0126, 0.0128, 0.0124,\n",
            "        0.0120, 0.0128, 0.0126, 0.0126, 0.0127, 0.0127],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [14]\n",
            "DEBUGGING: logits looks like: tensor([148.8695, 148.5257, 148.5271, 148.5383, 148.4917, 148.5307, 148.5225,\n",
            "        148.5287, 148.5230, 148.5279, 148.5219, 148.5250, 148.5252, 148.5237,\n",
            "        148.5280, 148.5285, 148.5342, 148.5305, 148.5166, 148.5222, 148.5301,\n",
            "        148.5291, 148.5273, 148.5298, 148.5320, 148.5212, 148.5224, 148.5284,\n",
            "        148.5366, 148.5179, 148.5275, 148.5305, 148.5216, 148.5264, 148.5228,\n",
            "        148.5230, 148.5262, 148.5331, 148.5225, 148.5240, 148.5214, 148.5288,\n",
            "        148.5225, 148.5324, 148.5243, 148.5171, 148.5249, 148.5236, 148.5209,\n",
            "        148.5184, 148.5321, 148.5305, 148.5354, 148.5213, 148.5219, 148.5392,\n",
            "        148.5324, 148.5238, 148.5193, 148.5282, 148.5207, 148.5271, 148.5144,\n",
            "        148.5262, 148.5190, 148.5280, 148.5205, 148.5398, 148.5340, 148.5229,\n",
            "        148.5310, 148.5149, 148.4976, 148.5317, 148.5239, 148.5233, 148.5265,\n",
            "        148.5254], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0231, 0.0115, 0.0113, 0.0113, 0.0114, 0.0113, 0.0114, 0.0114, 0.0113,\n",
            "        0.0113, 0.0113, 0.0113, 0.0114, 0.0113, 0.0114, 0.0113, 0.0113, 0.0113,\n",
            "        0.0113, 0.0114, 0.0114, 0.0113, 0.0113, 0.0113, 0.0113, 0.0113, 0.0113,\n",
            "        0.0113, 0.0113, 0.0114, 0.0114, 0.0113, 0.0113, 0.0113, 0.0113, 0.0115,\n",
            "        0.0114, 0.0113, 0.0114, 0.0113, 0.0114, 0.0114, 0.0113, 0.0113, 0.0113,\n",
            "        0.0113, 0.0113, 0.0113, 0.0114, 0.0113, 0.0113, 0.0113, 0.0114, 0.0113,\n",
            "        0.0113, 0.0113, 0.0113, 0.0114, 0.0113, 0.0115, 0.0113, 0.0115, 0.0116,\n",
            "        0.0114, 0.0113, 0.0114, 0.0114, 0.0114, 0.0113, 0.0113, 0.0113, 0.0114,\n",
            "        0.0114, 0.0114, 0.0113, 0.0113, 0.0113, 0.0113, 0.0115, 0.0113, 0.0113,\n",
            "        0.0113, 0.0114, 0.0114, 0.0114, 0.0115, 0.0114],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [4]\n",
            "DEBUGGING: logits looks like: tensor([148.8328, 148.4826, 148.4754, 148.4757, 148.4790, 148.4758, 148.4782,\n",
            "        148.4775, 148.4762, 148.4752, 148.4767, 148.4750, 148.4794, 148.4763,\n",
            "        148.4803, 148.4754, 148.4760, 148.4767, 148.4751, 148.4791, 148.4776,\n",
            "        148.4742, 148.4769, 148.4763, 148.4756, 148.4733, 148.4751, 148.4762,\n",
            "        148.4760, 148.4770, 148.4783, 148.4762, 148.4768, 148.4764, 148.4768,\n",
            "        148.4816, 148.4789, 148.4755, 148.4771, 148.4763, 148.4787, 148.4771,\n",
            "        148.4737, 148.4740, 148.4762, 148.4767, 148.4745, 148.4751, 148.4773,\n",
            "        148.4767, 148.4744, 148.4756, 148.4810, 148.4757, 148.4767, 148.4765,\n",
            "        148.4766, 148.4771, 148.4761, 148.4822, 148.4758, 148.4826, 148.4896,\n",
            "        148.4802, 148.4765, 148.4774, 148.4811, 148.4809, 148.4769, 148.4751,\n",
            "        148.4733, 148.4773, 148.4799, 148.4803, 148.4762, 148.4764, 148.4762,\n",
            "        148.4753, 148.4837, 148.4766, 148.4761, 148.4768, 148.4778, 148.4785,\n",
            "        148.4802, 148.4838, 148.4773], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0208, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [84]\n",
            "DEBUGGING: logits looks like: tensor([148.8029, 148.4450, 148.4465, 148.4461, 148.4457, 148.4459, 148.4454,\n",
            "        148.4456, 148.4468, 148.4460, 148.4457, 148.4461, 148.4457, 148.4459,\n",
            "        148.4459, 148.4460, 148.4452, 148.4461, 148.4463, 148.4458, 148.4458,\n",
            "        148.4461, 148.4459, 148.4457, 148.4456, 148.4459, 148.4459, 148.4456,\n",
            "        148.4459, 148.4459, 148.4455, 148.4457, 148.4460, 148.4457, 148.4452,\n",
            "        148.4456, 148.4464, 148.4464, 148.4456, 148.4457, 148.4460, 148.4466,\n",
            "        148.4456, 148.4461, 148.4460, 148.4463, 148.4452, 148.4463, 148.4460,\n",
            "        148.4457, 148.4456, 148.4463, 148.4460, 148.4457, 148.4462, 148.4458,\n",
            "        148.4452, 148.4454, 148.4458, 148.4455, 148.4459, 148.4455, 148.4460,\n",
            "        148.4450, 148.4459, 148.4461, 148.4462, 148.4460, 148.4460, 148.4457,\n",
            "        148.4455, 148.4459, 148.4459, 148.4459, 148.4462, 148.4455, 148.4460,\n",
            "        148.4462, 148.4453, 148.4453, 148.4458, 148.4448, 148.4466, 148.4454,\n",
            "        148.4463, 148.4469, 148.4455, 148.4454, 148.4459, 148.4460, 148.4457,\n",
            "        148.4466, 148.4462, 148.4462, 148.4462, 148.4458, 148.4460],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0188, 0.0091, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092,\n",
            "        0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0091, 0.0092, 0.0092, 0.0092,\n",
            "        0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0091, 0.0092, 0.0092, 0.0092,\n",
            "        0.0091, 0.0092, 0.0092, 0.0092, 0.0092, 0.0091, 0.0092, 0.0092, 0.0092,\n",
            "        0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0091, 0.0092, 0.0092, 0.0092,\n",
            "        0.0092, 0.0092, 0.0092, 0.0091, 0.0092, 0.0092, 0.0091, 0.0092, 0.0092,\n",
            "        0.0091, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092,\n",
            "        0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0091,\n",
            "        0.0091, 0.0092, 0.0091, 0.0091, 0.0092, 0.0092, 0.0092, 0.0091, 0.0092,\n",
            "        0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092,\n",
            "        0.0092, 0.0092, 0.0091, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092,\n",
            "        0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0091],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [98]\n",
            "DEBUGGING: logits looks like: tensor([148.7784, 148.4188, 148.4202, 148.4196, 148.4214, 148.4211, 148.4227,\n",
            "        148.4194, 148.4221, 148.4202, 148.4198, 148.4201, 148.4214, 148.4214,\n",
            "        148.4191, 148.4209, 148.4204, 148.4209, 148.4209, 148.4197, 148.4214,\n",
            "        148.4204, 148.4210, 148.4185, 148.4203, 148.4203, 148.4214, 148.4186,\n",
            "        148.4207, 148.4221, 148.4196, 148.4208, 148.4187, 148.4217, 148.4208,\n",
            "        148.4201, 148.4201, 148.4206, 148.4203, 148.4207, 148.4206, 148.4190,\n",
            "        148.4202, 148.4201, 148.4210, 148.4208, 148.4208, 148.4207, 148.4178,\n",
            "        148.4201, 148.4192, 148.4190, 148.4203, 148.4211, 148.4181, 148.4219,\n",
            "        148.4210, 148.4212, 148.4195, 148.4209, 148.4203, 148.4196, 148.4207,\n",
            "        148.4213, 148.4194, 148.4205, 148.4198, 148.4206, 148.4209, 148.4206,\n",
            "        148.4211, 148.4188, 148.4173, 148.4207, 148.4184, 148.4188, 148.4210,\n",
            "        148.4206, 148.4197, 148.4173, 148.4211, 148.4201, 148.4199, 148.4210,\n",
            "        148.4200, 148.4198, 148.4219, 148.4215, 148.4204, 148.4214, 148.4202,\n",
            "        148.4207, 148.4184, 148.4203, 148.4199, 148.4200, 148.4208, 148.4202,\n",
            "        148.4209, 148.4198, 148.4211, 148.4207, 148.4206, 148.4214, 148.4199,\n",
            "        148.4207, 148.4206, 148.4147], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.1485937418337926 and immediate abs rewards look like: [0.042150341945216496, 0.007507998156143003, 0.02332279857546382, 0.0013648801345880202, 0.006851540379557264, 0.01957724788417181, 0.003981870537700161, 0.0031845842227085086, 0.0005192323264964216, 0.009877025385321758, 0.010777938466162595, 0.0011123731937914272, 0.006468603042776522, 0.004097120500773599, 4.647469540941529e-05, 0.00036265117796574486, 0.0025196224687533686, 0.00032769746394478716, 1.0500730240892153e-06, 0.00026102054562215926, 0.00018161093657909078, 0.00036369478766573593, 6.742364348610863e-06, 0.0001762186320775072, 3.8009361560398247e-06, 0.0005226530242907756, 0.00052205482552381, 6.993888609940768e-05, 0.0002517079851713788, 0.00012988525986656896, 6.31941793471924e-05, 0.0004096037860108481, 1.1035966053896118e-05, 2.8189185286464635e-05, 3.002501080118236e-05, 7.3329470069438685e-06, 2.2827762677479768e-05, 3.6958335840608925e-06, 5.553952905756887e-05, 8.884208091330947e-05, 0.0002481936394360673, 0.00022873703301229398, 3.7903314478171524e-05, 8.014492095753667e-05, 6.618795396207133e-06, 0.00015290758483388345, 0.0005099190743749205, 4.111911039217375e-06, 2.1552493763010716e-05, 4.298797239243868e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 2.543443604329364 and immediate relative rewards look like: [0.1136659281691786, 0.04095887991437324, 0.19124326859399415, 0.01501813961882849, 0.09427204916236055, 0.32385247550804436, 0.0772644963776762, 0.07069963280975691, 0.012979639786491063, 0.2743766916325991, 0.3302498816978857, 0.03729510873150858, 0.23502224285918288, 0.16060081396103967, 0.0019541021683932907, 0.016265004521425094, 0.12008082364617026, 0.016547855710136727, 5.597694210837047e-05, 0.014646737032234297, 0.01070112148588294, 0.02245173412469802, 0.0004351855934285176, 0.011868568628865199, 0.00026667809186449844, 0.038136781137333695, 0.03956405567100516, 0.0054974502966397935, 0.020492176469712606, 0.010939687287312528, 0.00550019889890596, 0.036801139706092834, 0.001022637165724607, 0.002691287309611028, 0.002950891739219866, 0.0007412876569543173, 0.0023717651795024763, 0.00039437139253685103, 0.006082423429252529, 0.00997919105442941, 0.028576034586043048, 0.026980096763273478, 0.004577530773436931, 0.009904189310666165, 0.00083654921754934, 0.01975548495522313, 0.06731604660069551, 0.0005544554296687625, 0.002966714833081634, 0.00603812069736546]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 3\n",
            "DEBUGGING: the action_prob is: tensor([0.0224, 0.0122, 0.0130, 0.0114, 0.0163, 0.0090, 0.0173, 0.0148, 0.0206,\n",
            "        0.0161, 0.0153, 0.0084, 0.0155, 0.0174, 0.0167, 0.0134, 0.0183, 0.0131,\n",
            "        0.0199, 0.0146, 0.0136, 0.0173, 0.0199, 0.0186, 0.0135, 0.0148, 0.0093,\n",
            "        0.0103, 0.0081, 0.0169, 0.0147, 0.0115, 0.0110, 0.0103, 0.0167, 0.0288,\n",
            "        0.0153, 0.0154, 0.0150, 0.0196, 0.0133, 0.0045, 0.0104, 0.0151, 0.0175,\n",
            "        0.0121, 0.0143, 0.0150, 0.0142, 0.0162, 0.0154, 0.0127, 0.0149, 0.0163,\n",
            "        0.0133, 0.0149, 0.0174, 0.0182, 0.0161, 0.0139, 0.0120, 0.0123, 0.0142,\n",
            "        0.0143, 0.0139, 0.0150, 0.0134, 0.0126], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [35]\n",
            "DEBUGGING: logits looks like: tensor([148.1869, 147.8816, 147.9132, 147.8465, 148.0282, 147.7313, 148.0557,\n",
            "        147.9780, 148.1438, 148.0213, 147.9944, 147.6946, 148.0016, 148.0603,\n",
            "        148.0395, 147.9285, 148.0853, 147.9188, 148.1275, 147.9706, 147.9348,\n",
            "        148.0565, 148.1264, 148.0930, 147.9335, 147.9797, 147.7453, 147.7961,\n",
            "        147.6798, 148.0454, 147.9765, 147.8536, 147.8310, 147.7988, 148.0402,\n",
            "        148.3114, 147.9957, 147.9979, 147.9863, 148.1185, 147.9252, 147.3829,\n",
            "        147.8028, 147.9878, 148.0635, 147.8782, 147.9622, 147.9863, 147.9570,\n",
            "        148.0228, 147.9976, 147.9007, 147.9825, 148.0256, 147.9241, 147.9833,\n",
            "        148.0590, 148.0826, 148.0211, 147.9473, 147.8741, 147.8843, 147.9580,\n",
            "        147.9609, 147.9484, 147.9866, 147.9277, 147.8979],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0270, 0.0110, 0.0122, 0.0128, 0.0146, 0.0144, 0.0054, 0.0112, 0.0112,\n",
            "        0.0127, 0.0119, 0.0089, 0.0150, 0.0115, 0.0121, 0.0134, 0.0143, 0.0123,\n",
            "        0.0099, 0.0125, 0.0126, 0.0108, 0.0115, 0.0130, 0.0129, 0.0107, 0.0082,\n",
            "        0.0117, 0.0097, 0.0146, 0.0141, 0.0132, 0.0122, 0.0136, 0.0124, 0.0101,\n",
            "        0.0113, 0.0126, 0.0149, 0.0128, 0.0096, 0.0144, 0.0092, 0.0140, 0.0118,\n",
            "        0.0123, 0.0141, 0.0147, 0.0118, 0.0129, 0.0109, 0.0148, 0.0169, 0.0122,\n",
            "        0.0104, 0.0142, 0.0169, 0.0135, 0.0115, 0.0099, 0.0122, 0.0128, 0.0116,\n",
            "        0.0115, 0.0119, 0.0107, 0.0123, 0.0093, 0.0141, 0.0133, 0.0139, 0.0154,\n",
            "        0.0129, 0.0110, 0.0095, 0.0143, 0.0117, 0.0124, 0.0127, 0.0135],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [32]\n",
            "DEBUGGING: logits looks like: tensor([148.2487, 147.8002, 147.8532, 147.8776, 147.9427, 147.9345, 147.4493,\n",
            "        147.8078, 147.8080, 147.8716, 147.8393, 147.6951, 147.9563, 147.8247,\n",
            "        147.8487, 147.8973, 147.9302, 147.8571, 147.7485, 147.8649, 147.8678,\n",
            "        147.7902, 147.8221, 147.8843, 147.8795, 147.7844, 147.6541, 147.8323,\n",
            "        147.7357, 147.9414, 147.9251, 147.8929, 147.8514, 147.9076, 147.8590,\n",
            "        147.7601, 147.8126, 147.8675, 147.9515, 147.8772, 147.7342, 147.9345,\n",
            "        147.7102, 147.9212, 147.8357, 147.8567, 147.9234, 147.9441, 147.8342,\n",
            "        147.8806, 147.7957, 147.9485, 148.0152, 147.8508, 147.7725, 147.9279,\n",
            "        148.0164, 147.9021, 147.8245, 147.7488, 147.8517, 147.8756, 147.8271,\n",
            "        147.8206, 147.8400, 147.7864, 147.8564, 147.7177, 147.9247, 147.8936,\n",
            "        147.9192, 147.9671, 147.8797, 147.8025, 147.7282, 147.9328, 147.8292,\n",
            "        147.8607, 147.8705, 147.9040], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0256, 0.0116, 0.0116, 0.0112, 0.0116, 0.0116, 0.0112, 0.0117, 0.0111,\n",
            "        0.0108, 0.0113, 0.0116, 0.0115, 0.0115, 0.0115, 0.0116, 0.0114, 0.0115,\n",
            "        0.0116, 0.0114, 0.0115, 0.0114, 0.0117, 0.0115, 0.0116, 0.0113, 0.0104,\n",
            "        0.0114, 0.0115, 0.0114, 0.0117, 0.0112, 0.0118, 0.0115, 0.0115, 0.0113,\n",
            "        0.0129, 0.0117, 0.0113, 0.0115, 0.0114, 0.0122, 0.0115, 0.0115, 0.0120,\n",
            "        0.0112, 0.0113, 0.0115, 0.0114, 0.0117, 0.0115, 0.0114, 0.0115, 0.0116,\n",
            "        0.0111, 0.0113, 0.0115, 0.0116, 0.0114, 0.0113, 0.0115, 0.0112, 0.0117,\n",
            "        0.0114, 0.0115, 0.0111, 0.0116, 0.0112, 0.0112, 0.0111, 0.0117, 0.0114,\n",
            "        0.0116, 0.0114, 0.0114, 0.0115, 0.0114, 0.0115, 0.0115, 0.0116, 0.0117,\n",
            "        0.0110, 0.0117, 0.0116, 0.0115, 0.0115], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [41]\n",
            "DEBUGGING: logits looks like: tensor([148.2471, 147.8505, 147.8501, 147.8351, 147.8528, 147.8502, 147.8338,\n",
            "        147.8573, 147.8290, 147.8154, 147.8388, 147.8511, 147.8496, 147.8465,\n",
            "        147.8489, 147.8525, 147.8436, 147.8478, 147.8502, 147.8431, 147.8470,\n",
            "        147.8414, 147.8550, 147.8468, 147.8522, 147.8412, 147.7972, 147.8451,\n",
            "        147.8475, 147.8438, 147.8548, 147.8347, 147.8627, 147.8489, 147.8490,\n",
            "        147.8394, 147.9065, 147.8551, 147.8400, 147.8486, 147.8426, 147.8782,\n",
            "        147.8474, 147.8472, 147.8674, 147.8326, 147.8407, 147.8484, 147.8418,\n",
            "        147.8577, 147.8476, 147.8426, 147.8481, 147.8506, 147.8287, 147.8385,\n",
            "        147.8467, 147.8513, 147.8455, 147.8398, 147.8462, 147.8364, 147.8563,\n",
            "        147.8442, 147.8471, 147.8321, 147.8508, 147.8332, 147.8327, 147.8320,\n",
            "        147.8565, 147.8421, 147.8506, 147.8452, 147.8451, 147.8487, 147.8414,\n",
            "        147.8490, 147.8478, 147.8536, 147.8551, 147.8278, 147.8578, 147.8504,\n",
            "        147.8473, 147.8478], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0212, 0.0105, 0.0099, 0.0097, 0.0105, 0.0099, 0.0098, 0.0103, 0.0097,\n",
            "        0.0095, 0.0098, 0.0103, 0.0097, 0.0102, 0.0106, 0.0103, 0.0103, 0.0104,\n",
            "        0.0108, 0.0104, 0.0114, 0.0108, 0.0107, 0.0098, 0.0104, 0.0100, 0.0102,\n",
            "        0.0103, 0.0099, 0.0099, 0.0101, 0.0103, 0.0108, 0.0096, 0.0103, 0.0098,\n",
            "        0.0103, 0.0104, 0.0106, 0.0105, 0.0099, 0.0101, 0.0102, 0.0101, 0.0101,\n",
            "        0.0103, 0.0102, 0.0113, 0.0101, 0.0099, 0.0102, 0.0109, 0.0100, 0.0103,\n",
            "        0.0104, 0.0101, 0.0098, 0.0097, 0.0099, 0.0096, 0.0109, 0.0113, 0.0101,\n",
            "        0.0095, 0.0102, 0.0099, 0.0105, 0.0108, 0.0101, 0.0097, 0.0099, 0.0098,\n",
            "        0.0104, 0.0106, 0.0096, 0.0101, 0.0098, 0.0101, 0.0103, 0.0102, 0.0105,\n",
            "        0.0099, 0.0106, 0.0103, 0.0100, 0.0099, 0.0100, 0.0100, 0.0097, 0.0104,\n",
            "        0.0100, 0.0107, 0.0097, 0.0104, 0.0103, 0.0103, 0.0105],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [58]\n",
            "DEBUGGING: logits looks like: tensor([148.2180, 147.8682, 147.8398, 147.8266, 147.8687, 147.8368, 147.8349,\n",
            "        147.8594, 147.8275, 147.8173, 147.8316, 147.8560, 147.8293, 147.8551,\n",
            "        147.8700, 147.8591, 147.8577, 147.8626, 147.8799, 147.8645, 147.9084,\n",
            "        147.8819, 147.8762, 147.8327, 147.8615, 147.8454, 147.8528, 147.8578,\n",
            "        147.8388, 147.8363, 147.8471, 147.8581, 147.8830, 147.8204, 147.8560,\n",
            "        147.8315, 147.8599, 147.8634, 147.8713, 147.8685, 147.8378, 147.8493,\n",
            "        147.8533, 147.8493, 147.8501, 147.8592, 147.8509, 147.9033, 147.8491,\n",
            "        147.8364, 147.8516, 147.8849, 147.8418, 147.8592, 147.8636, 147.8487,\n",
            "        147.8312, 147.8304, 147.8357, 147.8249, 147.8882, 147.9036, 147.8461,\n",
            "        147.8170, 147.8534, 147.8387, 147.8676, 147.8794, 147.8494, 147.8255,\n",
            "        147.8373, 147.8336, 147.8610, 147.8714, 147.8217, 147.8484, 147.8330,\n",
            "        147.8495, 147.8565, 147.8551, 147.8684, 147.8395, 147.8708, 147.8596,\n",
            "        147.8406, 147.8376, 147.8445, 147.8415, 147.8284, 147.8605, 147.8418,\n",
            "        147.8789, 147.8296, 147.8643, 147.8586, 147.8569, 147.8682],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0203, 0.0092, 0.0092, 0.0093, 0.0093, 0.0081, 0.0092, 0.0094, 0.0092,\n",
            "        0.0092, 0.0092, 0.0092, 0.0092, 0.0093, 0.0093, 0.0093, 0.0092, 0.0093,\n",
            "        0.0093, 0.0092, 0.0092, 0.0094, 0.0093, 0.0092, 0.0092, 0.0092, 0.0094,\n",
            "        0.0092, 0.0093, 0.0093, 0.0093, 0.0093, 0.0093, 0.0092, 0.0093, 0.0093,\n",
            "        0.0094, 0.0093, 0.0092, 0.0093, 0.0092, 0.0092, 0.0093, 0.0092, 0.0092,\n",
            "        0.0092, 0.0093, 0.0094, 0.0093, 0.0093, 0.0092, 0.0092, 0.0092, 0.0093,\n",
            "        0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0093, 0.0092,\n",
            "        0.0093, 0.0094, 0.0092, 0.0094, 0.0092, 0.0092, 0.0093, 0.0093, 0.0092,\n",
            "        0.0094, 0.0092, 0.0092, 0.0092, 0.0093, 0.0092, 0.0093, 0.0092, 0.0094,\n",
            "        0.0092, 0.0093, 0.0093, 0.0092, 0.0092, 0.0093, 0.0092, 0.0092, 0.0093,\n",
            "        0.0093, 0.0092, 0.0092, 0.0093, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092,\n",
            "        0.0093, 0.0092, 0.0092, 0.0092, 0.0093, 0.0093, 0.0093, 0.0092],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [36]\n",
            "DEBUGGING: logits looks like: tensor([148.1966, 147.8020, 147.7993, 147.8031, 147.8043, 147.7369, 147.8016,\n",
            "        147.8109, 147.7996, 147.7983, 147.8014, 147.8027, 147.8018, 147.8037,\n",
            "        147.8029, 147.8044, 147.7979, 147.8030, 147.8048, 147.7989, 147.7983,\n",
            "        147.8130, 147.8060, 147.8005, 147.8016, 147.8009, 147.8108, 147.8004,\n",
            "        147.8047, 147.8051, 147.8028, 147.8046, 147.8049, 147.8006, 147.8067,\n",
            "        147.8029, 147.8106, 147.8078, 147.7985, 147.8037, 147.7975, 147.8025,\n",
            "        147.8029, 147.8011, 147.8007, 147.7989, 147.8031, 147.8109, 147.8053,\n",
            "        147.8073, 147.8020, 147.7989, 147.7989, 147.8029, 147.8023, 147.7994,\n",
            "        147.8021, 147.8000, 147.8004, 147.7993, 147.8025, 147.8031, 147.7987,\n",
            "        147.8047, 147.8084, 147.8024, 147.8120, 147.8010, 147.8018, 147.8073,\n",
            "        147.8070, 147.8023, 147.8123, 147.8014, 147.8023, 147.7998, 147.8055,\n",
            "        147.7995, 147.8036, 147.8009, 147.8093, 147.8011, 147.8065, 147.8038,\n",
            "        147.8012, 147.7996, 147.8049, 147.8006, 147.8019, 147.8038, 147.8029,\n",
            "        147.8007, 147.8009, 147.8055, 147.7988, 147.8008, 147.8009, 147.7974,\n",
            "        147.8003, 147.8042, 147.8013, 147.8011, 147.8022, 147.8035, 147.8027,\n",
            "        147.8028, 147.8019], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.09048041292089692 and immediate abs rewards look like: [0.0004934376884193625, 0.002388787923791824, 0.020173112437532836, 0.0025062948943741503, 0.0008360646043001907, 0.004919176531529956, 0.0020721278947348765, 0.003845621561140433, 0.001385611358728056, 0.01921701167430001, 0.000121204823244625, 0.0002501144981579273, 0.0012746980441988853, 0.00021757333843197557, 0.0007622082439411315, 0.001322441287811671, 0.0017533498548800708, 0.013178071567836014, 0.0008664452798257116, 0.00014690830721519887, 4.06058370572282e-05, 0.000499916301578196, 0.0006380358204296499, 0.00028176387149869697, 0.0007902927518443903, 0.00015403134375446825, 0.00020811066997339367, 1.0205399121332448e-06, 4.256171587257995e-05, 0.00025108270574492053, 3.303569792478811e-05, 0.0013063863693787425, 0.0020263827250346367, 0.00037112454810994677, 0.00120311630780634, 0.00042364074079159764, 0.00038512359105880023, 0.0002233534942206461, 0.0003202882467121526, 0.0010481226545380196, 0.0008895974292499886, 0.0004098026347492123, 0.0003648310625976592, 0.00034519985456427094, 2.4797895093797706e-05, 0.0001748198787936417, 1.1635466307780007e-05, 0.00011741644175344845, 0.0001334621560999949, 3.0592354050895665e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 3.7451405696287847 and immediate relative rewards look like: [0.0015910615672972772, 0.015407471133883726, 0.19532266175306232, 0.0325677279082169, 0.013591233874221502, 0.09598663577856184, 0.04724730485145849, 0.10027951037294558, 0.040699056839303055, 0.6274551556405286, 0.0043806949692906825, 0.009862064420039776, 0.05445453921132127, 0.010013803909378463, 0.037589048916778535, 0.06958276208664901, 0.09806447261884252, 0.7808527710651331, 0.05442865827631891, 0.009717032748814011, 0.002820240722971471, 0.036375102774933256, 0.04854326235250267, 0.022374033336506276, 0.06537568158464876, 0.01325513814754046, 0.01859867730158576, 9.458927356607832e-05, 0.004085743867037713, 0.02493435767066092, 0.0033903255919038593, 0.13839569985450545, 0.22147476979649747, 0.041819516930664685, 0.13957559625277988, 0.05057166811803139, 0.047257410313660916, 0.028151393201177946, 0.041434426208627154, 0.1390829719365398, 0.12104037829419659, 0.057135385849357026, 0.05208353772532719, 0.0504331505566468, 0.0037056972313092972, 0.02670513782452786, 0.0018161555475974187, 0.018717300871946622, 0.021719219829204446, 0.005080332720283205]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 200 number of matrices\n",
            "DEBUGGING: ACT_MAT has 200 number of matrices\n",
            "DEBUGGING: VAL looks like: [[4.793355507305327, 4.746061398577254, 4.724096689988444, 8.494715228647159e-10, 8.549897715745516e-10, 8.636260318934865e-10, 8.677561195804264e-10, 8.711623573940245e-10, 8.738374337193986e-10, 8.82664074464039e-10, 8.839241938881448e-10, 8.928527210991362e-10, 8.926846202842487e-10, 9.017016366507563e-10, 9.10809733990663e-10, 9.085263133520216e-10, 8.932051730350926e-10, 8.761981378634965e-10, 8.574881785962693e-10, 8.66149675349767e-10, 8.442759447380522e-10, 8.528039845838911e-10, 8.445756717690769e-10, 8.531067391606838e-10, 8.433503486113387e-10, 8.518690390013522e-10, 8.604737767690427e-10, 8.484950969486366e-10, 8.35629852431584e-10, 7.774661480333755e-10, 7.85319341447854e-10, 7.695192541939969e-10, 7.772921759535322e-10, 7.346161286424495e-10, 7.160071839315298e-10, 7.23239579728818e-10, 7.029845845208385e-10, 6.534334120318219e-10, 6.600337495270929e-10, 6.069864584968253e-10, 5.518722003824685e-10, 4.946700967286093e-10, 4.032052050933784e-10, 3.085197218715186e-10, 2.4426610478939273e-10, 1.7783232541053365e-10, 1.444124867096654e-10, 7.39078132028142e-11, 7.465435677051939e-11, 3.789561257386914e-11], [1.7138605098294233, 1.7260580342470841, 1.7419123980621005, 1.7168794073062086, 1.729210278675542, 1.529463628254793, 1.5388565963892074, 1.2910876815125498, 1.267058160935418, 1.2534053539316807, 1.249311715666042, 1.2468337322858787, 1.1895665544963065, 1.172690830050449, 1.0908111240447445, 1.0401235182357478, 0.8221185383539091, 0.7775598962713717, 0.7345071371516314, 0.7307439708205534, 0.7307482752970537, 0.6636654054634943, 0.43895565442600354, 0.4371225307534798, 0.436754186186129, 0.4324609430646156, 0.4340750808798896, 0.41002809431938086, 0.4138676367949055, 0.4180209706867185, 0.42221425382784394, 0.40391068488092724, 0.40037994646854486, 0.35761076497261945, 0.26893145386035017, 0.12176781765252143, 0.12198597404287928, 0.12294436530264649, 0.1188367851909089, 0.08559525866611374, 0.08509059286664172, 0.08236966849402798, 0.07655684205105596, 0.07177343549136761, 0.06478213800586928, 0.051469068714395556, 0.010240487801518502, 0.008624483254566688, 0.00857731848681551, 0.004964373735264508], [2.2631510612128345, 2.171197104084501, 2.151755781990028, 1.980315670097004, 1.9851490206850257, 1.909976738911783, 1.602145720609837, 1.5402840648809706, 1.4844287192638523, 1.4863122014922843, 1.2241772826865507, 0.9029569706956213, 0.8744059211758715, 0.6458420993097864, 0.49014271247348157, 0.49311980838897806, 0.4816715190581343, 0.36524312667875153, 0.3522174454228432, 0.3557186550310453, 0.3445170888876879, 0.33718784586040906, 0.3179152643795061, 0.32068694826876526, 0.3119377572120203, 0.3148192718385412, 0.279477263334553, 0.24233657339752307, 0.23923143747563969, 0.22094874849083543, 0.2121303648520433, 0.2087173393466034, 0.17365272690960662, 0.17437382802412327, 0.17341670779243662, 0.17218769298304723, 0.17317818719807365, 0.17253173941269817, 0.17387612931329427, 0.16948859180206238, 0.16112060681579088, 0.1338834062926746, 0.107983140938789, 0.10445011127813339, 0.09550093128026992, 0.095620587942142, 0.07663141715850391, 0.009409465209907469, 0.00894445432347344, 0.00603812069736546], [3.0747997489523464, 3.1042511993788375, 3.1200441699443977, 2.9542641496882176, 2.9512085068484852, 2.9672901747214784, 2.900306604992845, 2.8818780809508957, 2.809695525836313, 2.79696613030001, 2.1914252269287693, 2.20913589086816, 2.22148871358396, 2.1889234084572107, 2.200918792472558, 2.1851815591472517, 2.136968481879397, 2.059498999253085, 1.2915618466544971, 1.249629483210281, 1.2524368186479464, 1.2622389676009849, 1.2382463281071228, 1.2017202684390103, 1.1912588233358625, 1.1372556987385998, 1.1353541016071305, 1.1280357821268128, 1.1393345382356028, 1.1467159539076417, 1.1331127234716978, 1.1411337352321151, 1.012866702401626, 0.799385790510231, 0.7652184581611781, 0.6319624867761597, 0.5872634531900287, 0.5454606493700684, 0.5225346021907984, 0.48595977371936483, 0.35038060786143943, 0.23165679754266955, 0.1762842542356692, 0.12545526920236566, 0.07577991782395845, 0.07280224302287792, 0.04656273252358593, 0.04519856260200859, 0.026748749222284818, 0.005080332720283205]]\n",
            "DEBUGGING: traj_returns = [4.793355507305327, 1.7138605098294233, 2.2631510612128345, 3.0747997489523464]\n",
            "DEBUGGING: actions = [[45], [17], [0], [8], [55], [2], [49], [17], [32], [0], [32], [12], [47], [13], [43], [37], [33], [65], [34], [16], [10], [24], [16], [11], [50], [38], [52], [61], [28], [14], [20], [49], [18], [1], [88], [28], [37], [74], [9], [57], [42], [39], [87], [44], [45], [13], [90], [73], [105], [66], [17], [56], [41], [18], [4], [56], [2], [60], [5], [7], [31], [42], [19], [1], [64], [52], [70], [55], [10], [13], [69], [1], [38], [48], [63], [47], [35], [69], [36], [3], [69], [63], [85], [16], [28], [75], [92], [42], [42], [94], [46], [85], [20], [48], [94], [98], [49], [37], [43], [97], [29], [22], [18], [41], [15], [52], [1], [40], [15], [22], [52], [50], [15], [11], [68], [69], [35], [46], [71], [14], [71], [51], [50], [14], [69], [52], [19], [83], [13], [4], [23], [42], [18], [51], [3], [66], [92], [2], [76], [84], [11], [51], [30], [51], [50], [87], [39], [47], [48], [98], [34], [51], [2], [13], [7], [57], [1], [46], [38], [35], [8], [46], [37], [45], [14], [7], [40], [58], [5], [32], [20], [73], [34], [46], [14], [19], [19], [5], [79], [41], [31], [71], [58], [70], [48], [9], [29], [50], [1], [58], [21], [25], [3], [82], [10], [78], [67], [90], [33], [36]]\n",
            "DEBUGGING: actions length = 200\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[ 4.4221,  3.9373,  3.7510,  ..., -2.7056, -3.2789, -4.9694],\n",
            "        [ 4.4343,  3.9632,  3.7644,  ..., -2.7274, -3.2965, -4.9961],\n",
            "        [ 4.4186,  3.9800,  3.7484,  ..., -2.7287, -3.2927, -4.9930],\n",
            "        ...,\n",
            "        [ 4.3844,  3.9225,  3.7122,  ..., -2.6911, -3.2511, -4.9398],\n",
            "        [ 4.3844,  3.9225,  3.7122,  ..., -2.6911, -3.2511, -4.9398],\n",
            "        [ 4.3844,  3.9225,  3.7121,  ..., -2.6910, -3.2511, -4.9397]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[ 4.3938,  3.9335,  3.7220,  ..., -2.7002, -3.2611, -4.9527],\n",
            "        [ 4.3844,  3.9225,  3.7122,  ..., -2.6911, -3.2511, -4.9398],\n",
            "        [ 4.3844,  3.9224,  3.7122,  ..., -2.6910, -3.2511, -4.9397],\n",
            "        ...,\n",
            "        [ 4.3845,  3.9225,  3.7122,  ..., -2.6911, -3.2511, -4.9398],\n",
            "        [ 4.3845,  3.9225,  3.7122,  ..., -2.6911, -3.2511, -4.9398],\n",
            "        [ 4.3844,  3.9225,  3.7122,  ..., -2.6911, -3.2511, -4.9398]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([148.1966, 147.8020, 147.7993, 147.8031, 147.8043, 147.7369, 147.8016,\n",
            "        147.8109, 147.7996, 147.7983, 147.8014, 147.8027, 147.8018, 147.8037,\n",
            "        147.8029, 147.8044, 147.7979, 147.8030, 147.8048, 147.7989, 147.7983,\n",
            "        147.8130, 147.8060, 147.8005, 147.8016, 147.8009, 147.8108, 147.8004,\n",
            "        147.8047, 147.8051, 147.8028, 147.8046, 147.8049, 147.8006, 147.8067,\n",
            "        147.8029, 147.8106, 147.8078, 147.7985, 147.8037, 147.7975, 147.8025,\n",
            "        147.8029, 147.8011, 147.8007, 147.7989, 147.8031, 147.8109, 147.8053,\n",
            "        147.8073, 147.8020, 147.7989, 147.7989, 147.8029, 147.8023, 147.7994,\n",
            "        147.8021, 147.8000, 147.8004, 147.7993, 147.8025, 147.8031, 147.7987,\n",
            "        147.8047, 147.8084, 147.8024, 147.8120, 147.8010, 147.8018, 147.8073,\n",
            "        147.8070, 147.8023, 147.8123, 147.8014, 147.8023, 147.7998, 147.8055,\n",
            "        147.7995, 147.8036, 147.8009, 147.8093, 147.8011, 147.8065, 147.8038,\n",
            "        147.8012, 147.7996, 147.8049, 147.8006, 147.8019, 147.8038, 147.8029,\n",
            "        147.8007, 147.8009, 147.8055, 147.7988, 147.8008, 147.8009, 147.7974,\n",
            "        147.8003, 147.8042, 147.8013, 147.8011, 147.8022, 147.8035, 147.8027,\n",
            "        147.8028, 147.8019], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[2.96129171 2.93689193 2.93445226 1.66286481 1.66639195 1.60168264\n",
            "  1.51032723 1.42831246 1.3902956  1.38417092 1.16622856 1.08973165\n",
            "  1.0713653  1.00186408 0.94546816 0.92960622 0.86018964 0.80057551\n",
            "  0.59457161 0.58402303 0.58192555 0.56577305 0.49877931 0.48988244\n",
            "  0.48498769 0.47113398 0.46222661 0.44510011 0.4481084  0.44642142\n",
            "  0.44186434 0.43844044 0.39672484 0.3328426  0.30189166 0.2314795\n",
            "  0.2206069  0.21023419 0.20381188 0.18526091 0.14914795 0.11197747\n",
            "  0.09020606 0.0754197  0.05901575 0.05497297 0.03335866 0.01580813\n",
            "  0.01106763 0.00402071]]\n",
            "DEBUGGING: baseline2 looks like: 2.9612917068249827\n",
            "DEBUGGING: ADS looks like: [ 1.83206380e+00  1.80916946e+00  1.78964443e+00 -1.66286481e+00\n",
            " -1.66639195e+00 -1.60168263e+00 -1.51032723e+00 -1.42831246e+00\n",
            " -1.39029560e+00 -1.38417092e+00 -1.16622856e+00 -1.08973165e+00\n",
            " -1.07136530e+00 -1.00186408e+00 -9.45468157e-01 -9.29606221e-01\n",
            " -8.60189634e-01 -8.00575505e-01 -5.94571607e-01 -5.84023027e-01\n",
            " -5.81925545e-01 -5.65773054e-01 -4.98779311e-01 -4.89882436e-01\n",
            " -4.84987691e-01 -4.71133978e-01 -4.62226611e-01 -4.45100112e-01\n",
            " -4.48108402e-01 -4.46421418e-01 -4.41864335e-01 -4.38440439e-01\n",
            " -3.96724843e-01 -3.32842595e-01 -3.01891654e-01 -2.31479499e-01\n",
            " -2.20606903e-01 -2.10234188e-01 -2.03811879e-01 -1.85260906e-01\n",
            " -1.49147951e-01 -1.11977468e-01 -9.02060590e-02 -7.54197038e-02\n",
            " -5.90157466e-02 -5.49729748e-02 -3.33586593e-02 -1.58081277e-02\n",
            " -1.10676305e-02 -4.02070676e-03 -1.24743120e+00 -1.21083390e+00\n",
            " -1.19253986e+00  5.40146003e-02  6.28183269e-02 -7.22190074e-02\n",
            "  2.85293657e-02 -1.37224776e-01 -1.23237441e-01 -1.30765568e-01\n",
            "  8.30831591e-02  1.57102084e-01  1.18201257e-01  1.70826745e-01\n",
            "  1.45342967e-01  1.10517297e-01 -3.80710967e-02 -2.30156095e-02\n",
            "  1.39935530e-01  1.46720943e-01  1.48822729e-01  9.78923505e-02\n",
            " -5.98236575e-02 -5.27599063e-02 -4.82335057e-02 -3.86730356e-02\n",
            " -2.81515308e-02 -3.50720184e-02 -3.42407665e-02 -2.84004478e-02\n",
            " -1.96500819e-02 -3.45297552e-02  3.65510233e-03  2.47681689e-02\n",
            " -3.29602013e-02 -1.09711682e-01 -9.86209297e-02 -8.72898234e-02\n",
            " -8.49750941e-02 -9.96656475e-02 -6.40573592e-02 -2.96077997e-02\n",
            " -1.36492174e-02 -3.64626858e-03  5.76639117e-03 -3.50390625e-03\n",
            " -2.31181716e-02 -7.18364453e-03 -2.49031204e-03  9.43666938e-04\n",
            " -6.98140646e-01 -7.65694830e-01 -7.82696478e-01  3.17450863e-01\n",
            "  3.18757069e-01  3.08294103e-01  9.18184899e-02  1.11971608e-01\n",
            "  9.41331175e-02  1.02141280e-01  5.79487261e-02 -1.86774678e-01\n",
            " -1.96959376e-01 -3.56021985e-01 -4.55325445e-01 -4.36486413e-01\n",
            " -3.78518116e-01 -4.35332379e-01 -2.42354162e-01 -2.28304372e-01\n",
            " -2.37408457e-01 -2.28585209e-01 -1.80864048e-01 -1.69195489e-01\n",
            " -1.73049935e-01 -1.56314707e-01 -1.82749348e-01 -2.02763539e-01\n",
            " -2.08876966e-01 -2.25472670e-01 -2.29733971e-01 -2.29723101e-01\n",
            " -2.23072117e-01 -1.58468768e-01 -1.28474947e-01 -5.92918066e-02\n",
            " -4.74287166e-02 -3.77024493e-02 -2.99357500e-02 -1.57723144e-02\n",
            "  1.19726548e-02  2.19059381e-02  1.77770815e-02  2.90304072e-02\n",
            "  3.64851844e-02  4.06476130e-02  4.32727578e-02 -6.39866258e-03\n",
            " -2.12317620e-03  2.01741390e-03  1.13508042e-01  1.67359265e-01\n",
            "  1.85591910e-01  1.29139934e+00  1.28481656e+00  1.36560754e+00\n",
            "  1.38997937e+00  1.45356562e+00  1.41939992e+00  1.41279521e+00\n",
            "  1.02519667e+00  1.11940424e+00  1.15012342e+00  1.18705932e+00\n",
            "  1.25545063e+00  1.25557534e+00  1.27677885e+00  1.25892349e+00\n",
            "  6.96990239e-01  6.65606456e-01  6.70511273e-01  6.96465913e-01\n",
            "  7.39467016e-01  7.11837831e-01  7.06271131e-01  6.66121720e-01\n",
            "  6.73127490e-01  6.82935669e-01  6.91226135e-01  7.00294535e-01\n",
            "  6.91248388e-01  7.02693295e-01  6.16141858e-01  4.66543194e-01\n",
            "  4.63326803e-01  4.00482987e-01  3.66656549e-01  3.35226461e-01\n",
            "  3.18722723e-01  3.00698868e-01  2.01232656e-01  1.19679329e-01\n",
            "  8.60781948e-02  5.00355651e-02  1.67641710e-02  1.78292681e-02\n",
            "  1.32040731e-02  2.93904348e-02  1.56811187e-02  1.05962592e-03]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(-0.0351, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-0.1534, -0.1249, -0.0758,  ..., -0.1676, -0.1825,  1.1551],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.2040, -0.1661, -0.1008,  ..., -0.2228, -0.2426,  1.5423],\n",
            "        [-0.1019, -0.0830, -0.0504,  ..., -0.1113, -0.1212,  0.7599]])\n",
            "   Last layer:\n",
            "tensor([[ 0.3566,  0.1187,  0.0000,  0.4225,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.4507,\n",
            "          0.0000,  0.4582,  0.5471,  0.0868],\n",
            "        [ 0.3345,  0.1118,  0.0000,  0.3959,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.4248,\n",
            "          0.0000,  0.4327,  0.5166,  0.0825],\n",
            "        [ 0.3087,  0.1031,  0.0000,  0.3655,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3918,\n",
            "          0.0000,  0.3990,  0.4764,  0.0760],\n",
            "        [-0.0828, -0.0280,  0.0000, -0.0977,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1065,\n",
            "          0.0000, -0.1091, -0.1302, -0.0212],\n",
            "        [-0.0750, -0.0254,  0.0000, -0.0885,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0966,\n",
            "          0.0000, -0.0989, -0.1180, -0.0192],\n",
            "        [ 0.2809,  0.0943,  0.0000,  0.3321,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3583,\n",
            "          0.0000,  0.3657,  0.4366,  0.0702],\n",
            "        [-0.5887, -0.1976,  0.0000, -0.6961,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.7507,\n",
            "          0.0000, -0.7660, -0.9145, -0.1470],\n",
            "        [-0.2797, -0.0949,  0.0000, -0.3299,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.3607,\n",
            "          0.0000, -0.3698, -0.4413, -0.0721],\n",
            "        [-0.3120, -0.1060,  0.0000, -0.3679,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.4028,\n",
            "          0.0000, -0.4130, -0.4929, -0.0807],\n",
            "        [-0.4405, -0.1481,  0.0000, -0.5207,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.5628,\n",
            "          0.0000, -0.5746, -0.6860, -0.1106]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-0.0050, -0.0042,  0.0047,  ...,  0.0011,  0.0012, -0.0407],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0063, -0.0053,  0.0060,  ...,  0.0014,  0.0015, -0.0516],\n",
            "        [-0.0033, -0.0028,  0.0031,  ...,  0.0007,  0.0008, -0.0269]])\n",
            "   Last layer:\n",
            "tensor([[-0.0121, -0.0036,  0.0000, -0.0108,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0160,\n",
            "          0.0000, -0.0169, -0.0207, -0.0039],\n",
            "        [-0.0100, -0.0030,  0.0000, -0.0088,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0131,\n",
            "          0.0000, -0.0138, -0.0169, -0.0032],\n",
            "        [-0.0103, -0.0031,  0.0000, -0.0092,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0136,\n",
            "          0.0000, -0.0144, -0.0176, -0.0033],\n",
            "        [ 0.0017,  0.0005,  0.0000,  0.0015,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0023,\n",
            "          0.0000,  0.0025,  0.0030,  0.0006],\n",
            "        [ 0.0016,  0.0005,  0.0000,  0.0014,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0021,\n",
            "          0.0000,  0.0022,  0.0027,  0.0005],\n",
            "        [-0.0085, -0.0025,  0.0000, -0.0075,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0112,\n",
            "          0.0000, -0.0119, -0.0145, -0.0028],\n",
            "        [ 0.0188,  0.0056,  0.0000,  0.0168,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0249,\n",
            "          0.0000,  0.0263,  0.0323,  0.0061],\n",
            "        [ 0.0079,  0.0023,  0.0000,  0.0071,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0105,\n",
            "          0.0000,  0.0111,  0.0137,  0.0026],\n",
            "        [ 0.0092,  0.0027,  0.0000,  0.0082,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0122,\n",
            "          0.0000,  0.0129,  0.0158,  0.0030],\n",
            "        [ 0.0135,  0.0040,  0.0000,  0.0120,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0178,\n",
            "          0.0000,  0.0188,  0.0230,  0.0044]])\n",
            "DEBUGGING: training for one iteration takes 0.007435 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 24\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([0.0352, 0.0151, 0.0128, 0.0124, 0.0164, 0.0123, 0.0129, 0.0126, 0.0121,\n",
            "        0.0126, 0.0133, 0.0145, 0.0098, 0.0125, 0.0237, 0.0120, 0.0117, 0.0119,\n",
            "        0.0202, 0.0150, 0.0120, 0.0135, 0.0143, 0.0221, 0.0150, 0.0109, 0.0163,\n",
            "        0.0125, 0.0147, 0.0140, 0.0144, 0.0128, 0.0144, 0.0131, 0.0150, 0.0139,\n",
            "        0.0151, 0.0149, 0.0127, 0.0123, 0.0126, 0.0124, 0.0179, 0.0124, 0.0118,\n",
            "        0.0139, 0.0123, 0.0120, 0.0137, 0.0125, 0.0140, 0.0163, 0.0132, 0.0206,\n",
            "        0.0308, 0.0159, 0.0195, 0.0129, 0.0125, 0.0132, 0.0131, 0.0134, 0.0121,\n",
            "        0.0108, 0.0127, 0.0157, 0.0133, 0.0136, 0.0120],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [9]\n",
            "DEBUGGING: logits looks like: tensor([77.4470, 77.0226, 76.9399, 76.9270, 77.0655, 76.9196, 76.9459, 76.9338,\n",
            "        76.9143, 76.9346, 76.9593, 77.0034, 76.8068, 76.9271, 77.2481, 76.9090,\n",
            "        76.8958, 76.9040, 77.1683, 77.0204, 76.9070, 76.9669, 76.9971, 77.2130,\n",
            "        77.0206, 76.8599, 77.0614, 76.9286, 77.0115, 76.9855, 77.0012, 76.9414,\n",
            "        76.9981, 76.9514, 77.0187, 76.9838, 77.0235, 77.0168, 76.9377, 76.9190,\n",
            "        76.9348, 76.9259, 77.1076, 76.9266, 76.9009, 76.9831, 76.9208, 76.9087,\n",
            "        76.9747, 76.9309, 76.9855, 77.0628, 76.9549, 77.1788, 77.3805, 77.0486,\n",
            "        77.1502, 76.9441, 76.9275, 76.9575, 76.9541, 76.9635, 76.9132, 76.8554,\n",
            "        76.9379, 77.0440, 76.9609, 76.9699, 76.9090], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0276, 0.0142, 0.0128, 0.0127, 0.0135, 0.0113, 0.0128, 0.0126, 0.0142,\n",
            "        0.0145, 0.0130, 0.0130, 0.0135, 0.0134, 0.0121, 0.0128, 0.0098, 0.0125,\n",
            "        0.0129, 0.0121, 0.0126, 0.0138, 0.0140, 0.0137, 0.0125, 0.0135, 0.0125,\n",
            "        0.0134, 0.0137, 0.0132, 0.0135, 0.0117, 0.0121, 0.0124, 0.0119, 0.0126,\n",
            "        0.0121, 0.0140, 0.0140, 0.0130, 0.0126, 0.0127, 0.0129, 0.0145, 0.0117,\n",
            "        0.0136, 0.0132, 0.0119, 0.0122, 0.0123, 0.0108, 0.0122, 0.0133, 0.0128,\n",
            "        0.0146, 0.0119, 0.0139, 0.0135, 0.0122, 0.0129, 0.0123, 0.0128, 0.0108,\n",
            "        0.0132, 0.0136, 0.0136, 0.0125, 0.0139, 0.0137, 0.0126, 0.0117, 0.0082,\n",
            "        0.0138, 0.0124, 0.0128, 0.0133, 0.0119], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [1]\n",
            "DEBUGGING: logits looks like: tensor([77.5047, 77.1715, 77.1201, 77.1164, 77.1465, 77.0574, 77.1205, 77.1143,\n",
            "        77.1718, 77.1843, 77.1289, 77.1281, 77.1462, 77.1445, 77.0946, 77.1229,\n",
            "        76.9854, 77.1109, 77.1233, 77.0933, 77.1145, 77.1604, 77.1651, 77.1546,\n",
            "        77.1095, 77.1490, 77.1092, 77.1428, 77.1559, 77.1363, 77.1478, 77.0754,\n",
            "        77.0912, 77.1038, 77.0867, 77.1142, 77.0949, 77.1646, 77.1649, 77.1276,\n",
            "        77.1138, 77.1155, 77.1265, 77.1828, 77.0774, 77.1498, 77.1353, 77.0858,\n",
            "        77.0991, 77.1030, 77.0380, 77.0959, 77.1413, 77.1218, 77.1885, 77.0832,\n",
            "        77.1641, 77.1462, 77.0965, 77.1234, 77.1031, 77.1226, 77.0342, 77.1377,\n",
            "        77.1499, 77.1515, 77.1090, 77.1633, 77.1539, 77.1146, 77.0753, 76.9001,\n",
            "        77.1584, 77.1041, 77.1218, 77.1394, 77.0865], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0260, 0.0107, 0.0113, 0.0109, 0.0102, 0.0130, 0.0116, 0.0103, 0.0113,\n",
            "        0.0115, 0.0107, 0.0128, 0.0138, 0.0098, 0.0088, 0.0110, 0.0105, 0.0129,\n",
            "        0.0115, 0.0117, 0.0091, 0.0118, 0.0109, 0.0107, 0.0125, 0.0094, 0.0118,\n",
            "        0.0088, 0.0122, 0.0100, 0.0079, 0.0135, 0.0128, 0.0121, 0.0128, 0.0085,\n",
            "        0.0109, 0.0113, 0.0101, 0.0122, 0.0101, 0.0114, 0.0112, 0.0101, 0.0122,\n",
            "        0.0116, 0.0146, 0.0095, 0.0110, 0.0107, 0.0127, 0.0093, 0.0085, 0.0119,\n",
            "        0.0109, 0.0114, 0.0102, 0.0100, 0.0088, 0.0102, 0.0120, 0.0115, 0.0113,\n",
            "        0.0152, 0.0094, 0.0125, 0.0124, 0.0097, 0.0115, 0.0119, 0.0120, 0.0101,\n",
            "        0.0112, 0.0124, 0.0097, 0.0113, 0.0103, 0.0105, 0.0117, 0.0090, 0.0121,\n",
            "        0.0100, 0.0119, 0.0115, 0.0092, 0.0117, 0.0116, 0.0113, 0.0098],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [88]\n",
            "DEBUGGING: logits looks like: tensor([77.5442, 77.0991, 77.1271, 77.1093, 77.0765, 77.1986, 77.1396, 77.0820,\n",
            "        77.1282, 77.1357, 77.1017, 77.1894, 77.2275, 77.0571, 77.0037, 77.1138,\n",
            "        77.0931, 77.1928, 77.1358, 77.1453, 77.0185, 77.1504, 77.1109, 77.0986,\n",
            "        77.1777, 77.0361, 77.1503, 77.0032, 77.1660, 77.0675, 76.9479, 77.2159,\n",
            "        77.1900, 77.1622, 77.1911, 76.9833, 77.1078, 77.1289, 77.0707, 77.1663,\n",
            "        77.0735, 77.1323, 77.1215, 77.0699, 77.1669, 77.1411, 77.2558, 77.0400,\n",
            "        77.1164, 77.1020, 77.1850, 77.0333, 76.9858, 77.1535, 77.1079, 77.1331,\n",
            "        77.0750, 77.0684, 77.0006, 77.0776, 77.1592, 77.1350, 77.1281, 77.2771,\n",
            "        77.0364, 77.1777, 77.1760, 77.0495, 77.1373, 77.1521, 77.1584, 77.0724,\n",
            "        77.1222, 77.1751, 77.0507, 77.1292, 77.0801, 77.0899, 77.1475, 77.0119,\n",
            "        77.1623, 77.0673, 77.1527, 77.1366, 77.0275, 77.1454, 77.1425, 77.1287,\n",
            "        77.0571], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0245, 0.0101, 0.0100, 0.0099, 0.0119, 0.0097, 0.0084, 0.0101, 0.0096,\n",
            "        0.0109, 0.0101, 0.0102, 0.0100, 0.0104, 0.0101, 0.0099, 0.0102, 0.0100,\n",
            "        0.0095, 0.0097, 0.0094, 0.0096, 0.0099, 0.0087, 0.0097, 0.0099, 0.0101,\n",
            "        0.0105, 0.0095, 0.0101, 0.0099, 0.0098, 0.0103, 0.0111, 0.0103, 0.0096,\n",
            "        0.0099, 0.0101, 0.0099, 0.0103, 0.0104, 0.0099, 0.0103, 0.0106, 0.0112,\n",
            "        0.0107, 0.0104, 0.0104, 0.0099, 0.0103, 0.0096, 0.0100, 0.0099, 0.0090,\n",
            "        0.0102, 0.0099, 0.0094, 0.0102, 0.0099, 0.0101, 0.0120, 0.0099, 0.0099,\n",
            "        0.0103, 0.0103, 0.0104, 0.0100, 0.0100, 0.0102, 0.0094, 0.0098, 0.0107,\n",
            "        0.0101, 0.0113, 0.0100, 0.0095, 0.0093, 0.0096, 0.0101, 0.0098, 0.0105,\n",
            "        0.0103, 0.0093, 0.0101, 0.0100, 0.0098, 0.0099, 0.0102, 0.0101, 0.0106,\n",
            "        0.0100, 0.0093, 0.0097, 0.0102, 0.0105, 0.0102, 0.0101, 0.0105],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [38]\n",
            "DEBUGGING: logits looks like: tensor([77.5582, 77.1125, 77.1094, 77.1032, 77.1983, 77.0963, 77.0207, 77.1138,\n",
            "        77.0917, 77.1544, 77.1131, 77.1196, 77.1081, 77.1280, 77.1127, 77.1036,\n",
            "        77.1206, 77.1113, 77.0866, 77.0951, 77.0802, 77.0885, 77.1026, 77.0406,\n",
            "        77.0940, 77.1062, 77.1141, 77.1342, 77.0850, 77.1130, 77.1033, 77.0994,\n",
            "        77.1252, 77.1620, 77.1247, 77.0910, 77.1065, 77.1164, 77.1027, 77.1257,\n",
            "        77.1316, 77.1062, 77.1257, 77.1379, 77.1643, 77.1437, 77.1308, 77.1303,\n",
            "        77.1022, 77.1243, 77.0901, 77.1102, 77.1057, 77.0594, 77.1221, 77.1059,\n",
            "        77.0779, 77.1201, 77.1041, 77.1144, 77.2000, 77.1043, 77.1028, 77.1230,\n",
            "        77.1230, 77.1284, 77.1110, 77.1107, 77.1202, 77.0808, 77.1014, 77.1438,\n",
            "        77.1138, 77.1704, 77.1094, 77.0822, 77.0726, 77.0903, 77.1141, 77.0999,\n",
            "        77.1349, 77.1249, 77.0734, 77.1154, 77.1107, 77.0987, 77.1039, 77.1193,\n",
            "        77.1171, 77.1374, 77.1100, 77.0753, 77.0920, 77.1175, 77.1323, 77.1200,\n",
            "        77.1166, 77.1324], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0231, 0.0092, 0.0095, 0.0091, 0.0091, 0.0092, 0.0092, 0.0092, 0.0093,\n",
            "        0.0094, 0.0093, 0.0092, 0.0091, 0.0091, 0.0094, 0.0093, 0.0093, 0.0093,\n",
            "        0.0092, 0.0092, 0.0093, 0.0093, 0.0092, 0.0094, 0.0093, 0.0091, 0.0092,\n",
            "        0.0092, 0.0092, 0.0094, 0.0092, 0.0093, 0.0091, 0.0092, 0.0093, 0.0092,\n",
            "        0.0091, 0.0092, 0.0092, 0.0094, 0.0093, 0.0093, 0.0092, 0.0092, 0.0083,\n",
            "        0.0094, 0.0091, 0.0093, 0.0091, 0.0092, 0.0092, 0.0090, 0.0092, 0.0092,\n",
            "        0.0092, 0.0093, 0.0091, 0.0093, 0.0093, 0.0093, 0.0092, 0.0094, 0.0093,\n",
            "        0.0090, 0.0094, 0.0092, 0.0092, 0.0091, 0.0094, 0.0093, 0.0092, 0.0092,\n",
            "        0.0093, 0.0098, 0.0090, 0.0094, 0.0092, 0.0093, 0.0092, 0.0094, 0.0091,\n",
            "        0.0091, 0.0092, 0.0090, 0.0091, 0.0091, 0.0094, 0.0091, 0.0092, 0.0091,\n",
            "        0.0092, 0.0092, 0.0091, 0.0091, 0.0092, 0.0090, 0.0093, 0.0094, 0.0088,\n",
            "        0.0091, 0.0092, 0.0092, 0.0093, 0.0094, 0.0092, 0.0092, 0.0092],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [71]\n",
            "DEBUGGING: logits looks like: tensor([77.5681, 77.1081, 77.1231, 77.1019, 77.1049, 77.1099, 77.1084, 77.1093,\n",
            "        77.1111, 77.1173, 77.1121, 77.1103, 77.1013, 77.1014, 77.1171, 77.1120,\n",
            "        77.1125, 77.1152, 77.1061, 77.1079, 77.1137, 77.1143, 77.1068, 77.1174,\n",
            "        77.1133, 77.1037, 77.1101, 77.1077, 77.1088, 77.1166, 77.1077, 77.1150,\n",
            "        77.1024, 77.1100, 77.1120, 77.1099, 77.1051, 77.1091, 77.1081, 77.1202,\n",
            "        77.1132, 77.1148, 77.1067, 77.1102, 77.0584, 77.1186, 77.1051, 77.1121,\n",
            "        77.1045, 77.1072, 77.1104, 77.0966, 77.1087, 77.1077, 77.1067, 77.1155,\n",
            "        77.1033, 77.1119, 77.1114, 77.1140, 77.1076, 77.1213, 77.1136, 77.0997,\n",
            "        77.1176, 77.1063, 77.1081, 77.1035, 77.1179, 77.1146, 77.1106, 77.1086,\n",
            "        77.1157, 77.1401, 77.0945, 77.1174, 77.1105, 77.1139, 77.1101, 77.1163,\n",
            "        77.1015, 77.1033, 77.1063, 77.0996, 77.1034, 77.1053, 77.1185, 77.1003,\n",
            "        77.1108, 77.1029, 77.1074, 77.1069, 77.1026, 77.1044, 77.1074, 77.0950,\n",
            "        77.1158, 77.1170, 77.0847, 77.1038, 77.1065, 77.1084, 77.1135, 77.1168,\n",
            "        77.1066, 77.1067, 77.1081], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.07645168822955384 and immediate abs rewards look like: [0.003618813007051358, 0.002586994500234141, 0.00013138358599462663, 0.014026229217961372, 0.0004707509092440887, 0.00010965266983475885, 0.0010729008317866828, 0.0009962363956219633, 0.0005594348776867264, 0.0013438439186757023, 1.661741862335475e-05, 0.0001997477929762681, 0.0017050530673259345, 0.012572792409628164, 0.0010042634694400476, 0.002377668999997695, 0.00024040320113272173, 0.0006425861774914665, 0.0017295627653766132, 1.1292952876829077e-05, 9.779413630894851e-06, 0.0005214377470110776, 0.00020067343348273425, 2.964849045383744e-05, 0.00019776769522650284, 0.00041125547659248696, 0.0014092876822360267, 0.0014489258619505563, 0.004574873785713862, 0.0009406311278326029, 8.481751274302951e-05, 0.004472556285236351, 5.81103672629979e-05, 0.0006077590001041244, 0.006768028907117696, 0.00029494399359464296, 9.661177409725497e-05, 0.00045986612531123683, 0.0005204578505981772, 8.03060947873746e-06, 0.00018765515505947405, 0.0038475313717754034, 3.005699454661226e-05, 0.0005234636878412857, 6.565196144947549e-06, 3.902086291418527e-05, 0.00047884048990454176, 0.0006846181408945995, 0.0004837874362237926, 0.0016384575856136507]\n",
            "DEBUGGING: the total relative reward of the trajectory = 5.618444955290919 and immediate relative rewards look like: [0.013374053088048218, 0.019147126993621963, 0.0014600121047436145, 0.20783378646543918, 0.008764735365420375, 0.00245032805805895, 0.027972361403595575, 0.029695967587114163, 0.018767152271397886, 0.05010092337546623, 0.0006818216474306207, 0.008940884143651755, 0.08268578308189906, 0.6570307418306536, 0.05649471329760543, 0.14272625239586667, 0.015346496073779359, 0.04343733341737467, 0.12343946078858802, 0.0008489533848869669, 0.0007719342069206714, 0.04311961951937013, 0.017352123072957446, 0.0026753554812937756, 0.018589506913806373, 0.04020590536772726, 0.14309860090251839, 0.15265337054573952, 0.4994777595738584, 0.10642123334101583, 0.009919482164667513, 0.5399598453425418, 0.00724697340901833, 0.07809243432967046, 0.8954238466970388, 0.04023953622770125, 0.01354850067965428, 0.066235432368813, 0.07694869093005795, 0.0012179943118083777, 0.02917309056337618, 0.6127741652066597, 0.004908141641922069, 0.0874676127282947, 0.0011221595194749216, 0.006817892704905217, 0.08548513911115455, 0.12484482262112666, 0.09008335119240739, 0.31137154784077575]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([0.0201, 0.0143, 0.0146, 0.0143, 0.0156, 0.0148, 0.0138, 0.0158, 0.0146,\n",
            "        0.0126, 0.0115, 0.0139, 0.0151, 0.0154, 0.0126, 0.0148, 0.0147, 0.0151,\n",
            "        0.0149, 0.0149, 0.0129, 0.0146, 0.0148, 0.0146, 0.0145, 0.0138, 0.0144,\n",
            "        0.0152, 0.0129, 0.0137, 0.0142, 0.0155, 0.0137, 0.0175, 0.0142, 0.0201,\n",
            "        0.0142, 0.0152, 0.0152, 0.0141, 0.0145, 0.0142, 0.0139, 0.0146, 0.0144,\n",
            "        0.0133, 0.0154, 0.0140, 0.0145, 0.0149, 0.0152, 0.0146, 0.0149, 0.0151,\n",
            "        0.0131, 0.0146, 0.0149, 0.0143, 0.0159, 0.0150, 0.0147, 0.0154, 0.0148,\n",
            "        0.0154, 0.0137, 0.0150, 0.0156, 0.0159], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [3]\n",
            "DEBUGGING: logits looks like: tensor([77.2774, 77.1078, 77.1168, 77.1071, 77.1507, 77.1236, 77.0907, 77.1569,\n",
            "        77.1185, 77.0429, 76.9973, 77.0931, 77.1346, 77.1432, 77.0437, 77.1259,\n",
            "        77.1208, 77.1358, 77.1272, 77.1269, 77.0569, 77.1179, 77.1242, 77.1170,\n",
            "        77.1136, 77.0878, 77.1124, 77.1370, 77.0569, 77.0866, 77.1039, 77.1479,\n",
            "        77.0846, 77.2092, 77.1028, 77.2779, 77.1053, 77.1370, 77.1376, 77.1020,\n",
            "        77.1151, 77.1040, 77.0936, 77.1167, 77.1099, 77.0709, 77.1432, 77.0981,\n",
            "        77.1157, 77.1265, 77.1367, 77.1177, 77.1272, 77.1330, 77.0627, 77.1173,\n",
            "        77.1265, 77.1084, 77.1601, 77.1304, 77.1209, 77.1429, 77.1236, 77.1459,\n",
            "        77.0862, 77.1307, 77.1508, 77.1601], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0192, 0.0126, 0.0128, 0.0126, 0.0127, 0.0124, 0.0127, 0.0131, 0.0121,\n",
            "        0.0127, 0.0123, 0.0125, 0.0127, 0.0128, 0.0127, 0.0126, 0.0130, 0.0125,\n",
            "        0.0125, 0.0116, 0.0127, 0.0124, 0.0125, 0.0126, 0.0128, 0.0125, 0.0127,\n",
            "        0.0127, 0.0127, 0.0126, 0.0127, 0.0128, 0.0127, 0.0128, 0.0126, 0.0126,\n",
            "        0.0124, 0.0128, 0.0127, 0.0128, 0.0123, 0.0125, 0.0126, 0.0124, 0.0128,\n",
            "        0.0127, 0.0130, 0.0127, 0.0122, 0.0126, 0.0127, 0.0121, 0.0126, 0.0126,\n",
            "        0.0126, 0.0122, 0.0123, 0.0126, 0.0125, 0.0126, 0.0122, 0.0121, 0.0126,\n",
            "        0.0126, 0.0128, 0.0126, 0.0124, 0.0127, 0.0125, 0.0128, 0.0127, 0.0127,\n",
            "        0.0127, 0.0125, 0.0126, 0.0126, 0.0126, 0.0128, 0.0116],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [76]\n",
            "DEBUGGING: logits looks like: tensor([77.3195, 77.1092, 77.1189, 77.1096, 77.1120, 77.1021, 77.1141, 77.1277,\n",
            "        77.0890, 77.1145, 77.0993, 77.1042, 77.1147, 77.1174, 77.1123, 77.1089,\n",
            "        77.1232, 77.1058, 77.1047, 77.0684, 77.1148, 77.1031, 77.1071, 77.1082,\n",
            "        77.1156, 77.1063, 77.1153, 77.1150, 77.1147, 77.1109, 77.1123, 77.1187,\n",
            "        77.1121, 77.1181, 77.1093, 77.1097, 77.1000, 77.1174, 77.1145, 77.1155,\n",
            "        77.0990, 77.1059, 77.1094, 77.1030, 77.1177, 77.1142, 77.1245, 77.1117,\n",
            "        77.0926, 77.1109, 77.1124, 77.0893, 77.1101, 77.1075, 77.1096, 77.0947,\n",
            "        77.0960, 77.1087, 77.1039, 77.1091, 77.0933, 77.0897, 77.1102, 77.1104,\n",
            "        77.1156, 77.1095, 77.1032, 77.1141, 77.1052, 77.1164, 77.1121, 77.1122,\n",
            "        77.1147, 77.1057, 77.1086, 77.1097, 77.1103, 77.1164, 77.0684],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0170, 0.0112, 0.0112, 0.0112, 0.0111, 0.0112, 0.0112, 0.0111, 0.0112,\n",
            "        0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0111, 0.0112, 0.0110, 0.0112,\n",
            "        0.0112, 0.0112, 0.0112, 0.0111, 0.0111, 0.0112, 0.0111, 0.0111, 0.0112,\n",
            "        0.0111, 0.0109, 0.0111, 0.0110, 0.0112, 0.0112, 0.0112, 0.0111, 0.0112,\n",
            "        0.0111, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112,\n",
            "        0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0111, 0.0112, 0.0112, 0.0113,\n",
            "        0.0111, 0.0112, 0.0112, 0.0113, 0.0112, 0.0113, 0.0111, 0.0111, 0.0111,\n",
            "        0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0113, 0.0112, 0.0112, 0.0111,\n",
            "        0.0112, 0.0112, 0.0110, 0.0111, 0.0112, 0.0112, 0.0112, 0.0113, 0.0111,\n",
            "        0.0111, 0.0111, 0.0112, 0.0111, 0.0112, 0.0112, 0.0112, 0.0111],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [16]\n",
            "DEBUGGING: logits looks like: tensor([77.3301, 77.1212, 77.1179, 77.1212, 77.1172, 77.1211, 77.1202, 77.1135,\n",
            "        77.1180, 77.1193, 77.1220, 77.1188, 77.1218, 77.1203, 77.1169, 77.1187,\n",
            "        77.1131, 77.1198, 77.1216, 77.1213, 77.1186, 77.1177, 77.1147, 77.1207,\n",
            "        77.1175, 77.1151, 77.1181, 77.1174, 77.1078, 77.1176, 77.1121, 77.1194,\n",
            "        77.1196, 77.1191, 77.1135, 77.1181, 77.1145, 77.1188, 77.1202, 77.1203,\n",
            "        77.1185, 77.1222, 77.1201, 77.1188, 77.1215, 77.1205, 77.1203, 77.1198,\n",
            "        77.1216, 77.1206, 77.1177, 77.1193, 77.1206, 77.1240, 77.1161, 77.1191,\n",
            "        77.1178, 77.1246, 77.1193, 77.1225, 77.1153, 77.1133, 77.1169, 77.1192,\n",
            "        77.1190, 77.1213, 77.1208, 77.1180, 77.1231, 77.1209, 77.1199, 77.1143,\n",
            "        77.1187, 77.1198, 77.1132, 77.1171, 77.1188, 77.1180, 77.1203, 77.1224,\n",
            "        77.1168, 77.1166, 77.1171, 77.1182, 77.1153, 77.1217, 77.1209, 77.1180,\n",
            "        77.1155], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0106, 0.0109, 0.0092, 0.0110, 0.0110, 0.0103, 0.0106, 0.0103, 0.0104,\n",
            "        0.0104, 0.0122, 0.0109, 0.0100, 0.0113, 0.0124, 0.0095, 0.0094, 0.0107,\n",
            "        0.0121, 0.0120, 0.0107, 0.0106, 0.0108, 0.0100, 0.0100, 0.0117, 0.0099,\n",
            "        0.0114, 0.0100, 0.0097, 0.0111, 0.0098, 0.0103, 0.0113, 0.0117, 0.0103,\n",
            "        0.0106, 0.0108, 0.0103, 0.0095, 0.0109, 0.0110, 0.0102, 0.0104, 0.0109,\n",
            "        0.0099, 0.0104, 0.0104, 0.0094, 0.0105, 0.0101, 0.0106, 0.0097, 0.0101,\n",
            "        0.0100, 0.0112, 0.0106, 0.0108, 0.0100, 0.0118, 0.0098, 0.0100, 0.0108,\n",
            "        0.0108, 0.0097, 0.0079, 0.0104, 0.0114, 0.0093, 0.0100, 0.0101, 0.0106,\n",
            "        0.0112, 0.0103, 0.0108, 0.0098, 0.0114, 0.0110, 0.0094, 0.0115, 0.0114,\n",
            "        0.0112, 0.0088, 0.0113, 0.0062, 0.0107, 0.0102, 0.0107, 0.0109, 0.0101,\n",
            "        0.0081, 0.0068, 0.0111, 0.0102, 0.0107, 0.0113],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [83]\n",
            "DEBUGGING: logits looks like: tensor([77.1194, 77.1312, 77.0454, 77.1355, 77.1360, 77.1029, 77.1167, 77.1038,\n",
            "        77.1109, 77.1099, 77.1884, 77.1327, 77.0889, 77.1514, 77.1970, 77.0616,\n",
            "        77.0564, 77.1219, 77.1846, 77.1807, 77.1220, 77.1203, 77.1277, 77.0918,\n",
            "        77.0898, 77.1684, 77.0841, 77.1564, 77.0879, 77.0756, 77.1417, 77.0792,\n",
            "        77.1025, 77.1523, 77.1678, 77.1070, 77.1188, 77.1285, 77.1029, 77.0664,\n",
            "        77.1309, 77.1380, 77.1005, 77.1080, 77.1313, 77.0825, 77.1078, 77.1076,\n",
            "        77.0567, 77.1131, 77.0936, 77.1211, 77.0742, 77.0942, 77.0876, 77.1451,\n",
            "        77.1175, 77.1293, 77.0879, 77.1725, 77.0780, 77.0915, 77.1260, 77.1286,\n",
            "        77.0768, 76.9710, 77.1114, 77.1547, 77.0515, 77.0910, 77.0931, 77.1204,\n",
            "        77.1481, 77.1032, 77.1296, 77.0817, 77.1554, 77.1360, 77.0588, 77.1600,\n",
            "        77.1565, 77.1457, 77.0268, 77.1520, 76.8503, 77.1224, 77.0986, 77.1215,\n",
            "        77.1350, 77.0951, 76.9865, 76.9002, 77.1425, 77.1016, 77.1228, 77.1523],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0093, 0.0097, 0.0096, 0.0089, 0.0092, 0.0092, 0.0090, 0.0095, 0.0093,\n",
            "        0.0097, 0.0088, 0.0096, 0.0093, 0.0097, 0.0094, 0.0097, 0.0095, 0.0092,\n",
            "        0.0094, 0.0089, 0.0083, 0.0089, 0.0096, 0.0095, 0.0094, 0.0098, 0.0088,\n",
            "        0.0092, 0.0098, 0.0095, 0.0086, 0.0094, 0.0091, 0.0099, 0.0094, 0.0091,\n",
            "        0.0100, 0.0094, 0.0092, 0.0093, 0.0098, 0.0098, 0.0095, 0.0094, 0.0091,\n",
            "        0.0097, 0.0098, 0.0096, 0.0098, 0.0101, 0.0096, 0.0095, 0.0094, 0.0095,\n",
            "        0.0093, 0.0092, 0.0103, 0.0094, 0.0089, 0.0095, 0.0094, 0.0089, 0.0094,\n",
            "        0.0097, 0.0095, 0.0094, 0.0093, 0.0085, 0.0092, 0.0098, 0.0096, 0.0092,\n",
            "        0.0084, 0.0099, 0.0097, 0.0090, 0.0095, 0.0098, 0.0095, 0.0094, 0.0084,\n",
            "        0.0082, 0.0095, 0.0088, 0.0094, 0.0085, 0.0096, 0.0095, 0.0098, 0.0096,\n",
            "        0.0097, 0.0092, 0.0093, 0.0095, 0.0086, 0.0095, 0.0093, 0.0090, 0.0095,\n",
            "        0.0093, 0.0087, 0.0091, 0.0090, 0.0099, 0.0094, 0.0092, 0.0089],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [30]\n",
            "DEBUGGING: logits looks like: tensor([77.0389, 77.0603, 77.0588, 77.0215, 77.0335, 77.0345, 77.0279, 77.0526,\n",
            "        77.0418, 77.0639, 77.0156, 77.0582, 77.0397, 77.0641, 77.0475, 77.0611,\n",
            "        77.0522, 77.0339, 77.0474, 77.0195, 76.9866, 77.0209, 77.0588, 77.0515,\n",
            "        77.0468, 77.0688, 77.0146, 77.0341, 77.0660, 77.0536, 77.0016, 77.0468,\n",
            "        77.0298, 77.0706, 77.0460, 77.0310, 77.0782, 77.0467, 77.0379, 77.0440,\n",
            "        77.0695, 77.0667, 77.0542, 77.0444, 77.0305, 77.0634, 77.0695, 77.0559,\n",
            "        77.0655, 77.0832, 77.0581, 77.0536, 77.0449, 77.0537, 77.0394, 77.0360,\n",
            "        77.0914, 77.0483, 77.0200, 77.0536, 77.0479, 77.0184, 77.0495, 77.0610,\n",
            "        77.0539, 77.0477, 77.0399, 76.9938, 77.0385, 77.0655, 77.0585, 77.0387,\n",
            "        76.9885, 77.0738, 77.0621, 77.0247, 77.0545, 77.0695, 77.0525, 77.0460,\n",
            "        76.9887, 76.9788, 77.0539, 77.0150, 77.0483, 76.9950, 77.0570, 77.0545,\n",
            "        77.0656, 77.0577, 77.0621, 77.0337, 77.0392, 77.0540, 77.0035, 77.0507,\n",
            "        77.0441, 77.0273, 77.0535, 77.0425, 77.0108, 77.0280, 77.0257, 77.0742,\n",
            "        77.0469, 77.0360, 77.0219], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.6072478073094771 and immediate abs rewards look like: [0.021818130716383166, 0.08825414502052809, 0.0005616608434593218, 0.07409669975481847, 0.08003217314535505, 3.859534376715601e-05, 0.00013677202878170647, 0.0009089178904559958, 0.000449370144679051, 0.0037683218611164193, 0.00022962099637879874, 0.000275628546887674, 2.170194761674793e-05, 0.0008812892067453504, 0.00420144577242354, 0.0026771394664137915, 0.0003743540169125481, 0.0004979807542895287, 0.0006931892767170211, 0.0002573001131622732, 0.0016950442393408593, 6.085908580644173e-06, 9.993906019190035e-05, 0.00015345461156357487, 0.0001659087249663571, 0.00022858646548229444, 0.0023518904313277744, 0.0005870315876563836, 0.00023769007248120033, 1.6485717196701444e-05, 4.369027737993747e-05, 0.3214875633602787, 4.547473508864641e-13, 9.094947017729282e-13, 2.2737367544323206e-13, 0.0, 2.2737367544323206e-13, 2.2737367544323206e-13, 2.2737367544323206e-13, 4.547473508864641e-13, 0.0, 0.0, 9.094947017729282e-13, 6.821210263296962e-13, 2.2737367544323206e-13, 2.2737367544323206e-13, 4.547473508864641e-13, 2.2737367544323206e-13, 6.821210263296962e-13, 0.0]\n",
            "DEBUGGING: the total relative reward of the trajectory = 34.593922795519106 and immediate relative rewards look like: [0.06048414714456524, 0.4922932701585972, 0.004818123983680485, 0.8476394877367789, 1.1692004619325425, 0.0006928140672397683, 0.002864381612108791, 0.021755444371169566, 0.012103700364071096, 0.11279188096144577, 0.007568751682512318, 0.00991186320759169, 0.000845527612731638, 0.03697728695753803, 0.1889266834407539, 0.1285705796249609, 0.01911750296630966, 0.026929832539703817, 0.039574825218448, 0.015465857688153568, 0.10698871068562285, 0.00040263084569535864, 0.006912304001793807, 0.011075516059672634, 0.012473894364270528, 0.017874683382053065, 0.19099641032866393, 0.049473334634366546, 0.02075092521296179, 0.0014889790986329099, 0.004077633161798043, 30.972875349627603, 5.002220859751484e-11, 1.0307606620095531e-10, 2.6526928801708398e-11, 0.0, 2.8042753304661037e-11, 2.8800665556140544e-11, 2.955857780761569e-11, 6.063298011819062e-11, 0.0, 0.0, 1.303609072541296e-10, 1.0004441719499936e-10, 3.410605131648481e-11, 3.486396356795961e-11, 7.124375163887937e-11, 3.637978807091162e-11, 1.1141310096715838e-10, 0.0]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([0.0195, 0.0144, 0.0138, 0.0156, 0.0152, 0.0140, 0.0148, 0.0134, 0.0162,\n",
            "        0.0141, 0.0146, 0.0151, 0.0145, 0.0153, 0.0135, 0.0137, 0.0137, 0.0178,\n",
            "        0.0158, 0.0136, 0.0132, 0.0136, 0.0132, 0.0138, 0.0146, 0.0138, 0.0147,\n",
            "        0.0130, 0.0141, 0.0132, 0.0144, 0.0149, 0.0149, 0.0153, 0.0151, 0.0148,\n",
            "        0.0133, 0.0148, 0.0128, 0.0159, 0.0153, 0.0160, 0.0150, 0.0135, 0.0147,\n",
            "        0.0160, 0.0146, 0.0146, 0.0148, 0.0151, 0.0140, 0.0140, 0.0137, 0.0133,\n",
            "        0.0138, 0.0144, 0.0157, 0.0134, 0.0152, 0.0133, 0.0146, 0.0138, 0.0147,\n",
            "        0.0121, 0.0147, 0.0154, 0.0120, 0.0150, 0.0150],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [59]\n",
            "DEBUGGING: logits looks like: tensor([77.5081, 77.3564, 77.3370, 77.3986, 77.3848, 77.3431, 77.3710, 77.3198,\n",
            "        77.4170, 77.3456, 77.3647, 77.3809, 77.3609, 77.3891, 77.3261, 77.3312,\n",
            "        77.3317, 77.4629, 77.4038, 77.3292, 77.3138, 77.3281, 77.3134, 77.3361,\n",
            "        77.3632, 77.3371, 77.3684, 77.3057, 77.3484, 77.3126, 77.3580, 77.3755,\n",
            "        77.3748, 77.3880, 77.3829, 77.3707, 77.3173, 77.3698, 77.2975, 77.4076,\n",
            "        77.3887, 77.4096, 77.3794, 77.3271, 77.3690, 77.4118, 77.3653, 77.3645,\n",
            "        77.3697, 77.3822, 77.3452, 77.3438, 77.3332, 77.3188, 77.3375, 77.3585,\n",
            "        77.4021, 77.3230, 77.3841, 77.3195, 77.3645, 77.3355, 77.3672, 77.2725,\n",
            "        77.3693, 77.3896, 77.2674, 77.3785, 77.3779], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0184, 0.0124, 0.0127, 0.0124, 0.0124, 0.0125, 0.0124, 0.0123, 0.0124,\n",
            "        0.0125, 0.0122, 0.0123, 0.0122, 0.0127, 0.0124, 0.0126, 0.0124, 0.0124,\n",
            "        0.0125, 0.0127, 0.0124, 0.0125, 0.0123, 0.0124, 0.0123, 0.0124, 0.0124,\n",
            "        0.0123, 0.0129, 0.0124, 0.0125, 0.0124, 0.0124, 0.0124, 0.0123, 0.0125,\n",
            "        0.0124, 0.0124, 0.0123, 0.0119, 0.0122, 0.0125, 0.0123, 0.0125, 0.0123,\n",
            "        0.0123, 0.0127, 0.0122, 0.0125, 0.0127, 0.0124, 0.0123, 0.0125, 0.0124,\n",
            "        0.0122, 0.0125, 0.0124, 0.0124, 0.0122, 0.0126, 0.0124, 0.0125, 0.0122,\n",
            "        0.0124, 0.0129, 0.0123, 0.0126, 0.0125, 0.0124, 0.0123, 0.0122, 0.0129,\n",
            "        0.0124, 0.0122, 0.0124, 0.0123, 0.0125, 0.0125, 0.0128, 0.0122],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [4]\n",
            "DEBUGGING: logits looks like: tensor([77.4636, 77.2667, 77.2755, 77.2634, 77.2641, 77.2696, 77.2657, 77.2619,\n",
            "        77.2648, 77.2708, 77.2571, 77.2616, 77.2558, 77.2753, 77.2649, 77.2742,\n",
            "        77.2658, 77.2669, 77.2692, 77.2768, 77.2638, 77.2704, 77.2613, 77.2662,\n",
            "        77.2632, 77.2663, 77.2667, 77.2604, 77.2863, 77.2657, 77.2699, 77.2645,\n",
            "        77.2644, 77.2658, 77.2604, 77.2707, 77.2656, 77.2662, 77.2624, 77.2467,\n",
            "        77.2557, 77.2707, 77.2593, 77.2689, 77.2609, 77.2621, 77.2789, 77.2592,\n",
            "        77.2684, 77.2775, 77.2672, 77.2617, 77.2675, 77.2665, 77.2576, 77.2708,\n",
            "        77.2648, 77.2667, 77.2557, 77.2729, 77.2664, 77.2684, 77.2581, 77.2671,\n",
            "        77.2838, 77.2629, 77.2718, 77.2677, 77.2643, 77.2612, 77.2570, 77.2845,\n",
            "        77.2661, 77.2576, 77.2669, 77.2619, 77.2689, 77.2694, 77.2820, 77.2576],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0167, 0.0112, 0.0112, 0.0113, 0.0111, 0.0112, 0.0111, 0.0112, 0.0111,\n",
            "        0.0112, 0.0111, 0.0112, 0.0114, 0.0112, 0.0111, 0.0112, 0.0113, 0.0113,\n",
            "        0.0111, 0.0113, 0.0112, 0.0112, 0.0112, 0.0112, 0.0113, 0.0112, 0.0112,\n",
            "        0.0111, 0.0112, 0.0108, 0.0112, 0.0112, 0.0112, 0.0112, 0.0111, 0.0111,\n",
            "        0.0111, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0111, 0.0111, 0.0113,\n",
            "        0.0112, 0.0112, 0.0112, 0.0112, 0.0111, 0.0111, 0.0111, 0.0113, 0.0111,\n",
            "        0.0111, 0.0111, 0.0112, 0.0112, 0.0111, 0.0111, 0.0112, 0.0112, 0.0112,\n",
            "        0.0111, 0.0112, 0.0112, 0.0113, 0.0112, 0.0112, 0.0111, 0.0112, 0.0112,\n",
            "        0.0112, 0.0112, 0.0111, 0.0113, 0.0111, 0.0112, 0.0111, 0.0111, 0.0111,\n",
            "        0.0111, 0.0111, 0.0113, 0.0113, 0.0111, 0.0112, 0.0111, 0.0111],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [71]\n",
            "DEBUGGING: logits looks like: tensor([77.4415, 77.2416, 77.2422, 77.2457, 77.2381, 77.2428, 77.2396, 77.2416,\n",
            "        77.2389, 77.2418, 77.2362, 77.2412, 77.2491, 77.2401, 77.2375, 77.2414,\n",
            "        77.2462, 77.2444, 77.2384, 77.2466, 77.2403, 77.2420, 77.2404, 77.2430,\n",
            "        77.2450, 77.2414, 77.2442, 77.2375, 77.2428, 77.2226, 77.2418, 77.2408,\n",
            "        77.2414, 77.2422, 77.2389, 77.2379, 77.2391, 77.2408, 77.2415, 77.2411,\n",
            "        77.2431, 77.2442, 77.2362, 77.2398, 77.2472, 77.2406, 77.2427, 77.2406,\n",
            "        77.2416, 77.2379, 77.2391, 77.2379, 77.2445, 77.2397, 77.2376, 77.2391,\n",
            "        77.2408, 77.2409, 77.2396, 77.2382, 77.2425, 77.2439, 77.2421, 77.2375,\n",
            "        77.2416, 77.2438, 77.2487, 77.2414, 77.2415, 77.2388, 77.2426, 77.2410,\n",
            "        77.2409, 77.2426, 77.2386, 77.2447, 77.2397, 77.2421, 77.2381, 77.2356,\n",
            "        77.2376, 77.2384, 77.2379, 77.2451, 77.2451, 77.2369, 77.2438, 77.2397,\n",
            "        77.2398], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0149, 0.0101, 0.0102, 0.0101, 0.0102, 0.0103, 0.0102, 0.0102, 0.0101,\n",
            "        0.0102, 0.0102, 0.0101, 0.0101, 0.0102, 0.0102, 0.0101, 0.0101, 0.0102,\n",
            "        0.0101, 0.0101, 0.0101, 0.0101, 0.0101, 0.0101, 0.0101, 0.0101, 0.0101,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0101, 0.0102, 0.0101, 0.0101, 0.0101,\n",
            "        0.0101, 0.0101, 0.0101, 0.0102, 0.0101, 0.0102, 0.0101, 0.0101, 0.0101,\n",
            "        0.0101, 0.0102, 0.0102, 0.0101, 0.0101, 0.0102, 0.0102, 0.0102, 0.0101,\n",
            "        0.0101, 0.0102, 0.0101, 0.0102, 0.0102, 0.0102, 0.0101, 0.0102, 0.0102,\n",
            "        0.0101, 0.0101, 0.0101, 0.0102, 0.0102, 0.0101, 0.0102, 0.0101, 0.0102,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0101, 0.0101, 0.0101, 0.0102,\n",
            "        0.0102, 0.0101, 0.0102, 0.0101, 0.0102, 0.0102, 0.0101, 0.0101, 0.0102,\n",
            "        0.0102, 0.0101, 0.0102, 0.0102, 0.0101, 0.0101, 0.0102, 0.0102],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [15]\n",
            "DEBUGGING: logits looks like: tensor([77.4245, 77.2329, 77.2346, 77.2308, 77.2341, 77.2410, 77.2347, 77.2336,\n",
            "        77.2323, 77.2336, 77.2360, 77.2320, 77.2329, 77.2341, 77.2337, 77.2330,\n",
            "        77.2299, 77.2345, 77.2331, 77.2314, 77.2317, 77.2325, 77.2326, 77.2324,\n",
            "        77.2330, 77.2321, 77.2332, 77.2337, 77.2351, 77.2378, 77.2334, 77.2316,\n",
            "        77.2339, 77.2330, 77.2318, 77.2332, 77.2330, 77.2324, 77.2324, 77.2340,\n",
            "        77.2320, 77.2334, 77.2319, 77.2331, 77.2331, 77.2317, 77.2350, 77.2334,\n",
            "        77.2321, 77.2322, 77.2352, 77.2355, 77.2348, 77.2330, 77.2329, 77.2340,\n",
            "        77.2323, 77.2376, 77.2338, 77.2333, 77.2316, 77.2351, 77.2335, 77.2329,\n",
            "        77.2320, 77.2323, 77.2342, 77.2339, 77.2327, 77.2348, 77.2325, 77.2341,\n",
            "        77.2337, 77.2342, 77.2336, 77.2332, 77.2332, 77.2331, 77.2330, 77.2320,\n",
            "        77.2340, 77.2360, 77.2331, 77.2357, 77.2323, 77.2342, 77.2334, 77.2326,\n",
            "        77.2330, 77.2351, 77.2357, 77.2329, 77.2336, 77.2338, 77.2324, 77.2323,\n",
            "        77.2338, 77.2333], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0096, 0.0090, 0.0107, 0.0106, 0.0094, 0.0097, 0.0089, 0.0091, 0.0082,\n",
            "        0.0092, 0.0090, 0.0093, 0.0102, 0.0085, 0.0103, 0.0096, 0.0086, 0.0085,\n",
            "        0.0086, 0.0117, 0.0082, 0.0096, 0.0100, 0.0109, 0.0094, 0.0096, 0.0097,\n",
            "        0.0085, 0.0117, 0.0092, 0.0116, 0.0085, 0.0080, 0.0092, 0.0095, 0.0091,\n",
            "        0.0111, 0.0102, 0.0094, 0.0093, 0.0093, 0.0085, 0.0087, 0.0095, 0.0097,\n",
            "        0.0092, 0.0101, 0.0096, 0.0094, 0.0103, 0.0092, 0.0099, 0.0101, 0.0083,\n",
            "        0.0109, 0.0093, 0.0095, 0.0101, 0.0103, 0.0090, 0.0103, 0.0078, 0.0094,\n",
            "        0.0102, 0.0095, 0.0088, 0.0101, 0.0079, 0.0093, 0.0095, 0.0104, 0.0097,\n",
            "        0.0099, 0.0087, 0.0101, 0.0090, 0.0085, 0.0089, 0.0104, 0.0094, 0.0086,\n",
            "        0.0100, 0.0084, 0.0098, 0.0070, 0.0097, 0.0087, 0.0086, 0.0091, 0.0088,\n",
            "        0.0098, 0.0086, 0.0092, 0.0089, 0.0122, 0.0096, 0.0097, 0.0098, 0.0081,\n",
            "        0.0078, 0.0099, 0.0088, 0.0093, 0.0095, 0.0098, 0.0099],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [62]\n",
            "DEBUGGING: logits looks like: tensor([77.2047, 77.1729, 77.2562, 77.2534, 77.1931, 77.2100, 77.1647, 77.1795,\n",
            "        77.1243, 77.1814, 77.1729, 77.1884, 77.2335, 77.1401, 77.2386, 77.2020,\n",
            "        77.1508, 77.1450, 77.1477, 77.3034, 77.1230, 77.2060, 77.2231, 77.2649,\n",
            "        77.1909, 77.2042, 77.2090, 77.1426, 77.3004, 77.1807, 77.2987, 77.1455,\n",
            "        77.1095, 77.1844, 77.1979, 77.1764, 77.2780, 77.2342, 77.1928, 77.1898,\n",
            "        77.1890, 77.1409, 77.1565, 77.1965, 77.2106, 77.1810, 77.2305, 77.2035,\n",
            "        77.1914, 77.2399, 77.1798, 77.2175, 77.2292, 77.1317, 77.2692, 77.1881,\n",
            "        77.1984, 77.2314, 77.2406, 77.1685, 77.2409, 77.1020, 77.1904, 77.2320,\n",
            "        77.1973, 77.1581, 77.2269, 77.1046, 77.1883, 77.1985, 77.2433, 77.2102,\n",
            "        77.2181, 77.1546, 77.2280, 77.1724, 77.1407, 77.1642, 77.2456, 77.1953,\n",
            "        77.1504, 77.2216, 77.1368, 77.2158, 77.0424, 77.2085, 77.1563, 77.1463,\n",
            "        77.1787, 77.1591, 77.2150, 77.1507, 77.1814, 77.1676, 77.3215, 77.2056,\n",
            "        77.2075, 77.2162, 77.1186, 77.1012, 77.2204, 77.1598, 77.1890, 77.1982,\n",
            "        77.2164, 77.2172], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.7082653196207502 and immediate abs rewards look like: [0.01800319187805144, 0.01692824666361048, 0.006575228018846246, 0.0020798785399165354, 0.003228708781534806, 0.010933356234090752, 0.0027611908494691306, 0.000527148945366207, 0.0002137127112291637, 0.0008659516320221883, 0.011461826512459083, 0.0059421968271635706, 0.0008631776281617931, 0.003230699243431445, 4.3101521896460326e-05, 5.998848610033747e-05, 0.00025533045482006855, 0.00031404420724356896, 0.001854451568760851, 1.5732543033664115e-05, 0.0004653107798731071, 0.0015477323172490287, 0.00018437048402120126, 0.00026767451390696806, 0.0003652940204119659, 7.762554605506011e-05, 2.6270710804965347e-05, 0.0003411459560993535, 8.914466889109462e-06, 1.283383880945621e-06, 8.424686257058056e-06, 0.0005528538868020405, 0.00026597169153319555, 0.00023189289368019672, 0.00014538656796503346, 5.4013898989069276e-06, 0.00023349720095211524, 2.56551502388902e-05, 4.847879836233915e-05, 0.00017189861773658777, 0.00034643212620721897, 0.0002921162422353518, 4.396180929688853e-05, 0.6164505631322754, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13]\n",
            "DEBUGGING: the total relative reward of the trajectory = 76.81225150784313 and immediate relative rewards look like: [0.048548823577426944, 0.0917454970819079, 0.05369967635707798, 0.022689014868008332, 0.04405172977211648, 0.17916436446423123, 0.052946849677373994, 0.011561058687632124, 0.005273633033338024, 0.023744122617128494, 0.3457897683972938, 0.19618295688915088, 0.03092339128097042, 0.12467273077472395, 0.0017836830723872976, 0.002648054233961566, 0.011975612057201828, 0.01559696384944158, 0.09722624280846628, 0.0008686916028360295, 0.026977456098718385, 0.09401841217146745, 0.011713839000906105, 0.0177468141902671, 0.02522997527113855, 0.005576428014967147, 0.001959850692387561, 0.026393003190163605, 0.0007143727243733133, 0.00010639234836843777, 0.000721685773483247, 0.048887076932709675, 0.02425768953792849, 0.021792063743557223, 0.01406540265011683, 0.0005375084824338374, 0.023881485894534985, 0.002695033283888136, 0.005226675142158726, 0.019008473885460505, 0.03926788671199827, 0.033922051232386376, 0.005227044550265834, 75.00123202106671, 0.0, 0.0, 0.0, 0.0, 7.427540064478913e-11, 7.579122514773254e-11]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 3\n",
            "DEBUGGING: the action_prob is: tensor([0.0333, 0.0143, 0.0168, 0.0135, 0.0146, 0.0149, 0.0148, 0.0146, 0.0140,\n",
            "        0.0162, 0.0150, 0.0150, 0.0138, 0.0154, 0.0152, 0.0156, 0.0140, 0.0146,\n",
            "        0.0147, 0.0155, 0.0155, 0.0143, 0.0162, 0.0155, 0.0149, 0.0141, 0.0156,\n",
            "        0.0138, 0.0153, 0.0149, 0.0146, 0.0167, 0.0140, 0.0153, 0.0147, 0.0138,\n",
            "        0.0148, 0.0147, 0.0160, 0.0140, 0.0151, 0.0146, 0.0158, 0.0138, 0.0146,\n",
            "        0.0140, 0.0143, 0.0151, 0.0158, 0.0148, 0.0152, 0.0153, 0.0155, 0.0141,\n",
            "        0.0148, 0.0171, 0.0138, 0.0145, 0.0147, 0.0155, 0.0136, 0.0155, 0.0144,\n",
            "        0.0142, 0.0144, 0.0151], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [16]\n",
            "DEBUGGING: logits looks like: tensor([78.3778, 77.9566, 78.0350, 77.9268, 77.9645, 77.9769, 77.9729, 77.9660,\n",
            "        77.9463, 78.0185, 77.9795, 77.9788, 77.9390, 77.9937, 77.9844, 78.0003,\n",
            "        77.9465, 77.9659, 77.9684, 77.9944, 77.9954, 77.9547, 78.0165, 77.9966,\n",
            "        77.9764, 77.9467, 77.9989, 77.9371, 77.9883, 77.9775, 77.9648, 78.0330,\n",
            "        77.9437, 77.9906, 77.9700, 77.9383, 77.9734, 77.9680, 78.0115, 77.9465,\n",
            "        77.9830, 77.9651, 78.0063, 77.9378, 77.9657, 77.9438, 77.9564, 77.9816,\n",
            "        78.0051, 77.9715, 77.9844, 77.9893, 77.9952, 77.9470, 77.9726, 78.0452,\n",
            "        77.9360, 77.9635, 77.9695, 77.9945, 77.9294, 77.9956, 77.9605, 77.9534,\n",
            "        77.9606, 77.9827], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0311, 0.0131, 0.0128, 0.0129, 0.0130, 0.0128, 0.0128, 0.0129, 0.0129,\n",
            "        0.0129, 0.0130, 0.0130, 0.0129, 0.0129, 0.0127, 0.0129, 0.0129, 0.0130,\n",
            "        0.0130, 0.0131, 0.0129, 0.0128, 0.0130, 0.0130, 0.0129, 0.0130, 0.0128,\n",
            "        0.0129, 0.0130, 0.0130, 0.0129, 0.0130, 0.0128, 0.0128, 0.0130, 0.0128,\n",
            "        0.0129, 0.0129, 0.0129, 0.0130, 0.0129, 0.0129, 0.0128, 0.0129, 0.0127,\n",
            "        0.0129, 0.0130, 0.0129, 0.0129, 0.0129, 0.0128, 0.0130, 0.0129, 0.0130,\n",
            "        0.0129, 0.0127, 0.0130, 0.0128, 0.0129, 0.0130, 0.0129, 0.0129, 0.0128,\n",
            "        0.0129, 0.0131, 0.0129, 0.0130, 0.0130, 0.0129, 0.0128, 0.0129, 0.0130,\n",
            "        0.0130, 0.0130, 0.0130, 0.0129], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [4]\n",
            "DEBUGGING: logits looks like: tensor([78.4396, 78.0067, 77.9970, 78.0010, 78.0023, 77.9967, 77.9946, 78.0008,\n",
            "        77.9973, 77.9976, 78.0042, 78.0016, 77.9982, 78.0009, 77.9925, 77.9998,\n",
            "        78.0007, 78.0013, 78.0024, 78.0052, 78.0003, 77.9958, 78.0023, 78.0041,\n",
            "        78.0001, 78.0011, 77.9949, 77.9997, 78.0013, 78.0047, 77.9994, 78.0042,\n",
            "        77.9959, 77.9945, 78.0013, 77.9943, 77.9989, 78.0000, 78.0004, 78.0012,\n",
            "        77.9991, 77.9997, 77.9949, 78.0007, 77.9896, 78.0007, 78.0013, 78.0011,\n",
            "        78.0011, 78.0005, 77.9966, 78.0033, 77.9996, 78.0044, 77.9985, 77.9920,\n",
            "        78.0039, 77.9969, 77.9997, 78.0017, 77.9982, 77.9979, 77.9963, 77.9997,\n",
            "        78.0069, 77.9979, 78.0043, 78.0022, 78.0003, 77.9960, 78.0002, 78.0022,\n",
            "        78.0013, 78.0028, 78.0032, 77.9997], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0264, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112,\n",
            "        0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112,\n",
            "        0.0112, 0.0113, 0.0111, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112,\n",
            "        0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0115,\n",
            "        0.0112, 0.0112, 0.0112, 0.0112, 0.0113, 0.0111, 0.0112, 0.0112, 0.0113,\n",
            "        0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112,\n",
            "        0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0114, 0.0112, 0.0113,\n",
            "        0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112,\n",
            "        0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112,\n",
            "        0.0111, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [41]\n",
            "DEBUGGING: logits looks like: tensor([78.4700, 78.0403, 78.0400, 78.0389, 78.0407, 78.0404, 78.0410, 78.0395,\n",
            "        78.0391, 78.0384, 78.0412, 78.0418, 78.0396, 78.0405, 78.0414, 78.0391,\n",
            "        78.0385, 78.0403, 78.0400, 78.0428, 78.0369, 78.0384, 78.0402, 78.0412,\n",
            "        78.0390, 78.0388, 78.0394, 78.0393, 78.0383, 78.0392, 78.0408, 78.0391,\n",
            "        78.0395, 78.0395, 78.0400, 78.0526, 78.0389, 78.0399, 78.0383, 78.0418,\n",
            "        78.0436, 78.0379, 78.0394, 78.0390, 78.0428, 78.0395, 78.0387, 78.0392,\n",
            "        78.0397, 78.0403, 78.0392, 78.0387, 78.0416, 78.0395, 78.0386, 78.0411,\n",
            "        78.0409, 78.0415, 78.0401, 78.0387, 78.0511, 78.0389, 78.0435, 78.0392,\n",
            "        78.0419, 78.0384, 78.0402, 78.0384, 78.0393, 78.0412, 78.0389, 78.0394,\n",
            "        78.0390, 78.0388, 78.0392, 78.0391, 78.0395, 78.0389, 78.0386, 78.0392,\n",
            "        78.0389, 78.0356, 78.0397, 78.0385, 78.0407, 78.0418, 78.0415, 78.0400],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0241, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0101, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0101, 0.0102, 0.0102, 0.0102, 0.0101, 0.0102, 0.0101, 0.0101,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0101, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0101, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0101, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102, 0.0102,\n",
            "        0.0102, 0.0102, 0.0102, 0.0101, 0.0102, 0.0102, 0.0102],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [62]\n",
            "DEBUGGING: logits looks like: tensor([78.4944, 78.0623, 78.0627, 78.0616, 78.0620, 78.0619, 78.0624, 78.0624,\n",
            "        78.0616, 78.0611, 78.0618, 78.0614, 78.0617, 78.0616, 78.0623, 78.0620,\n",
            "        78.0625, 78.0623, 78.0622, 78.0610, 78.0625, 78.0618, 78.0612, 78.0606,\n",
            "        78.0615, 78.0610, 78.0603, 78.0615, 78.0618, 78.0615, 78.0634, 78.0608,\n",
            "        78.0614, 78.0619, 78.0612, 78.0621, 78.0615, 78.0614, 78.0622, 78.0629,\n",
            "        78.0635, 78.0625, 78.0621, 78.0616, 78.0623, 78.0619, 78.0613, 78.0621,\n",
            "        78.0621, 78.0618, 78.0622, 78.0614, 78.0621, 78.0623, 78.0623, 78.0613,\n",
            "        78.0619, 78.0621, 78.0629, 78.0609, 78.0613, 78.0616, 78.0622, 78.0620,\n",
            "        78.0608, 78.0621, 78.0614, 78.0617, 78.0616, 78.0621, 78.0625, 78.0614,\n",
            "        78.0618, 78.0616, 78.0616, 78.0628, 78.0619, 78.0618, 78.0623, 78.0623,\n",
            "        78.0613, 78.0617, 78.0619, 78.0613, 78.0627, 78.0612, 78.0617, 78.0622,\n",
            "        78.0612, 78.0621, 78.0622, 78.0622, 78.0617, 78.0607, 78.0616, 78.0623,\n",
            "        78.0623], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0217, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091,\n",
            "        0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091, 0.0091],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [62]\n",
            "DEBUGGING: logits looks like: tensor([78.5144, 78.0823, 78.0826, 78.0826, 78.0826, 78.0827, 78.0824, 78.0826,\n",
            "        78.0827, 78.0826, 78.0826, 78.0826, 78.0825, 78.0826, 78.0825, 78.0827,\n",
            "        78.0827, 78.0827, 78.0827, 78.0825, 78.0826, 78.0825, 78.0824, 78.0823,\n",
            "        78.0826, 78.0825, 78.0827, 78.0826, 78.0826, 78.0827, 78.0826, 78.0823,\n",
            "        78.0826, 78.0827, 78.0826, 78.0826, 78.0827, 78.0826, 78.0826, 78.0826,\n",
            "        78.0826, 78.0826, 78.0826, 78.0827, 78.0826, 78.0826, 78.0826, 78.0825,\n",
            "        78.0826, 78.0826, 78.0825, 78.0826, 78.0825, 78.0825, 78.0828, 78.0828,\n",
            "        78.0827, 78.0827, 78.0827, 78.0827, 78.0824, 78.0826, 78.0827, 78.0825,\n",
            "        78.0826, 78.0826, 78.0825, 78.0826, 78.0827, 78.0825, 78.0826, 78.0824,\n",
            "        78.0827, 78.0826, 78.0825, 78.0826, 78.0825, 78.0826, 78.0825, 78.0826,\n",
            "        78.0826, 78.0828, 78.0827, 78.0827, 78.0826, 78.0826, 78.0825, 78.0828,\n",
            "        78.0826, 78.0828, 78.0825, 78.0825, 78.0827, 78.0824, 78.0826, 78.0825,\n",
            "        78.0826, 78.0825, 78.0826, 78.0826, 78.0826, 78.0826, 78.0826, 78.0827,\n",
            "        78.0825, 78.0826, 78.0827, 78.0826], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.17258515290041032 and immediate abs rewards look like: [0.004696446445905167, 0.018189859280937526, 0.011749029649763543, 0.03906423982971319, 0.008214629946905916, 0.028236780513452686, 0.028199862117617158, 0.008720961198378063, 0.013048748648088804, 0.004793536215402128, 0.0013749303411714209, 0.00013488982631315594, 6.770478375983657e-05, 0.0009452723493268422, 0.0006654713843090576, 0.0012266659109627653, 0.0001706467865005834, 3.8741710341128055e-05, 0.0002657739833011874, 0.0007436585615323565, 9.479085747443605e-07, 0.00016278114389933762, 1.531415136923897e-05, 0.00013918649119659676, 9.88883107311267e-05, 6.608090552617796e-05, 0.0001596014094502607, 0.00018978841353600728, 3.5093617498205276e-05, 0.00034308457406950765, 0.00018392120773569332, 8.357500064448686e-06, 0.00028833575424869196, 0.00011609539751589182, 1.6891699488041922e-06, 2.6150058147322852e-05, 0.00015343351287810947, 2.0680681700468995e-07, 1.951878221007064e-05, 1.140762833529152e-06, 1.1131674455100438e-05, 1.5453988453373313e-06, 6.461648808908649e-06, 8.258612069766968e-07, 1.0550547813181765e-07, 2.0055722416145727e-06, 1.1288011592114344e-06, 2.040401341218967e-07, 4.238871497364016e-06, 4.016465027234517e-08]\n",
            "DEBUGGING: the total relative reward of the trajectory = 3.6645984734530774 and immediate relative rewards look like: [0.016269024171890467, 0.1262288411344237, 0.12307567479216291, 0.5478651903880916, 0.14600974080650284, 0.6040325324935139, 0.7109404356289858, 0.25384926219384063, 0.42866023429434585, 0.17580502084428032, 0.05556647224959761, 0.005950032327016278, 0.0032355128266939115, 0.048649257607027305, 0.03670817664173137, 0.07219294219523807, 0.010675580477586705, 0.002566392227866096, 0.0185842053251108, 0.05474241940437026, 7.328667939139804e-05, 0.013184577765191456, 0.0012968395557371446, 0.012299182743988961, 0.009102803114633958, 0.006326380802365789, 0.015867812137310765, 0.01956905323024893, 0.003747991329303887, 0.03790534908531687, 0.02100034528184456, 0.0009851190552830412, 0.035049040145224884, 0.014541316870970858, 0.00021780597213978117, 0.0034681975157677307, 0.020914852184507345, 2.8953818256320318e-05, 0.002804624705686053, 0.00016811865538877456, 0.0016815318180101483, 0.00023914009134512056, 0.00102370440067023, 0.000133882416103045, 1.7492482740755147e-05, 0.00033990698473859195, 0.00019546975688215865, 3.608454939776289e-05, 0.0007652631699791689, 7.3991043758034085e-06]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 200 number of matrices\n",
            "DEBUGGING: ACT_MAT has 200 number of matrices\n",
            "DEBUGGING: VAL looks like: [[4.232502500426047, 4.261745906402019, 4.285453312533734, 4.327265960029283, 4.161042599559439, 4.194220064842443, 4.234110845236752, 4.248624731144603, 4.2615442056136255, 4.2856333872143715, 4.278315620039298, 4.3208422205978465, 4.355455895408277, 4.315929406390281, 3.6958572369289167, 3.676123761243749, 3.569088392775639, 3.589638279496828, 3.5820211576560133, 3.493516865522652, 3.5279473859977424, 3.562803486657396, 3.5552362294323494, 3.5736203094539314, 3.6070151050228665, 3.624672321322283, 3.6206731474288443, 3.5127015621478037, 3.3939880723253175, 2.923747790658039, 2.8457844013303264, 2.8645100193592516, 2.3480304788047572, 2.3644277832280194, 2.3094296453518677, 1.4282886855099282, 1.4020698477598252, 1.4025468152324958, 1.3498094776400835, 1.2857179663737632, 1.2974747192544998, 1.2811127562536602, 0.6750894859060611, 0.6769508527920596, 0.5954376162260251, 0.6003186431379295, 0.5994957075081053, 0.5192025943403543, 0.3983411835547754, 0.31137154784077575], [26.05640422157367, 26.258505125685964, 26.026476621744816, 26.284503533092053, 25.69380206601543, 24.772324852608975, 25.02185054398155, 25.271703194312565, 25.50499772721353, 25.750398006918648, 25.896571844401215, 26.150508174463337, 26.404642738642167, 26.670502233363067, 26.902550450914678, 26.98345835098376, 27.126149263998787, 27.38084016265907, 27.630212454666026, 27.869330938835937, 28.13521725368463, 28.31134196262526, 28.596908415938955, 28.878783951451677, 29.159301449890915, 29.44123995507742, 29.720570981510473, 29.827853102203846, 30.079171482393413, 30.36204096684894, 30.667224230050817, 30.972875350392947, 7.730757870742117e-10, 7.303571499764614e-10, 6.336172563388951e-10, 6.132225530678654e-10, 6.194167202705712e-10, 5.973474413797072e-10, 5.742896725490572e-10, 5.502334290317591e-10, 4.945459079935035e-10, 4.995413212055591e-10, 5.045871931369284e-10, 3.780063493765645e-10, 2.8076962846622745e-10, 2.491551284340835e-10, 2.164557220869938e-10, 1.466787580283984e-10, 1.1141310096715838e-10, 0.0], [50.266689260899625, 50.72539438113353, 51.14509988288043, 51.6074749560842, 52.10584438506686, 52.58766934878257, 52.93788382254378, 53.41912825542061, 53.94703757245755, 54.48663024184264, 55.01301628204597, 55.219420720857244, 55.57902804441221, 56.109196619324486, 56.55002412984824, 57.119434794723084, 57.69372398029205, 58.264392291146315, 58.83716699726957, 59.333273489354646, 59.931722017931115, 60.50984299174989, 61.0260854339176, 61.630678378703735, 62.23528440859946, 62.83843882154376, 63.467537771241204, 64.10664436419073, 64.72752662727329, 65.3806184389383, 66.04092125918174, 66.70727229637198, 67.33170224185784, 67.98731772961607, 68.65204612714395, 69.33129366110488, 70.03106682083074, 70.71432862114769, 71.42589251299374, 72.14208670490059, 72.85159417274255, 73.5478043293238, 74.25644674554688, 75.00123202120871, 1.4342535448576017e-10, 1.4487409544016178e-10, 1.4633747014157755e-10, 1.478156264056339e-10, 1.4930871354104434e-10, 7.579122514773254e-11], [3.4034312675504914, 3.4213760034127283, 3.3284314770487926, 3.237733133592555, 2.7170383264691553, 2.596998571376417, 2.0130970089726294, 1.3153096700440845, 1.0721822301517614, 0.6500222180377936, 0.4790072698924377, 0.4277179774170102, 0.42602822736363016, 0.4270633480171073, 0.3822364549596768, 0.3490184629474196, 0.2796217381335167, 0.2716627855110404, 0.27181453866987304, 0.25578821549975983, 0.20307656171251473, 0.20505381316477103, 0.1938073084844238, 0.1944550191198855, 0.18399579431908739, 0.1766595870752055, 0.17205374370993912, 0.15776356724507914, 0.13959041819679818, 0.13721457259342856, 0.1003123469778906, 0.08011313302630912, 0.0799272868394203, 0.04533156231736911, 0.0311012580266649, 0.031195406115681938, 0.028007281414054758, 0.007164069928835769, 0.007207187990484292, 0.004447033621008323, 0.004322136328908635, 0.0026672772837358456, 0.0024526638306977024, 0.0014433933636641139, 0.0013227383308697666, 0.0013184301496252642, 0.000988407237259265, 0.000800946949875865, 0.0007725882833112143, 7.3991043758034085e-06]]\n",
            "DEBUGGING: traj_returns = [4.232502500426047, 26.05640422157367, 50.266689260899625, 3.4034312675504914]\n",
            "DEBUGGING: actions = [[9], [52], [49], [28], [43], [30], [49], [17], [12], [9], [44], [36], [32], [34], [58], [30], [33], [12], [55], [1], [44], [48], [22], [39], [17], [46], [84], [40], [13], [88], [85], [23], [74], [18], [72], [74], [25], [61], [21], [38], [53], [70], [82], [27], [44], [50], [31], [52], [38], [71], [33], [18], [12], [24], [4], [36], [26], [20], [56], [3], [12], [44], [17], [7], [19], [16], [3], [61], [20], [76], [76], [13], [10], [3], [67], [68], [43], [55], [33], [16], [11], [0], [23], [6], [77], [90], [49], [2], [35], [83], [68], [39], [67], [91], [5], [79], [10], [49], [50], [30], [53], [25], [16], [53], [54], [3], [65], [58], [44], [59], [56], [29], [1], [64], [36], [18], [74], [52], [7], [4], [60], [61], [6], [39], [60], [6], [2], [1], [66], [71], [83], [61], [73], [60], [1], [51], [48], [52], [48], [15], [60], [89], [80], [0], [28], [45], [80], [46], [19], [62], [18], [24], [31], [15], [9], [52], [49], [17], [52], [16], [67], [41], [1], [37], [33], [41], [26], [40], [67], [4], [12], [9], [45], [64], [77], [81], [25], [79], [78], [41], [50], [51], [5], [11], [26], [88], [55], [74], [13], [62], [32], [31], [6], [15], [56], [49], [19], [104], [51], [62]]\n",
            "DEBUGGING: actions length = 200\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[ 3.3085,  2.9014,  2.8325,  ..., -1.6749, -2.3336, -3.5524],\n",
            "        [ 3.2898,  2.8678,  2.8234,  ..., -1.6481, -2.3123, -3.5154],\n",
            "        [ 3.2397,  2.8422,  2.7566,  ..., -1.6234, -2.2715, -3.4710],\n",
            "        ...,\n",
            "        [ 3.3031,  2.8945,  2.8222,  ..., -1.6708, -2.3275, -3.5462],\n",
            "        [ 3.3031,  2.8945,  2.8222,  ..., -1.6708, -2.3275, -3.5462],\n",
            "        [ 3.3030,  2.8945,  2.8222,  ..., -1.6708, -2.3275, -3.5462]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[ 3.3189,  2.9103,  2.8364,  ..., -1.6834, -2.3415, -3.5662],\n",
            "        [ 3.3030,  2.8945,  2.8222,  ..., -1.6708, -2.3275, -3.5462],\n",
            "        [ 3.3030,  2.8945,  2.8222,  ..., -1.6708, -2.3275, -3.5462],\n",
            "        ...,\n",
            "        [ 3.3030,  2.8945,  2.8222,  ..., -1.6708, -2.3275, -3.5462],\n",
            "        [ 3.3030,  2.8945,  2.8222,  ..., -1.6708, -2.3275, -3.5462],\n",
            "        [ 3.3030,  2.8945,  2.8222,  ..., -1.6708, -2.3275, -3.5462]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([78.5144, 78.0823, 78.0826, 78.0826, 78.0826, 78.0827, 78.0824, 78.0826,\n",
            "        78.0827, 78.0826, 78.0826, 78.0826, 78.0825, 78.0826, 78.0825, 78.0827,\n",
            "        78.0827, 78.0827, 78.0827, 78.0825, 78.0826, 78.0825, 78.0824, 78.0823,\n",
            "        78.0826, 78.0825, 78.0827, 78.0826, 78.0826, 78.0827, 78.0826, 78.0823,\n",
            "        78.0826, 78.0827, 78.0826, 78.0826, 78.0827, 78.0826, 78.0826, 78.0826,\n",
            "        78.0826, 78.0826, 78.0826, 78.0827, 78.0826, 78.0826, 78.0826, 78.0825,\n",
            "        78.0826, 78.0826, 78.0825, 78.0826, 78.0825, 78.0825, 78.0828, 78.0828,\n",
            "        78.0827, 78.0827, 78.0827, 78.0827, 78.0824, 78.0826, 78.0827, 78.0825,\n",
            "        78.0826, 78.0826, 78.0825, 78.0826, 78.0827, 78.0825, 78.0826, 78.0824,\n",
            "        78.0827, 78.0826, 78.0825, 78.0826, 78.0825, 78.0826, 78.0825, 78.0826,\n",
            "        78.0826, 78.0828, 78.0827, 78.0827, 78.0826, 78.0826, 78.0825, 78.0828,\n",
            "        78.0826, 78.0828, 78.0825, 78.0825, 78.0827, 78.0824, 78.0826, 78.0825,\n",
            "        78.0826, 78.0825, 78.0826, 78.0826, 78.0826, 78.0826, 78.0826, 78.0827,\n",
            "        78.0825, 78.0826, 78.0827, 78.0826], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[20.98975681 21.16675535 21.19636532 21.3642444  21.16943184 21.03780321\n",
            "  21.05173556 21.06369146 21.19644043 21.29317096 21.41672775 21.52962227\n",
            "  21.69128873 21.8806729  21.88266707 22.03200884 22.16714584 22.37663338\n",
            "  22.58030379 22.73797738 22.9494908  23.14726056 23.34300935 23.56938441\n",
            "  23.79639919 24.02025267 24.24520891 24.40124065 24.58506915 24.70090544\n",
            "  24.91356056 25.1561927  17.439915   17.59926927 17.74814426 17.69769444\n",
            "  17.86528599 18.03100988 18.19572729 18.35806293 18.53834776 18.70789609\n",
            "  18.73349722 18.91990657  0.14919009  0.15040927  0.15012103  0.13000089\n",
            "   0.09977844  0.07784474]]\n",
            "DEBUGGING: baseline2 looks like: 20.98975681261246\n",
            "DEBUGGING: ADS looks like: [-16.75725431 -16.90500945 -16.91091201 -17.03697844 -17.00838924\n",
            " -16.84358314 -16.81762471 -16.81506673 -16.93489623 -17.00753758\n",
            " -17.13841213 -17.20878005 -17.33583283 -17.5647435  -18.18680983\n",
            " -18.35588508 -18.59805745 -18.7869951  -18.99828263 -19.24446051\n",
            " -19.42154342 -19.58445708 -19.78777312 -19.99576411 -20.18938408\n",
            " -20.39558035 -20.62453576 -20.88853909 -21.19108108 -21.77715765\n",
            " -22.06777616 -22.29168268 -15.09188452 -15.23484149 -15.43871461\n",
            " -16.26940575 -16.46321614 -16.62846306 -16.84591782 -17.07234496\n",
            " -17.24087304 -17.42678333 -18.05840774 -18.24295571   0.44624753\n",
            "   0.44990937   0.44937468   0.38920171   0.29856274   0.23352681\n",
            "   5.06664741   5.09174977   4.8301113    4.92025914   4.52437022\n",
            "   3.73452164   3.97011499   4.20801173   4.30855729   4.45722704\n",
            "   4.47984409   4.6208859    4.71335401   4.78982933   5.01988338\n",
            "   4.95144951   4.95900342   5.00420678   5.04990867   5.13135356\n",
            "   5.18572645   5.1640814    5.25389907   5.30939954   5.36290226\n",
            "   5.42098728   5.47536207   5.42661245   5.49410233   5.66113552\n",
            "   5.75366367   5.81668265 -17.439915   -17.59926927 -17.74814426\n",
            " -17.69769444 -17.86528599 -18.03100988 -18.19572729 -18.35806293\n",
            " -18.53834776 -18.70789609 -18.73349722 -18.91990657  -0.14919009\n",
            "  -0.15040927  -0.15012103  -0.13000089  -0.09977844  -0.07784474\n",
            "  29.27693245  29.55863903  29.94873456  30.24323056  30.93641254\n",
            "  31.54986614  31.88614827  32.35543679  32.75059714  33.19345928\n",
            "  33.59628853  33.68979845  33.88773932  34.22852372  34.66735706\n",
            "  35.08742595  35.52657814  35.88775891  36.25686321  36.59529611\n",
            "  36.98223121  37.36258243  37.68307609  38.06129396  38.43888522\n",
            "  38.81818615  39.22232886  39.70540372  40.14245748  40.679713\n",
            "  41.1273607   41.5510796   49.89178724  50.38804846  50.90390187\n",
            "  51.63359922  52.16578083  52.68331874  53.23016522  53.78402378\n",
            "  54.31324642  54.83990824  55.52294952  56.08132545  -0.14919009\n",
            "  -0.15040927  -0.15012103  -0.13000089  -0.09977844  -0.07784474\n",
            " -17.58632555 -17.74537935 -17.86793385 -18.12651126 -18.45239352\n",
            " -18.44080464 -19.03863855 -19.74838179 -20.1242582  -20.64314875\n",
            " -20.93772048 -21.1019043  -21.2652605  -21.45360955 -21.50043061\n",
            " -21.68299038 -21.88752411 -22.10497059 -22.30848925 -22.48218916\n",
            " -22.74641424 -22.94220675 -23.14920204 -23.3749294  -23.6124034\n",
            " -23.84359308 -24.07315517 -24.24347708 -24.44547873 -24.56369087\n",
            " -24.81324821 -25.07607957 -17.35998772 -17.55393771 -17.717043\n",
            " -17.66649903 -17.83727871 -18.02384581 -18.18852011 -18.35361589\n",
            " -18.53402562 -18.70522881 -18.73104456 -18.91846317  -0.14786735\n",
            "  -0.14909084  -0.14913262  -0.12919994  -0.09900585  -0.07783734]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(-0.2244, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-0.0050, -0.0042,  0.0047,  ...,  0.0011,  0.0012, -0.0407],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0063, -0.0053,  0.0060,  ...,  0.0014,  0.0015, -0.0516],\n",
            "        [-0.0033, -0.0028,  0.0031,  ...,  0.0007,  0.0008, -0.0269]])\n",
            "   Last layer:\n",
            "tensor([[-0.0121, -0.0036,  0.0000, -0.0108,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0160,\n",
            "          0.0000, -0.0169, -0.0207, -0.0039],\n",
            "        [-0.0100, -0.0030,  0.0000, -0.0088,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0131,\n",
            "          0.0000, -0.0138, -0.0169, -0.0032],\n",
            "        [-0.0103, -0.0031,  0.0000, -0.0092,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0136,\n",
            "          0.0000, -0.0144, -0.0176, -0.0033],\n",
            "        [ 0.0017,  0.0005,  0.0000,  0.0015,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0023,\n",
            "          0.0000,  0.0025,  0.0030,  0.0006],\n",
            "        [ 0.0016,  0.0005,  0.0000,  0.0014,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0021,\n",
            "          0.0000,  0.0022,  0.0027,  0.0005],\n",
            "        [-0.0085, -0.0025,  0.0000, -0.0075,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0112,\n",
            "          0.0000, -0.0119, -0.0145, -0.0028],\n",
            "        [ 0.0188,  0.0056,  0.0000,  0.0168,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0249,\n",
            "          0.0000,  0.0263,  0.0323,  0.0061],\n",
            "        [ 0.0079,  0.0023,  0.0000,  0.0071,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0105,\n",
            "          0.0000,  0.0111,  0.0137,  0.0026],\n",
            "        [ 0.0092,  0.0027,  0.0000,  0.0082,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0122,\n",
            "          0.0000,  0.0129,  0.0158,  0.0030],\n",
            "        [ 0.0135,  0.0040,  0.0000,  0.0120,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0178,\n",
            "          0.0000,  0.0188,  0.0230,  0.0044]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.0215,  0.0347,  0.0347,  ...,  0.0055,  0.0163, -0.4356],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0280,  0.0451,  0.0451,  ...,  0.0071,  0.0212, -0.5627],\n",
            "        [ 0.0133,  0.0214,  0.0214,  ...,  0.0034,  0.0101, -0.2569]])\n",
            "   Last layer:\n",
            "tensor([[-9.8858e-02, -2.2590e-02,  0.0000e+00, -1.1289e-01,  1.0134e-04,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.5804e-01,  0.0000e+00, -1.4460e-01, -2.0290e-01, -4.3655e-02],\n",
            "        [-9.3102e-02, -2.0076e-02,  0.0000e+00, -1.0449e-01, -1.6056e-04,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.4775e-01,  0.0000e+00, -1.3759e-01, -1.9189e-01, -4.1512e-02],\n",
            "        [-8.8639e-02, -1.9471e-02,  0.0000e+00, -1.0004e-01, -7.0233e-05,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.4101e-01,  0.0000e+00, -1.3059e-01, -1.8247e-01, -3.9404e-02],\n",
            "        [ 6.0906e-03, -2.4287e-04,  0.0000e+00,  4.4691e-03,  3.4010e-04,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          8.2676e-03,  0.0000e+00,  1.0827e-02,  1.3627e-02,  3.2377e-03],\n",
            "        [ 1.3816e-02,  3.1764e-03,  0.0000e+00,  1.5805e-02, -1.8791e-05,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          2.2101e-02,  0.0000e+00,  2.0175e-02,  2.8334e-02,  6.0905e-03],\n",
            "        [-6.9280e-02, -1.4669e-02,  0.0000e+00, -7.7344e-02, -1.7316e-04,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "         -1.0971e-01,  0.0000e+00, -1.0270e-01, -1.4299e-01, -3.0983e-02],\n",
            "        [ 1.6611e-01,  3.5194e-02,  0.0000e+00,  1.8549e-01,  4.1225e-04,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          2.6310e-01,  0.0000e+00,  2.4621e-01,  3.4284e-01,  7.4275e-02],\n",
            "        [ 6.4121e-02,  1.1992e-02,  0.0000e+00,  6.9187e-02,  4.9179e-04,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.0013e-01,  0.0000e+00,  9.6920e-02,  1.3344e-01,  2.9208e-02],\n",
            "        [ 8.0787e-02,  1.6372e-02,  0.0000e+00,  8.9082e-02,  3.5461e-04,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.2729e-01,  0.0000e+00,  1.2061e-01,  1.6726e-01,  3.6373e-02],\n",
            "        [ 1.1475e-01,  2.4599e-02,  0.0000e+00,  1.2857e-01,  2.2395e-04,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
            "          1.8198e-01,  0.0000e+00,  1.6973e-01,  2.3661e-01,  5.1210e-02]])\n",
            "DEBUGGING: training for one iteration takes 0.005394 min:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329,
          "referenced_widgets": [
            "0ad219b399b44471bc490c2b5c91713f",
            "60ac11db0064467d9749b65cd81fee82",
            "7ea347ef3c8c44778b2490a4b374fce1",
            "ff202ffc63ea444089192b817e453725",
            "90d478299c25496b8b23d186e8309435",
            "5abf4e83301542dd9f0df60a63b9e506",
            "2f63691b8d784549a3311d45cb330af0",
            "8ff18ac0e9a34ae792976faf45a8a97a"
          ]
        },
        "id": "Oe4fCU1V-kAs",
        "outputId": "56513acb-0fa5-4e51-aa54-0dbd0fdc1eb2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ad219b399b44471bc490c2b5c91713f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>▂▂▁▂▂▂▁▂▁▂▂▂▆▂▁▂▁▁▂▇█▄▃▂▁</td></tr><tr><td>training reward</td><td>▁▁▆▁▆▆▂▆▁█▆▂▆█▁▆▂▃▆▁▆▁█▁▂</td></tr><tr><td>training reward moving average</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>-0.22443</td></tr><tr><td>training reward</td><td>0.17259</td></tr><tr><td>training reward moving average</td><td>0.49766</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">deft-field-2710</strong>: <a href=\"https://wandb.ai/ieor4575-spring2022/finalproject/runs/1md5pyok\" target=\"_blank\">https://wandb.ai/ieor4575-spring2022/finalproject/runs/1md5pyok</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220508_230428-1md5pyok/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [   54246.9141, 27220988.0000,  3948314.5000,  3902082.5000,\n",
        "        27219886.0000,  3816622.7500, 27175632.0000,  3976903.5000,\n",
        "         3977309.0000,  3961905.7500,  3904790.7500, 23420360.0000,\n",
        "        27218672.0000, 27206276.0000, 27190054.0000,  3976984.7500,\n",
        "         3931598.0000,  3963138.5000, 19419398.0000,  3931559.5000,\n",
        "         7862683.0000, 19299310.0000,  3915878.7500, 15562425.0000,\n",
        "        27141808.0000, 27323768.0000, 11622510.0000, 15451909.0000,\n",
        "        23389744.0000,  7781165.5000, 11871555.0000, 11657742.0000,\n",
        "        27473456.0000, 11592561.0000,  4054315.2500,  7718911.0000,\n",
        "        27136936.0000,  3914171.2500, 23255876.0000, 15599427.0000,\n",
        "        19661078.0000,  3915166.7500,  7554840.5000, 27196042.0000,\n",
        "        11791202.0000, 23477022.0000, 15708443.0000, 23297932.0000,\n",
        "        23511102.0000,  7689591.5000, 27405178.0000,  4021836.7500,\n",
        "        15558291.0000,  3948567.5000,  7915618.5000,  3864714.5000,\n",
        "         3995934.2500, 19536616.0000,  3890406.7500, 27284138.0000,\n",
        "        11731948.0000, 23232848.0000, 19200360.0000, 22949674.0000,\n",
        "        26724900.0000,  3268551.2500, 22647966.0000, 25925040.0000,\n",
        "        25380838.0000,  5669201.5000,  7810961.0000, 13092715.0000,\n",
        "        14364957.0000, 15622157.0000, 27473452.0000]"
      ],
      "metadata": {
        "id": "R5xFgG-ZGZkL"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_t = torch.FloatTensor(a)\n",
        "print(a_t)\n",
        "b_t = a_t /1000000\n",
        "print(b_t)\n",
        "print(torch.nn.functional.softmax(b_t, dim=0))\n",
        "b_t = a_t / a_t.max()\n",
        "print(b_t)\n",
        "torch.nn.functional.softmax(b_t, dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5GfEt5DGbcN",
        "outputId": "69e79137-899e-42eb-f930-780511f5a027"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   54246.9141, 27220988.0000,  3948314.5000,  3902082.5000,\n",
            "        27219886.0000,  3816622.7500, 27175632.0000,  3976903.5000,\n",
            "         3977309.0000,  3961905.7500,  3904790.7500, 23420360.0000,\n",
            "        27218672.0000, 27206276.0000, 27190054.0000,  3976984.7500,\n",
            "         3931598.0000,  3963138.5000, 19419398.0000,  3931559.5000,\n",
            "         7862683.0000, 19299310.0000,  3915878.7500, 15562425.0000,\n",
            "        27141808.0000, 27323768.0000, 11622510.0000, 15451909.0000,\n",
            "        23389744.0000,  7781165.5000, 11871555.0000, 11657742.0000,\n",
            "        27473456.0000, 11592561.0000,  4054315.2500,  7718911.0000,\n",
            "        27136936.0000,  3914171.2500, 23255876.0000, 15599427.0000,\n",
            "        19661078.0000,  3915166.7500,  7554840.5000, 27196042.0000,\n",
            "        11791202.0000, 23477022.0000, 15708443.0000, 23297932.0000,\n",
            "        23511102.0000,  7689591.5000, 27405178.0000,  4021836.7500,\n",
            "        15558291.0000,  3948567.5000,  7915618.5000,  3864714.5000,\n",
            "         3995934.2500, 19536616.0000,  3890406.7500, 27284138.0000,\n",
            "        11731948.0000, 23232848.0000, 19200360.0000, 22949674.0000,\n",
            "        26724900.0000,  3268551.2500, 22647966.0000, 25925040.0000,\n",
            "        25380838.0000,  5669201.5000,  7810961.0000, 13092715.0000,\n",
            "        14364957.0000, 15622157.0000, 27473452.0000])\n",
            "tensor([ 0.0542, 27.2210,  3.9483,  3.9021, 27.2199,  3.8166, 27.1756,  3.9769,\n",
            "         3.9773,  3.9619,  3.9048, 23.4204, 27.2187, 27.2063, 27.1901,  3.9770,\n",
            "         3.9316,  3.9631, 19.4194,  3.9316,  7.8627, 19.2993,  3.9159, 15.5624,\n",
            "        27.1418, 27.3238, 11.6225, 15.4519, 23.3897,  7.7812, 11.8716, 11.6577,\n",
            "        27.4735, 11.5926,  4.0543,  7.7189, 27.1369,  3.9142, 23.2559, 15.5994,\n",
            "        19.6611,  3.9152,  7.5548, 27.1960, 11.7912, 23.4770, 15.7084, 23.2979,\n",
            "        23.5111,  7.6896, 27.4052,  4.0218, 15.5583,  3.9486,  7.9156,  3.8647,\n",
            "         3.9959, 19.5366,  3.8904, 27.2841, 11.7319, 23.2328, 19.2004, 22.9497,\n",
            "        26.7249,  3.2686, 22.6480, 25.9250, 25.3808,  5.6692,  7.8110, 13.0927,\n",
            "        14.3650, 15.6222, 27.4735])\n",
            "tensor([1.0010e-13, 6.2920e-02, 4.9158e-12, 4.6937e-12, 6.2851e-02, 4.3093e-12,\n",
            "        6.0130e-02, 5.0584e-12, 5.0605e-12, 4.9831e-12, 4.7065e-12, 1.4067e-03,\n",
            "        6.2775e-02, 6.2001e-02, 6.1004e-02, 5.0588e-12, 4.8344e-12, 4.9893e-12,\n",
            "        2.5740e-05, 4.8342e-12, 2.4637e-10, 2.2827e-05, 4.7589e-12, 5.4393e-07,\n",
            "        5.8130e-02, 6.9731e-02, 1.0579e-08, 4.8702e-07, 1.3643e-03, 2.2708e-10,\n",
            "        1.3571e-08, 1.0959e-08, 8.0991e-02, 1.0267e-08, 5.4655e-12, 2.1338e-10,\n",
            "        5.7848e-02, 4.7508e-12, 1.1933e-03, 5.6443e-07, 3.2777e-05, 4.7556e-12,\n",
            "        1.8109e-10, 6.1370e-02, 1.2523e-08, 1.4887e-03, 6.2944e-07, 1.2446e-03,\n",
            "        1.5403e-03, 2.0721e-10, 7.5646e-02, 5.2909e-12, 5.4168e-07, 4.9171e-12,\n",
            "        2.5976e-10, 4.5216e-12, 5.1556e-12, 2.8941e-05, 4.6393e-12, 6.7022e-02,\n",
            "        1.1803e-08, 1.1662e-03, 2.0676e-05, 8.7858e-04, 3.8313e-02, 2.4910e-12,\n",
            "        6.4976e-04, 1.7217e-02, 9.9914e-03, 2.7477e-11, 2.3395e-10, 4.6021e-08,\n",
            "        1.6424e-07, 5.7741e-07, 8.0991e-02])\n",
            "tensor([0.0020, 0.9908, 0.1437, 0.1420, 0.9908, 0.1389, 0.9892, 0.1448, 0.1448,\n",
            "        0.1442, 0.1421, 0.8525, 0.9907, 0.9903, 0.9897, 0.1448, 0.1431, 0.1443,\n",
            "        0.7068, 0.1431, 0.2862, 0.7025, 0.1425, 0.5665, 0.9879, 0.9946, 0.4230,\n",
            "        0.5624, 0.8514, 0.2832, 0.4321, 0.4243, 1.0000, 0.4220, 0.1476, 0.2810,\n",
            "        0.9878, 0.1425, 0.8465, 0.5678, 0.7156, 0.1425, 0.2750, 0.9899, 0.4292,\n",
            "        0.8545, 0.5718, 0.8480, 0.8558, 0.2799, 0.9975, 0.1464, 0.5663, 0.1437,\n",
            "        0.2881, 0.1407, 0.1454, 0.7111, 0.1416, 0.9931, 0.4270, 0.8456, 0.6989,\n",
            "        0.8353, 0.9728, 0.1190, 0.8244, 0.9436, 0.9238, 0.2064, 0.2843, 0.4766,\n",
            "        0.5229, 0.5686, 1.0000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0074, 0.0199, 0.0085, 0.0085, 0.0199, 0.0085, 0.0199, 0.0085, 0.0085,\n",
              "        0.0085, 0.0085, 0.0173, 0.0199, 0.0199, 0.0199, 0.0085, 0.0085, 0.0085,\n",
              "        0.0150, 0.0085, 0.0098, 0.0149, 0.0085, 0.0130, 0.0198, 0.0200, 0.0113,\n",
              "        0.0130, 0.0173, 0.0098, 0.0114, 0.0113, 0.0201, 0.0113, 0.0086, 0.0098,\n",
              "        0.0198, 0.0085, 0.0172, 0.0130, 0.0151, 0.0085, 0.0097, 0.0199, 0.0113,\n",
              "        0.0174, 0.0131, 0.0172, 0.0174, 0.0098, 0.0200, 0.0085, 0.0130, 0.0085,\n",
              "        0.0099, 0.0085, 0.0085, 0.0150, 0.0085, 0.0199, 0.0113, 0.0172, 0.0149,\n",
              "        0.0170, 0.0195, 0.0083, 0.0168, 0.0190, 0.0186, 0.0091, 0.0098, 0.0119,\n",
              "        0.0125, 0.0130, 0.0201])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYdGyAom2SMj",
        "outputId": "89fa2c20-b7b4-4cf4-8223-1846c89596b2"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 0., 1., 3., 0., 0., 0., 3., 2., 3., 1., 1., 2., 0., 4., 4., 0.,\n",
              "       2., 1., 2., 2., 2., 4., 1., 3., 2., 0., 1., 2., 0., 3., 0., 3., 1.,\n",
              "       3., 0., 4., 1., 4., 4., 0., 0., 1., 2., 4., 0., 0., 1., 1., 1., 2.,\n",
              "       3., 4., 4., 3., 3., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s[1][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WUaedhX198a",
        "outputId": "5b2fc9b5-dd64-4116-992a-003461c4363e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20655680.0"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s[-2] / np.max(s[-2], axis=1, keepdims=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmmYGIMyEQNl",
        "outputId": "df318952-6fbb-45ab-fe60-bc5078c88f45"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.54545455, 0.63636364, 0.81818182, ..., 0.63636364, 0.81818182,\n",
              "        0.63636364],\n",
              "       [0.59204253, 0.72272276, 0.80233403, ..., 0.71290849, 0.71459982,\n",
              "        0.58222368],\n",
              "       [0.59206416, 0.72271493, 0.80230557, ..., 0.71290297, 0.71451933,\n",
              "        0.58222376],\n",
              "       ...,\n",
              "       [0.59207576, 0.72270644, 0.80232062, ..., 0.71292965, 0.71457005,\n",
              "        0.58218961],\n",
              "       [0.59205913, 0.72271276, 0.80231302, ..., 0.71291558, 0.71456072,\n",
              "        0.58223248],\n",
              "       [0.59204855, 0.72270337, 0.80230828, ..., 0.7129393 , 0.7145267 ,\n",
              "        0.58223474]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(s[-2]), len(s[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GEP-MOCEZKu",
        "outputId": "c107c04d-5147-4cfe-c7ef-f1801b603739"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(110, 110)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([0.0057, 0.0235, 0.0144, 0.0181, 0.0181, 0.0123, 0.0293, 0.0095, 0.0122,\n",
        "        0.0146, 0.0152, 0.0095, 0.0184, 0.0151, 0.0143, 0.0095, 0.0220, 0.0120,\n",
        "        0.0209, 0.0226, 0.0142, 0.0124, 0.0145, 0.0133, 0.0218, 0.0146, 0.0098,\n",
        "        0.0186, 0.0146, 0.0126, 0.0182, 0.0204, 0.0155, 0.0180, 0.0098, 0.0184,\n",
        "        0.0248, 0.0150, 0.0215, 0.0114, 0.0186, 0.0175, 0.0141, 0.0199, 0.0250,\n",
        "        0.0178, 0.0310, 0.0170, 0.0153, 0.0204, 0.0121, 0.0247, 0.0187, 0.0197,\n",
        "        0.0130, 0.0127, 0.0240, 0.0189, 0.0104, 0.0125])\n",
        "a.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlcbwh-Ts6Jt",
        "outputId": "f5962b02-c6b2-417d-8fbb-5f7e2a6f6c80"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.env_now.env.remain_gap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "aIRTZjAPgkW_",
        "outputId": "32f179c5-6ce3-45f0-f9af-fe13d706e44e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-c243c5b8551f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_now\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremain_gap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'GurobiOriginalEnv' object has no attribute 'remain_gap'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.env_now.env.oldobj"
      ],
      "metadata": {
        "id": "gg-stUzCuAdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.env_now.env.newobj\n"
      ],
      "metadata": {
        "id": "kyF1UWObuLoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.env_now.env.ip_obj"
      ],
      "metadata": {
        "id": "aPL2qJZ0nNrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OH notes:\n",
        "\n",
        "baseline is what you use to interprete the reward\n",
        "\n",
        "don't use nn, use \"mean\" of rewards in this episode (I think so)\n",
        "\n",
        "Maybe look in to the instances, and look at how your agent is solving them\n",
        "\n",
        "Cutting off early, but only after solved some LP's\n",
        "- counterfactual exploration\n",
        "  - more than to do it more random\n",
        "- all prob entirely the same\n",
        "- activation function ?\n",
        "\n",
        "not learning? \n",
        "\n",
        "reward shaping?\n",
        "- someone: amplify the reward (shouldn't, since every step wil GIVE a reward), compare it to other POSSIBLE states\n",
        "- pre-trained on the instances and pre-trained the baseline?\n",
        "- get the max reward from the LP solver (isn't this cheating lol)\n",
        "- recalcluate the max-gap-to-go (lol remaining max gap) every step\n",
        "- go in the environment to make if return the shaped new-gap reward\n",
        "- the original reward doesn't help you across LPs?\n",
        "- moving average of *returns* from all *previous* episodes\n",
        "  - return is the discounted sum of the reward\n",
        "- advantage? Q - running averaged RETURN (but different states are mixed in, how do you deal with that)\n",
        "- Think about what's wrong with this base line, and write it down\n",
        "  - something about the states\n",
        "\n",
        "\n",
        "differences between LPs\n",
        "\n",
        "mode: \n",
        "- standardize the constraints, and the b vector by itself\n",
        "  - do you normalize by row or columns?\n",
        "  - He thinks it's more sense to normalize by rows\n",
        "  - Normalize it twice? LOL\n",
        "- or a normalization layer\\\n",
        "\n",
        "\n",
        "When doing softmax you can use a lamda (parameter) to mitigate large score difference\n",
        "- softmax comes with a scalar parameter\n",
        "\n",
        "Professor didn't think normalizing the input is necessary & and it shouldn't make a difference anyways (but come numerical value can be lost after normalization)\n",
        "\n",
        "iteration: \n",
        "\n",
        "plot random policy together, (as a bseline to see if your model is really learning)\n",
        "\n",
        "For baseline, Prof is suggesting Q network can work too.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ha4GPGL8Dduc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sKnhC54KYNNL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}