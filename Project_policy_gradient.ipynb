{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_policy_gradient.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a4c01a5febb2446db1addbed08d0b626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_029807dd33df482a8fbb2f6322d335f1",
              "IPY_MODEL_5a18ceec6ca94b10b6a18562d94040b3"
            ],
            "layout": "IPY_MODEL_8768a6635cfc44a1b9e74c0a59935b88"
          }
        },
        "029807dd33df482a8fbb2f6322d335f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33b77f26a8b943abb314e573174ec97f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c5f76eb274744562a487eef20da90f7e",
            "value": "3.279 MB of 3.279 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "5a18ceec6ca94b10b6a18562d94040b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3550f11c0ae48b7bc2cf034ef581e64",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd230810735740d28b4f42b781a40eb5",
            "value": 1
          }
        },
        "8768a6635cfc44a1b9e74c0a59935b88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33b77f26a8b943abb314e573174ec97f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5f76eb274744562a487eef20da90f7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3550f11c0ae48b7bc2cf034ef581e64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd230810735740d28b4f42b781a40eb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ClaireZixiWang/learn2cut/blob/main/Project_policy_gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## See README.md file for further details about the project and the environment.\n",
        "\n",
        "### State-Action Description\n",
        "\n",
        "### State\n",
        "State s is an array with give components\n",
        "\n",
        "* s[0]:  constraint matrix $A$of the current LP ($\\max  -c^Tx \\text{ s.t. }Ax \\le  b$) . Dimension is $m \\times n$. See by printing s[0].shape. Here $n$ is the (fixed) number of variables. For instances of size 60 by 60 used in the above command, $n$ will remain fixed as 60. And $m$ is the current number of constraints. Initially, $m$ is to the number of constraints in the IP instance. (For instances generated with --num-c=60, $m$ is 60 at the first step).  But $m$ will increase by one in every step of the episode as one new constraint (cut) is added on taking an action.\n",
        "* s[1]: rhs $b$ for the current LP ($Ax\\le b$). Dimension same as the number $m$ in matrix A.\n",
        "* s[2]: coefficient vector $c$ from the LP objective ($-c^Tx$). Dimension same as the number of variables, i.e., $n$.\n",
        "* s[3],  s[4]: Gomory cuts available in the current round of Gomory's cutting plane algorithm. Each cut $i$ is of the form $D_i x\\le d_i$.   s[3] gives the matrix $D$ (of dimension $k \\times n$) of cuts and s[4] gives the rhs $d$ (of dimension $k$). The number of cuts $k$ available in each round changes, you can find it out by printing the size of last component of state, i.e., s[4].size or s[-1].size.\n",
        "\n",
        "### Actions\n",
        "There are k=s[4].size actions available in each state $s$, with $i^{th}$ action corresponding to the $i^{th}$ cut with inequality $D_i x\\le d_i$ in $s[3], s[4]$."
      ],
      "metadata": {
        "id": "5TN-sMTvcG_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***QUESTIONS***:\n",
        "1. By \"current\" LP, you mean the LP that the agent was running in the last state? As in, the LP with all the added constraints? \n",
        "  * ==> I think so.\n",
        "1. What do you mean Gomory cuts *available*? As in, after doing Simplex methods, the *variables* that you can choose to cut?\n",
        "  * Yes I think so.\n",
        "2. Isn't the number of variables (n) changing? in the C-G cutting plane method?\n",
        "  * No, as the spec says, **$n$ is the fixed number of variables**.\n",
        "  * If you look that cuttng plane lecture notes, you can see that after each step, the dummy variable is not added in the constraint. They are merely there for the sake of the LP solver (simplex method), but not really relevant for us.\n",
        "    * This is not correct, I think they are still very much relevant, it's just that I think among the 60 variables a lot of them are space holders for dummy variables so that our $n$ is fixed, so that we don't have to worry about using LSTM. Since each time the sequence [a, b] will be of size n+1. And we can just use a fixed-input-size network to do that.\n",
        "    * But still need to verify with the TA about the place holder understanding.\n",
        "3. dimension of s[3] and s[4]? Where is the \"available all\" stored? In which dimension?\n",
        "  * Each row of D is an \"available cut\". Therefore each $D_i x\\le d_i$ is an \"available\" cut in CG method solved from the simplex method.\n",
        "4. pointing towards the slides: why does the number of constraints m increase 1 in each step, if you can choose *multiple* cuts in one step? (OR in the algorithm we just choose one cut each time? or is that a more vanilla version to start, but to expand on multiple cuts a time later?)\n",
        "5. What do you mean by each \"instance\"?"
      ],
      "metadata": {
        "id": "XJE0bz30UL1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYROdPaaZOVa",
        "outputId": "1a6d14fa-c142-40a0-a074-3edef12daa53"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -i https://pypi.gurobi.com gurobipy"
      ],
      "metadata": {
        "id": "xSXTKB2zurrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e0455f-2228-42ac-9521-ec63489b3c5d"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.gurobi.com\n",
            "Requirement already satisfied: gurobipy in /usr/local/lib/python3.7/dist-packages (9.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qqq"
      ],
      "metadata": {
        "id": "YULy9ymNvDxN"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/IEOR_RL/Project_learn2cut\n",
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "lTnvB0_iZUrX",
        "outputId": "0ea40d57-b926-484c-8052-2cb8ad92ab2e"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive/IEOR_RL/Project_learn2cut'\n",
            "/content/drive/MyDrive/IEOR_RL/Project_learn2cut\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/IEOR_RL/Project_learn2cut'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "Q8PiSPj5us0O"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.Sequential(\n",
        "            torch.nn.Linear(4, 40),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(40, 20), \n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(20, 10)\n",
        "        )\n",
        "\n",
        "datapoint = torch.FloatTensor([\n",
        "                               [[1,2,3,4],\n",
        "                                [2,3,4,5]],\n",
        "                               [[3,4,5,6],\n",
        "                                [4,5,6,7]]\n",
        "                              ])\n"
      ],
      "metadata": {
        "id": "ojB8UvBAPAWk"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(datapoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r_nraniPaKl",
        "outputId": "c273057b-ae68-4408-9faa-a291d1a3d536"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.3510,  0.0903,  0.3748, -0.0656,  0.1056,  0.4354, -0.1858,\n",
              "           0.5488,  0.0457, -0.2506],\n",
              "         [ 0.4773,  0.1405,  0.5424, -0.1342,  0.1491,  0.5649, -0.3352,\n",
              "           0.7610,  0.1103, -0.4118]],\n",
              "\n",
              "        [[ 0.6142,  0.1912,  0.7181, -0.2041,  0.1909,  0.6979, -0.4886,\n",
              "           0.9789,  0.1799, -0.5784],\n",
              "         [ 0.7512,  0.2420,  0.8938, -0.2740,  0.2327,  0.8309, -0.6420,\n",
              "           1.1968,  0.2494, -0.7450]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Code for Policy Model\n",
        "\n",
        "class Policy(object):\n",
        "\n",
        "    # inputsize = n+1 = 61\n",
        "    def __init__(self, lr, input_size, attention_size=10, temperature=1) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Linear(input_size, 40),\n",
        "            # torch.nn.Sigmoid(),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(40, 30), \n",
        "            # torch.nn.Sigmoid(),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(30, 20), \n",
        "            # torch.nn.Sigmoid(),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(20, attention_size)\n",
        "        )\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
        "\n",
        "        # RECORD HYPER-PARAMS\n",
        "        self.input_size = input_size\n",
        "        self.attention_size = attention_size\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def compute_logits_big_batch(self, obs_matrix, act_matrix, batchsize):\n",
        "        '''\n",
        "        Function that takes in a batch of observations and computes the action logits for each of observations in this batch\n",
        "        Args: obs_matrix: np.array(m * batchsize, n+1) # TODO maybe change this to tensor\n",
        "              act_matrix: np.array(k * batchsize, n+1)\n",
        "        Return: batch_logit: tensor(batchsize, k)\n",
        "        '''\n",
        "\n",
        "        # Get the batch result\n",
        "\n",
        "        # transform to tensor\n",
        "        obs_attention = self.model(torch.FloatTensor(obs_matrix)) # tensor(m * batchsize, u)\n",
        "        act_attention = self.model(torch.FloatTensor(act_matrix)) # tensor(k * batchsize, u)\n",
        "\n",
        "        assert obs_attention.shape == (obs_matrix.shape[0], self.attention_size)\n",
        "        assert act_attention.shape == (act_matrix.shape[0], self.attention_size)\n",
        "\n",
        "        # split a batch of output of size tensor(m * batchsize, u) into (batchsize, m, u)\n",
        "        batch_obs_output = torch.reshape(obs_attention, (batchsize, obs_attention.shape[0]/batchsize, obs_attention.shape[1]))\n",
        "        \n",
        "        # split a batch of output of size tensor(k * batchsize, u) into (batchsize, k, u)\n",
        "        batch_act_output = torch.reshape(act_attention, (batchsize, act_attention.shape[0]/batchsize, act_attention.shape[1]))\n",
        "\n",
        "        # To do batch matrix multiplication, transpose (batchsize, k, u) into (batchsize, u, k)\n",
        "        # (batchsize, m, u) @ (batchsize, u, k) =  (batchsize, m, k)\n",
        "        # (batchsize, m, k) == mean across all observation ==> (batchsize, k)\n",
        "        batch_logit = torch.bmm(batch_obs_output, batch_act_output.transpose(0, 2, 1)).mean(dim=1)\n",
        "\n",
        "        assert batch_logit.shape == (batchsize, act_matrix.shape[0]/batchsize)\n",
        "\n",
        "        return batch_logit\n",
        "\n",
        "    def compute_batch_selected_prob(self, batch_probs):\n",
        "        '''\n",
        "        Function that takes in a batch of probabilities and return the max probability for each \"datapoint\" in the batch\n",
        "        Args:    batch_logit: tensor(batchsize, k)\n",
        "        Return:  batch_selected_prob: tensor(batchsize,)\n",
        "        '''\n",
        "        # TODO\n",
        "\n",
        "        return\n",
        "\n",
        "\n",
        "    def compute_one_step_logits(self, obs, act):\n",
        "        '''\n",
        "        Function that takes in ONE observation and action space, computes the action logits\n",
        "        Args:   obs_matrix: np.array(m, n+1)\n",
        "                act_matrix: np.array(k, n+1)\n",
        "        Return: logit: tensor(k)\n",
        "        '''\n",
        "\n",
        "        obs_attention = self.model(torch.FloatTensor(obs)) #-> (m, 10)\n",
        "        act_attention = self.model(torch.FloatTensor(act)) #-> (k, 10)\n",
        "        # print(\"DEBUGGING: obs_attention looks like:\", obs_attention)\n",
        "        # print(\"DEBUGGING: act_attention looks like:\", act_attention)\n",
        "\n",
        "        # attention matrix multiplication & mean to get the score\n",
        "        logits = torch.mm(obs_attention, act_attention.transpose(1, 0)).mean(dim=0)\n",
        "        # print(\"DEBUGGING: logits looks like:\", logits)\n",
        "\n",
        "        # print(\"DEBUGGING: act.shape =\", act_attention.shape)\n",
        "        # print(\"DEBUGGING: logits.shape =\", logits.shape)\n",
        "        assert logits.shape[0] == act_attention.shape[0]\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def predict_prob(self, obs, act):\n",
        "        # Function that uses softmax to transform logits to probabilities\n",
        "        # TODO: What shape should obs and act take?\n",
        "        # Args:   obs_matrix: np.array(m, n+1)\n",
        "        #         act_matrix: np.array(k, n+1)\n",
        "        # Return: probs: tensor(k)\n",
        "\n",
        "        logits = self.compute_one_step_logits(obs, act)\n",
        "\n",
        "        # TODO: make temperature a argument in the function, so that it's depended on the steps\n",
        "        probs = torch.nn.functional.softmax(logits/self.temperature, dim=0)\n",
        "        return probs\n",
        "\n",
        "    def selected_prob(self, probs, action):\n",
        "\n",
        "\n",
        "        # TODO: do I need this function?\n",
        "        one_hot = torch.zeros()\n",
        "        return probs.max()\n",
        "\n",
        "    def choose_action(self, obs, act):\n",
        "\n",
        "        # TODO: is this returning a number?\n",
        "        return torch.argmax(self.predict_prob(obs, act)).item()\n",
        "\n",
        "\n",
        "    def train(self, obs_matrix, act_matrix, actions, Qs):\n",
        "        \"\"\"\n",
        "        Args: obs_matrix: np.array(batchsize * m, n+1) => changed to [np.array(m, n+1)] * batchsize, note that m are varied!\n",
        "              act_matrix: np.array(batchsize * k, n+1)  \n",
        "              actions: => [[action number]] * batchsize      \n",
        "              Qs: np.array(batchsize, )\n",
        "        \"\"\"\n",
        "        # Convert numpy array to tensor\n",
        "\n",
        "        # use compute_batch_prob to compute the batch logits for every datapoint in batch.\n",
        "        # use compute_batch_selected_prob the compute the max probabilty for every datapoint in batch.\n",
        "        start = time.time()\n",
        "        print(\"DEBUGGING: I'm inside the training now!\")\n",
        "        \n",
        "        Qs = torch.FloatTensor(Qs)\n",
        "\n",
        "\n",
        "        # Try using a for loop first, see whether it really cost too much time & whether it works at all\n",
        "        prob_selected = torch.zeros(len(actions))\n",
        "        for i in range(len(obs_matrix)):\n",
        "            #TODO: adjust the temperatures based on trajectory steps\n",
        "            probs = self.predict_prob(obs_matrix[i], act_matrix[i])\n",
        "            one_hot = torch.zeros_like(probs)\n",
        "            one_hot[actions[i][0]] = 1\n",
        "            prob_selected[i] = torch.sum(probs * one_hot)\n",
        "\n",
        "\n",
        "        # For robustness add in noise for prob_selected # TODO: why do this?\n",
        "\n",
        "        # define loss function as in lab 4\n",
        "        # TODO define loss function as described in the text above\n",
        "        loss = - (torch.sum(Qs * torch.log(prob_selected)) / (len(obs_matrix) + 1))\n",
        "        print(\"DEBUGGING: the loss =\", loss)\n",
        "\n",
        "        print(\"DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\")\n",
        "        print(\"   First layer:\")\n",
        "        print(policy.model[0].weight.grad)\n",
        "        print(\"   Last layer:\")\n",
        "        print(policy.model[6].weight.grad)\n",
        "\n",
        "        # backward pass\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        print(\"DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\")\n",
        "        print(\"   First layer:\")\n",
        "        print(policy.model[0].weight.grad)\n",
        "        print(\"   Last layer:\")\n",
        "        print(policy.model[6].weight.grad)\n",
        "\n",
        "        # step\n",
        "        self.optimizer.step()\n",
        "\n",
        "\n",
        "        print(\"DEBUGGING: training for one iteration takes %f min:\" % ((time.time() - start)/60))\n",
        "\n",
        "\n",
        "        # return detached loss (why?)\n",
        "        return loss.detach().cpu().data.numpy()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HViRnY1ssGfc"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchsummary import summary\n",
        "# summary(policy.model, (61,))\n",
        "# print(policy.model)"
      ],
      "metadata": {
        "id": "OGm4an0pWPHr"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(policy.model[6].weight.grad)"
      ],
      "metadata": {
        "id": "dfkXKSJWW6OR"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP model for policy model:\n",
        "#   model.forward\n",
        "#   model.train --> What is in this function? what are the function arguments?\n",
        "# Baseline function b(s) ==> Okay maybe we stil need the V model as a proper baseline\n",
        "\n",
        "\n",
        "# Q value model ==> Discard this right now, just do vanilla policy gradient\n",
        "#   Can I just use the one in Lab4? What does it mean? what does the states and actions mean? --> Print out the s, r to check\n",
        "#   What is a Q-value in our set-up?\n",
        "#   How do I used this? \n",
        "#   (What's the baseline function??)"
      ],
      "metadata": {
        "id": "ACiQz-gESgOO"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "2xI0riE6md5V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "b9e47a0e-b7b1-4788-c19d-2b2d76f7e697"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/My Drive/IEOR_RL/Project_learn2cut/wandb/run-20220509_005505-1ppyhfj2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ieor4575-spring2022/finalproject/runs/1ppyhfj2\" target=\"_blank\">peach-sound-2762</a></strong> to <a href=\"https://wandb.ai/ieor4575-spring2022/finalproject\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# import gymenv_v2\n",
        "from gymenv_v2 import make_multiple_env\n",
        "\n",
        "\n",
        "import wandb\n",
        "wandb.login()\n",
        "run=wandb.init(project=\"finalproject\", entity=\"ieor4575-spring2022\", tags=[\"training-easy\"])\n",
        "#run=wandb.init(project=\"finalproject\", entity=\"ieor-4575\", tags=[\"training-hard\"])\n",
        "#run=wandb.init(project=\"finalproject\", entity=\"ieor-4575\", tags=[\"test\"])\n",
        "\n",
        "### TRAINING\n",
        "\n",
        "# Setup: You may generate your own instances on which you train the cutting agent.\n",
        "custom_config = {\n",
        "    \"load_dir\"        : 'instances/randomip_n60_m60',   # this is the location of the randomly generated instances (you may specify a different directory)\n",
        "    \"idx_list\"        : list(range(20)),                # take the first 20 instances from the directory\n",
        "    \"timelimit\"       : 50,                             # the maximum horizon length is 50\n",
        "    \"reward_type\"     : 'obj'                           # DO NOT CHANGE reward_type\n",
        "}\n",
        "\n",
        "# Easy Setup: Use the following environment settings. We will evaluate your agent with the same easy config below:\n",
        "easy_config = {\n",
        "    \"load_dir\"        : 'instances/train_10_n60_m60',\n",
        "    \"idx_list\"        : list(range(5)),\n",
        "    \"timelimit\"       : 50,\n",
        "    \"reward_type\"     : 'obj'\n",
        "}\n",
        "\n",
        "# Hard Setup: Use the following environment settings. We will evaluate your agent with the same hard config below:\n",
        "hard_config = {\n",
        "    \"load_dir\"        : 'instances/train_100_n60_m60',\n",
        "    \"idx_list\"        : list(range(99)),\n",
        "    \"timelimit\"       : 50,\n",
        "    \"reward_type\"     : 'obj'\n",
        "}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch._C import dtype\n",
        "def discounted_rewards(r, gamma):\n",
        "    \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
        "    discounted_r = np.zeros_like(r, dtype=float)\n",
        "    running_sum = 0\n",
        "    for i in reversed(range(0,len(r))):\n",
        "        discounted_r[i] = running_sum * gamma + r[i]\n",
        "        running_sum = discounted_r[i]\n",
        "    return list(discounted_r)"
      ],
      "metadata": {
        "id": "COyIO0TEDRjt"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = make_multiple_env(**easy_config) \n",
        "s = env.reset()   # samples a RANDOM INSTANCE every time env.reset() is called\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFhvgi_q53V4",
        "outputId": "8324973c-f6c3-4498-b0e4-64d14436c067"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading training instances, dir instances/train_10_n60_m60 idx 0\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 1\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 2\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 3\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "A, b, c0, cuts_a, cuts_b = s\n",
        "concat = np.hstack((s[0], np.expand_dims(s[1], axis=1)))\n",
        "concat\n",
        "# np.linalg.norm(concat, axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJXouQZx9DQ7",
        "outputId": "d9c48ea1-ad45-4189-c9ca-80e3ada467e6"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   1,   3, ...,   3,   3, 577],\n",
              "       [  1,   4,   4, ...,   0,   2, 588],\n",
              "       [  0,   1,   1, ...,   0,   1, 541],\n",
              "       ...,\n",
              "       [  0,   1,   1, ...,   1,   4, 578],\n",
              "       [  3,   1,   1, ...,   4,   0, 599],\n",
              "       [  2,   3,   4, ...,   2,   2, 562]])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.expand_dims(s[1], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSUhT5go6czx",
        "outputId": "7526f8d9-de93-440a-878c-a4c32964d05f"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[577],\n",
              "       [588],\n",
              "       [541],\n",
              "       [566],\n",
              "       [563],\n",
              "       [586],\n",
              "       [589],\n",
              "       [555],\n",
              "       [585],\n",
              "       [589],\n",
              "       [543],\n",
              "       [549],\n",
              "       [574],\n",
              "       [584],\n",
              "       [554],\n",
              "       [543],\n",
              "       [555],\n",
              "       [553],\n",
              "       [552],\n",
              "       [559],\n",
              "       [547],\n",
              "       [588],\n",
              "       [582],\n",
              "       [576],\n",
              "       [555],\n",
              "       [590],\n",
              "       [548],\n",
              "       [587],\n",
              "       [563],\n",
              "       [551],\n",
              "       [547],\n",
              "       [576],\n",
              "       [576],\n",
              "       [581],\n",
              "       [563],\n",
              "       [589],\n",
              "       [565],\n",
              "       [553],\n",
              "       [562],\n",
              "       [587],\n",
              "       [554],\n",
              "       [564],\n",
              "       [573],\n",
              "       [546],\n",
              "       [561],\n",
              "       [551],\n",
              "       [570],\n",
              "       [547],\n",
              "       [540],\n",
              "       [594],\n",
              "       [578],\n",
              "       [570],\n",
              "       [562],\n",
              "       [544],\n",
              "       [557],\n",
              "       [598],\n",
              "       [579],\n",
              "       [578],\n",
              "       [599],\n",
              "       [562]])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.hstack((s[0], np.expand_dims(s[1], axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjIckPCE7n2z",
        "outputId": "43f4d2bd-9d0e-4b2c-8d01-a069af46e70c"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   1,   3, ...,   3,   3, 577],\n",
              "       [  1,   4,   4, ...,   0,   2, 588],\n",
              "       [  0,   1,   1, ...,   0,   1, 541],\n",
              "       ...,\n",
              "       [  0,   1,   1, ...,   1,   4, 578],\n",
              "       [  3,   1,   1, ...,   4,   0, 599],\n",
              "       [  2,   3,   4, ...,   2,   2, 562]])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([\n",
        "              [1,2,3,4],\n",
        "              [3,3,3,3],\n",
        "              [2,2,2,2],\n",
        "              [1,1,1,1]\n",
        "])\n",
        "print(a.mean(axis=0, keepdims=True))\n",
        "a = a - a.mean(axis=0, keepdims=True)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMUMT8x_A8I0",
        "outputId": "177c87fa-53ed-4c7b-ab53-ce1dfd5b331a"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.75 2.   2.25 2.5 ]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.75,  0.  ,  0.75,  1.5 ],\n",
              "       [ 1.25,  1.  ,  0.75,  0.5 ],\n",
              "       [ 0.25,  0.  , -0.25, -0.5 ],\n",
              "       [-0.75, -1.  , -1.25, -1.5 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "empty = [np.array([1,2]), np.array([3,4])]\n",
        "a = []\n",
        "b = a + empty + empty\n",
        "\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBFhGXfSJz3l",
        "outputId": "a2f0130c-a001-4732-bc00-8efd27a72359"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 2]), array([3, 4]), array([1, 2]), array([3, 4])]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "empty = [np.array([10,20])]\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJY9NttjZiM7",
        "outputId": "71aa2184-dbff-4adb-a79a-e1c822f6ee54"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 2]), array([3, 4]), array([1, 2]), array([3, 4])]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%wandb\n",
        "# create env\n",
        "env = make_multiple_env(**easy_config) \n",
        "# Parameter initialization\n",
        "numtrajs = 4  # num of trajecories from the current policy to collect in each iteration\n",
        "lr_pg = 1e-2  # learning rate for PG\n",
        "attention_size = 10\n",
        "iterations = 50\n",
        "discount_gamma = .99\n",
        "\n",
        "# Network initialize\n",
        "policy = Policy(lr_pg, 61, attention_size, 0.25)\n",
        "\n",
        "#To record training reward for logging and plotting purposes\n",
        "rrecord = []\n",
        "\n",
        "VAL_ALL = []  # Monte carlo value predictions of ALL trajectories (to compute baseline, and policy gradient) => 2 d list (numtrajs, #steps per traj)\n",
        "\n",
        "# For every training iteration, we roll out 5 random instances using the policy network\n",
        "# collect observation and action matrices from these 5 roll-outs, consider this a BATCH\n",
        "# train the network using this BATCH\n",
        "for ite in range(iterations):\n",
        "\n",
        "    print(\"==========================================================================================================\")\n",
        "    print(\"Outer iteration no\", ite)\n",
        "\n",
        "    # To record traectories generated from current policy\n",
        "    OBS_MAT = []  # observations: [obs_matrices_batch_traj1, obs_matrices_batch_traj2, ....]\n",
        "    ACT_MAT = []  # actions\n",
        "    ADS = []  # advantages (to compute policy gradient)\n",
        "    VAL = []  # Monte carlo value predictions (to compute baseline, and policy gradient) => 2 d list (numtrajs, #steps per traj)\n",
        "    traj_returns = []  # a list of 5 numbers, each number represents the RETURN of that roll-out\n",
        "    actions = []\n",
        "    \n",
        "    # collect some trajectories\n",
        "    for num in range(numtrajs):\n",
        "        print(\"-------------------------------------------------------------------------------------------\")\n",
        "        print(\"Running trajectories:\", num)\n",
        "        # Initialize a list of obs_matrices and act_matrices, to store all the obs_matrix and act_matrix in the trajectory\n",
        "        obs_matrices = []  # states: [obs_matrix_state1, obs_matrix_state2, ...]\n",
        "        act_matrices = []  # actions matrices\n",
        "        \n",
        "        # this is used to collect all the immedaite rewards in this trajectory\n",
        "        rews = []  # instant rewards\n",
        "        rel_rews = []\n",
        "\n",
        "        # gym loop\n",
        "        s = env.reset()   # samples a RANDOM INSTANCE every time env.reset() is called\n",
        "        done = False\n",
        "\n",
        "        # TODO: wandb logging -> what reward average should we log??\n",
        "        t = 0 # TODO: how is this used?\n",
        "        repisode = 0  # TODO: how is this used?\n",
        "\n",
        "        inner_step = 1\n",
        "        \n",
        "\n",
        "        # roll out ONE policy\n",
        "        while not done:\n",
        "\n",
        "            # TODO compute the running average RETURN as basline\n",
        "            A, b, c0, cuts_a, cuts_b = s\n",
        "\n",
        "            # choose the action according to the model output probabilities\n",
        "\n",
        "            # Concat [A,b] and [cuts_a, cuts_b]\n",
        "            assert A.shape[0] == b.shape[0]\n",
        "            assert cuts_a.shape[0] == cuts_b.shape[0]\n",
        "\n",
        "            obs_matrix = np.hstack((A, np.expand_dims(b, axis=1)))\n",
        "            act_matrix = np.hstack((cuts_a, np.expand_dims(cuts_b, axis=1)))\n",
        "\n",
        "            assert obs_matrix.shape == (A.shape[0], A.shape[1]+1)\n",
        "            assert act_matrix.shape == (cuts_a.shape[0], cuts_a.shape[1]+1)\n",
        "\n",
        "            # Normalize on a row (MIGHT NOT NEED THIS)\n",
        "            \n",
        "            # The reason we want to normalize a row: we want the numeric space of the model input to be just between 0, 1\n",
        "            # Right now I'm normalizing such that the largest number has value 1 --> each row divided by the largest num in that row\n",
        "            #   => This would result in b vector always be 1 (does it make sense?)\n",
        "            # another option is to normalize such that the SUM of the row is 1\n",
        "            #   => I think this makes more sense, consider this differentiates the max among datapoints\n",
        "            #   => According to prof in OH this might cause some information loss\n",
        "            \n",
        "            obs_matrix = obs_matrix / obs_matrix.max(axis=1, keepdims=True) * 100\n",
        "            act_matrix = act_matrix / act_matrix.max(axis=1, keepdims=True) * 100\n",
        "            \n",
        "            # print(\"DEBUGGING: obs_matrix.shape = \", obs_matrix.shape)\n",
        "            # print(\"DEBUGGING: act_matrix.shape = \", act_matrix.shape)\n",
        "\n",
        "            action_prob = policy.predict_prob(obs_matrix, act_matrix)\n",
        "            action = random.choices(range(0, len(cuts_b)), action_prob) # this returns a list\n",
        "            actions.append(action)\n",
        "\n",
        "            if  inner_step %10 == 0:\n",
        "                # TODO: print the logits as well as well.\n",
        "                print(\"DEBUGGING: the action_prob is:\", action_prob)\n",
        "                print(\"DEBUGGING: the actual action to take is:\", action)\n",
        "                logits_dbg = policy.compute_one_step_logits(obs_matrix, act_matrix)\n",
        "                print(\"DEBUGGING: logits looks like:\", logits_dbg)\n",
        "\n",
        "\n",
        "\n",
        "            # take the action in the environment\n",
        "            # TODO: why does the environment.step function takes in a list?\n",
        "            # TODO: remember to go in the environment to change the returned r to the NORMALIZED r!!\n",
        "            s, r, done, _ = env.step(action)\n",
        "            \n",
        "            # Record the observed immediate reward & observed matrices along the trajectory\n",
        "            abs_reward, rel_reward = r\n",
        "            # print(\"DEBUGGING: rel_reward looks like:\", rel_reward)\n",
        "            rews.append(abs_reward) # rews = list(len of trajectory)\n",
        "            rel_rews.append(rel_reward * 10 * inner_step)\n",
        "            obs_matrices.append(obs_matrix)\n",
        "            act_matrices.append(act_matrix)\n",
        "\n",
        "            inner_step += 1\n",
        "\n",
        "            # TODO: do we need to also record the one step of observation and action where the environment terminates?\n",
        "            #   ==> RN I'm thinking maybe don't need to\n",
        "        print(\"-------------------------------------------------------------------------------------------\")\n",
        "        #Below is for logging training performance\n",
        "        print(\"DEBUGGING: the total abs reward of the trajectory =\", np.sum(rews), \"and immediate abs rewards look like:\", rews)\n",
        "        print(\"DEBUGGING: the total relative reward of the trajectory =\", np.sum(rel_rews), \"and immediate relative rewards look like:\", rel_rews)\n",
        "\n",
        "        rrecord.append(np.sum(rews))\n",
        "\n",
        "        # After the policy roll out for this trajectory,\n",
        "        # compute the monte-carlo RETURN of this trajectory (i.e. discounted sum of rewards), add to big list\n",
        "        # TODO: one of the next steps could be: to make the basline state-dependent\n",
        "        v_hat = discounted_rewards(rel_rews, discount_gamma) # This is a list\n",
        "        traj_returns.append(v_hat[0])\n",
        "        # OBS_MAT.append(np.concatenate(obs_matrices, axis=1))\n",
        "        # ACT_MAT.append(np.concatenate(act_matrices, aixs=1))\n",
        "        VAL.append(v_hat) # VAL -> 2d list\n",
        "        VAL_ALL.append(v_hat) # VAL_ALL -> 2d list\n",
        "        OBS_MAT += obs_matrices\n",
        "        ACT_MAT += act_matrices\n",
        "\n",
        "        # TODO: do I need to specify batchsize somewhere?\n",
        "\n",
        "    print(\"+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\")\n",
        "    \n",
        "    # After collecting 5 (or however many) trajectories,\n",
        "    print(\"DEBUGGING: OBS_MAT has %d number of matrices\" % len(OBS_MAT))\n",
        "    print(\"DEBUGGING: ACT_MAT has %d number of matrices\" % len(ACT_MAT))\n",
        "    print(\"DEBUGGING: VAL looks like:\", VAL)\n",
        "    # print(\"DEBUGGING: OBS_MAT looks like:\", OBS_MAT)\n",
        "    # print(\"DEBUGGING: ACT_MAT looks like:\", ACT_MAT)\n",
        "    print(\"DEBUGGING: traj_returns =\", traj_returns)\n",
        "    print(\"DEBUGGING: actions =\", actions)\n",
        "    print(\"DEBUGGING: actions length =\", len(actions))\n",
        "\n",
        "    ## For debugging purposes, let's look at what does the model output\n",
        "    print(\"DEBUGGING: what does the model output in this round of roll-out?\")\n",
        "    obs_attention_dbg = policy.model(torch.FloatTensor(obs_matrix))\n",
        "    act_attention_dbg = policy.model(torch.FloatTensor(act_matrix))\n",
        "    logits_dbg = policy.compute_one_step_logits(obs_matrix, act_matrix)\n",
        "    print(\"DEBUGGING: obs_attention looks like:\", obs_attention_dbg)\n",
        "    print(\"DEBUGGING: act_attention looks like:\", act_attention_dbg)\n",
        "    print(\"DEBUGGING: logits looks like:\", logits_dbg)\n",
        "\n",
        "\n",
        "    assert len(traj_returns) == numtrajs\n",
        "    VAL = np.array(VAL)\n",
        "    VAL_ALL_np = np.array(VAL_ALL)\n",
        "    # 1. calculate the baseline: average return of the trajectories\n",
        "    # TODO: potentially can make this into *running average*, take into account of all the previous trajectories as well\n",
        "    # TODO: potentially make the baseline the average *VALUE* of every *state*, \n",
        "    #       but I'm not sure whether that \"state\" is useful in this concept, since the first *step*\n",
        "    #       doesn't really mean the same thing among instances\n",
        "    #       I think prof says it makes sense in the OH, also it would make more sense if you engineered the reward\n",
        "    baseline = np.mean(traj_returns)\n",
        "    baseline_2 = VAL.mean(axis=0, keepdims=True) # This is NOT a good baseline, this is only the mean of that episode, NOT running mean\n",
        "    baseline_3 = VAL_ALL_np.mean(axis=0, keepdims=True)\n",
        "    # assert baseline_2.shape == VAL.shape\n",
        "\n",
        "    # 2. Update the policy\n",
        "    ADS = (VAL - baseline_3).flatten()\n",
        "    print(\"DEBUGGING: baseline2 looks like:\", baseline_2)\n",
        "    print(\"DEBUGGING: baseline2 looks like:\", baseline)\n",
        "    print(\"DEBUGGING: ADS looks like:\", ADS)\n",
        "\n",
        "\n",
        "    # Train the agent using the batch\n",
        "    # obs_batch = np.concatenate(OBS_MAT)\n",
        "    # act_batch = np.concatenate(ACT_MAT)\n",
        "\n",
        "    assert ADS.shape[0] == len(actions)\n",
        "\n",
        "    # scaling up the rewards to artificially make bigger loss, improve learning\n",
        "\n",
        "    loss = policy.train(OBS_MAT, ACT_MAT, actions, ADS)\n",
        "\n",
        "    fixedWindow=50\n",
        "    movingAverage=0\n",
        "    if len(rrecord) >= fixedWindow:\n",
        "        movingAverage=np.mean(rrecord[len(rrecord)-fixedWindow:len(rrecord)-1])\n",
        "\n",
        "    # TODO: wandb logging\n",
        "    wandb.log({ \"training reward\" : rrecord[-1], \"training reward moving average\" : movingAverage, \"training loss\": loss})\n",
        "    #make sure to use the correct tag in wandb.init in the initialization on top\n"
      ],
      "metadata": {
        "id": "aeQHQnp1-8fR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03968604-f9e6-4d67-cf0f-c9a8687f7108"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<wandb.jupyter.IFrame at 0x7f788bb97f90>"
            ],
            "text/html": [
              "<iframe src=\"https://wandb.ai/ieor4575-spring2022/finalproject/runs/1ppyhfj2?jupyter=true\" style=\"border:none;width:100%;height:420px;\"></iframe>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            " -10.16076766 -10.11754138 -10.12357613  -9.82839657  -9.82920495\n",
            " -10.08036025 -10.0923826   -9.95727121 -10.13384123  -9.83323207\n",
            " -10.06140268  -9.3953641   -9.09262548  -8.50180485  -8.27680477\n",
            "  -8.19013203  -7.68884716  -7.71252959  -7.46545583  -7.1534823\n",
            "  -6.78585988  -6.45145879  -6.46296248  -6.43193354  -6.4684059\n",
            "  -6.48612769  -5.34476606  -5.40347801  -5.08640594  -4.9573734\n",
            "  -4.84616963  -4.82340378  -4.84090326  -4.23366277  -4.47556552\n",
            "  -4.54532652  -3.92173035  -3.95962613  -3.98572024  -3.86233238\n",
            "  -3.88298699  -3.13321697  -3.14195628  -3.25615231  -1.98290043\n",
            "  -1.98139563  -1.5957138   -1.59920137  -0.90195637  -0.92157616\n",
            " -10.16729352 -10.12413316 -10.13023449  -9.83512219  -9.83599851\n",
            " -10.08722243 -10.0993141   -9.96427272 -10.14091346  -9.84037573\n",
            " -10.06861851  -9.40265281  -9.09146429  -8.54676404  -8.36641852\n",
            "  -8.2698816   -7.70001252  -7.79989048  -7.5775532   -7.24050944\n",
            "  -6.69315336  -6.5483811   -6.62698949  -6.83268103  -7.04598154\n",
            "  -7.07815605  -5.94859664  -6.07916738  -5.90590834  -5.76775224\n",
            "  -5.70868922  -6.03843404  -6.08334946  -5.47200336  -4.82978595\n",
            "  -4.85481897  -4.16868347  -4.22879254  -4.2678123   -4.05797042\n",
            "  -4.0943042   -3.3299684   -3.34003355  -3.35554415  -2.08084902\n",
            "  -2.07934329  -1.62519016  -1.63311263  -0.93732296  -0.92728631]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(-4.9186, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-0.1262,  0.0057,  0.0164,  ...,  0.0718,  0.3070,  0.0263],\n",
            "        [-0.1517,  0.0069,  0.0197,  ...,  0.0863,  0.3692,  0.0303],\n",
            "        [-0.1621,  0.0073,  0.0211,  ...,  0.0922,  0.3944,  0.0354],\n",
            "        ...,\n",
            "        [-0.2354,  0.0107,  0.0306,  ...,  0.1339,  0.5727,  0.0507],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0165,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0167,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0178,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0316,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0329,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0348,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0323,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0326,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0346,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0163,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0170,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0179,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0311,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0320,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0338,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0392,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0400,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0415,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0235,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0240,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0253,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0268,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0279,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0296,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0344,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0357,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0374,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0160,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0164,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0174,  0.0000,  0.0000,  0.0000]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.2734,  0.0869, -0.2985,  ...,  0.0921, -0.3316,  0.1617],\n",
            "        [ 0.3269,  0.1039, -0.3570,  ...,  0.1101, -0.3965,  0.1943],\n",
            "        [ 0.3621,  0.1151, -0.3954,  ...,  0.1219, -0.4392,  0.2145],\n",
            "        ...,\n",
            "        [ 0.5218,  0.1658, -0.5697,  ...,  0.1757, -0.6328,  0.3077],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0921,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1009,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1244,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1633,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1796,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.2207,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1694,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1854,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.2294,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0810,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0891,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1095,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1562,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1706,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.2108,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2080,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.2278,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.2813,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1267,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1386,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1710,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1356,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1486,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1832,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1769,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1939,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.2382,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0888,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0975,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1199,  0.0000,  0.0000,  0.0000]])\n",
            "DEBUGGING: training for one iteration takes 0.004631 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 44\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [57]\n",
            "DEBUGGING: logits looks like: tensor([21577.5918, 21624.4883, 21561.2031, 21600.8398, 21549.7188, 21619.0898,\n",
            "        21616.5977, 21571.1543, 21609.8398, 21661.6777, 21620.6602, 21571.3555,\n",
            "        21688.7871, 21620.2480, 21635.1875, 21647.0391, 21632.0820, 21652.4102,\n",
            "        21646.3418, 21577.2109, 21625.4941, 21576.1191, 21618.0156, 21588.1523,\n",
            "        21658.2695, 21637.7129, 21625.0117, 21591.0371, 21654.9219, 21603.5430,\n",
            "        21612.5977, 21619.5000, 21601.0371, 21632.8027, 21627.2754, 21648.2715,\n",
            "        21583.2285, 21579.7402, 21567.9785, 21590.3809, 21584.4922, 21682.1934,\n",
            "        21593.3125, 21597.0293, 21547.9238, 21627.2793, 21651.8145, 21601.0938,\n",
            "        21632.7090, 21655.5938, 21656.7129, 21598.5156, 21643.5801, 21606.2109,\n",
            "        21610.9922, 21674.1113, 21632.7559, 21718.8047, 21640.5117, 21657.0449,\n",
            "        21690.1660, 21634.1562, 21566.2676, 21569.2344, 21636.4199, 21672.6875,\n",
            "        21650.4102, 21667.1387, 21671.8867], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.8590e-32, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8713e-14,\n",
            "        0.0000e+00, 1.4991e-08, 1.0239e-37, 0.0000e+00, 9.2469e-01, 0.0000e+00,\n",
            "        0.0000e+00, 5.0869e-40, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.8492e-37, 1.6830e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.4991e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 3.1519e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 8.2966e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.5670e-44,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.3877e-41, 0.0000e+00, 3.2982e-38, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6481e-42, 0.0000e+00,\n",
            "        4.5052e-42, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.5312e-02, 0.0000e+00],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [16]\n",
            "DEBUGGING: logits looks like: tensor([21760.5566, 21751.9434, 21741.4199, 21717.4863, 21733.2051, 21731.6543,\n",
            "        21751.4141, 21741.0371, 21746.8105, 21745.7949, 21715.0117, 21770.9199,\n",
            "        21745.7461, 21774.3184, 21757.5293, 21739.5547, 21778.8027, 21739.8926,\n",
            "        21734.9883, 21756.2031, 21730.3047, 21752.1797, 21751.5684, 21745.2910,\n",
            "        21757.7852, 21754.7754, 21734.9531, 21741.3125, 21739.6426, 21751.2578,\n",
            "        21774.3184, 21736.8809, 21733.1934, 21749.8535, 21749.6172, 21732.4844,\n",
            "        21729.3164, 21755.5078, 21735.9199, 21746.2637, 21747.8574, 21748.5195,\n",
            "        21746.0312, 21759.7793, 21740.9707, 21744.2148, 21741.3594, 21754.0000,\n",
            "        21747.6582, 21740.2871, 21732.5859, 21738.9668, 21738.6934, 21739.2559,\n",
            "        21749.2441, 21704.4668, 21755.3027, 21720.9297, 21757.2461, 21745.3652,\n",
            "        21747.1816, 21743.2871, 21742.8789, 21739.8926, 21755.0293, 21749.0391,\n",
            "        21755.0215, 21750.3301, 21740.1348, 21741.7070, 21749.3047, 21752.5469,\n",
            "        21744.1094, 21747.6680, 21745.4316, 21778.1758, 21717.4844],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.1988e-32, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.2457e-01, 2.0596e-31, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        5.3249e-44, 4.2082e-33, 2.5848e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.2013e-31, 0.0000e+00, 1.6103e-18, 1.4013e-45, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.0347e-24, 1.3869e-37, 4.6383e-43, 1.4153e-43, 0.0000e+00, 0.0000e+00,\n",
            "        6.5256e-25, 0.0000e+00, 0.0000e+00, 5.1036e-23, 2.8026e-45, 0.0000e+00,\n",
            "        1.7469e-35, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 9.9267e-41, 0.0000e+00, 7.0495e-18, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5036e-06, 1.0168e-36, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.6387e-39, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.9186e-35, 2.5848e-01, 0.0000e+00, 2.5848e-01, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3899e-35, 0.0000e+00],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [14]\n",
            "DEBUGGING: logits looks like: tensor([21750.8301, 21734.3223, 21737.9883, 21708.4551, 21631.0840, 21735.6133,\n",
            "        21726.4980, 21768.8320, 21751.5410, 21736.0645, 21741.7129, 21699.2070,\n",
            "        21744.2930, 21750.5684, 21768.8672, 21708.0605, 21713.6250, 21652.0020,\n",
            "        21722.9727, 21751.4062, 21740.5078, 21758.9629, 21743.4297, 21728.4473,\n",
            "        21740.1230, 21735.3516, 21695.6875, 21736.8105, 21738.4277, 21713.8672,\n",
            "        21755.3984, 21747.9883, 21744.8359, 21744.5391, 21734.7949, 21722.8633,\n",
            "        21755.2832, 21708.4746, 21738.8574, 21756.3730, 21743.5820, 21717.5938,\n",
            "        21749.1973, 21719.1973, 21730.4395, 21721.5059, 21732.5176, 21742.1133,\n",
            "        21724.0273, 21740.0957, 21746.1777, 21725.4551, 21759.3320, 21695.0684,\n",
            "        21667.6016, 21739.9668, 21707.1211, 21765.8535, 21748.4863, 21736.7168,\n",
            "        21698.4824, 21721.6465, 21706.2969, 21725.9082, 21740.1797, 21731.8477,\n",
            "        21726.3574, 21712.9824, 21731.8730, 21728.7988, 21739.0527, 21734.6016,\n",
            "        21683.9707, 21732.4863, 21747.0781, 21739.2383, 21708.3789, 21734.1191,\n",
            "        21722.7012, 21749.2207, 21768.8672, 21728.0762, 21768.8672, 21722.4883,\n",
            "        21722.6992, 21708.9473, 21738.1406, 21749.5215, 21695.2871],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.3876e-30, 1.5747e-33, 0.0000e+00, 6.3108e-23, 1.3702e-36, 2.6755e-41,\n",
            "        0.0000e+00, 0.0000e+00, 1.8371e-34, 1.5512e-29, 4.2625e-35, 1.5512e-29,\n",
            "        6.1002e-28, 2.5606e-21, 0.0000e+00, 2.4330e-23, 0.0000e+00, 0.0000e+00,\n",
            "        6.8856e-41, 1.5559e-35, 9.7892e-26, 3.4353e-41, 5.1601e-37, 2.7512e-24,\n",
            "        1.8779e-31, 1.1962e-30, 7.1042e-41, 0.0000e+00, 1.5230e-34, 8.9212e-33,\n",
            "        0.0000e+00, 0.0000e+00, 5.4338e-31, 2.1478e-34, 7.6583e-35, 1.5116e-19,\n",
            "        8.6753e-24, 2.0390e-29, 8.7645e-34, 2.6634e-32, 5.1943e-19, 6.3261e-33,\n",
            "        5.2681e-16, 0.0000e+00, 0.0000e+00, 1.1944e-27, 1.4900e-37, 1.7763e-24,\n",
            "        0.0000e+00, 1.2996e-24, 6.0765e-41, 1.8184e-24, 9.6027e-24, 3.2447e-31,\n",
            "        1.8344e-31, 9.9075e-24, 1.9478e-43, 4.4589e-21, 5.4962e-33, 2.0147e-31,\n",
            "        9.8542e-34, 0.0000e+00, 1.0483e-37, 2.0905e-32, 7.7743e-39, 1.3697e-25,\n",
            "        3.0244e-31, 7.6698e-38, 1.2341e-30, 5.9428e-33, 0.0000e+00, 0.0000e+00,\n",
            "        1.2680e-32, 1.6657e-36, 1.6374e-33, 5.4929e-37, 5.8033e-22, 0.0000e+00,\n",
            "        2.0237e-14, 0.0000e+00, 0.0000e+00, 1.4013e-45, 4.8606e-32, 9.4369e-36,\n",
            "        4.8606e-32, 9.9673e-36, 1.1010e-36, 2.9882e-33, 2.9454e-25, 7.2442e-28,\n",
            "        2.9882e-33, 5.7272e-32, 5.4731e-35, 1.1039e-31, 6.8834e-30, 3.4467e-32,\n",
            "        1.0937e-28, 1.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [97]\n",
            "DEBUGGING: logits looks like: tensor([21774.3047, 21772.6094, 21760.9648, 21778.7129, 21770.8477, 21768.1367,\n",
            "        21751.6953, 21763.8789, 21772.0723, 21774.9082, 21771.7070, 21774.9082,\n",
            "        21775.8262, 21779.6387, 21757.0000, 21778.4746, 21749.3281, 21759.3105,\n",
            "        21768.3730, 21771.4551, 21777.0957, 21768.1992, 21770.6035, 21777.9297,\n",
            "        21773.8047, 21774.2676, 21768.3809, 21761.0762, 21772.0254, 21773.0430,\n",
            "        21763.9297, 21761.0762, 21774.0703, 21772.1113, 21771.8535, 21780.6582,\n",
            "        21778.2168, 21774.9766, 21772.4629, 21773.3164, 21780.9668, 21772.9570,\n",
            "        21782.6973, 21764.6367, 21762.5977, 21775.9941, 21770.2930, 21777.8203,\n",
            "        21764.7617, 21777.7422, 21768.3418, 21777.8262, 21778.2422, 21773.9414,\n",
            "        21773.7988, 21778.2500, 21766.9062, 21779.7773, 21772.9219, 21773.8223,\n",
            "        21772.4922, 21761.5879, 21770.2051, 21773.2559, 21769.5547, 21777.1797,\n",
            "        21773.9238, 21770.1270, 21774.2754, 21772.9414, 21749.7598, 21764.7324,\n",
            "        21773.1309, 21770.8965, 21772.6191, 21770.6191, 21779.2676, 21761.1289,\n",
            "        21783.6094, 21764.9141, 21757.7598, 21765.7402, 21773.4668, 21771.3301,\n",
            "        21773.4668, 21771.3438, 21770.7930, 21772.7695, 21777.3711, 21775.8691,\n",
            "        21772.7695, 21773.5078, 21771.7695, 21773.6719, 21774.7051, 21773.3809,\n",
            "        21775.3965, 21791.4922], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.5125e-30, 0.0000e+00, 2.7753e-31, 1.5271e-29, 3.4663e-33, 2.9900e-29,\n",
            "        6.8523e-43, 4.9667e-18, 7.8067e-11, 8.9157e-37, 1.1019e-17, 1.0687e-13,\n",
            "        8.2406e-15, 4.3203e-10, 1.0045e-09, 1.5880e-29, 1.2044e-23, 2.7786e-23,\n",
            "        1.1383e-35, 9.4765e-34, 1.1345e-18, 2.4506e-27, 2.7470e-21, 1.3328e-12,\n",
            "        0.0000e+00, 3.7199e-18, 4.4629e-28, 5.3446e-24, 6.2055e-31, 3.1618e-21,\n",
            "        7.4335e-12, 8.7536e-16, 5.6909e-09, 1.4797e-18, 0.0000e+00, 9.1352e-18,\n",
            "        4.7166e-24, 4.9060e-35, 1.4615e-09, 0.0000e+00, 8.7668e-19, 1.7994e-29,\n",
            "        6.0127e-20, 3.4956e-29, 1.0813e-26, 5.0632e-20, 6.4274e-18, 1.0027e-21,\n",
            "        1.8846e-33, 1.8233e-19, 1.6681e-13, 1.9097e-23, 6.2918e-17, 2.1685e-22,\n",
            "        2.3881e-17, 1.5470e-34, 2.0873e-29, 1.7503e-05, 7.1445e-16, 9.7801e-19,\n",
            "        5.7408e-16, 5.9784e-19, 3.5400e-23, 2.9374e-30, 1.3871e-19, 2.0420e-06,\n",
            "        2.7256e-21, 5.9839e-26, 5.6757e-40, 9.6517e-29, 1.6482e-15, 9.4252e-18,\n",
            "        1.6023e-21, 0.0000e+00, 2.0861e-33, 8.5484e-31, 2.5170e-18, 1.3102e-35,\n",
            "        1.3591e-25, 9.5997e-39, 9.8627e-15, 1.1826e-28, 2.6032e-28, 1.1826e-28,\n",
            "        3.2232e-23, 5.8522e-18, 1.2890e-13, 1.9538e-27, 1.7258e-34, 5.4615e-36,\n",
            "        7.4627e-25, 3.9254e-11, 8.5691e-41, 1.7388e-23, 1.3280e-10, 2.0019e-08,\n",
            "        6.1277e-37, 3.3708e-24, 2.6434e-17, 1.6787e-36, 2.7919e-17, 1.3578e-18,\n",
            "        1.3097e-24, 1.6995e-19, 9.9998e-01, 0.0000e+00],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [104]\n",
            "DEBUGGING: logits looks like: tensor([21785.9590, 21776.1719, 21785.4082, 21786.4102, 21784.3125, 21786.5781,\n",
            "        21778.7266, 21793.0371, 21797.1797, 21782.2461, 21793.2363, 21795.5312,\n",
            "        21794.8906, 21797.6074, 21797.8184, 21786.4199, 21789.8047, 21790.0137,\n",
            "        21782.8828, 21783.9883, 21792.6680, 21787.6797, 21791.1621, 21796.1621,\n",
            "        21774.8203, 21792.9648, 21787.2539, 21789.6016, 21785.6094, 21791.1973,\n",
            "        21796.5918, 21794.3301, 21798.2520, 21792.7344, 21772.2207, 21793.1895,\n",
            "        21789.5703, 21783.2480, 21797.9121, 21761.1289, 21792.6035, 21786.4512,\n",
            "        21791.9336, 21786.6172, 21788.0508, 21791.8906, 21793.1016, 21790.9102,\n",
            "        21784.1602, 21792.2109, 21795.6426, 21789.9199, 21793.6719, 21790.5273,\n",
            "        21793.4297, 21783.5352, 21786.4883, 21800.2598, 21794.2793, 21792.6309,\n",
            "        21794.2246, 21792.5078, 21790.0742, 21785.9980, 21792.1426, 21799.7227,\n",
            "        21791.1602, 21788.4785, 21780.4062, 21786.8711, 21794.4883, 21793.1973,\n",
            "        21791.0273, 21774.6660, 21784.1855, 21785.6895, 21792.8672, 21782.9180,\n",
            "        21788.6836, 21781.1133, 21794.9355, 21786.9219, 21787.1191, 21786.9219,\n",
            "        21790.0508, 21793.0781, 21795.5781, 21787.6230, 21783.5625, 21782.6992,\n",
            "        21789.1094, 21797.0078, 21779.9336, 21789.8965, 21797.3125, 21798.5664,\n",
            "        21782.1523, 21789.4863, 21793.4551, 21782.4043, 21793.4688, 21792.7129,\n",
            "        21789.2500, 21792.1934, 21802.9980, 21774.1699],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.7058461509377594 and immediate abs rewards look like: [0.7058461509227527, 1.8189894035458565e-12, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 1.3642420526593924e-12, 0.0, 9.094947017729282e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.094947017729282e-13, 9.094947017729282e-13, 0.0, 0.0, 4.547473508864641e-13, 1.3642420526593924e-12, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0]\n",
            "DEBUGGING: the total relative reward of the trajectory = 2.608596763948431 and immediate relative rewards look like: [2.608596762540988, 1.8189894035470972e-11, 6.821210263295411e-12, 9.094947017729282e-12, 1.1368683772164188e-11, 1.3642420526593924e-11, 3.1832314562059726e-11, 1.818989403545443e-11, 0.0, 0.0, 2.5011104298755527e-11, 8.185452315954493e-11, 0.0, 6.366462912413393e-11, 0.0, 3.637978807091713e-11, 3.865352482534066e-11, 0.0, 4.320099833421409e-11, 4.547473508863607e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.3642420526593924e-10, 1.4097167877473977e-10, 0.0, 0.0, 7.73070496506989e-11, 2.387423592153394e-10, 8.185452315960076e-11, 8.412825991401499e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.000444171950221e-10, 0.0, 1.0459189070391053e-10, 0.0, 0.0, 0.0, 0.0]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 6.8031e-17, 2.2870e-19, 8.2505e-07, 6.8504e-36, 4.9075e-20,\n",
            "        0.0000e+00, 2.2856e-23, 1.4081e-23, 1.8233e-19, 0.0000e+00, 1.4181e-42,\n",
            "        1.1400e-38, 9.9999e-01, 6.0536e-43, 2.8300e-18, 3.8880e-23, 4.1399e-08,\n",
            "        2.7984e-42, 3.8928e-41, 5.4093e-22, 2.3603e-30, 1.5460e-12, 2.9596e-19,\n",
            "        1.3706e-21, 1.3859e-12, 1.4502e-35, 9.3156e-31, 1.5695e-16, 9.5222e-28,\n",
            "        4.1127e-26, 2.3056e-30, 9.0833e-17, 5.8137e-10, 1.7493e-35, 1.4014e-29,\n",
            "        7.6374e-14, 3.5369e-42, 0.0000e+00, 8.0571e-22, 4.4017e-16, 1.0277e-13,\n",
            "        3.4147e-29, 5.2318e-23, 9.2515e-38, 5.0830e-07, 1.0179e-25, 0.0000e+00,\n",
            "        9.9433e-26, 1.3018e-42, 6.1407e-36, 5.1275e-14, 9.1574e-28, 2.9330e-27,\n",
            "        4.9998e-26, 5.1322e-21, 5.7564e-11, 1.2271e-29, 2.4112e-31, 6.4897e-32,\n",
            "        1.0642e-15, 3.2174e-09, 1.7047e-25, 2.0225e-18, 1.4293e-42, 9.0833e-17,\n",
            "        4.9460e-20, 3.9981e-06], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [13]\n",
            "DEBUGGING: logits looks like: tensor([21477.2012, 21525.5898, 21524.1660, 21531.3945, 21514.6543, 21523.7812,\n",
            "        21461.8574, 21521.8633, 21521.7422, 21524.1094, 21500.6699, 21510.8066,\n",
            "        21513.0547, 21534.8965, 21510.5938, 21524.7949, 21521.9961, 21530.6465,\n",
            "        21510.9766, 21511.6348, 21522.6543, 21517.8418, 21528.0977, 21524.2305,\n",
            "        21522.8867, 21528.0703, 21514.8418, 21517.6094, 21525.7988, 21519.3418,\n",
            "        21520.2832, 21517.8359, 21525.6621, 21529.5801, 21514.8887, 21518.2871,\n",
            "        21527.3457, 21511.0352, 21488.2383, 21522.7539, 21526.0566, 21527.4199,\n",
            "        21518.5098, 21522.0703, 21513.5781, 21531.2734, 21520.5098, 21506.6719,\n",
            "        21520.5039, 21510.7852, 21514.6270, 21527.2461, 21519.3320, 21519.6230,\n",
            "        21520.3320, 21523.2168, 21529.0020, 21518.2539, 21517.2715, 21516.9434,\n",
            "        21526.2773, 21530.0078, 21520.6387, 21524.7109, 21510.8086, 21525.6621,\n",
            "        21523.7832, 21531.7891], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 3.9094e-07, 2.0124e-07, 3.4698e-08, 1.6078e-06, 6.0205e-06,\n",
            "        2.4049e-04, 2.7178e-09, 2.0282e-07, 5.9183e-03, 4.5228e-12, 1.7521e-06,\n",
            "        1.4300e-06, 4.4862e-01, 6.4050e-10, 4.4876e-12, 9.6962e-06, 8.8418e-09,\n",
            "        3.6836e-13, 2.9413e-16, 2.0009e-06, 1.5072e-07, 1.1484e-10, 1.4473e-04,\n",
            "        1.2628e-28, 1.8257e-05, 5.9023e-08, 1.5136e-05, 1.5729e-09, 6.6461e-11,\n",
            "        2.6003e-04, 6.4727e-05, 1.9711e-02, 6.1893e-04, 7.6588e-03, 1.5186e-22,\n",
            "        2.7605e-09, 1.1880e-05, 2.5785e-08, 2.0324e-06, 1.6683e-07, 2.0750e-11,\n",
            "        5.8687e-07, 4.5187e-05, 2.1838e-09, 1.6194e-10, 5.1900e-06, 1.8651e-06,\n",
            "        2.6604e-08, 1.9283e-05, 1.3369e-12, 4.4021e-10, 2.9929e-04, 1.2865e-08,\n",
            "        3.1056e-05, 3.2274e-09, 2.4049e-04, 3.2547e-05, 6.1245e-09, 5.3660e-05,\n",
            "        1.0694e-03, 1.4134e-19, 4.4406e-17, 1.3889e-05, 1.1515e-05, 8.5031e-09,\n",
            "        1.4442e-05, 3.3268e-02, 2.8904e-02, 1.1130e-10, 8.9434e-11, 5.1791e-07,\n",
            "        1.0343e-04, 3.3459e-03, 3.8848e-10, 8.2936e-06, 6.0933e-04, 4.4862e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [77]\n",
            "DEBUGGING: logits looks like: tensor([21483.0703, 21538.4922, 21538.3262, 21537.8867, 21538.8457, 21539.1758,\n",
            "        21540.0977, 21537.2500, 21538.3281, 21540.8984, 21535.6504, 21538.8672,\n",
            "        21538.8164, 21541.9805, 21536.8887, 21535.6484, 21539.2949, 21537.5449,\n",
            "        21535.0234, 21533.2402, 21538.9004, 21538.2539, 21536.4590, 21539.9707,\n",
            "        21526.1211, 21539.4531, 21538.0195, 21539.4062, 21537.1133, 21536.3223,\n",
            "        21540.1172, 21539.7695, 21541.1992, 21540.3340, 21540.9629, 21529.6211,\n",
            "        21537.2539, 21539.3457, 21537.8125, 21538.9043, 21538.2793, 21536.0312,\n",
            "        21538.5938, 21539.6797, 21537.1953, 21536.5449, 21539.1387, 21538.8828,\n",
            "        21537.8203, 21539.4668, 21535.3457, 21536.7949, 21540.1523, 21537.6387,\n",
            "        21539.5859, 21537.2930, 21540.0977, 21539.5977, 21537.4531, 21539.7227,\n",
            "        21540.4707, 21531.3301, 21532.7676, 21539.3848, 21539.3379, 21537.5352,\n",
            "        21539.3945, 21541.3301, 21541.2949, 21536.4512, 21536.3965, 21538.5625,\n",
            "        21539.8867, 21540.7559, 21536.7637, 21539.2559, 21540.3301, 21541.9805],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 9.4795e-04, 7.5736e-03, 2.9260e-02, 8.6493e-03, 6.3280e-03,\n",
            "        1.2487e-02, 2.6025e-02, 1.0764e-02, 1.0681e-02, 1.9451e-03, 2.8106e-10,\n",
            "        7.2268e-03, 1.6159e-02, 2.8746e-03, 1.1459e-02, 5.0451e-03, 3.3678e-02,\n",
            "        7.5147e-03, 9.7804e-04, 4.2153e-03, 1.4230e-03, 6.8422e-03, 9.1878e-04,\n",
            "        2.4975e-03, 1.7336e-02, 2.4448e-02, 5.2872e-03, 2.8522e-03, 5.2650e-05,\n",
            "        3.6339e-03, 4.2153e-03, 6.0856e-03, 1.8892e-02, 1.2172e-03, 1.3714e-02,\n",
            "        4.1177e-03, 1.3236e-04, 2.2611e-02, 5.0451e-03, 1.2883e-02, 1.6033e-02,\n",
            "        7.7976e-04, 8.6493e-03, 5.0557e-02, 1.0826e-03, 1.5909e-02, 6.3776e-03,\n",
            "        5.0451e-03, 3.9994e-02, 1.2657e-03, 1.9451e-03, 8.4490e-03, 1.0112e-02,\n",
            "        4.9282e-03, 1.9149e-03, 1.1706e-03, 7.7976e-04, 9.9553e-03, 2.8522e-03,\n",
            "        6.6038e-05, 3.7200e-03, 5.5928e-06, 5.1246e-03, 2.5368e-03, 2.5567e-03,\n",
            "        2.8021e-04, 1.7989e-03, 3.7980e-08, 3.2388e-02, 8.8544e-03, 5.4551e-03,\n",
            "        2.2611e-02, 1.1434e-03, 4.7766e-03, 1.7067e-02, 1.0352e-02, 2.7216e-03,\n",
            "        1.6033e-02, 1.3425e-01, 3.6056e-03, 1.5419e-02, 1.3425e-01, 3.7786e-03,\n",
            "        6.0382e-03, 2.2516e-04, 7.3406e-03, 3.7200e-03, 6.6837e-03, 1.3901e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [2]\n",
            "DEBUGGING: logits looks like: tensor([21487.5996, 21544.4102, 21544.9297, 21545.2676, 21544.9629, 21544.8848,\n",
            "        21545.0547, 21545.2383, 21545.0176, 21545.0156, 21544.5898, 21540.6523,\n",
            "        21544.9180, 21545.1191, 21544.6875, 21545.0332, 21544.8281, 21545.3027,\n",
            "        21544.9277, 21544.4180, 21544.7832, 21544.5117, 21544.9043, 21544.4023,\n",
            "        21544.6523, 21545.1367, 21545.2227, 21544.8398, 21544.6855, 21543.6875,\n",
            "        21544.7461, 21544.7832, 21544.8750, 21545.1582, 21544.4727, 21545.0781,\n",
            "        21544.7773, 21543.9180, 21545.2031, 21544.8281, 21545.0625, 21545.1172,\n",
            "        21544.3613, 21544.9629, 21545.4043, 21544.4434, 21545.1152, 21544.8867,\n",
            "        21544.8281, 21545.3457, 21544.4824, 21544.5898, 21544.9570, 21545.0020,\n",
            "        21544.8223, 21544.5859, 21544.4629, 21544.3613, 21544.9980, 21544.6855,\n",
            "        21543.7441, 21544.7520, 21543.1270, 21544.8320, 21544.6562, 21544.6582,\n",
            "        21544.1055, 21544.5703, 21541.8789, 21545.2930, 21544.9688, 21544.8477,\n",
            "        21545.2031, 21544.4570, 21544.8145, 21545.1328, 21545.0078, 21544.6738,\n",
            "        21545.1172, 21545.6484, 21544.7441, 21545.1074, 21545.6484, 21544.7559,\n",
            "        21544.8730, 21544.0508, 21544.9219, 21544.7520, 21544.8984, 21544.5059],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000, 0.0046, 0.0113, 0.0073, 0.0058, 0.0118, 0.0088, 0.0139, 0.0136,\n",
            "        0.0143, 0.0003, 0.0052, 0.0118, 0.0086, 0.0096, 0.0080, 0.0021, 0.0027,\n",
            "        0.0150, 0.0113, 0.0089, 0.0056, 0.0131, 0.0070, 0.0122, 0.0077, 0.0070,\n",
            "        0.0082, 0.0110, 0.0081, 0.0073, 0.0011, 0.0537, 0.0025, 0.0015, 0.0086,\n",
            "        0.0125, 0.0063, 0.0059, 0.0042, 0.0183, 0.0102, 0.0031, 0.0061, 0.0079,\n",
            "        0.0151, 0.0123, 0.0111, 0.0057, 0.0081, 0.0066, 0.0048, 0.0093, 0.0061,\n",
            "        0.0076, 0.0043, 0.0025, 0.0070, 0.0062, 0.0202, 0.0081, 0.0102, 0.0136,\n",
            "        0.0165, 0.0014, 0.0074, 0.0066, 0.0020, 0.0024, 0.0076, 0.0136, 0.0089,\n",
            "        0.0099, 0.0100, 0.0219, 0.0378, 0.0122, 0.0172, 0.0063, 0.0026, 0.1182,\n",
            "        0.0026, 0.0132, 0.0066, 0.0031, 0.0114, 0.0117, 0.0141, 0.0147, 0.0073,\n",
            "        0.0080, 0.0072, 0.0043, 0.0096, 0.0021, 0.0103, 0.0034, 0.0058],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [40]\n",
            "DEBUGGING: logits looks like: tensor([21491.1133, 21547.7812, 21548.0078, 21547.8965, 21547.8418, 21548.0176,\n",
            "        21547.9453, 21548.0586, 21548.0527, 21548.0664, 21547.0723, 21547.8125,\n",
            "        21548.0176, 21547.9375, 21547.9668, 21547.9219, 21547.5879, 21547.6484,\n",
            "        21548.0781, 21548.0078, 21547.9473, 21547.8301, 21548.0430, 21547.8867,\n",
            "        21548.0254, 21547.9121, 21547.8867, 21547.9277, 21548.0000, 21547.9238,\n",
            "        21547.8965, 21547.4199, 21548.3965, 21547.6309, 21547.5020, 21547.9375,\n",
            "        21548.0312, 21547.8594, 21547.8438, 21547.7598, 21548.1270, 21547.9805,\n",
            "        21547.6875, 21547.8516, 21547.9160, 21548.0801, 21548.0273, 21548.0020,\n",
            "        21547.8340, 21547.9238, 21547.8730, 21547.7930, 21547.9570, 21547.8516,\n",
            "        21547.9062, 21547.7656, 21547.6309, 21547.8867, 21547.8555, 21548.1523,\n",
            "        21547.9238, 21547.9824, 21548.0527, 21548.1016, 21547.4824, 21547.9023,\n",
            "        21547.8711, 21547.5723, 21547.6211, 21547.9082, 21548.0527, 21547.9473,\n",
            "        21547.9727, 21547.9766, 21548.1719, 21548.3086, 21548.0254, 21548.1113,\n",
            "        21547.8594, 21547.6387, 21548.5938, 21547.6387, 21548.0449, 21547.8711,\n",
            "        21547.6797, 21548.0098, 21548.0156, 21548.0625, 21548.0723, 21547.8965,\n",
            "        21547.9219, 21547.8945, 21547.7656, 21547.9668, 21547.5918, 21547.9844,\n",
            "        21547.7051, 21547.8418], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000, 0.0113, 0.0108, 0.0090, 0.0142, 0.0098, 0.0064, 0.0117, 0.0098,\n",
            "        0.0100, 0.0046, 0.0097, 0.0082, 0.0100, 0.0100, 0.0102, 0.0134, 0.0092,\n",
            "        0.0058, 0.0120, 0.0116, 0.0098, 0.0111, 0.0104, 0.0110, 0.0072, 0.0080,\n",
            "        0.0111, 0.0110, 0.0025, 0.0098, 0.0098, 0.0103, 0.0025, 0.0092, 0.0102,\n",
            "        0.0061, 0.0046, 0.0078, 0.0026, 0.0100, 0.0083, 0.0058, 0.0089, 0.0109,\n",
            "        0.0104, 0.0121, 0.0108, 0.0087, 0.0101, 0.0130, 0.0112, 0.0103, 0.0120,\n",
            "        0.0068, 0.0104, 0.0059, 0.0110, 0.0071, 0.0098, 0.0125, 0.0052, 0.0094,\n",
            "        0.0071, 0.0098, 0.0128, 0.0082, 0.0080, 0.0120, 0.0119, 0.0100, 0.0101,\n",
            "        0.0126, 0.0117, 0.0089, 0.0112, 0.0070, 0.0085, 0.0080, 0.0100, 0.0110,\n",
            "        0.0115, 0.0110, 0.0068, 0.0075, 0.0090, 0.0080, 0.0100, 0.0119, 0.0105,\n",
            "        0.0029, 0.0087, 0.0092, 0.0113, 0.0093, 0.0097, 0.0063, 0.0092, 0.0083,\n",
            "        0.0083, 0.0013, 0.0108, 0.0063, 0.0120, 0.0049, 0.0090, 0.0103, 0.0033,\n",
            "        0.0114, 0.0092], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [59]\n",
            "DEBUGGING: logits looks like: tensor([21493.9648, 21550.6543, 21550.6426, 21550.5977, 21550.7109, 21550.6172,\n",
            "        21550.5137, 21550.6621, 21550.6172, 21550.6230, 21550.4316, 21550.6152,\n",
            "        21550.5742, 21550.6230, 21550.6230, 21550.6289, 21550.6973, 21550.6016,\n",
            "        21550.4883, 21550.6699, 21550.6602, 21550.6191, 21550.6484, 21550.6328,\n",
            "        21550.6465, 21550.5410, 21550.5684, 21550.6484, 21550.6465, 21550.2793,\n",
            "        21550.6191, 21550.6172, 21550.6309, 21550.2734, 21550.6016, 21550.6289,\n",
            "        21550.5000, 21550.4316, 21550.5605, 21550.2852, 21550.6230, 21550.5781,\n",
            "        21550.4863, 21550.5938, 21550.6445, 21550.6328, 21550.6719, 21550.6426,\n",
            "        21550.5879, 21550.6270, 21550.6895, 21550.6523, 21550.6309, 21550.6680,\n",
            "        21550.5254, 21550.6328, 21550.4922, 21550.6465, 21550.5371, 21550.6191,\n",
            "        21550.6797, 21550.4609, 21550.6074, 21550.5371, 21550.6191, 21550.6855,\n",
            "        21550.5742, 21550.5664, 21550.6699, 21550.6660, 21550.6230, 21550.6270,\n",
            "        21550.6816, 21550.6621, 21550.5938, 21550.6523, 21550.5352, 21550.5840,\n",
            "        21550.5684, 21550.6230, 21550.6465, 21550.6582, 21550.6465, 21550.5273,\n",
            "        21550.5508, 21550.5977, 21550.5664, 21550.6230, 21550.6660, 21550.6367,\n",
            "        21550.3145, 21550.5879, 21550.6035, 21550.6543, 21550.6055, 21550.6152,\n",
            "        21550.5098, 21550.6016, 21550.5762, 21550.5762, 21550.1191, 21550.6426,\n",
            "        21550.5098, 21550.6699, 21550.4473, 21550.5957, 21550.6309, 21550.3438,\n",
            "        21550.6562, 21550.6016], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.10361629372800962 and immediate abs rewards look like: [0.010754348344562459, 0.012717792419607576, 0.0065206662161472195, 0.013523074034310412, 0.0013198213255236624, 0.006750685518454702, 0.007228201553516556, 0.0036055261489309487, 0.0072994954552996205, 0.00839556322671342, 0.005126418202962668, 0.00549253599729127, 0.0033448821300225973, 0.0007765802574795089, 0.0009478675310674589, 0.0009580179021213553, 0.0006993425031396328, 0.0013952318468000158, 0.0031470689768866578, 0.0001173898417619057, 0.00021661861273969407, 0.0002090142961606034, 0.0002923738147728727, 0.0006636172174694366, 0.0003375080168552813, 5.3411366479849676e-05, 1.1351233752066037e-05, 0.00015032617511678836, 0.000683880196447717, 2.4427984044450568e-05, 6.198117807798553e-05, 8.62312595018011e-05, 2.4202990971389227e-06, 2.165744899684796e-05, 2.5788351194933057e-05, 0.0002921719292316993, 9.043938007380348e-07, 3.115837898803875e-08, 2.2989797798800282e-07, 6.722545549564529e-06, 2.3719016098766588e-05, 5.030738066125195e-07, 1.7893195035867393e-05, 1.7997399027080974e-05, 0.00011507567887747427, 1.4895919775881339e-05, 5.727141842726269e-05, 3.187555694239563e-05, 1.1128466212539934e-05, 6.475719555965043e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 2.1767237119842195 and immediate relative rewards look like: [0.029001021819185686, 0.06879110038297566, 0.0530884576119323, 0.14705896844610103, 0.01800697902591098, 0.11056337187338919, 0.13836984821154563, 0.07903712455327722, 0.1801926725373864, 0.23073952889644272, 0.15533958093828804, 0.1818206911955338, 0.12013563468190355, 0.030065164445522843, 0.03932614567249673, 0.042408211850952934, 0.03290109286927646, 0.06951434332102073, 0.1655705739972973, 0.006506724581210431, 0.012607561799321215, 0.012745027814776348, 0.01863947111551266, 0.04415006620224367, 0.023394107086259663, 0.003850614576252523, 0.0008498382546968657, 0.011671413376927443, 0.05499547296262342, 0.0020325449800493766, 0.005329123019550385, 0.007653435015924906, 0.00022153128009248373, 0.0020423895854699455, 0.0025034942544894336, 0.029174207947161725, 9.282235493625722e-05, 3.284368230850401e-06, 2.4870994581218054e-05, 0.0007459112663615825, 0.0026975826421408193, 5.861085885032378e-05, 0.0021342903524085885, 0.00219665436458112, 0.014364732173950037, 0.001900817815072517, 0.007467116534659154, 0.004244465919880851, 0.0015127224900483177, 0.008982293665516313]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 2.0699e-33, 1.7160e-33, 5.3947e-27, 1.2124e-31, 5.0542e-32,\n",
            "        1.9241e-38, 1.0000e+00, 4.5114e-08, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.1351e-43, 0.0000e+00, 4.9937e-08, 2.1286e-42, 3.3351e-43, 0.0000e+00,\n",
            "        3.3892e-40, 0.0000e+00, 1.1119e-35, 0.0000e+00, 0.0000e+00, 2.0274e-28,\n",
            "        0.0000e+00, 1.1797e-18, 0.0000e+00, 4.1997e-42, 0.0000e+00, 3.6755e-20,\n",
            "        2.6610e-25, 1.1133e-27, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4784e-11,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7256e-21, 1.6038e-28, 2.9287e-24,\n",
            "        0.0000e+00, 0.0000e+00, 1.7784e-16, 1.1695e-11, 0.0000e+00, 3.6230e-38,\n",
            "        9.0754e-36, 4.6715e-10, 7.4696e-32, 1.4700e-36, 1.0878e-38, 9.2711e-37,\n",
            "        0.0000e+00, 3.9397e-13, 0.0000e+00, 1.8835e-11, 0.0000e+00, 3.8636e-26,\n",
            "        0.0000e+00, 0.0000e+00, 1.2208e-24, 0.0000e+00, 5.1848e-44, 0.0000e+00,\n",
            "        0.0000e+00, 2.5606e-21, 0.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [7]\n",
            "DEBUGGING: logits looks like: tensor([21556.1191, 21585.0645, 21585.0176, 21588.7578, 21586.0820, 21585.8633,\n",
            "        21582.1680, 21603.8789, 21599.6504, 21574.3535, 21546.7246, 21546.3867,\n",
            "        21579.1582, 21511.1973, 21599.6758, 21579.8906, 21579.4277, 21554.8184,\n",
            "        21581.1582, 21575.0547, 21583.7578, 21554.0332, 21573.9199, 21587.9375,\n",
            "        21574.2637, 21593.5586, 21570.2793, 21580.0605, 21566.5957, 21592.6914,\n",
            "        21589.7324, 21588.3633, 21553.4570, 21575.7012, 21573.1973, 21597.6445,\n",
            "        21575.3633, 21575.5508, 21564.3281, 21592.1191, 21587.8789, 21590.3320,\n",
            "        21546.3164, 21562.4629, 21594.8125, 21597.5859, 21550.1953, 21582.3262,\n",
            "        21583.7070, 21598.5078, 21585.9609, 21583.2520, 21582.0254, 21583.1367,\n",
            "        21569.9688, 21596.7383, 21562.7988, 21597.7051, 21568.8203, 21589.2500,\n",
            "        21568.7090, 21577.5273, 21590.1133, 21573.0898, 21578.9629, 21570.0430,\n",
            "        21551.3047, 21592.0254, 21572.5273], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 2.4295e-05, 1.2034e-01, 3.6834e-04, 9.0402e-08, 5.8861e-04,\n",
            "        2.5514e-04, 5.9788e-04, 1.7202e-02, 4.6103e-05, 9.8722e-07, 6.7181e-08,\n",
            "        5.2132e-06, 2.6627e-06, 6.9314e-08, 6.7323e-07, 1.0575e-03, 1.1281e-02,\n",
            "        1.5267e-03, 2.6908e-01, 5.6691e-07, 1.9029e-06, 2.2121e-05, 5.4602e-10,\n",
            "        3.0518e-08, 6.2488e-09, 2.0899e-06, 9.0266e-05, 1.2052e-04, 3.1601e-10,\n",
            "        3.4117e-07, 4.7567e-05, 3.3730e-05, 8.4976e-04, 7.5693e-07, 1.3922e-06,\n",
            "        5.8526e-03, 2.2693e-04, 5.3256e-07, 5.3256e-07, 1.2631e-04, 3.8521e-05,\n",
            "        9.0646e-03, 4.4565e-10, 7.1149e-03, 1.8044e-09, 8.0744e-06, 1.0553e-04,\n",
            "        8.7122e-07, 4.2396e-04, 4.8974e-06, 6.0821e-07, 2.1869e-03, 1.3494e-06,\n",
            "        6.7748e-04, 3.0491e-01, 1.6508e-03, 5.5695e-08, 2.1427e-09, 9.7895e-11,\n",
            "        1.6864e-04, 2.6475e-05, 1.3714e-02, 1.0713e-08, 1.6439e-05, 6.7606e-05,\n",
            "        8.9081e-15, 1.0287e-05, 5.3900e-05, 6.1334e-03, 1.5508e-03, 1.0658e-03,\n",
            "        1.6961e-05, 1.2856e-03, 9.0130e-02, 4.8418e-04, 7.9373e-03, 1.2128e-01,\n",
            "        5.5030e-10, 1.1411e-04], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [19]\n",
            "DEBUGGING: logits looks like: tensor([21561.2129, 21605.2695, 21607.3965, 21605.9492, 21603.8711, 21606.0664,\n",
            "        21605.8574, 21606.0703, 21606.9102, 21605.4297, 21604.4688, 21603.7969,\n",
            "        21604.8848, 21604.7168, 21603.8047, 21604.3730, 21606.2129, 21606.8047,\n",
            "        21606.3047, 21607.5977, 21604.3301, 21604.6328, 21605.2461, 21602.5938,\n",
            "        21603.5996, 21603.2031, 21604.6562, 21605.5977, 21605.6699, 21602.4570,\n",
            "        21604.2031, 21605.4375, 21605.3516, 21606.1582, 21604.4023, 21604.5547,\n",
            "        21606.6406, 21605.8281, 21604.3145, 21604.3145, 21605.6816, 21605.3848,\n",
            "        21606.7500, 21602.5430, 21606.6895, 21602.8926, 21604.9941, 21605.6367,\n",
            "        21604.4375, 21605.9844, 21604.8691, 21604.3477, 21606.3945, 21604.5469,\n",
            "        21606.1016, 21607.6289, 21606.3242, 21603.7500, 21602.9355, 21602.1641,\n",
            "        21605.7539, 21605.2910, 21606.8535, 21603.3379, 21605.1719, 21605.5254,\n",
            "        21599.8379, 21605.0547, 21605.4688, 21606.6523, 21606.3086, 21606.2148,\n",
            "        21605.1797, 21606.2617, 21607.3242, 21606.0176, 21606.7168, 21607.3984,\n",
            "        21602.5957, 21605.6562], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.6802e-03, 3.4820e-02, 1.9080e-02, 1.5818e-02, 2.7920e-03,\n",
            "        2.9489e-03, 2.7761e-02, 1.5093e-02, 6.0163e-02, 5.2982e-03, 1.3113e-02,\n",
            "        5.2349e-05, 6.1942e-03, 1.4515e-02, 1.1393e-02, 7.2833e-04, 2.8582e-03,\n",
            "        7.3558e-03, 1.4744e-02, 1.3850e-02, 1.0703e-02, 1.1482e-02, 1.8064e-02,\n",
            "        5.0162e-03, 1.3113e-02, 1.1042e-02, 1.2611e-02, 7.1854e-03, 1.1393e-02,\n",
            "        1.1393e-02, 5.5525e-03, 1.3424e-02, 6.1942e-03, 1.2611e-02, 1.1847e-02,\n",
            "        1.8206e-02, 9.3716e-03, 1.1393e-02, 1.4744e-02, 1.2128e-02, 7.6489e-03,\n",
            "        6.6976e-03, 6.0507e-03, 1.4744e-02, 1.4859e-02, 4.9000e-03, 1.5694e-02,\n",
            "        1.4068e-02, 1.1663e-02, 1.0054e-02, 1.1572e-02, 9.9760e-03, 1.3424e-02,\n",
            "        5.2982e-03, 2.9032e-03, 8.8038e-03, 2.8139e-03, 1.5572e-02, 3.7278e-03,\n",
            "        1.8349e-02, 2.8419e-02, 1.2611e-02, 6.7501e-03, 1.2611e-02, 1.4944e-03,\n",
            "        7.8303e-03, 1.5818e-02, 2.9260e-03, 8.6673e-03, 2.1119e-02, 1.9995e-02,\n",
            "        1.1755e-02, 1.3113e-02, 1.7508e-02, 1.2033e-02, 7.3558e-03, 7.9536e-03,\n",
            "        2.8419e-02, 6.2918e-03, 2.7487e-03, 5.6399e-03, 1.5572e-02, 4.3924e-03,\n",
            "        1.3850e-02, 2.8806e-03, 1.5694e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [5]\n",
            "DEBUGGING: logits looks like: tensor([21564.8848, 21608.9492, 21609.7070, 21609.5566, 21609.5098, 21609.0762,\n",
            "        21609.0898, 21609.6504, 21609.4980, 21609.8438, 21609.2363, 21609.4629,\n",
            "        21608.0820, 21609.2754, 21609.4883, 21609.4277, 21608.7402, 21609.0820,\n",
            "        21609.3184, 21609.4922, 21609.4766, 21609.4121, 21609.4297, 21609.5430,\n",
            "        21609.2227, 21609.4629, 21609.4199, 21609.4531, 21609.3125, 21609.4277,\n",
            "        21609.4277, 21609.2480, 21609.4688, 21609.2754, 21609.4531, 21609.4375,\n",
            "        21609.5449, 21609.3789, 21609.4277, 21609.4922, 21609.4434, 21609.3281,\n",
            "        21609.2949, 21609.2695, 21609.4922, 21609.4941, 21609.2168, 21609.5078,\n",
            "        21609.4805, 21609.4336, 21609.3965, 21609.4316, 21609.3945, 21609.4688,\n",
            "        21609.2363, 21609.0859, 21609.3633, 21609.0781, 21609.5059, 21609.1484,\n",
            "        21609.5469, 21609.6562, 21609.4531, 21609.2969, 21609.4531, 21608.9199,\n",
            "        21609.3340, 21609.5098, 21609.0879, 21609.3594, 21609.5820, 21609.5684,\n",
            "        21609.4355, 21609.4629, 21609.5352, 21609.4414, 21609.3184, 21609.3379,\n",
            "        21609.6562, 21609.2793, 21609.0723, 21609.2520, 21609.5059, 21609.1895,\n",
            "        21609.4766, 21609.0840, 21609.5078], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000, 0.0104, 0.0093, 0.0109, 0.0099, 0.0099, 0.0033, 0.0114, 0.0163,\n",
            "        0.0110, 0.0085, 0.0096, 0.0051, 0.0073, 0.0143, 0.0130, 0.0094, 0.0125,\n",
            "        0.0063, 0.0130, 0.0137, 0.0106, 0.0163, 0.0178, 0.0061, 0.0091, 0.0081,\n",
            "        0.0097, 0.0079, 0.0096, 0.0070, 0.0049, 0.0122, 0.0083, 0.0124, 0.0016,\n",
            "        0.0117, 0.0122, 0.0118, 0.0134, 0.0145, 0.0104, 0.0081, 0.0082, 0.0124,\n",
            "        0.0105, 0.0068, 0.0097, 0.0113, 0.0035, 0.0124, 0.0085, 0.0093, 0.0106,\n",
            "        0.0144, 0.0087, 0.0147, 0.0147, 0.0089, 0.0114, 0.0087, 0.0091, 0.0133,\n",
            "        0.0126, 0.0121, 0.0097, 0.0118, 0.0147, 0.0124, 0.0063, 0.0101, 0.0124,\n",
            "        0.0130, 0.0154, 0.0114, 0.0081, 0.0088, 0.0118, 0.0088, 0.0087, 0.0087,\n",
            "        0.0065, 0.0117, 0.0076, 0.0114, 0.0124, 0.0097, 0.0102, 0.0074, 0.0065,\n",
            "        0.0051, 0.0113, 0.0147, 0.0017, 0.0057, 0.0085, 0.0112, 0.0129, 0.0121],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [37]\n",
            "DEBUGGING: logits looks like: tensor([21567.6992, 21611.7910, 21611.7617, 21611.8027, 21611.7773, 21611.7773,\n",
            "        21611.5059, 21611.8125, 21611.9023, 21611.8047, 21611.7383, 21611.7695,\n",
            "        21611.6133, 21611.7012, 21611.8691, 21611.8457, 21611.7656, 21611.8359,\n",
            "        21611.6660, 21611.8457, 21611.8594, 21611.7949, 21611.9023, 21611.9238,\n",
            "        21611.6582, 21611.7559, 21611.7266, 21611.7734, 21611.7227, 21611.7695,\n",
            "        21611.6895, 21611.6035, 21611.8301, 21611.7324, 21611.8340, 21611.3223,\n",
            "        21611.8184, 21611.8301, 21611.8223, 21611.8535, 21611.8730, 21611.7910,\n",
            "        21611.7266, 21611.7305, 21611.8340, 21611.7930, 21611.6836, 21611.7734,\n",
            "        21611.8105, 21611.5176, 21611.8340, 21611.7383, 21611.7617, 21611.7949,\n",
            "        21611.8711, 21611.7441, 21611.8770, 21611.8770, 21611.7500, 21611.8125,\n",
            "        21611.7441, 21611.7578, 21611.8516, 21611.8379, 21611.8281, 21611.7734,\n",
            "        21611.8223, 21611.8770, 21611.8340, 21611.6641, 21611.7832, 21611.8340,\n",
            "        21611.8457, 21611.8887, 21611.8125, 21611.7266, 21611.7480, 21611.8223,\n",
            "        21611.7480, 21611.7441, 21611.7441, 21611.6738, 21611.8184, 21611.7129,\n",
            "        21611.8125, 21611.8340, 21611.7734, 21611.7852, 21611.7051, 21611.6738,\n",
            "        21611.6113, 21611.8105, 21611.8770, 21611.3379, 21611.6406, 21611.7402,\n",
            "        21611.8086, 21611.8438, 21611.8281], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000, 0.0095, 0.0095, 0.0093, 0.0093, 0.0093, 0.0092, 0.0095, 0.0095,\n",
            "        0.0093, 0.0093, 0.0095, 0.0090, 0.0087, 0.0090, 0.0092, 0.0094, 0.0091,\n",
            "        0.0093, 0.0091, 0.0094, 0.0093, 0.0093, 0.0093, 0.0095, 0.0091, 0.0095,\n",
            "        0.0089, 0.0094, 0.0094, 0.0093, 0.0093, 0.0094, 0.0091, 0.0093, 0.0092,\n",
            "        0.0095, 0.0093, 0.0093, 0.0094, 0.0091, 0.0092, 0.0093, 0.0091, 0.0094,\n",
            "        0.0094, 0.0091, 0.0094, 0.0091, 0.0092, 0.0094, 0.0093, 0.0090, 0.0093,\n",
            "        0.0090, 0.0091, 0.0094, 0.0092, 0.0093, 0.0092, 0.0094, 0.0094, 0.0090,\n",
            "        0.0093, 0.0093, 0.0093, 0.0091, 0.0094, 0.0094, 0.0095, 0.0094, 0.0093,\n",
            "        0.0095, 0.0093, 0.0094, 0.0095, 0.0094, 0.0094, 0.0092, 0.0090, 0.0091,\n",
            "        0.0091, 0.0094, 0.0094, 0.0094, 0.0093, 0.0095, 0.0094, 0.0093, 0.0094,\n",
            "        0.0089, 0.0093, 0.0093, 0.0093, 0.0090, 0.0091, 0.0093, 0.0089, 0.0092,\n",
            "        0.0092, 0.0090, 0.0091, 0.0094, 0.0090, 0.0092, 0.0094, 0.0094, 0.0092,\n",
            "        0.0094], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [71]\n",
            "DEBUGGING: logits looks like: tensor([21569.9922, 21614.1191, 21614.1191, 21614.1133, 21614.1133, 21614.1133,\n",
            "        21614.1094, 21614.1191, 21614.1191, 21614.1133, 21614.1133, 21614.1191,\n",
            "        21614.1055, 21614.0957, 21614.1055, 21614.1094, 21614.1152, 21614.1074,\n",
            "        21614.1133, 21614.1074, 21614.1152, 21614.1133, 21614.1133, 21614.1133,\n",
            "        21614.1191, 21614.1074, 21614.1191, 21614.1035, 21614.1152, 21614.1152,\n",
            "        21614.1133, 21614.1133, 21614.1152, 21614.1074, 21614.1133, 21614.1094,\n",
            "        21614.1191, 21614.1133, 21614.1133, 21614.1152, 21614.1074, 21614.1094,\n",
            "        21614.1133, 21614.1074, 21614.1152, 21614.1152, 21614.1074, 21614.1152,\n",
            "        21614.1074, 21614.1094, 21614.1152, 21614.1133, 21614.1055, 21614.1133,\n",
            "        21614.1055, 21614.1074, 21614.1152, 21614.1094, 21614.1133, 21614.1094,\n",
            "        21614.1152, 21614.1152, 21614.1055, 21614.1133, 21614.1133, 21614.1133,\n",
            "        21614.1074, 21614.1152, 21614.1152, 21614.1191, 21614.1152, 21614.1133,\n",
            "        21614.1191, 21614.1133, 21614.1152, 21614.1191, 21614.1152, 21614.1152,\n",
            "        21614.1094, 21614.1055, 21614.1074, 21614.1074, 21614.1152, 21614.1152,\n",
            "        21614.1152, 21614.1133, 21614.1191, 21614.1152, 21614.1133, 21614.1152,\n",
            "        21614.1035, 21614.1133, 21614.1133, 21614.1133, 21614.1055, 21614.1074,\n",
            "        21614.1133, 21614.1016, 21614.1094, 21614.1094, 21614.1055, 21614.1074,\n",
            "        21614.1152, 21614.1055, 21614.1094, 21614.1172, 21614.1172, 21614.1094,\n",
            "        21614.1152], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.29835179641895593 and immediate abs rewards look like: [0.1100722757364565, 0.14929593634997218, 0.0012034063638566295, 0.0002987925056459062, 2.121358875228907e-05, 0.00028725664196826983, 0.010993433698104127, 0.0005462698982228176, 0.001272452237571997, 0.006908467604489488, 0.009769924919282857, 0.0001419619934495131, 0.00022909584413355333, 0.0007394952071990701, 0.00043505392659426434, 0.0016476759874421987, 0.002403528512786579, 0.0001987847053896985, 0.00037829100051567366, 0.00014043539817976125, 3.012997126461414e-05, 0.0002778339480755676, 0.00018452437780069886, 6.561070449606632e-06, 0.0002808674937568867, 5.0280535560887074e-05, 0.00013201497540649143, 9.095069799514022e-07, 3.3613102914387127e-06, 8.250605719695159e-05, 0.00013449048924485396, 3.1365245831693755e-06, 3.0432912808464607e-05, 1.1833462167487596e-05, 2.3357024701908813e-05, 1.6998094451992074e-06, 6.824410093031474e-06, 3.162104985676706e-05, 3.796660871557833e-05, 1.858694781731174e-05, 6.691859653074061e-07, 3.2888040095713222e-06, 7.462385838152841e-07, 7.92665446169849e-06, 3.5974585443909746e-07, 8.7938565229706e-07, 2.0665404463215964e-06, 1.0602207112242468e-07, 6.943855623831041e-07, 2.3688501187280053e-06]\n",
            "DEBUGGING: the total relative reward of the trajectory = 2.4063873407488794 and immediate relative rewards look like: [0.3051419852930756, 0.8538086521673165, 0.010783598958361664, 0.0035712150059946657, 0.0003169634837876518, 0.005150497310148532, 0.22998341512362058, 0.013103628975467713, 0.0343438889688088, 0.20725878864423208, 0.3230845489799944, 0.005136450061962186, 0.008980259532727691, 0.031219196817384068, 0.019682920311485413, 0.07952505336112647, 0.12331794689816634, 0.010806839679953143, 0.021709455086521303, 0.00848448572247448, 0.001911416690660043, 0.01846499974249203, 0.012822105708948154, 0.0004757599961459361, 0.021215063098390767, 0.003950144100844662, 0.010770435334699935, 7.695337762544301e-05, 0.00029455767370907136, 0.007479477629500405, 0.01259877367749996, 0.0003033132145712705, 0.003034942944721026, 0.0012158718596740343, 0.002470496147484123, 0.0001849287444067444, 0.0007630776716067228, 0.0036313046218938365, 0.0044747972707610325, 0.002246880654857332, 8.291728137466464e-05, 0.0004174473852169304, 9.697528148986942e-05, 0.0010540412185247477, 4.892426875425926e-05, 0.00012225124365867503, 0.0002935336951336917, 1.537991681468558e-05, 0.00010282843868794243, 0.00035795147612212856]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 3\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 6.2272e-30, 0.0000e+00, 4.7033e-26, 2.4547e-12, 0.0000e+00,\n",
            "        1.8815e-01, 3.3785e-31, 0.0000e+00, 1.4013e-45, 0.0000e+00, 8.2969e-31,\n",
            "        1.8068e-24, 3.8134e-18, 6.9970e-08, 6.8024e-40, 1.4013e-45, 1.0498e-37,\n",
            "        9.1313e-04, 0.0000e+00, 5.2077e-37, 9.4840e-38, 0.0000e+00, 0.0000e+00,\n",
            "        8.8612e-22, 0.0000e+00, 0.0000e+00, 2.4949e-08, 9.0244e-43, 0.0000e+00,\n",
            "        0.0000e+00, 2.6013e-29, 3.5642e-39, 2.8374e-36, 0.0000e+00, 0.0000e+00,\n",
            "        1.1789e-19, 9.6534e-11, 9.0197e-21, 5.6052e-45, 3.3012e-16, 2.5749e-19,\n",
            "        1.1423e-34, 4.8135e-41, 0.0000e+00, 2.8026e-45, 9.6709e-25, 5.8078e-26,\n",
            "        0.0000e+00, 0.0000e+00, 6.6089e-24, 2.5009e-18, 0.0000e+00, 2.3508e-40,\n",
            "        4.7104e-29, 1.3447e-27, 2.1715e-22, 0.0000e+00, 3.4900e-23, 1.6882e-34,\n",
            "        4.0619e-40, 1.0824e-15, 5.0489e-22, 8.1093e-01, 5.8305e-13, 1.1585e-31],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [63]\n",
            "DEBUGGING: logits looks like: tensor([21625.6934, 21674.8184, 21660.3613, 21677.0508, 21684.9473, 21664.8594,\n",
            "        21691.2129, 21674.0898, 21658.3477, 21665.7305, 21662.9531, 21674.3145,\n",
            "        21677.9629, 21681.6035, 21687.5117, 21669.0840, 21665.7773, 21670.3438,\n",
            "        21689.8809, 21660.3574, 21670.7441, 21670.3184, 21664.6211, 21635.1367,\n",
            "        21679.5117, 21659.5234, 21660.0566, 21687.2539, 21667.4277, 21662.2656,\n",
            "        21659.6875, 21675.1758, 21669.4980, 21671.1680, 21663.3027, 21664.3320,\n",
            "        21680.7344, 21685.8652, 21680.0918, 21666.1582, 21682.7188, 21680.9297,\n",
            "        21672.0918, 21668.4219, 21664.8359, 21666.0684, 21677.8066, 21677.1035,\n",
            "        21661.7188, 21657.8828, 21678.2871, 21681.4980, 21657.1719, 21668.8184,\n",
            "        21675.3242, 21676.1621, 21679.1602, 21664.5918, 21678.7031, 21672.1895,\n",
            "        21668.9551, 21683.0156, 21679.3711, 21691.5781, 21684.5879, 21673.8223],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 5.4739e-08, 5.2801e-14, 4.5476e-07, 3.0312e-03, 2.9054e-12,\n",
            "        1.3605e-05, 3.0467e-08, 2.5841e-12, 6.6506e-12, 3.3371e-13, 3.6180e-08,\n",
            "        3.8375e-06, 1.3111e-04, 2.3842e-02, 1.8838e-10, 1.0221e-11, 7.0540e-10,\n",
            "        8.5139e-06, 1.2839e-14, 7.7917e-11, 1.8105e-14, 6.4966e-12, 4.7558e-08,\n",
            "        2.8296e-06, 1.1781e-14, 1.1034e-08, 2.5471e-04, 1.0047e-08, 2.2723e-10,\n",
            "        1.1419e-14, 1.0903e-10, 5.8939e-10, 4.6262e-10, 1.8585e-09, 1.0501e-13,\n",
            "        6.7940e-13, 4.1493e-06, 2.3046e-07, 2.0952e-04, 1.8040e-12, 2.2963e-05,\n",
            "        3.4794e-08, 1.9146e-06, 1.4444e-10, 1.2947e-10, 7.1910e-12, 4.4865e-06,\n",
            "        5.0337e-07, 1.0068e-07, 3.4941e-06, 3.3937e-05, 6.1029e-12, 1.0083e-10,\n",
            "        7.4819e-08, 1.2666e-13, 4.3146e-06, 5.6004e-12, 7.9358e-06, 1.2681e-05,\n",
            "        6.6267e-10, 5.2642e-08, 6.1674e-07, 3.9700e-01, 2.6903e-04, 6.9260e-15,\n",
            "        1.3226e-11, 3.0076e-03, 1.3226e-11, 3.0076e-03, 1.4605e-01, 2.8356e-05,\n",
            "        6.5278e-06, 1.3009e-04, 1.9529e-04, 1.0132e-04, 4.2261e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [76]\n",
            "DEBUGGING: logits looks like: tensor([21658.2344, 21707.1836, 21703.7207, 21707.7129, 21709.9141, 21704.7227,\n",
            "        21708.5625, 21707.0371, 21704.6934, 21704.9297, 21704.1816, 21707.0801,\n",
            "        21708.2461, 21709.1289, 21710.4297, 21705.7656, 21705.0371, 21706.0957,\n",
            "        21708.4453, 21703.3672, 21705.5449, 21703.4531, 21704.9238, 21707.1484,\n",
            "        21708.1699, 21703.3457, 21706.7832, 21709.2949, 21706.7598, 21705.8125,\n",
            "        21703.3379, 21705.6289, 21706.0508, 21705.9902, 21706.3379, 21703.8926,\n",
            "        21704.3594, 21708.2656, 21707.5430, 21709.2461, 21704.6035, 21708.6934,\n",
            "        21707.0703, 21708.0723, 21705.6992, 21705.6719, 21704.9492, 21708.2852,\n",
            "        21707.7383, 21707.3359, 21708.2227, 21708.7910, 21704.9082, 21705.6094,\n",
            "        21707.2617, 21703.9395, 21708.2754, 21704.8867, 21708.4277, 21708.5449,\n",
            "        21706.0801, 21707.1738, 21707.7891, 21711.1328, 21709.3086, 21703.2129,\n",
            "        21705.1016, 21709.9121, 21705.1016, 21709.9121, 21710.8828, 21708.7461,\n",
            "        21708.3789, 21709.1270, 21709.2285, 21709.0645, 21711.1484],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.7103e-03, 2.3349e-11, 2.8030e-17, 3.5775e-05, 7.0445e-06,\n",
            "        3.3296e-02, 6.3413e-04, 3.4116e-09, 1.3980e-06, 8.1915e-16, 3.3366e-01,\n",
            "        3.5094e-03, 1.9369e-07, 1.5475e-06, 1.7876e-08, 1.9230e-03, 6.1333e-05,\n",
            "        2.7979e-03, 2.6778e-09, 2.8241e-06, 9.8215e-04, 5.8983e-05, 1.8349e-03,\n",
            "        7.4004e-16, 1.7170e-16, 4.9878e-03, 1.8532e-02, 4.1475e-09, 8.9213e-20,\n",
            "        2.3660e-01, 3.8659e-09, 1.2382e-08, 1.1890e-05, 1.5785e-04, 6.0346e-09,\n",
            "        6.9604e-08, 4.6296e-05, 1.5752e-05, 4.8533e-16, 6.2787e-05, 3.2770e-17,\n",
            "        7.3141e-03, 1.5975e-02, 7.5304e-04, 1.1458e-04, 5.5094e-04, 2.9120e-10,\n",
            "        1.3714e-04, 5.3818e-04, 8.7409e-26, 9.1740e-03, 1.0155e-02, 1.9166e-12,\n",
            "        6.1333e-05, 1.3628e-07, 2.6546e-02, 3.4209e-04, 1.0871e-03, 2.6948e-06,\n",
            "        1.9011e-01, 4.2637e-07, 6.5387e-08, 1.8532e-02, 4.8445e-02, 1.8532e-02,\n",
            "        8.7670e-06, 7.3782e-10, 1.2856e-05, 2.3881e-04, 8.1546e-07, 2.6948e-06,\n",
            "        3.8243e-03, 5.8419e-17, 2.9721e-04, 3.5571e-04, 3.2711e-03, 2.9304e-07,\n",
            "        4.4845e-09, 1.1106e-04, 5.4978e-05, 9.1547e-04, 6.9103e-04, 4.5579e-05,\n",
            "        8.0790e-04, 2.5915e-06, 2.1031e-05, 3.5497e-05],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [11]\n",
            "DEBUGGING: logits looks like: tensor([21675.4043, 21724.8496, 21720.3223, 21716.9141, 21723.8828, 21723.4766,\n",
            "        21725.5918, 21724.6016, 21721.5684, 21723.0723, 21717.7578, 21726.1680,\n",
            "        21725.0293, 21722.5781, 21723.0977, 21721.9824, 21724.8789, 21724.0176,\n",
            "        21724.9727, 21721.5078, 21723.2480, 21724.7109, 21724.0078, 21724.8672,\n",
            "        21717.7324, 21717.3672, 21725.1172, 21725.4453, 21721.6172, 21715.4766,\n",
            "        21726.0820, 21721.5996, 21721.8906, 21723.6074, 21724.2539, 21721.7109,\n",
            "        21722.3223, 21723.9473, 21723.6777, 21717.6270, 21724.0234, 21716.9531,\n",
            "        21725.2129, 21725.4082, 21724.6445, 21724.1738, 21724.5664, 21720.9531,\n",
            "        21724.2188, 21724.5605, 21712.0176, 21725.2695, 21725.2949, 21719.6973,\n",
            "        21724.0176, 21722.4902, 21725.5352, 21724.4473, 21724.7363, 21723.2363,\n",
            "        21726.0273, 21722.7754, 21722.3066, 21725.4453, 21725.6855, 21725.4453,\n",
            "        21723.5312, 21721.1855, 21723.6270, 21724.3574, 21722.9375, 21723.2363,\n",
            "        21725.0508, 21717.0977, 21724.4121, 21724.4570, 21725.0117, 21722.6816,\n",
            "        21721.6367, 21724.1660, 21723.9902, 21724.6934, 21724.6230, 21723.9434,\n",
            "        21724.6621, 21723.2266, 21723.7500, 21723.8809],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 6.9540e-03, 0.0000e+00, 0.0000e+00, 2.9801e-01, 1.0581e-03,\n",
            "        9.1409e-03, 0.0000e+00, 2.1981e-38, 0.0000e+00, 0.0000e+00, 2.9909e-03,\n",
            "        6.6876e-03, 6.8854e-04, 5.7772e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        3.0389e-14, 0.0000e+00, 1.1994e-14, 9.2849e-03, 0.0000e+00, 5.7859e-05,\n",
            "        1.9574e-04, 0.0000e+00, 1.3193e-17, 1.6101e-04, 4.5963e-03, 6.6738e-30,\n",
            "        3.4240e-13, 1.5244e-30, 0.0000e+00, 2.3476e-03, 5.6912e-24, 0.0000e+00,\n",
            "        6.9540e-03, 1.1929e-24, 0.0000e+00, 1.2179e-03, 8.2906e-16, 7.4293e-05,\n",
            "        0.0000e+00, 1.1555e-02, 3.8243e-05, 1.1352e-03, 4.4710e-05, 3.4157e-03,\n",
            "        1.1940e-05, 3.9315e-03, 0.0000e+00, 0.0000e+00, 9.5711e-22, 0.0000e+00,\n",
            "        2.6490e-05, 0.0000e+00, 0.0000e+00, 3.7144e-04, 0.0000e+00, 3.3436e-02,\n",
            "        4.3219e-36, 2.5133e-04, 3.2987e-01, 2.7175e-04, 1.2326e-01, 2.6754e-04,\n",
            "        5.7530e-04, 8.3530e-05, 1.7446e-03, 7.8800e-03, 9.4113e-04, 2.1209e-03,\n",
            "        1.4922e-03, 1.1465e-02, 1.4069e-05, 5.2682e-05, 5.4158e-03, 1.9727e-04,\n",
            "        7.7252e-05, 7.8800e-03, 1.0725e-04, 3.2020e-04, 6.9939e-04, 4.6227e-04,\n",
            "        6.4314e-03, 1.6389e-03, 4.5579e-07, 7.8469e-05, 1.8179e-02, 4.2420e-04,\n",
            "        1.9882e-04, 6.0291e-04, 4.9312e-03, 2.5383e-03, 6.8999e-03, 5.7375e-09,\n",
            "        2.5931e-04, 3.3537e-08, 1.3320e-05, 1.8971e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [62]\n",
            "DEBUGGING: logits looks like: tensor([21689.0098, 21736.5195, 21623.5859, 21642.1406, 21737.4590, 21736.0488,\n",
            "        21736.5879, 21699.8301, 21716.0840, 21668.0586, 21612.3125, 21736.3086,\n",
            "        21736.5098, 21735.9414, 21737.0488, 21595.8477, 21687.8047, 21593.6953,\n",
            "        21729.9805, 21701.3867, 21729.7480, 21736.5918, 21658.8125, 21735.3223,\n",
            "        21735.6270, 21535.9941, 21728.0449, 21735.5781, 21736.4160, 21720.9668,\n",
            "        21730.5859, 21720.5977, 21708.5098, 21736.2480, 21724.3809, 21691.9688,\n",
            "        21736.5195, 21723.9902, 21662.5449, 21736.0840, 21729.0801, 21735.3848,\n",
            "        21664.9883, 21736.6465, 21735.2188, 21736.0664, 21735.2578, 21736.3418,\n",
            "        21734.9277, 21736.3770, 21703.6621, 21699.8457, 21725.6621, 21668.1875,\n",
            "        21735.1270, 21675.6211, 21684.5664, 21735.7871, 21574.6875, 21736.9121,\n",
            "        21717.4043, 21735.6895, 21737.4844, 21735.7090, 21737.2383, 21735.7051,\n",
            "        21735.8965, 21735.4141, 21736.1738, 21736.5508, 21736.0195, 21736.2227,\n",
            "        21736.1348, 21736.6445, 21734.9688, 21735.2988, 21736.4570, 21735.6289,\n",
            "        21735.3945, 21736.5508, 21735.4766, 21735.7500, 21735.9453, 21735.8418,\n",
            "        21736.5000, 21736.1582, 21734.1113, 21735.3984, 21736.7598, 21735.8203,\n",
            "        21735.6309, 21735.9082, 21736.4336, 21736.2676, 21736.5176, 21733.0176,\n",
            "        21735.6973, 21733.4590, 21734.9551, 21735.6191],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 3.0532e-11, 4.5559e-25, 5.4723e-01, 3.0688e-16, 4.4785e-22,\n",
            "        2.2696e-22, 7.7499e-25, 0.0000e+00, 1.5450e-34, 1.2068e-14, 1.1845e-08,\n",
            "        5.7904e-15, 4.4316e-01, 1.2682e-35, 1.4042e-20, 4.5178e-29, 6.0792e-03,\n",
            "        2.4919e-11, 4.2414e-07, 7.8483e-19, 2.7900e-13, 3.8934e-18, 3.2501e-11,\n",
            "        2.2648e-23, 8.1879e-10, 3.6652e-17, 1.3626e-12, 2.8484e-18, 3.1768e-33,\n",
            "        3.3724e-12, 5.7748e-20, 2.1559e-13, 0.0000e+00, 2.0375e-25, 1.1337e-14,\n",
            "        2.1136e-15, 0.0000e+00, 1.1543e-24, 6.1453e-09, 2.5687e-04, 1.0304e-26,\n",
            "        3.0131e-21, 0.0000e+00, 6.7029e-16, 0.0000e+00, 1.3753e-15, 4.9766e-09,\n",
            "        2.3922e-23, 1.2901e-12, 1.4318e-07, 9.2615e-22, 2.3262e-14, 8.7686e-22,\n",
            "        6.7576e-27, 8.2226e-34, 1.9309e-32, 2.0671e-07, 2.0338e-11, 1.1892e-21,\n",
            "        7.6159e-11, 2.1436e-12, 6.0664e-04, 2.0296e-12, 1.6993e-11, 5.0566e-20,\n",
            "        9.7526e-16, 1.0291e-08, 6.6467e-20, 1.9987e-23, 8.8293e-15, 5.0656e-08,\n",
            "        4.1408e-37, 0.0000e+00, 2.6146e-03, 5.8481e-14, 6.1288e-14, 1.0385e-26,\n",
            "        7.8129e-10, 3.3724e-12, 4.0303e-35, 1.7841e-25, 7.3397e-36, 6.5653e-11,\n",
            "        5.7419e-19, 7.0065e-45, 1.0818e-14, 3.0994e-15, 6.5124e-26, 3.5026e-20,\n",
            "        4.7459e-13, 1.7665e-26, 5.0947e-09, 2.0314e-19, 8.1024e-41, 4.6612e-29,\n",
            "        5.1780e-05, 9.8498e-15, 1.4733e-12, 1.4263e-20, 9.6014e-16, 1.7360e-12,\n",
            "        4.4960e-09, 1.6157e-09, 8.1535e-12], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [13]\n",
            "DEBUGGING: logits looks like: tensor([21699.9570, 21740.6289, 21732.6699, 21746.5312, 21737.7520, 21734.3926,\n",
            "        21734.2227, 21732.8027, 21717.7285, 21727.2188, 21738.6699, 21742.1191,\n",
            "        21738.4863, 21746.4785, 21726.5938, 21735.2539, 21730.3652, 21745.4062,\n",
            "        21740.5781, 21743.0137, 21736.2598, 21739.4551, 21736.6602, 21740.6445,\n",
            "        21733.6465, 21741.4512, 21737.2207, 21739.8516, 21736.5820, 21727.9746,\n",
            "        21740.0781, 21735.6074, 21739.3906, 21697.5254, 21732.4688, 21738.6543,\n",
            "        21738.2344, 21720.4922, 21732.9023, 21741.9551, 21744.6152, 21731.7227,\n",
            "        21734.8691, 21712.3340, 21737.9473, 21695.3770, 21738.1270, 21741.9023,\n",
            "        21733.6602, 21739.8379, 21742.7422, 21734.5742, 21738.8340, 21734.5605,\n",
            "        21731.6172, 21727.6367, 21728.4258, 21742.8340, 21740.5273, 21734.6367,\n",
            "        21740.8574, 21739.9648, 21744.8301, 21739.9512, 21740.4824, 21735.5742,\n",
            "        21738.0410, 21742.0840, 21735.6426, 21733.6152, 21738.5918, 21742.4824,\n",
            "        21725.7383, 21680.2773, 21745.1953, 21739.0645, 21739.0762, 21731.7246,\n",
            "        21741.4395, 21740.0781, 21726.8828, 21732.4355, 21726.4570, 21740.8203,\n",
            "        21736.1816, 21721.2520, 21738.6426, 21738.3301, 21732.1836, 21735.4824,\n",
            "        21739.5879, 21731.8574, 21741.9082, 21735.9219, 21723.6035, 21730.3730,\n",
            "        21744.2148, 21738.6191, 21739.8711, 21735.2578, 21738.0371, 21739.9121,\n",
            "        21741.8770, 21741.6211, 21740.2988], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.09083441412985849 and immediate abs rewards look like: [0.017294578184191778, 0.012272575242604944, 0.0024996665515573113, 0.0011182527596247382, 0.0012108692526453524, 0.0051692562142307, 0.0004399879649099603, 0.00029027676646364853, 0.00010101176167154335, 0.00038729019797756337, 0.0018118599241461197, 0.0030445749189311755, 0.0003132076958536345, 0.0003190912689206016, 0.00032514219674339984, 0.0004834090418626147, 0.0045935447233205196, 0.0004027953918921412, 1.817664042391698e-05, 0.004040353696382226, 5.296153176459484e-06, 0.0026402853336549015, 0.0002744239800449577, 0.00027327823681844166, 0.000993820013718505, 0.00013470519979819073, 0.0051705553109968605, 0.0006973797912905866, 0.00040713218459131895, 0.002375496609147376, 0.00026549477752269013, 3.8630176732112886e-05, 0.0005459779986267677, 4.717635374618112e-05, 0.001185426009215007, 0.0005312202324603277, 0.00027701652970790747, 0.0001030958569572249, 0.0012515444527707587, 0.00012162587108832668, 2.294516207257402e-05, 0.0004784648872373509, 1.7448187463742215e-05, 0.00046918426733100205, 0.004505453191995912, 0.00016534095811948646, 0.0010180192825828271, 0.0006526348602164944, 0.004710425218036107, 0.0053189966483842]\n",
            "DEBUGGING: the total relative reward of the trajectory = 5.934402493574708 and immediate relative rewards look like: [0.05991038410894446, 0.08553966188243509, 0.026246211095055864, 0.015669075491463853, 0.021216845646546138, 0.10873696231507382, 0.010817440203599685, 0.008157461792095436, 0.003193828015109175, 0.013606580291770077, 0.07003076720883072, 0.12845649564939865, 0.014331415394549633, 0.015725488449944022, 0.017170168879090328, 0.02723293438386489, 0.2749986006182202, 0.025573708605595658, 0.0012183319627884922, 0.2850693903382117, 0.00039291671092195536, 0.2052083481712358, 0.02231909902173384, 0.023194509815079693, 0.08787364291317921, 0.012391425532199535, 0.49395252979444376, 0.06921606418871698, 0.041862032967382154, 0.25271164060777396, 0.02921011359085153, 0.004387662019398093, 0.06395161702826507, 0.005694425398157217, 0.14729784370931343, 0.06792252357115718, 0.036410451218582544, 0.013918300270426436, 0.1734156092333289, 0.017292445225391233, 0.003343984190109182, 0.07143188876469773, 0.0026673832201675996, 0.07339482714979409, 0.720929471196107, 0.02708796574184144, 0.17041881729633593, 0.11161760274741572, 0.8225804436976675, 0.9494051562504453]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 200 number of matrices\n",
            "DEBUGGING: ACT_MAT has 200 number of matrices\n",
            "DEBUGGING: VAL looks like: [[2.6085967636139022, 1.0837516116341642e-09, 1.0763249672714073e-09, 1.0803068252607192e-09, 1.0820322002454445e-09, 1.08147829946796e-09, 1.0786220999407739e-09, 1.0573634195744587e-09, 1.049670227817176e-09, 1.0602729573910869e-09, 1.070982785243522e-09, 1.05653705145936e-09, 9.845278063634496e-10, 9.94472531680252e-10, 9.402100025819374e-10, 9.497070733150882e-10, 9.225528133779506e-10, 8.928275641945555e-10, 9.01846024438945e-10, 8.673182081865969e-10, 8.301449223211726e-10, 8.38530224566841e-10, 8.47000226835193e-10, 8.555557846820131e-10, 8.641977623050637e-10, 8.729270326313774e-10, 8.817444774054318e-10, 8.90650987278214e-10, 8.996474618971858e-10, 9.087348099971574e-10, 7.801117219507255e-10, 6.455960032080663e-10, 6.521171749576428e-10, 6.587042171289322e-10, 5.872698661396296e-10, 3.5204798679221233e-10, 2.7292269053799146e-10, 1.9070144507472372e-10, 1.9262772229770073e-10, 1.9457345686636438e-10, 1.9653884531955998e-10, 1.9852408618137372e-10, 2.0052937998118558e-10, 2.0255492927392482e-10, 1.0354597179687142e-10, 1.0459189070391053e-10, 0.0, 0.0, 0.0, 0.0], [1.9397155741129648, 1.9300146992866456, 1.8800238372764342, 1.8453892723883858, 1.7154851554972574, 1.7146244206781278, 1.6202636856613521, 1.4968624620705115, 1.432146805572964, 1.2646001343793714, 1.0443036419019482, 0.8979434959228891, 0.72335636841147, 0.6093138724541075, 0.5850997050591764, 0.5512864236229088, 0.5140183957292485, 0.48597707359593134, 0.42066942452011175, 0.2576756065887015, 0.2537059414217081, 0.24353371679028976, 0.23311988785405396, 0.2166468855944862, 0.17423921150731567, 0.15236879234450101, 0.1500183613820692, 0.15067527588623467, 0.14040794192859316, 0.0862752211777472, 0.0850936123209069, 0.08057019121349143, 0.07365328908845105, 0.07417349273571572, 0.0728597001517634, 0.07106687464371109, 0.04231582494600947, 0.042649497566740614, 0.04307698302879774, 0.04348698185274396, 0.04317279857210341, 0.04088405649491171, 0.04123782387480948, 0.039498518709495854, 0.03767865085344922, 0.023549412807574936, 0.021867267669194366, 0.014545607206601224, 0.010405193218909467, 0.008982293665516313], [2.261138578027925, 1.9757541340756053, 1.133278264553827, 1.1338329955509754, 1.1416785662070512, 1.1528905078012763, 1.159333343930432, 0.9387373018250621, 0.9349835079288833, 0.9097369888485601, 0.7095739396003313, 0.3903933238589263, 0.3891483573706708, 0.384008179634286, 0.3563525078958606, 0.34007029048926785, 0.2631770072001428, 0.1412717780828045, 0.13178276606348624, 0.11118516260299488, 0.10373805745507111, 0.10285519269132432, 0.08524261914023464, 0.07315203376897625, 0.07341037754831345, 0.05272253984840675, 0.04926504620965868, 0.03888344532824115, 0.03919847671779365, 0.03929688792331776, 0.03213879827658318, 0.019737398584932547, 0.01963038926299119, 0.01676307708916178, 0.01570424770655328, 0.013367425817241574, 0.013315653608924071, 0.012679369633653887, 0.009139459607838435, 0.004711780138462022, 0.0024897974581865553, 0.002431192097789789, 0.0020340855682554125, 0.001956677057338932, 0.0009117533725395802, 0.000871544549278102, 0.000756861924868108, 0.00046800831286304673, 0.0004572004000488497, 0.00035795147612212856], [4.249969513289158, 4.232382958767893, 4.188730602914604, 4.204529688706614, 4.23117233658096, 4.252480293873146, 4.185599324806133, 4.216951398588417, 4.251307006864971, 4.2910234129796585, 4.320623063321099, 4.293527571830574, 4.207142501193107, 4.235162712927836, 4.2620578025029205, 4.2877652864887175, 4.303568032429144, 4.069262052334267, 4.084533680534011, 4.12456095815275, 3.878274310923776, 3.917051913346317, 3.7493369345202843, 3.764664480301566, 3.7792625964509963, 3.72867571064426, 3.753822510214202, 3.292797960019958, 3.2561433291224655, 3.2467487839950335, 3.0242799428154137, 3.02532305982279, 3.051449896771103, 3.0176750300432706, 3.0424046511566805, 2.924350310552896, 2.885280592910847, 2.877646607769964, 2.892654856060139, 2.7467063099260707, 2.756983701717858, 2.7814542601290393, 2.737396334711456, 2.7623524762538265, 2.7161188374788208, 2.0153427942249635, 2.008338210589012, 1.8564842356491678, 1.7624915483856083, 0.9494051562504453]]\n",
            "DEBUGGING: traj_returns = [2.6085967636139022, 1.9397155741129648, 2.261138578027925, 4.249969513289158]\n",
            "DEBUGGING: actions = [[0], [5], [17], [17], [18], [0], [11], [11], [17], [57], [1], [1], [66], [0], [44], [19], [22], [3], [12], [16], [77], [21], [12], [41], [73], [0], [23], [29], [31], [14], [52], [60], [14], [14], [27], [30], [9], [0], [77], [97], [1], [22], [32], [33], [95], [83], [37], [22], [68], [104], [43], [36], [3], [11], [19], [5], [64], [13], [13], [13], [69], [12], [23], [12], [13], [29], [68], [13], [26], [77], [79], [38], [8], [47], [25], [25], [14], [48], [82], [2], [28], [46], [17], [40], [69], [61], [3], [12], [4], [40], [29], [49], [39], [2], [76], [103], [84], [92], [57], [59], [17], [14], [13], [26], [52], [27], [3], [41], [22], [7], [60], [68], [2], [20], [2], [62], [22], [77], [34], [19], [50], [75], [2], [79], [52], [53], [80], [8], [32], [5], [76], [16], [77], [73], [59], [37], [60], [28], [18], [37], [32], [89], [17], [64], [4], [45], [19], [92], [70], [71], [17], [25], [17], [63], [64], [62], [63], [61], [63], [63], [38], [37], [65], [61], [73], [37], [21], [60], [62], [76], [4], [3], [15], [64], [73], [6], [4], [61], [20], [11], [4], [14], [81], [3], [3], [16], [74], [11], [43], [62], [73], [84], [2], [25], [56], [61], [61], [46], [57], [13]]\n",
            "DEBUGGING: actions length = 200\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[-29.3454,  52.0669, -55.3801,  ...,  44.1339,  57.0578, -27.8341],\n",
            "        [-28.8237,  51.1246, -54.3955,  ...,  43.3375,  56.0333, -27.3324],\n",
            "        [-29.1586,  51.7212, -55.0298,  ...,  43.8442,  56.6866, -27.6490],\n",
            "        ...,\n",
            "        [-29.1125,  51.6413, -54.9436,  ...,  43.7767,  56.5992, -27.6063],\n",
            "        [-29.1104,  51.6375, -54.9397,  ...,  43.7736,  56.5951, -27.6042],\n",
            "        [-29.1104,  51.6375, -54.9397,  ...,  43.7736,  56.5951, -27.6042]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[-29.0477,  51.5263, -54.8223,  ...,  43.6800,  56.4742, -27.5447],\n",
            "        [-29.1027,  51.6236, -54.9250,  ...,  43.7618,  56.5799, -27.5969],\n",
            "        [-29.0919,  51.6046, -54.9049,  ...,  43.7458,  56.5592, -27.5867],\n",
            "        ...,\n",
            "        [-29.1043,  51.6266, -54.9281,  ...,  43.7643,  56.5832, -27.5984],\n",
            "        [-29.1039,  51.6260, -54.9274,  ...,  43.7638,  56.5825, -27.5981],\n",
            "        [-29.1022,  51.6228, -54.9242,  ...,  43.7611,  56.5791, -27.5964]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([21699.9570, 21740.6289, 21732.6699, 21746.5312, 21737.7520, 21734.3926,\n",
            "        21734.2227, 21732.8027, 21717.7285, 21727.2188, 21738.6699, 21742.1191,\n",
            "        21738.4863, 21746.4785, 21726.5938, 21735.2539, 21730.3652, 21745.4062,\n",
            "        21740.5781, 21743.0137, 21736.2598, 21739.4551, 21736.6602, 21740.6445,\n",
            "        21733.6465, 21741.4512, 21737.2207, 21739.8516, 21736.5820, 21727.9746,\n",
            "        21740.0781, 21735.6074, 21739.3906, 21697.5254, 21732.4688, 21738.6543,\n",
            "        21738.2344, 21720.4922, 21732.9023, 21741.9551, 21744.6152, 21731.7227,\n",
            "        21734.8691, 21712.3340, 21737.9473, 21695.3770, 21738.1270, 21741.9023,\n",
            "        21733.6602, 21739.8379, 21742.7422, 21734.5742, 21738.8340, 21734.5605,\n",
            "        21731.6172, 21727.6367, 21728.4258, 21742.8340, 21740.5273, 21734.6367,\n",
            "        21740.8574, 21739.9648, 21744.8301, 21739.9512, 21740.4824, 21735.5742,\n",
            "        21738.0410, 21742.0840, 21735.6426, 21733.6152, 21738.5918, 21742.4824,\n",
            "        21725.7383, 21680.2773, 21745.1953, 21739.0645, 21739.0762, 21731.7246,\n",
            "        21741.4395, 21740.0781, 21726.8828, 21732.4355, 21726.4570, 21740.8203,\n",
            "        21736.1816, 21721.2520, 21738.6426, 21738.3301, 21732.1836, 21735.4824,\n",
            "        21739.5879, 21731.8574, 21741.9082, 21735.9219, 21723.6035, 21730.3730,\n",
            "        21744.2148, 21738.6191, 21739.8711, 21735.2578, 21738.0371, 21739.9121,\n",
            "        21741.8770, 21741.6211, 21740.2988], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[2.76485511 2.03453795 1.80050818 1.79593799 1.77208401 1.77999881\n",
            "  1.74129909 1.66313779 1.65460933 1.61634013 1.51862516 1.3954661\n",
            "  1.32991181 1.30712119 1.3008775  1.2947805  1.27019086 1.17412773\n",
            "  1.15924647 1.12335543 1.05892958 1.06586021 1.01692486 1.01361585\n",
            "  1.00672805 0.98344176 0.98827648 0.87058917 0.85893744 0.84308022\n",
            "  0.78537809 0.78140766 0.78618339 0.7771529  0.78274215 0.75219615\n",
            "  0.73522802 0.73324387 0.73621782 0.69872627 0.70066157 0.70619238\n",
            "  0.69516706 0.70095192 0.68867731 0.50994094 0.50774059 0.46787446\n",
            "  0.44333849 0.23968635]]\n",
            "DEBUGGING: baseline2 looks like: 2.7648551072609875\n",
            "DEBUGGING: ADS looks like: [-10.62720163 -13.2042291  -13.17588209 -12.83726876 -12.64386879\n",
            " -12.5893466  -12.55538722 -12.1376876  -11.97203395 -11.59692508\n",
            " -11.63045753 -10.98906    -10.68098629 -10.10484443  -9.86531415\n",
            "  -9.78581315  -9.22541569  -9.26252702  -9.03724989  -8.72177567\n",
            "  -8.13766633  -7.82119438  -7.83989093  -7.82224028  -7.86225539\n",
            "  -7.8935388   -6.79027929  -6.80432018  -6.43049398  -6.25896839\n",
            "  -6.09299218  -6.08414698  -6.1121934   -5.51562454  -4.88843104\n",
            "  -4.90396738  -4.22428183  -4.23572834  -4.26207666  -4.05263621\n",
            "  -4.0668147   -3.31936154  -3.32327409  -3.33116983  -2.08365756\n",
            "  -2.07482515  -1.62926195  -1.63156658  -0.94831843  -0.93397471\n",
            " -11.29608282 -11.2742144  -11.29585825 -10.99187949 -10.92838363\n",
            " -10.87472218 -10.93512354 -10.64082513 -10.53988715 -10.33232494\n",
            " -10.58615389 -10.0911165   -9.95762992  -9.49553056  -9.28021444\n",
            "  -9.23452673  -8.71139729  -8.77654995  -8.61658047  -8.46410006\n",
            "  -7.88396039  -7.57766066  -7.60677104  -7.60559339  -7.68801618\n",
            "  -7.74117001  -6.64026092  -6.6536449   -6.29008604  -6.17269317\n",
            "  -6.00789857  -6.00357679  -6.03854011  -5.44145105  -4.81557134\n",
            "  -4.83290051  -4.18196601  -4.19307884  -4.21899968  -4.00914923\n",
            "  -4.0236419   -3.27847748  -3.28203627  -3.29167131  -2.0459789\n",
            "  -2.05127573  -1.60739468  -1.61702097  -0.93791324  -0.92499242\n",
            " -10.97465982 -11.22847496 -12.04260382 -11.70343577 -11.50219022\n",
            " -11.43645609 -11.39605388 -11.19895029 -11.03705045 -10.68718809\n",
            " -10.92088359 -10.59866667 -10.29183793  -9.72083625  -9.50896164\n",
            "  -9.44574286  -8.96223868  -9.12125524  -8.90546713  -8.61059051\n",
            "  -8.03392827  -7.71833919  -7.75464831  -7.74908824  -7.78884502\n",
            "  -7.84081626  -6.74101424  -6.76543673  -6.3912955   -6.2196715\n",
            "  -6.06085339  -6.06440958  -6.09256301  -5.49886147  -4.87272679\n",
            "  -4.89059996  -4.21096618  -4.22304897  -4.2529372   -4.04792443\n",
            "  -4.0643249   -3.31693035  -3.32124001  -3.32921316  -2.0827458\n",
            "  -2.0739536   -1.62850509  -1.63109857  -0.94786123  -0.93361676\n",
            "  -8.98582888  -8.97184614  -8.98715149  -8.63273908  -8.41269645\n",
            "  -8.33686631  -8.3697879   -7.9207362   -7.72072695  -7.30590167\n",
            "  -7.30983447  -6.69553243  -6.47384379  -5.86968172  -5.60325634\n",
            "  -5.49804786  -4.92184766  -5.19326497  -4.95271621  -4.59721471\n",
            "  -4.25939202  -3.90414247  -4.090554    -4.0575758   -4.0829928\n",
            "  -4.16486309  -3.03645678  -3.51152222  -3.17435065  -3.01221961\n",
            "  -3.06871224  -3.05882392  -3.0607435   -2.49794951  -1.84602639\n",
            "  -1.97961707  -1.33900124  -1.35808173  -1.36942181  -1.3059299\n",
            "  -1.30983099  -0.53790728  -0.58587776  -0.56881736   0.63246128\n",
            "  -0.05948235   0.37907626   0.22491765   0.81417312   0.01543045]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(-7.3672, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.2734,  0.0869, -0.2985,  ...,  0.0921, -0.3316,  0.1617],\n",
            "        [ 0.3269,  0.1039, -0.3570,  ...,  0.1101, -0.3965,  0.1943],\n",
            "        [ 0.3621,  0.1151, -0.3954,  ...,  0.1219, -0.4392,  0.2145],\n",
            "        ...,\n",
            "        [ 0.5218,  0.1658, -0.5697,  ...,  0.1757, -0.6328,  0.3077],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0921,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1009,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1244,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1633,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1796,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.2207,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1694,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1854,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.2294,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0810,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0891,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1095,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1562,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1706,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.2108,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2080,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.2278,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.2813,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1267,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1386,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1710,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1356,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1486,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1832,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1769,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1939,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.2382,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0888,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0975,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1199,  0.0000,  0.0000,  0.0000]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.0854, -0.1949, -0.2270,  ..., -0.0132, -0.1883, -0.1058],\n",
            "        [ 0.1012, -0.2311, -0.2692,  ..., -0.0156, -0.2233, -0.1246],\n",
            "        [ 0.1161, -0.2650, -0.3087,  ..., -0.0179, -0.2560, -0.1432],\n",
            "        ...,\n",
            "        [ 0.1667, -0.3805, -0.4432,  ..., -0.0257, -0.3676, -0.2042],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0576,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0718,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0828,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0985,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1238,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1420,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1075,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1352,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1543,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0504,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0632,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0728,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0977,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1225,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1406,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1287,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1617,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1859,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0802,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1011,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1154,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0839,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1054,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1199,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1080,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1347,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1559,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0525,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0663,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0759,  0.0000,  0.0000,  0.0000]])\n",
            "DEBUGGING: training for one iteration takes 0.005027 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 45\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6585e-02, 0.0000e+00, 1.1223e-06,\n",
            "        1.3809e-30, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7199e-28,\n",
            "        2.5436e-07, 1.8343e-25, 1.5662e-37, 8.4870e-21, 0.0000e+00, 5.2904e-34,\n",
            "        0.0000e+00, 0.0000e+00, 8.8515e-01, 8.1790e-20, 1.1904e-30, 0.0000e+00,\n",
            "        5.5809e-16, 0.0000e+00, 0.0000e+00, 2.0531e-16, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.2039e-45, 2.4990e-34, 0.0000e+00, 0.0000e+00, 1.8621e-03,\n",
            "        1.2547e-05, 0.0000e+00, 1.9618e-44, 0.0000e+00, 1.2604e-40, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.5828e-41, 5.1217e-42, 0.0000e+00, 3.4260e-40,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6401e-37, 4.7380e-27, 1.7503e-25,\n",
            "        0.0000e+00, 1.3424e-10, 7.2727e-43, 1.3376e-34, 3.1007e-28, 1.8135e-23,\n",
            "        1.2352e-31, 0.0000e+00, 0.0000e+00, 2.2240e-30, 0.0000e+00, 0.0000e+00,\n",
            "        8.0983e-21, 1.2378e-04, 1.2378e-04, 5.6145e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [69]\n",
            "DEBUGGING: logits looks like: tensor([23051.2949, 23078.7988, 23062.2578, 23106.0000, 23075.4668, 23103.2930,\n",
            "        23089.5293, 23077.7031, 23067.7363, 23080.2559, 22950.5547, 23091.0762,\n",
            "        23102.9219, 23092.4785, 23085.5312, 23095.1641, 23062.7539, 23087.5625,\n",
            "        23076.2266, 23074.4707, 23106.6875, 23095.7305, 23089.4922, 23070.6367,\n",
            "        23097.9375, 23078.0176, 23069.8809, 23097.6875, 23073.7656, 23062.9688,\n",
            "        23079.9180, 23081.1699, 23087.3750, 23079.0098, 23074.5469, 23105.1465,\n",
            "        23103.8965, 23075.0801, 23081.5625, 23022.4473, 23083.7500, 23078.9629,\n",
            "        23075.4512, 23063.4121, 23083.4355, 23082.9492, 23078.2852, 23084.0000,\n",
            "        23074.8789, 23058.1074, 23078.9375, 23085.8516, 23091.5645, 23092.4668,\n",
            "        23078.0137, 23101.0352, 23082.4609, 23087.2188, 23090.8828, 23093.6270,\n",
            "        23088.9258, 23075.8184, 23010.6250, 23089.6484, 23076.2246, 23069.6152,\n",
            "        23095.1523, 23104.4688, 23104.4688, 23105.9980],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.7246e-18, 4.5820e-14, 1.8424e-20, 4.5110e-14, 7.9959e-13,\n",
            "        2.7691e-12, 2.5533e-06, 8.1292e-20, 1.6456e-18, 1.8720e-31, 7.2847e-09,\n",
            "        5.1039e-11, 6.1049e-15, 2.3487e-16, 9.6622e-01, 0.0000e+00, 1.2549e-02,\n",
            "        1.0495e-09, 6.0866e-09, 0.0000e+00, 1.5403e-16, 1.4059e-26, 2.8374e-19,\n",
            "        1.1488e-18, 2.0048e-17, 0.0000e+00, 1.3979e-25, 4.1048e-18, 2.6328e-10,\n",
            "        5.6666e-17, 5.8976e-24, 7.1675e-13, 7.0056e-09, 7.9170e-14, 0.0000e+00,\n",
            "        1.1303e-22, 2.5881e-07, 3.8457e-23, 1.2281e-16, 1.9695e-18, 1.1239e-21,\n",
            "        4.7318e-21, 2.7009e-09, 1.2325e-18, 2.4748e-32, 0.0000e+00, 2.4277e-30,\n",
            "        1.7256e-14, 2.3088e-13, 3.4858e-14, 2.7459e-16, 2.6702e-07, 5.1086e-18,\n",
            "        6.4578e-18, 4.3316e-11, 0.0000e+00, 1.1986e-35, 5.0339e-25, 0.0000e+00,\n",
            "        3.1087e-09, 1.3573e-13, 1.6051e-15, 1.9113e-36, 1.0348e-38, 1.8275e-09,\n",
            "        1.8264e-13, 1.8264e-13, 1.2606e-11, 9.5554e-10, 7.0394e-03, 6.3845e-16,\n",
            "        2.3686e-12, 7.0946e-03, 7.0946e-03, 9.9720e-12, 1.8569e-20],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [15]\n",
            "DEBUGGING: logits looks like: tensor([23050.1133, 23106.3867, 23108.9336, 23105.2520, 23108.9297, 23109.6484,\n",
            "        23109.9590, 23113.3926, 23105.6230, 23106.3750, 23098.9238, 23111.9277,\n",
            "        23110.6875, 23108.4297, 23107.6152, 23116.6035, 23058.7598, 23115.5176,\n",
            "        23111.4434, 23111.8828, 23089.0059, 23107.5098, 23101.7305, 23105.9355,\n",
            "        23106.2852, 23107.0000, 23087.4004, 23102.3047, 23106.6035, 23111.0977,\n",
            "        23107.2598, 23103.2402, 23109.6211, 23111.9180, 23109.0703, 23084.7910,\n",
            "        23103.9785, 23112.8203, 23103.7090, 23107.4531, 23106.4199, 23104.5527,\n",
            "        23104.9121, 23111.6797, 23106.3027, 23098.4180, 23082.0859, 23099.5645,\n",
            "        23108.6895, 23109.3379, 23108.8652, 23107.6543, 23112.8281, 23106.6582,\n",
            "        23106.7168, 23110.6465, 23081.3867, 23096.5098, 23102.6250, 23090.0488,\n",
            "        23111.7148, 23109.2051, 23108.0957, 23096.0508, 23094.7461, 23111.5820,\n",
            "        23109.2793, 23109.2793, 23110.3379, 23111.4199, 23115.3730, 23107.8652,\n",
            "        23109.9199, 23115.3750, 23115.3750, 23110.2793, 23105.2539],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 6.6748e-07, 6.7170e-04, 1.9548e-04, 4.1358e-08, 2.9099e-08,\n",
            "        7.8365e-05, 6.7453e-02, 9.4129e-07, 3.6729e-05, 8.3244e-06, 2.9300e-01,\n",
            "        7.4194e-05, 6.1861e-06, 3.5524e-06, 8.3720e-07, 2.1424e-05, 2.6759e-07,\n",
            "        5.8358e-04, 1.5454e-08, 6.9699e-05, 1.1155e-07, 2.7683e-02, 1.3861e-04,\n",
            "        2.4644e-09, 3.9797e-04, 2.8043e-07, 1.4527e-04, 2.8725e-03, 2.6439e-09,\n",
            "        1.1402e-04, 2.2792e-09, 1.1011e-02, 1.0178e-06, 1.6362e-18, 1.5302e-09,\n",
            "        2.7196e-03, 1.3350e-07, 5.0490e-06, 4.3906e-13, 4.8936e-06, 2.0690e-03,\n",
            "        1.9395e-04, 1.5764e-06, 1.4496e-05, 1.3415e-01, 2.4555e-07, 2.2251e-13,\n",
            "        8.6951e-15, 4.0509e-03, 2.2024e-03, 3.9797e-04, 2.7434e-10, 4.0363e-01,\n",
            "        1.1249e-03, 5.9617e-05, 1.8003e-06, 5.5336e-07, 4.5191e-03, 1.0162e-03,\n",
            "        1.0721e-11, 2.6550e-07, 7.0542e-03, 7.1610e-07, 1.6372e-14, 3.7017e-05,\n",
            "        1.1266e-06, 6.1509e-05, 2.3579e-04, 2.3785e-11, 5.4363e-08, 6.4694e-07,\n",
            "        9.0714e-06, 3.6806e-04, 1.2920e-04, 1.6206e-04, 3.3182e-05, 1.1141e-15,\n",
            "        2.3054e-11, 7.2323e-06, 9.1042e-08, 7.2847e-10, 2.5047e-05, 2.0796e-08,\n",
            "        8.9120e-07, 2.4621e-02, 6.5240e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [45]\n",
            "DEBUGGING: logits looks like: tensor([23055.2109, 23116.9902, 23118.7188, 23118.4102, 23116.2949, 23116.2070,\n",
            "        23118.1816, 23119.8711, 23117.0762, 23117.9922, 23117.6211, 23120.2383,\n",
            "        23118.1680, 23117.5469, 23117.4082, 23117.0469, 23117.8574, 23116.7617,\n",
            "        23118.6836, 23116.0488, 23118.1523, 23116.5430, 23119.6484, 23118.3242,\n",
            "        23115.5898, 23118.5879, 23116.7734, 23118.3359, 23119.0820, 23115.6074,\n",
            "        23118.2754, 23115.5703, 23119.4180, 23117.0957, 23110.3066, 23115.4707,\n",
            "        23119.0684, 23116.5879, 23117.4961, 23113.4316, 23117.4883, 23119.0000,\n",
            "        23118.4082, 23117.2051, 23117.7598, 23120.0430, 23116.7402, 23113.2617,\n",
            "        23112.4512, 23119.1680, 23119.0156, 23118.5879, 23115.0410, 23120.3184,\n",
            "        23118.8477, 23118.1133, 23117.2383, 23116.9434, 23119.1953, 23118.8223,\n",
            "        23114.2305, 23116.7598, 23119.3066, 23117.0078, 23112.6094, 23117.9941,\n",
            "        23117.1211, 23118.1211, 23118.4570, 23114.4297, 23116.3633, 23116.9824,\n",
            "        23117.6426, 23118.5684, 23118.3066, 23118.3633, 23117.9668, 23111.9375,\n",
            "        23114.4219, 23117.5859, 23116.4922, 23115.2852, 23117.8965, 23116.1230,\n",
            "        23117.0625, 23119.6191, 23119.2871], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.5245e-03, 5.6968e-04, 3.1282e-03, 1.4661e-03, 3.8408e-02,\n",
            "        5.3324e-02, 1.1991e-02, 1.4517e-04, 7.1304e-05, 4.1354e-04, 5.7743e-05,\n",
            "        5.7987e-03, 5.4050e-03, 2.6137e-03, 3.3490e-04, 1.3990e-03, 2.1166e-03,\n",
            "        1.9926e-02, 4.1119e-03, 3.0447e-01, 6.1950e-05, 1.5485e-03, 1.1177e-02,\n",
            "        4.7129e-05, 7.8642e-03, 5.7987e-03, 2.2135e-04, 6.6084e-04, 3.3560e-03,\n",
            "        1.6069e-04, 1.0198e-01, 5.8900e-03, 1.2276e-02, 6.3686e-03, 2.8260e-03,\n",
            "        1.2250e-03, 3.2528e-03, 1.5127e-03, 3.8327e-03, 2.6286e-04, 7.5470e-04,\n",
            "        2.0558e-02, 7.6222e-03, 4.0713e-04, 1.6709e-04, 3.9627e-02, 3.4480e-05,\n",
            "        4.9213e-03, 2.1792e-04, 7.6820e-03, 6.8716e-04, 4.6959e-03, 6.6223e-03,\n",
            "        1.0235e-03, 3.6005e-03, 1.5277e-02, 9.2997e-05, 2.4992e-02, 3.8029e-03,\n",
            "        8.8234e-04, 7.6177e-07, 2.5478e-04, 3.7148e-03, 4.3339e-04, 7.9092e-04,\n",
            "        1.3695e-02, 8.8419e-03, 9.8462e-15, 4.1354e-04, 1.1781e-03, 6.3552e-04,\n",
            "        2.2708e-03, 1.8640e-04, 9.3389e-03, 8.4370e-03, 1.1898e-02, 9.4661e-04,\n",
            "        3.0255e-04, 1.4661e-03, 2.7490e-05, 7.3302e-03, 7.5629e-03, 3.7653e-04,\n",
            "        2.9325e-04, 3.3823e-03, 1.9313e-02, 4.8727e-04, 8.3362e-05, 3.1956e-04,\n",
            "        1.5762e-02, 2.2838e-04, 3.0557e-03, 2.9849e-03, 1.5213e-04, 1.0198e-01,\n",
            "        5.8319e-04], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [5]\n",
            "DEBUGGING: logits looks like: tensor([23059.2070, 23123.9844, 23123.7383, 23124.1641, 23123.9746, 23124.7910,\n",
            "        23124.8730, 23124.5000, 23123.3965, 23123.2188, 23123.6582, 23123.1660,\n",
            "        23124.3184, 23124.3008, 23124.1191, 23123.6055, 23123.9629, 23124.0664,\n",
            "        23124.6270, 23124.2324, 23125.3086, 23123.1836, 23123.9883, 23124.4824,\n",
            "        23123.1152, 23124.3945, 23124.3184, 23123.5020, 23123.7754, 23124.1816,\n",
            "        23123.4219, 23125.0352, 23124.3223, 23124.5059, 23124.3418, 23124.1387,\n",
            "        23123.9297, 23124.1738, 23123.9824, 23124.2148, 23123.5449, 23123.8086,\n",
            "        23124.6348, 23124.3867, 23123.6543, 23123.4316, 23124.7988, 23123.0371,\n",
            "        23124.2773, 23123.4980, 23124.3887, 23123.7852, 23124.2656, 23124.3516,\n",
            "        23123.8848, 23124.1992, 23124.5605, 23123.2852, 23124.6836, 23124.2129,\n",
            "        23123.8477, 23122.0840, 23123.5371, 23124.2070, 23123.6699, 23123.8203,\n",
            "        23124.5332, 23124.4238, 23117.5430, 23123.6582, 23123.9199, 23123.7656,\n",
            "        23124.0840, 23123.4590, 23124.4375, 23124.4121, 23124.4980, 23123.8652,\n",
            "        23123.5801, 23123.9746, 23122.9805, 23124.3770, 23124.3848, 23123.6348,\n",
            "        23123.5723, 23124.1836, 23124.6191, 23123.6992, 23123.2578, 23123.5938,\n",
            "        23124.5684, 23123.5098, 23124.1582, 23124.1523, 23123.4082, 23125.0352,\n",
            "        23123.7441], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000, 0.0060, 0.0085, 0.0156, 0.0115, 0.0086, 0.0105, 0.0114, 0.0086,\n",
            "        0.0116, 0.0042, 0.0162, 0.0134, 0.0098, 0.0093, 0.0093, 0.0060, 0.0075,\n",
            "        0.0080, 0.0085, 0.0153, 0.0141, 0.0116, 0.0090, 0.0221, 0.0049, 0.0089,\n",
            "        0.0115, 0.0129, 0.0022, 0.0079, 0.0119, 0.0144, 0.0083, 0.0098, 0.0060,\n",
            "        0.0057, 0.0110, 0.0102, 0.0100, 0.0079, 0.0072, 0.0019, 0.0130, 0.0119,\n",
            "        0.0058, 0.0061, 0.0105, 0.0095, 0.0083, 0.0040, 0.0162, 0.0216, 0.0016,\n",
            "        0.0120, 0.0058, 0.0156, 0.0102, 0.0006, 0.0090, 0.0126, 0.0121, 0.0089,\n",
            "        0.0110, 0.0045, 0.0081, 0.0010, 0.0105, 0.0061, 0.0152, 0.0037, 0.0073,\n",
            "        0.0037, 0.0189, 0.0089, 0.0111, 0.0078, 0.0095, 0.0075, 0.0097, 0.0095,\n",
            "        0.0115, 0.0089, 0.0098, 0.0055, 0.0077, 0.0101, 0.0178, 0.0083, 0.0100,\n",
            "        0.0085, 0.0099, 0.0100, 0.0068, 0.0090, 0.0110, 0.0110, 0.0040, 0.0157,\n",
            "        0.0029, 0.0061, 0.0068, 0.0062, 0.0076, 0.0124, 0.0064, 0.0092, 0.0079],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [32]\n",
            "DEBUGGING: logits looks like: tensor([23062.4121, 23127.0449, 23127.1328, 23127.2852, 23127.2090, 23127.1367,\n",
            "        23127.1855, 23127.2070, 23127.1367, 23127.2109, 23126.9590, 23127.2949,\n",
            "        23127.2480, 23127.1680, 23127.1562, 23127.1562, 23127.0449, 23127.1035,\n",
            "        23127.1191, 23127.1328, 23127.2812, 23127.2598, 23127.2109, 23127.1484,\n",
            "        23127.3730, 23126.9980, 23127.1465, 23127.2090, 23127.2383, 23126.7910,\n",
            "        23127.1152, 23127.2188, 23127.2656, 23127.1289, 23127.1699, 23127.0449,\n",
            "        23127.0352, 23127.1992, 23127.1797, 23127.1738, 23127.1152, 23127.0918,\n",
            "        23126.7539, 23127.2402, 23127.2188, 23127.0391, 23127.0527, 23127.1855,\n",
            "        23127.1621, 23127.1289, 23126.9434, 23127.2949, 23127.3672, 23126.7109,\n",
            "        23127.2207, 23127.0391, 23127.2852, 23127.1797, 23126.4707, 23127.1484,\n",
            "        23127.2324, 23127.2227, 23127.1445, 23127.1992, 23126.9766, 23127.1230,\n",
            "        23126.5938, 23127.1875, 23127.0527, 23127.2793, 23126.9238, 23127.0957,\n",
            "        23126.9258, 23127.3340, 23127.1465, 23127.2012, 23127.1133, 23127.1621,\n",
            "        23127.1016, 23127.1660, 23127.1621, 23127.2090, 23127.1445, 23127.1680,\n",
            "        23127.0234, 23127.1074, 23127.1758, 23127.3184, 23127.1270, 23127.1738,\n",
            "        23127.1328, 23127.1719, 23127.1738, 23127.0781, 23127.1484, 23127.1992,\n",
            "        23127.1973, 23126.9434, 23127.2871, 23126.8672, 23127.0488, 23127.0781,\n",
            "        23127.0547, 23127.1055, 23127.2285, 23127.0645, 23127.1543, 23127.1152],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.19037598690647428 and immediate abs rewards look like: [0.010754348344562459, 0.012717792419607576, 0.0065206662161472195, 0.029698524268951587, 0.0019199828384444118, 0.0011962372022935597, 0.0042497824883867, 0.008576207812438952, 0.010111354340097023, 0.012099206432139908, 0.018894679581990204, 0.0009873498865999863, 0.010646298861956893, 0.010990615221999178, 0.004847470066124515, 0.0003755774000637757, 0.00037968188735248987, 0.011423014795582276, 0.0017087413325498346, 0.003307010906155483, 0.006301143618657079, 0.010432755887904932, 0.0004169019207438396, 0.0005429355933301849, 0.0024250328415291733, 0.0008832052785692213, 8.109120699373307e-05, 2.683071807041415e-05, 0.0003662197773337539, 0.00012093260420442675, 0.0005560234753829718, 0.0014450308167397452, 0.0005332397849997506, 6.047292936273152e-05, 0.0013235590486146975, 0.00013396016674960265, 0.0002235921347164549, 0.0010412514911877224, 0.00011430854647187516, 0.00023174771240519476, 0.0001181406282739772, 0.00014589227339456556, 0.0005302975491758843, 0.0003832351703749737, 2.365864429521025e-05, 0.00024837171940816916, 1.7037759789673146e-05, 8.81894952726725e-05, 1.4259437648433959e-05, 0.00014212637142918538]\n",
            "DEBUGGING: the total relative reward of the trajectory = 6.034647814414982 and immediate relative rewards look like: [0.029001021819185686, 0.06879110038297566, 0.0530884576119323, 0.3229616529705132, 0.026311414330148514, 0.019682216088701875, 0.08160423000137006, 0.188425552086821, 0.2505131117645211, 0.3339996747297551, 0.5756709893252066, 0.03298931113250405, 0.38546267835248715, 0.4298134549889866, 0.20373785947464074, 0.016860679007759158, 0.01811215789981764, 0.577033347214565, 0.09140544455387774, 0.1863016681705171, 0.37307361156678054, 0.6482608776008625, 0.027162604940299966, 0.03691650115429732, 0.1717850709416934, 0.06511204163577526, 0.006209728499280134, 0.0021307642385804174, 0.03012230274739094, 0.010291013536224343, 0.04889486026423143, 0.1311909809656862, 0.049944936087114894, 0.005836609472785044, 0.13150417259239483, 0.013695237054852483, 0.023494496486807938, 0.1123762942567719, 0.01266505950661058, 0.026336222109010987, 0.01376225995466964, 0.017410160882171684, 0.06479287944517839, 0.047920648321845616, 0.0030258982518699094, 0.03247243437082039, 0.002276123800417744, 0.012032219022252644, 0.0019860811958598385, 0.0201997016061589]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 2.9530e-15, 0.0000e+00, 0.0000e+00, 5.2674e-11, 2.2922e-24,\n",
            "        2.5334e-21, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7575e-30,\n",
            "        7.9645e-15, 2.2391e-24, 1.6278e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4570e-31, 0.0000e+00,\n",
            "        4.8775e-29, 5.2770e-25, 0.0000e+00, 2.4349e-25, 1.7533e-14, 0.0000e+00,\n",
            "        3.8191e-19, 0.0000e+00, 1.9198e-43, 0.0000e+00, 0.0000e+00, 6.0066e-34,\n",
            "        0.0000e+00, 4.3708e-18, 4.9230e-06, 9.9869e-30, 0.0000e+00, 5.3488e-26,\n",
            "        4.8819e-36, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        8.0270e-15, 0.0000e+00, 2.3227e-14, 8.3316e-01, 0.0000e+00, 0.0000e+00,\n",
            "        3.0761e-03, 0.0000e+00, 9.7553e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        7.9527e-38, 0.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [51]\n",
            "DEBUGGING: logits looks like: tensor([23206.0117, 23264.1953, 23158.2754, 23150.3262, 23266.6426, 23258.9512,\n",
            "        23260.7031, 23221.9141, 23186.9004, 23180.7168, 23133.7070, 23255.7676,\n",
            "        23264.4434, 23258.9453, 23272.1055, 23115.8945, 23199.9961, 23129.6348,\n",
            "        23193.3965, 23219.6504, 23116.9141, 23211.4297, 23255.0879, 23054.3301,\n",
            "        23256.2617, 23258.5840, 23215.9375, 23258.3906, 23264.6406, 23215.7988,\n",
            "        23261.9570, 23236.1211, 23247.9707, 23218.3438, 23236.3164, 23253.4355,\n",
            "        23176.6523, 23262.5664, 23269.5039, 23255.8652, 23237.6699, 23258.0117,\n",
            "        23252.2324, 23205.2480, 23195.4277, 23234.2363, 23141.5312, 23189.0117,\n",
            "        23264.4453, 23187.3223, 23264.7109, 23272.5137, 23244.7188, 23226.5449,\n",
            "        23271.1133, 23237.8848, 23270.8262, 23235.7891, 23229.1562, 23219.6484,\n",
            "        23251.2031, 23242.0234], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 6.5888e-08, 2.1116e-03, 4.3392e-06, 1.2144e-06, 1.7910e-07,\n",
            "        2.1990e-06, 8.9545e-07, 1.3790e-05, 1.0932e-04, 8.4907e-10, 4.0678e-07,\n",
            "        1.3927e-04, 2.4480e-07, 2.1391e-08, 7.9189e-06, 9.3167e-03, 7.9095e-14,\n",
            "        3.8133e-08, 1.8529e-02, 9.8228e-15, 2.0179e-06, 9.1175e-17, 2.6749e-02,\n",
            "        4.2082e-02, 2.0996e-02, 5.1934e-06, 1.8529e-02, 1.9753e-05, 1.5626e-05,\n",
            "        1.1728e-04, 5.7728e-04, 1.9146e-05, 1.1343e-05, 4.2899e-04, 4.2502e-01,\n",
            "        8.8929e-14, 1.6634e-05, 5.1236e-05, 7.4548e-05, 6.1915e-19, 3.0512e-10,\n",
            "        8.0727e-08, 1.8529e-02, 3.6960e-08, 8.5753e-09, 7.8904e-04, 1.7872e-08,\n",
            "        1.7723e-12, 1.7872e-08, 1.4826e-04, 7.0539e-09, 4.1343e-03, 3.9759e-03,\n",
            "        9.3167e-03, 1.8051e-07, 4.1806e-20, 1.7064e-04, 1.5059e-04, 4.9067e-07,\n",
            "        9.1476e-08, 7.8573e-06, 6.1822e-16, 1.8529e-02, 1.5159e-12, 1.2195e-04,\n",
            "        4.4864e-05, 1.7760e-11, 2.0689e-09, 6.9195e-07, 4.4864e-05, 1.1326e-02,\n",
            "        8.8024e-04, 1.6376e-05, 2.3422e-02, 1.4495e-11, 1.7172e-01, 1.7172e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [35]\n",
            "DEBUGGING: logits looks like: tensor([23240.8457, 23293.9180, 23296.5117, 23294.9648, 23294.6465, 23294.1680,\n",
            "        23294.7949, 23294.5703, 23295.2539, 23295.7715, 23292.8301, 23294.3730,\n",
            "        23295.8320, 23294.2461, 23293.6367, 23295.1152, 23296.8828, 23290.5098,\n",
            "        23293.7812, 23297.0547, 23289.9883, 23294.7734, 23288.8184, 23297.1465,\n",
            "        23297.2598, 23297.0859, 23295.0098, 23297.0547, 23295.3438, 23295.2852,\n",
            "        23295.7891, 23296.1875, 23295.3359, 23295.2051, 23296.1133, 23297.8379,\n",
            "        23290.5391, 23295.3008, 23295.5820, 23295.6758, 23287.5703, 23292.5742,\n",
            "        23293.9688, 23297.0547, 23293.7734, 23293.4082, 23296.2656, 23293.5918,\n",
            "        23291.2871, 23293.5918, 23295.8477, 23293.3594, 23296.6797, 23296.6699,\n",
            "        23296.8828, 23294.1699, 23286.8965, 23295.8828, 23295.8516, 23294.4199,\n",
            "        23294.0000, 23295.1133, 23289.2969, 23297.0547, 23291.2480, 23295.7988,\n",
            "        23295.5488, 23291.8633, 23293.0527, 23294.5059, 23295.5488, 23296.9316,\n",
            "        23296.2930, 23295.2969, 23297.1133, 23291.8125, 23297.6113, 23297.6113],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 0.0000e+00, 1.1210e-02, 3.4655e-04, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.8404e-02, 4.5553e-04, 0.0000e+00, 0.0000e+00, 1.7914e-02,\n",
            "        0.0000e+00, 0.0000e+00, 1.5719e-01, 7.1966e-02, 4.8491e-04, 0.0000e+00,\n",
            "        1.5620e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0528e-03,\n",
            "        1.7636e-02, 0.0000e+00, 7.9492e-03, 3.9887e-04, 0.0000e+00, 8.2016e-03,\n",
            "        4.5293e-03, 0.0000e+00, 4.7312e-38, 5.7377e-02, 0.0000e+00, 2.4908e-05,\n",
            "        3.0345e-04, 0.0000e+00, 0.0000e+00, 1.9592e-04, 0.0000e+00, 1.5578e-35,\n",
            "        6.2263e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4013e-45, 5.5812e-04,\n",
            "        3.5000e-03, 1.7636e-02, 2.9305e-02, 3.7401e-42, 0.0000e+00, 0.0000e+00,\n",
            "        6.6062e-39, 6.3244e-04, 0.0000e+00, 5.5930e-03, 4.2039e-45, 1.7636e-02,\n",
            "        1.7399e-01, 5.8826e-05, 2.5901e-05, 1.1274e-03, 1.4252e-03, 2.8284e-04,\n",
            "        3.9577e-04, 1.6345e-01, 1.5475e-01, 1.6854e-05, 1.4061e-02, 2.0931e-06,\n",
            "        5.1618e-04, 1.7022e-04, 5.9074e-03, 3.1620e-03, 1.9480e-03, 1.1632e-03,\n",
            "        3.1620e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.2546e-05, 9.0077e-03,\n",
            "        2.7283e-36, 0.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [60]\n",
            "DEBUGGING: logits looks like: tensor([23259.6934, 23254.3945, 23312.7070, 23311.8379, 23255.7734, 23264.1680,\n",
            "        23233.1621, 23312.9395, 23311.9062, 23144.7559, 23251.0273, 23312.8242,\n",
            "        23236.4883, 23237.4727, 23313.3672, 23313.1719, 23311.9219, 23281.3027,\n",
            "        23311.6387, 23283.7070, 23264.5391, 23280.0840, 23280.7422, 23312.5078,\n",
            "        23312.8203, 23283.1680, 23312.6211, 23311.8730, 23230.3672, 23312.6289,\n",
            "        23312.4805, 23172.1211, 23292.3438, 23313.1152, 23279.9414, 23311.1797,\n",
            "        23311.8047, 23228.1836, 23278.4805, 23311.6953, 23276.3027, 23293.7930,\n",
            "        23311.9844, 23269.1152, 23271.1641, 23255.5156, 23288.0430, 23311.9570,\n",
            "        23312.4160, 23312.8203, 23312.9473, 23289.9824, 23178.5469, 23232.6445,\n",
            "        23291.8516, 23311.9883, 23261.4023, 23312.5332, 23288.2695, 23312.8203,\n",
            "        23313.3926, 23311.3945, 23311.1895, 23312.1328, 23312.1914, 23311.7871,\n",
            "        23311.8711, 23313.3770, 23313.3633, 23311.0820, 23312.7637, 23310.5605,\n",
            "        23311.9375, 23311.6602, 23312.5469, 23312.3906, 23312.2695, 23312.1406,\n",
            "        23312.3906, 23267.0117, 23256.6133, 23254.3770, 23311.5078, 23312.6523,\n",
            "        23293.3574, 23284.2031], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.2980e-03, 3.9443e-02, 2.3187e-02, 2.6841e-03, 4.0378e-02,\n",
            "        9.9727e-03, 7.3534e-03, 1.8885e-03, 2.7478e-03, 2.2780e-03, 4.4601e-03,\n",
            "        4.3229e-03, 6.2897e-03, 5.1738e-03, 2.4060e-03, 2.1953e-02, 1.2098e-03,\n",
            "        2.6688e-02, 9.5907e-03, 1.1936e-02, 2.7911e-03, 1.0699e-02, 1.2193e-03,\n",
            "        2.1568e-03, 7.8891e-03, 9.9727e-03, 1.5088e-02, 1.5779e-03, 5.2144e-03,\n",
            "        1.0370e-02, 3.6402e-03, 5.5075e-03, 2.9022e-03, 2.2603e-03, 1.1726e-03,\n",
            "        2.4060e-03, 1.3212e-02, 9.2956e-03, 2.0580e-03, 5.2144e-03, 1.5689e-02,\n",
            "        8.2677e-03, 1.4708e-03, 8.5301e-03, 2.4491e-02, 9.5907e-03, 3.5559e-03,\n",
            "        9.5907e-03, 3.3931e-03, 3.9360e-03, 1.2706e-02, 6.6433e-03, 1.2509e-02,\n",
            "        1.5961e-31, 3.6402e-03, 2.1953e-02, 2.5215e-03, 1.4624e-02, 1.6536e-03,\n",
            "        1.7603e-03, 2.2603e-03, 0.0000e+00, 9.0096e-03, 1.6442e-02, 1.0289e-02,\n",
            "        4.0610e-03, 5.2144e-03, 2.6632e-03, 3.3145e-03, 4.2227e-03, 7.9057e-02,\n",
            "        6.2765e-04, 1.4174e-02, 3.4269e-02, 1.3212e-02, 2.0623e-02, 9.1323e-04,\n",
            "        3.3931e-03, 1.5567e-02, 9.0994e-02, 3.3931e-03, 2.7911e-03, 1.2315e-02,\n",
            "        1.1843e-02, 1.8058e-02, 1.5779e-03, 1.1843e-02, 9.5907e-03, 1.6442e-02,\n",
            "        2.2780e-03, 2.1112e-02, 1.3525e-02, 3.6402e-03, 1.6153e-03, 7.7668e-03,\n",
            "        2.5466e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [44]\n",
            "DEBUGGING: logits looks like: tensor([23274.3047, 23325.2070, 23326.0605, 23325.9277, 23325.3887, 23326.0664,\n",
            "        23325.7168, 23325.6406, 23325.3008, 23325.3945, 23325.3477, 23325.5156,\n",
            "        23325.5078, 23325.6016, 23325.5527, 23325.3613, 23325.9141, 23325.1895,\n",
            "        23325.9629, 23325.7070, 23325.7617, 23325.3984, 23325.7344, 23325.1914,\n",
            "        23325.3340, 23325.6582, 23325.7168, 23325.8203, 23325.2559, 23325.5547,\n",
            "        23325.7266, 23325.4648, 23325.5684, 23325.4082, 23325.3457, 23325.1816,\n",
            "        23325.3613, 23325.7871, 23325.6992, 23325.3223, 23325.5547, 23325.8301,\n",
            "        23325.6699, 23325.2383, 23325.6777, 23325.9414, 23325.7070, 23325.4590,\n",
            "        23325.7070, 23325.4473, 23325.4844, 23325.7773, 23325.6152, 23325.7734,\n",
            "        23309.1406, 23325.4648, 23325.9141, 23325.3730, 23325.8125, 23325.2676,\n",
            "        23325.2832, 23325.3457, 23241.5508, 23325.6914, 23325.8418, 23325.7246,\n",
            "        23325.4922, 23325.5547, 23325.3867, 23325.4414, 23325.5020, 23326.2344,\n",
            "        23325.0254, 23325.8047, 23326.0254, 23325.7871, 23325.8984, 23325.1191,\n",
            "        23325.4473, 23325.8281, 23326.2695, 23325.4473, 23325.3984, 23325.7695,\n",
            "        23325.7598, 23325.8652, 23325.2559, 23325.7598, 23325.7070, 23325.8418,\n",
            "        23325.3477, 23325.9043, 23325.7930, 23325.4648, 23325.2617, 23325.6543,\n",
            "        23325.9512], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 6.5537e-03, 6.6569e-03, 9.6858e-03, 1.1413e-02, 1.8342e-03,\n",
            "        8.0298e-03, 1.2054e-02, 3.4807e-03, 2.5465e-03, 9.9155e-03, 8.3497e-03,\n",
            "        1.0890e-02, 8.5477e-03, 5.6057e-03, 3.5355e-03, 4.0062e-03, 1.3553e-02,\n",
            "        1.5445e-03, 9.3878e-03, 1.6736e-02, 6.3521e-03, 2.0622e-03, 3.7930e-03,\n",
            "        1.5238e-02, 1.0721e-02, 1.4654e-02, 3.1445e-03, 8.2202e-03, 4.4693e-03,\n",
            "        7.3686e-03, 1.7366e-03, 1.1842e-03, 1.8161e-04, 8.3497e-03, 3.5632e-03,\n",
            "        6.8683e-03, 6.4019e-03, 1.5002e-02, 1.1413e-02, 1.5969e-02, 9.7618e-03,\n",
            "        8.3497e-03, 6.0612e-03, 6.4019e-03, 9.1703e-03, 5.7386e-03, 6.8683e-03,\n",
            "        4.7575e-03, 5.1441e-03, 4.6837e-03, 1.1867e-02, 3.6763e-03, 5.8960e-05,\n",
            "        2.8349e-04, 1.3343e-02, 1.7132e-02, 7.4846e-03, 2.1489e-02, 1.3659e-02,\n",
            "        2.1827e-02, 3.8527e-03, 5.4644e-04, 9.3878e-03, 5.7386e-03, 1.1592e-02,\n",
            "        1.5002e-02, 2.4734e-02, 1.1592e-02, 9.6104e-03, 1.5845e-02, 6.2050e-03,\n",
            "        3.0068e-02, 6.8827e-02, 2.1952e-03, 1.2805e-03, 1.3034e-02, 4.6473e-03,\n",
            "        4.7205e-03, 6.1088e-03, 1.6476e-02, 5.1441e-03, 1.3983e-02, 1.6476e-02,\n",
            "        9.9933e-03, 3.0241e-03, 9.3878e-03, 1.0151e-02, 8.0298e-03, 2.0666e-02,\n",
            "        1.1960e-02, 6.7092e-03, 1.6963e-03, 1.2932e-02, 2.0505e-02, 5.2251e-03,\n",
            "        3.3473e-03, 1.4769e-02, 1.9414e-02, 9.2228e-04, 2.7476e-04, 3.2954e-03,\n",
            "        5.2661e-03, 1.7815e-02, 5.7837e-03, 7.4264e-03, 8.1857e-05, 1.5722e-02,\n",
            "        9.7618e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [104]\n",
            "DEBUGGING: logits looks like: tensor([23286.0371, 23335.4258, 23335.4297, 23335.5234, 23335.5645, 23335.1074,\n",
            "        23335.4766, 23335.5781, 23335.2676, 23335.1895, 23335.5293, 23335.4863,\n",
            "        23335.5527, 23335.4922, 23335.3867, 23335.2715, 23335.3027, 23335.6074,\n",
            "        23335.0645, 23335.5156, 23335.6602, 23335.4180, 23335.1367, 23335.2891,\n",
            "        23335.6367, 23335.5488, 23335.6270, 23335.2422, 23335.4824, 23335.3301,\n",
            "        23335.4551, 23335.0938, 23334.9980, 23334.5293, 23335.4863, 23335.2734,\n",
            "        23335.4375, 23335.4199, 23335.6328, 23335.5645, 23335.6484, 23335.5254,\n",
            "        23335.4863, 23335.4062, 23335.4199, 23335.5098, 23335.3926, 23335.4375,\n",
            "        23335.3457, 23335.3652, 23335.3418, 23335.5742, 23335.2812, 23334.2480,\n",
            "        23334.6406, 23335.6035, 23335.6660, 23335.4590, 23335.7227, 23335.6094,\n",
            "        23335.7266, 23335.2930, 23334.8047, 23335.5156, 23335.3926, 23335.5684,\n",
            "        23335.6328, 23335.7578, 23335.5684, 23335.5215, 23335.6465, 23335.4121,\n",
            "        23335.8066, 23336.0137, 23335.1523, 23335.0176, 23335.5977, 23335.3398,\n",
            "        23335.3438, 23335.4082, 23335.6562, 23335.3652, 23335.6152, 23335.6562,\n",
            "        23335.5312, 23335.2324, 23335.5156, 23335.5352, 23335.4766, 23335.7129,\n",
            "        23335.5762, 23335.4316, 23335.0879, 23335.5957, 23335.7109, 23335.3691,\n",
            "        23335.2578, 23335.6289, 23335.6973, 23334.9355, 23334.6328, 23335.2539,\n",
            "        23335.3711, 23335.6758, 23335.3945, 23335.4570, 23334.3301, 23335.6445,\n",
            "        23335.5254], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.06789247330243597 and immediate abs rewards look like: [0.017294578184191778, 0.012272575242604944, 0.0024996665515573113, 0.0011182527596247382, 0.0012108692526453524, 0.0051692562142307, 0.0004399879649099603, 0.00039128852858993923, 0.00717427568815765, 0.0020203175113238103, 0.00042692855413406505, 0.005182663211598992, 0.001454362271942955, 0.0002242198388557881, 0.00023667784034842043, 0.00010461971214681398, 0.00011413760785217164, 0.0014660244569313363, 2.940706281151506e-05, 0.0008946538728196174, 2.8772956284228712e-06, 0.0003679782735162007, 6.675893928331789e-05, 5.755190750278416e-05, 0.000949792942719796, 0.0005406977902566723, 0.0012991855955988285, 9.705269667392713e-05, 0.0008414800067839678, 0.000232591851727193, 0.0001058667216966569, 0.0007753067443445616, 4.89013741571398e-05, 6.61578510516847e-05, 0.0006431659817280888, 5.2926687203580514e-05, 0.00035712721773961675, 5.558323437071522e-05, 8.558057152185938e-05, 2.1455547084769933e-05, 7.26864454918541e-05, 2.7251219762547407e-05, 9.358681109006284e-05, 0.0005240939690338564, 4.196477675577626e-06, 6.238355672394391e-05, 0.0005113535817145021, 3.838213160634041e-06, 6.343372433548211e-05, 0.00013684774557987112]\n",
            "DEBUGGING: the total relative reward of the trajectory = 2.0641545795719183 and immediate relative rewards look like: [0.05991038410894446, 0.08553966188243509, 0.026246211095055864, 0.015669075491463853, 0.021216845646546138, 0.10873696231507382, 0.010817440203599685, 0.0109961305568608, 0.2268470072994042, 0.07115872242976956, 0.01655257446144421, 0.21923871752387036, 0.06677180992025672, 0.011091809236260908, 0.012545373222555641, 0.005915678410340661, 0.006857483926562002, 0.09326492607825401, 0.001975763521940408, 0.06327312302651929, 0.00021373489250039966, 0.028636302851502766, 0.005432076604080963, 0.004886634350059675, 0.08400723081759512, 0.04975326942845664, 0.12416859214974173, 0.00962370286053895, 0.08642378720448195, 0.02471932968229888, 0.011627273382038736, 0.08790155438900703, 0.005719095274908929, 0.007971869159416193, 0.07978130722984106, 0.0067543919301060636, 0.046842694422226765, 0.007488582019991833, 0.01183369925236893, 0.0030429407793140352, 0.010566581527771967, 0.004058295339060218, 0.014269071497807453, 0.08176903260091077, 0.000669738350506359, 0.010177388363459874, 0.08523876576938845, 0.0006535323504778892, 0.01102588972816507, 0.0242725150067363]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 6.0929e-36, 1.4166e-35, 7.8163e-29, 1.1861e-34, 2.8454e-34,\n",
            "        1.2345e-41, 1.0000e+00, 3.6744e-09, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 7.2506e-09, 0.0000e+00, 1.4013e-45, 0.0000e+00,\n",
            "        5.1848e-44, 0.0000e+00, 3.7673e-38, 0.0000e+00, 0.0000e+00, 7.2551e-31,\n",
            "        0.0000e+00, 5.1834e-20, 0.0000e+00, 2.8026e-45, 0.0000e+00, 4.5908e-22,\n",
            "        2.5285e-27, 3.4343e-30, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.6953e-12,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.1607e-22, 6.0147e-31, 1.3145e-26,\n",
            "        0.0000e+00, 0.0000e+00, 3.6910e-18, 1.7657e-12, 0.0000e+00, 6.2206e-41,\n",
            "        4.2599e-39, 4.0819e-11, 9.4029e-34, 1.8322e-39, 6.3681e-41, 8.3231e-40,\n",
            "        0.0000e+00, 2.3293e-14, 0.0000e+00, 4.0733e-12, 0.0000e+00, 5.3415e-28,\n",
            "        0.0000e+00, 0.0000e+00, 1.9580e-26, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 3.2997e-23, 0.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [7]\n",
            "DEBUGGING: logits looks like: tensor([23132.5078, 23163.3633, 23163.5742, 23167.4551, 23164.1055, 23164.3242,\n",
            "        23160.0859, 23183.6348, 23178.7793, 23151.5176, 23122.1699, 23121.8867,\n",
            "        23156.7344, 23083.6836, 23178.9492, 23157.2207, 23157.7168, 23130.0137,\n",
            "        23158.7207, 23152.3496, 23162.0918, 23130.0703, 23151.8262, 23166.2852,\n",
            "        23151.6641, 23172.5332, 23147.0352, 23158.0137, 23143.2832, 23171.3516,\n",
            "        23168.3242, 23166.6738, 23128.5742, 23152.9590, 23150.5723, 23177.2949,\n",
            "        23153.1309, 23152.7969, 23140.5859, 23171.0078, 23166.2383, 23168.7363,\n",
            "        23121.8789, 23138.7285, 23173.5996, 23176.8691, 23125.7852, 23160.4902,\n",
            "        23161.5469, 23177.6543, 23164.6230, 23161.3359, 23160.4961, 23161.1387,\n",
            "        23147.0469, 23175.7871, 23139.3477, 23177.0781, 23145.7773, 23167.9355,\n",
            "        23145.5957, 23155.9648, 23168.8359, 23150.6953, 23156.6133, 23146.3555,\n",
            "        23127.3906, 23170.6934, 23150.0410], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 4.0154e-07, 1.7969e-03, 8.6761e-01, 1.4573e-06, 5.9809e-07,\n",
            "        2.7284e-05, 2.2222e-06, 4.5242e-06, 8.4777e-12, 3.1141e-09, 4.1280e-05,\n",
            "        7.5447e-08, 9.0625e-10, 2.0118e-05, 1.1343e-10, 5.1127e-11, 4.9733e-13,\n",
            "        4.9376e-09, 5.3500e-08, 2.7598e-07, 6.6963e-09, 3.0074e-07, 0.0000e+00,\n",
            "        2.0509e-07, 1.9806e-05, 2.8516e-10, 2.2175e-07, 6.0369e-10, 3.3742e-08,\n",
            "        1.1619e-06, 6.8060e-31, 2.8193e-08, 4.2989e-08, 1.0037e-05, 1.6835e-08,\n",
            "        4.2347e-04, 6.8161e-08, 9.4037e-11, 4.3784e-03, 4.3627e-27, 3.3480e-08,\n",
            "        6.7226e-22, 3.5287e-09, 2.8801e-09, 3.4366e-03, 8.9920e-10, 1.6895e-10,\n",
            "        1.0662e-06, 3.3429e-05, 1.1157e-03, 2.3977e-07, 5.0123e-13, 4.4101e-07,\n",
            "        2.1662e-07, 1.1728e-09, 1.1204e-01, 1.1963e-07, 3.2518e-07, 1.4741e-08,\n",
            "        4.3758e-07, 2.8516e-10, 1.1110e-05, 1.8061e-08, 1.3885e-03, 4.8815e-07,\n",
            "        4.8918e-06, 1.1945e-04, 5.3116e-04, 2.2845e-04, 2.6748e-07, 1.7208e-05,\n",
            "        5.1590e-03, 2.8861e-08, 6.2586e-04, 1.5668e-05, 9.3221e-04, 3.0074e-07,\n",
            "        1.2093e-13], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [3]\n",
            "DEBUGGING: logits looks like: tensor([23137.9648, 23183.1133, 23185.2148, 23186.7598, 23183.4355, 23183.2129,\n",
            "        23184.1680, 23183.5410, 23183.7188, 23180.4219, 23181.8984, 23184.2715,\n",
            "        23182.6953, 23181.5898, 23184.0918, 23181.0703, 23180.8711, 23179.7129,\n",
            "        23182.0137, 23182.6094, 23183.0195, 23182.0898, 23183.0410, 23114.1543,\n",
            "        23182.9453, 23184.0879, 23181.3008, 23182.9648, 23181.4883, 23182.4941,\n",
            "        23183.3789, 23169.4297, 23182.4492, 23182.5547, 23183.9180, 23182.3203,\n",
            "        23184.8535, 23182.6699, 23181.0234, 23185.4375, 23171.6211, 23182.4922,\n",
            "        23174.6074, 23181.9297, 23181.8789, 23185.3770, 23181.5879, 23181.1699,\n",
            "        23183.3574, 23184.2188, 23185.0957, 23182.9844, 23179.7148, 23183.1367,\n",
            "        23182.9590, 23181.6543, 23186.2480, 23182.8105, 23183.0605, 23182.2871,\n",
            "        23183.1348, 23181.3008, 23183.9434, 23182.3379, 23185.1504, 23183.1621,\n",
            "        23183.7383, 23184.5371, 23184.9102, 23184.6992, 23183.0117, 23184.0527,\n",
            "        23185.4785, 23182.4551, 23184.9512, 23184.0293, 23185.0508, 23183.0410,\n",
            "        23179.3594], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 2.3767e-02, 3.0517e-02, 5.3559e-02, 3.4239e-03, 1.4162e-03,\n",
            "        7.0254e-03, 1.3125e-02, 2.3036e-02, 1.9316e-04, 1.8762e-03, 1.6173e-03,\n",
            "        9.8659e-05, 7.2900e-04, 4.3964e-03, 9.9852e-03, 7.3626e-03, 1.2234e-02,\n",
            "        3.1420e-03, 5.9160e-03, 4.3036e-02, 3.8577e-02, 5.5143e-03, 1.3542e-02,\n",
            "        5.8121e-04, 3.7899e-03, 5.6451e-03, 2.5050e-03, 4.5169e-05, 8.8119e-03,\n",
            "        3.8798e-03, 1.7525e-02, 9.9075e-03, 5.7790e-03, 9.6780e-03, 9.1245e-05,\n",
            "        5.1399e-03, 1.0944e-03, 5.5143e-03, 7.1769e-04, 6.3470e-03, 4.4309e-03,\n",
            "        1.9097e-02, 2.8668e-02, 6.5484e-03, 1.3332e-02, 3.0453e-03, 1.0836e-04,\n",
            "        6.1517e-03, 1.2234e-02, 8.7433e-03, 7.5372e-03, 5.6451e-03, 1.5676e-03,\n",
            "        2.5900e-02, 1.9972e-03, 2.2631e-03, 1.7253e-02, 5.3031e-03, 6.2130e-02,\n",
            "        2.3717e-03, 1.5956e-02, 6.1999e-03, 3.7684e-02, 6.7563e-03, 1.0713e-02,\n",
            "        1.8949e-02, 3.2165e-03, 1.8366e-02, 1.8366e-02, 4.6074e-03, 2.1471e-02,\n",
            "        3.5678e-02, 1.6592e-02, 6.5998e-03, 2.6514e-02, 1.1227e-02, 1.1227e-02,\n",
            "        3.7684e-02, 1.6208e-02, 3.2928e-03, 8.5408e-03, 2.6875e-03, 7.1920e-03,\n",
            "        1.3332e-02, 1.2234e-02, 3.2417e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [21]\n",
            "DEBUGGING: logits looks like: tensor([23141.7891, 23188.4219, 23188.4844, 23188.6250, 23187.9375, 23187.7168,\n",
            "        23188.1172, 23188.2734, 23188.4141, 23187.2188, 23187.7871, 23187.7500,\n",
            "        23187.0508, 23187.5508, 23188.0000, 23188.2051, 23188.1289, 23188.2559,\n",
            "        23187.9160, 23188.0742, 23188.5703, 23188.5430, 23188.0566, 23188.2812,\n",
            "        23187.4941, 23187.9629, 23188.0625, 23187.8594, 23186.8555, 23188.1738,\n",
            "        23187.9688, 23188.3457, 23188.2031, 23188.0684, 23188.1973, 23187.0312,\n",
            "        23188.0391, 23187.6523, 23188.0566, 23187.5469, 23188.0918, 23188.0020,\n",
            "        23188.3672, 23188.4688, 23188.0996, 23188.2773, 23187.9082, 23187.0742,\n",
            "        23188.0840, 23188.2559, 23188.1719, 23188.1348, 23188.0625, 23187.7422,\n",
            "        23188.4434, 23187.8027, 23187.8340, 23188.3418, 23188.0469, 23188.6621,\n",
            "        23187.8457, 23188.3223, 23188.0859, 23188.5371, 23188.1074, 23188.2227,\n",
            "        23188.3652, 23187.9219, 23188.3574, 23188.3574, 23188.0117, 23188.3965,\n",
            "        23188.5234, 23188.3320, 23188.1016, 23188.4492, 23188.2344, 23188.2344,\n",
            "        23188.5371, 23188.3262, 23187.9277, 23188.1660, 23187.8770, 23188.1230,\n",
            "        23188.2773, 23188.2559, 23187.9238], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000, 0.0113, 0.0129, 0.0077, 0.0078, 0.0084, 0.0125, 0.0108, 0.0116,\n",
            "        0.0095, 0.0091, 0.0117, 0.0110, 0.0106, 0.0074, 0.0069, 0.0139, 0.0109,\n",
            "        0.0129, 0.0109, 0.0116, 0.0108, 0.0088, 0.0088, 0.0110, 0.0109, 0.0106,\n",
            "        0.0118, 0.0126, 0.0124, 0.0118, 0.0096, 0.0096, 0.0088, 0.0091, 0.0124,\n",
            "        0.0108, 0.0099, 0.0090, 0.0104, 0.0124, 0.0091, 0.0115, 0.0086, 0.0108,\n",
            "        0.0082, 0.0112, 0.0084, 0.0108, 0.0113, 0.0116, 0.0107, 0.0090, 0.0110,\n",
            "        0.0060, 0.0096, 0.0118, 0.0084, 0.0084, 0.0133, 0.0079, 0.0096, 0.0113,\n",
            "        0.0068, 0.0104, 0.0088, 0.0088, 0.0109, 0.0124, 0.0077, 0.0124, 0.0086,\n",
            "        0.0115, 0.0113, 0.0080, 0.0069, 0.0089, 0.0117, 0.0107, 0.0131, 0.0104,\n",
            "        0.0072, 0.0110, 0.0116, 0.0108, 0.0090, 0.0129, 0.0093, 0.0112, 0.0127,\n",
            "        0.0096, 0.0108, 0.0143, 0.0164, 0.0099, 0.0131, 0.0122],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [75]\n",
            "DEBUGGING: logits looks like: tensor([23144.7246, 23190.9824, 23191.0156, 23190.8887, 23190.8906, 23190.9082,\n",
            "        23191.0078, 23190.9727, 23190.9902, 23190.9395, 23190.9297, 23190.9922,\n",
            "        23190.9766, 23190.9668, 23190.8789, 23190.8594, 23191.0352, 23190.9746,\n",
            "        23191.0156, 23190.9746, 23190.9902, 23190.9727, 23190.9219, 23190.9199,\n",
            "        23190.9766, 23190.9746, 23190.9668, 23190.9941, 23191.0098, 23191.0059,\n",
            "        23190.9941, 23190.9414, 23190.9414, 23190.9199, 23190.9297, 23191.0059,\n",
            "        23190.9727, 23190.9492, 23190.9277, 23190.9629, 23191.0059, 23190.9297,\n",
            "        23190.9883, 23190.9141, 23190.9727, 23190.9043, 23190.9805, 23190.9082,\n",
            "        23190.9727, 23190.9824, 23190.9902, 23190.9688, 23190.9277, 23190.9766,\n",
            "        23190.8262, 23190.9414, 23190.9941, 23190.9082, 23190.9082, 23191.0234,\n",
            "        23190.8945, 23190.9414, 23190.9824, 23190.8555, 23190.9629, 23190.9199,\n",
            "        23190.9219, 23190.9746, 23191.0059, 23190.8887, 23191.0059, 23190.9141,\n",
            "        23190.9883, 23190.9824, 23190.8965, 23190.8594, 23190.9238, 23190.9922,\n",
            "        23190.9688, 23191.0195, 23190.9629, 23190.8711, 23190.9766, 23190.9902,\n",
            "        23190.9727, 23190.9277, 23191.0156, 23190.9336, 23190.9805, 23191.0117,\n",
            "        23190.9414, 23190.9727, 23191.0430, 23191.0762, 23190.9512, 23191.0195,\n",
            "        23191.0020], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000, 0.0094, 0.0096, 0.0093, 0.0094, 0.0096, 0.0091, 0.0096, 0.0096,\n",
            "        0.0094, 0.0094, 0.0096, 0.0091, 0.0094, 0.0093, 0.0094, 0.0092, 0.0096,\n",
            "        0.0096, 0.0093, 0.0093, 0.0094, 0.0094, 0.0096, 0.0094, 0.0094, 0.0094,\n",
            "        0.0091, 0.0096, 0.0093, 0.0092, 0.0096, 0.0096, 0.0096, 0.0093, 0.0091,\n",
            "        0.0096, 0.0094, 0.0094, 0.0096, 0.0096, 0.0096, 0.0094, 0.0093, 0.0094,\n",
            "        0.0093, 0.0093, 0.0094, 0.0096, 0.0093, 0.0093, 0.0094, 0.0094, 0.0094,\n",
            "        0.0093, 0.0093, 0.0093, 0.0093, 0.0091, 0.0093, 0.0093, 0.0050, 0.0093,\n",
            "        0.0094, 0.0094, 0.0096, 0.0092, 0.0096, 0.0093, 0.0096, 0.0094, 0.0094,\n",
            "        0.0093, 0.0096, 0.0093, 0.0096, 0.0093, 0.0094, 0.0094, 0.0092, 0.0096,\n",
            "        0.0094, 0.0093, 0.0096, 0.0094, 0.0094, 0.0092, 0.0093, 0.0094, 0.0093,\n",
            "        0.0094, 0.0092, 0.0091, 0.0096, 0.0094, 0.0093, 0.0094, 0.0093, 0.0094,\n",
            "        0.0093, 0.0093, 0.0093, 0.0094, 0.0093, 0.0093, 0.0094, 0.0093, 0.0093],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [28]\n",
            "DEBUGGING: logits looks like: tensor([23147.0938, 23193.2793, 23193.2852, 23193.2754, 23193.2793, 23193.2852,\n",
            "        23193.2715, 23193.2852, 23193.2852, 23193.2793, 23193.2793, 23193.2852,\n",
            "        23193.2715, 23193.2793, 23193.2773, 23193.2793, 23193.2734, 23193.2852,\n",
            "        23193.2852, 23193.2754, 23193.2754, 23193.2793, 23193.2793, 23193.2852,\n",
            "        23193.2793, 23193.2793, 23193.2793, 23193.2715, 23193.2852, 23193.2773,\n",
            "        23193.2734, 23193.2852, 23193.2852, 23193.2852, 23193.2773, 23193.2715,\n",
            "        23193.2852, 23193.2793, 23193.2793, 23193.2852, 23193.2852, 23193.2852,\n",
            "        23193.2793, 23193.2754, 23193.2793, 23193.2773, 23193.2754, 23193.2793,\n",
            "        23193.2852, 23193.2773, 23193.2754, 23193.2793, 23193.2793, 23193.2793,\n",
            "        23193.2754, 23193.2773, 23193.2754, 23193.2773, 23193.2715, 23193.2754,\n",
            "        23193.2754, 23193.1191, 23193.2773, 23193.2793, 23193.2793, 23193.2852,\n",
            "        23193.2734, 23193.2852, 23193.2754, 23193.2852, 23193.2793, 23193.2793,\n",
            "        23193.2773, 23193.2852, 23193.2754, 23193.2852, 23193.2773, 23193.2793,\n",
            "        23193.2793, 23193.2734, 23193.2852, 23193.2793, 23193.2754, 23193.2852,\n",
            "        23193.2793, 23193.2793, 23193.2734, 23193.2754, 23193.2793, 23193.2754,\n",
            "        23193.2793, 23193.2734, 23193.2715, 23193.2852, 23193.2793, 23193.2773,\n",
            "        23193.2793, 23193.2773, 23193.2793, 23193.2773, 23193.2773, 23193.2773,\n",
            "        23193.2793, 23193.2773, 23193.2773, 23193.2793, 23193.2773, 23193.2773],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.302090702972464 and immediate abs rewards look like: [0.1100722757364565, 0.14929593634997218, 0.0012034063638566295, 0.0002987925056459062, 2.121358875228907e-05, 0.00028725664196826983, 0.010993433698104127, 0.0005462698982228176, 0.001272452237571997, 0.006908467604489488, 0.009769924919282857, 0.0001419619934495131, 0.00022909584413355333, 0.0007394952071990701, 0.00043505392659426434, 0.0016476759874421987, 0.002403528512786579, 0.0001987847053896985, 0.0011103200727120566, 2.3052869664752507e-05, 0.0002424374545171304, 3.7745734516647644e-05, 0.0008943388108946237, 0.0005244834583209013, 6.539425953633327e-05, 0.0003204318545613205, 0.0007196403148554964, 0.0006380264485414955, 0.00019008908861906093, 4.276198569641565e-05, 0.00027497633436723845, 2.160448684662697e-05, 3.478149619695614e-05, 9.789187629394291e-05, 0.0002674844547527755, 3.862357971229358e-06, 4.732987713396142e-05, 8.972193654699367e-06, 1.1727626088031684e-05, 6.242707286219229e-06, 9.39909500630165e-06, 1.4550284959113924e-06, 3.7246124975354178e-06, 1.111625738303701e-05, 6.660382496193051e-06, 3.784354476010776e-06, 3.0014336971362354e-06, 6.308616775640985e-07, 2.0128591131651774e-06, 2.9660327527381014e-07]\n",
            "DEBUGGING: the total relative reward of the trajectory = 2.6961123345204943 and immediate relative rewards look like: [0.3051419852930756, 0.8538086521673165, 0.010783598958361664, 0.0035712150059946657, 0.0003169634837876518, 0.005150497310148532, 0.22998341512362058, 0.013103628975467713, 0.0343438889688088, 0.20725878864423208, 0.3230845489799944, 0.005136450061962186, 0.008980259532727691, 0.031219196817384068, 0.019682920311485413, 0.07952505336112647, 0.12331794689816634, 0.010806839679953143, 0.0637193158635735, 0.0013930604875771486, 0.015382857566634846, 0.0025092294982050206, 0.06215623355770144, 0.03804654238281742, 0.004942203748992531, 0.02518596685230697, 0.058745001188541895, 0.05402352060906599, 0.016673437929044924, 0.003880378232379904, 0.025784432099783178, 0.0020913687596954954, 0.0034721759215671382, 0.01006861327482036, 0.028321975554786556, 0.00042067540323611905, 0.005298216550282359, 0.0010315280880621987, 0.0013838044395415895, 0.0007555000645152819, 0.001165929414819535, 0.00018489466799682458, 0.000484566449234305, 0.0014798426805131871, 0.0009068123448304695, 0.0005266914344325829, 0.00042680915222125974, 9.161843939160953e-05, 0.00029841252477412207, 4.486976553522087e-05]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 3\n",
            "DEBUGGING: the action_prob is: tensor([1.2027e-13, 4.8625e-43, 4.5826e-01, 3.0610e-22, 4.3610e-06, 4.4045e-31,\n",
            "        0.0000e+00, 0.0000e+00, 3.6317e-41, 6.8136e-13, 0.0000e+00, 9.2516e-05,\n",
            "        2.0207e-04, 0.0000e+00, 8.0258e-02, 8.6548e-33, 9.7864e-08, 0.0000e+00,\n",
            "        6.7646e-09, 1.3047e-30, 2.9007e-03, 1.0716e-27, 1.9080e-09, 7.6240e-19,\n",
            "        0.0000e+00, 2.6420e-40, 6.4414e-36, 1.2001e-14, 1.3772e-34, 3.1260e-12,\n",
            "        2.1165e-34, 3.5116e-31, 4.1564e-40, 1.6675e-43, 8.9161e-30, 1.8521e-12,\n",
            "        1.6996e-12, 1.2461e-37, 0.0000e+00, 0.0000e+00, 1.1049e-05, 5.7670e-18,\n",
            "        0.0000e+00, 0.0000e+00, 1.4661e-34, 2.1876e-22, 4.5745e-39, 6.0257e-38,\n",
            "        4.7638e-16, 1.5254e-30, 4.1006e-39, 2.5255e-28, 2.4856e-17, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.0207e-39, 2.9042e-21, 6.2040e-39, 2.5885e-20,\n",
            "        0.0000e+00, 2.2041e-37, 1.2799e-28, 9.3046e-06, 8.9697e-42, 3.4066e-38,\n",
            "        0.0000e+00, 3.6317e-41, 4.5826e-01], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [68]\n",
            "DEBUGGING: logits looks like: tensor([23231.1445, 23214.2246, 23238.3867, 23226.1973, 23235.4961, 23221.1074,\n",
            "        23208.0586, 23206.2617, 23215.3027, 23231.5781, 23165.7871, 23236.2598,\n",
            "        23236.4551, 23203.3691, 23237.9512, 23220.1250, 23234.5469, 23204.3516,\n",
            "        23233.8789, 23221.3789, 23237.1211, 23223.0566, 23233.5625, 23228.1523,\n",
            "        23209.5020, 23215.7988, 23218.3242, 23230.5684, 23219.0898, 23231.9590,\n",
            "        23219.1973, 23221.0508, 23215.9121, 23213.9570, 23221.8594, 23231.8281,\n",
            "        23231.8066, 23217.3379, 23195.1953, 23204.9121, 23235.7285, 23228.6582,\n",
            "        23210.0742, 23207.4316, 23219.1055, 23226.1133, 23216.5117, 23217.1562,\n",
            "        23229.7617, 23221.4180, 23216.4844, 23222.6953, 23229.0234, 23202.9180,\n",
            "        23212.2363, 23212.5410, 23216.1367, 23226.7598, 23216.5879, 23227.3066,\n",
            "        23201.0898, 23217.4805, 23222.5254, 23235.6855, 23214.9531, 23217.0137,\n",
            "        23206.0391, 23215.3027, 23238.3867], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.1631e-43, 8.8445e-17, 6.1559e-11, 3.1507e-10, 3.7337e-11,\n",
            "        8.0725e-27, 1.4772e-21, 0.0000e+00, 3.3119e-16, 0.0000e+00, 2.1065e-38,\n",
            "        0.0000e+00, 5.4719e-15, 4.7100e-12, 3.9841e-21, 5.9398e-28, 1.3016e-18,\n",
            "        1.7033e-09, 2.8697e-21, 5.7173e-09, 3.3925e-12, 1.6684e-30, 7.7445e-17,\n",
            "        1.5000e-10, 1.1353e-31, 1.2525e-14, 7.2951e-38, 8.0966e-07, 9.3922e-07,\n",
            "        1.7182e-16, 1.3551e-36, 7.7352e-43, 2.3833e-09, 9.4235e-24, 4.7029e-09,\n",
            "        3.9878e-28, 1.8246e-06, 2.0076e-20, 5.4457e-21, 2.7746e-43, 9.6149e-07,\n",
            "        2.5956e-13, 9.2217e-12, 1.1067e-32, 2.3697e-08, 1.1204e-15, 2.0337e-25,\n",
            "        3.4960e-20, 3.0917e-19, 3.5350e-11, 1.0406e-13, 2.3260e-02, 6.1688e-10,\n",
            "        3.3070e-39, 9.1471e-01, 1.0749e-05, 1.9824e-26, 1.8217e-44, 3.3925e-12,\n",
            "        2.4820e-12, 4.8624e-08, 1.9764e-20, 4.8188e-16, 1.2799e-26, 1.8713e-20,\n",
            "        4.8786e-25, 6.5254e-13, 7.3169e-18, 7.5154e-35, 2.3219e-40, 5.8319e-33,\n",
            "        6.0751e-21, 4.9212e-06, 3.8477e-19, 4.2118e-02, 1.9895e-02, 2.1294e-18,\n",
            "        7.0983e-25], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [55]\n",
            "DEBUGGING: logits looks like: tensor([23174.1953, 23231.4941, 23246.9688, 23250.3320, 23250.7402, 23250.2070,\n",
            "        23241.1895, 23244.2188, 23224.5410, 23247.2988, 23225.0957, 23234.5215,\n",
            "        23218.5664, 23248.0000, 23249.6895, 23244.4668, 23240.5371, 23245.9141,\n",
            "        23251.1621, 23244.3848, 23251.4648, 23249.6074, 23239.0684, 23246.9355,\n",
            "        23250.5547, 23238.3965, 23248.2070, 23234.8320, 23252.7031, 23252.7402,\n",
            "        23247.1348, 23235.5625, 23231.9688, 23251.2461, 23242.9551, 23251.4160,\n",
            "        23240.4375, 23252.9062, 23244.8711, 23244.5449, 23231.7129, 23252.7461,\n",
            "        23248.9648, 23249.8574, 23237.8145, 23251.8203, 23247.6035, 23241.9961,\n",
            "        23245.0098, 23245.5547, 23250.1934, 23248.7363, 23255.2695, 23250.9082,\n",
            "        23234.0586, 23256.1875, 23253.3496, 23241.4141, 23231.0312, 23249.6074,\n",
            "        23249.5293, 23252.0000, 23244.8672, 23247.3926, 23241.3047, 23244.8535,\n",
            "        23242.2148, 23249.1953, 23246.3457, 23236.5664, 23233.3945, 23237.6543,\n",
            "        23244.5723, 23253.1543, 23245.6094, 23255.4180, 23255.2305, 23246.0371,\n",
            "        23242.3086], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 5.9483e-03, 3.1450e-20, 9.2268e-06, 5.1945e-08, 7.6103e-01,\n",
            "        4.6270e-11, 7.3254e-08, 2.4552e-04, 2.5955e-11, 5.1727e-10, 1.7473e-06,\n",
            "        2.7621e-26, 6.4087e-27, 1.2128e-05, 7.5625e-04, 2.7646e-07, 4.6131e-05,\n",
            "        7.1257e-10, 7.6539e-02, 1.0575e-07, 4.5294e-10, 7.1557e-08, 2.1229e-10,\n",
            "        9.6900e-05, 2.3918e-09, 4.3402e-08, 3.4180e-25, 1.6252e-07, 4.7868e-06,\n",
            "        6.0293e-04, 1.0155e-04, 3.8118e-14, 4.9566e-08, 6.6598e-05, 1.5332e-05,\n",
            "        8.4670e-06, 1.6355e-04, 3.3792e-23, 3.3277e-08, 1.8273e-07, 4.1526e-03,\n",
            "        2.3064e-04, 4.2948e-13, 5.6521e-05, 6.1853e-03, 4.2999e-05, 7.6172e-08,\n",
            "        1.6935e-06, 3.2692e-09, 5.1355e-06, 9.2992e-06, 1.3425e-05, 7.3298e-04,\n",
            "        1.5181e-06, 2.4070e-06, 4.2282e-13, 1.1493e-12, 3.4406e-07, 1.1731e-06,\n",
            "        2.2577e-03, 1.2532e-08, 1.2985e-06, 1.4959e-13, 7.4251e-09, 3.4354e-04,\n",
            "        6.7994e-10, 7.0194e-06, 1.1855e-01, 4.8798e-08, 9.2937e-10, 2.3064e-04,\n",
            "        9.1936e-04, 7.1107e-11, 2.4924e-34, 4.0092e-16, 8.4543e-03, 2.1576e-06,\n",
            "        4.5131e-08, 1.3059e-07, 1.9001e-07, 4.6034e-06, 4.3180e-03, 2.9385e-04,\n",
            "        1.1241e-04, 4.5553e-11, 2.5583e-03, 9.5398e-05, 2.3846e-03, 2.3846e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [5]\n",
            "DEBUGGING: logits looks like: tensor([23187.8066, 23273.4902, 23263.5449, 23271.8730, 23270.5781, 23274.7031,\n",
            "        23268.8223, 23270.6641, 23272.6934, 23268.6777, 23269.4258, 23271.4570,\n",
            "        23260.0586, 23259.6934, 23271.9414, 23272.9746, 23270.9961, 23272.2754,\n",
            "        23269.5059, 23274.1289, 23270.7559, 23269.3926, 23270.6582, 23269.2031,\n",
            "        23272.4609, 23269.8086, 23270.5332, 23260.6875, 23270.8633, 23271.7090,\n",
            "        23272.9180, 23272.4727, 23267.0469, 23270.5664, 23272.3672, 23272.0000,\n",
            "        23271.8516, 23272.5918, 23261.8359, 23270.4668, 23270.8926, 23273.4004,\n",
            "        23272.6777, 23267.6523, 23272.3262, 23273.5000, 23272.2578, 23270.6738,\n",
            "        23271.4492, 23269.8867, 23271.7266, 23271.8750, 23271.9668, 23272.9668,\n",
            "        23271.4219, 23271.5371, 23267.6484, 23267.8984, 23271.0508, 23271.3574,\n",
            "        23273.2480, 23270.2227, 23271.3828, 23267.3887, 23270.0918, 23272.7773,\n",
            "        23269.4941, 23271.8047, 23274.2383, 23270.5625, 23269.5723, 23272.6777,\n",
            "        23273.0234, 23268.9297, 23255.4277, 23265.9082, 23273.5781, 23271.5098,\n",
            "        23270.5430, 23270.8086, 23270.9023, 23271.6992, 23273.4102, 23272.7383,\n",
            "        23272.4980, 23268.8184, 23273.2793, 23272.4570, 23273.2617, 23273.2617],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 2.0756e-03, 4.4192e-04, 1.0853e-03, 4.6411e-03, 1.1285e-03,\n",
            "        5.7968e-05, 5.8090e-04, 1.1759e-02, 7.4008e-04, 7.8781e-04, 1.6282e-07,\n",
            "        1.9156e-04, 1.9569e-05, 5.9307e-09, 2.0712e-04, 6.9128e-03, 1.1685e-05,\n",
            "        2.7872e-04, 2.0800e-02, 1.0623e-02, 1.1826e-03, 2.2396e-04, 3.9614e-04,\n",
            "        7.4164e-03, 1.0284e-10, 2.9271e-03, 2.4128e-02, 1.4184e-02, 2.7713e-03,\n",
            "        6.5449e-03, 3.6428e-03, 1.4154e-03, 2.6595e-04, 6.5449e-03, 8.7203e-04,\n",
            "        1.9347e-03, 1.0356e-03, 5.1264e-04, 6.3799e-04, 3.7505e-04, 5.3724e-04,\n",
            "        2.0756e-03, 2.9271e-03, 6.1006e-03, 2.2221e-04, 9.7487e-03, 2.7283e-03,\n",
            "        1.1087e-04, 2.1969e-02, 2.9902e-04, 2.0595e-03, 2.5180e-04, 1.8175e-03,\n",
            "        2.1831e-05, 2.3926e-06, 1.2298e-03, 1.9540e-02, 1.0058e-02, 2.0117e-03,\n",
            "        2.6651e-03, 3.5307e-03, 2.4457e-03, 5.4259e-03, 1.0058e-02, 6.5824e-04,\n",
            "        2.6444e-03, 1.3563e-01, 7.2294e-04, 9.1388e-04, 1.6326e-02, 8.0022e-04,\n",
            "        1.0356e-03, 2.4686e-06, 1.3325e-02, 3.8476e-03, 1.1133e-02, 4.0322e-03,\n",
            "        1.2907e-06, 6.5449e-03, 1.5185e-03, 1.3193e-03, 4.7511e-03, 1.2132e-02,\n",
            "        1.2420e-02, 7.0217e-03, 2.1628e-02, 3.1046e-01, 9.1580e-03, 8.5362e-03,\n",
            "        5.5114e-03, 1.1759e-02, 6.2942e-03, 4.6508e-02, 3.3761e-02, 4.6508e-02,\n",
            "        1.9569e-05, 6.6480e-03, 9.2298e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [95]\n",
            "DEBUGGING: logits looks like: tensor([23198.6660, 23284.8184, 23284.4316, 23284.6562, 23285.0195, 23284.6660,\n",
            "        23283.9238, 23284.5000, 23285.2520, 23284.5605, 23284.5762, 23282.4551,\n",
            "        23284.2227, 23283.6523, 23281.6270, 23284.2422, 23285.1191, 23283.5234,\n",
            "        23284.3164, 23285.3945, 23285.2266, 23284.6777, 23284.2617, 23284.4043,\n",
            "        23285.1367, 23280.6133, 23284.9043, 23285.4316, 23285.2988, 23284.8906,\n",
            "        23285.1055, 23284.9590, 23284.7227, 23284.3047, 23285.1055, 23284.6016,\n",
            "        23284.8008, 23284.6445, 23284.4688, 23284.5234, 23284.3906, 23284.4805,\n",
            "        23284.8184, 23284.9043, 23285.0879, 23284.2598, 23285.2051, 23284.8867,\n",
            "        23284.0859, 23285.4082, 23284.3340, 23284.8164, 23284.2910, 23284.7852,\n",
            "        23283.6797, 23283.1270, 23284.6875, 23285.3789, 23285.2129, 23284.8105,\n",
            "        23284.8809, 23284.9512, 23284.8594, 23285.0586, 23285.2129, 23284.5312,\n",
            "        23284.8789, 23285.8633, 23284.5547, 23284.6133, 23285.3340, 23284.5801,\n",
            "        23284.6445, 23283.1348, 23285.2832, 23284.9727, 23285.2383, 23284.9844,\n",
            "        23282.9727, 23285.1055, 23284.7402, 23284.7051, 23285.0254, 23285.2598,\n",
            "        23285.2656, 23285.1230, 23285.4043, 23286.0703, 23285.1895, 23285.1719,\n",
            "        23285.0625, 23285.2520, 23285.0957, 23285.5957, 23285.5156, 23285.5957,\n",
            "        23283.6523, 23285.1094, 23285.1914], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 3.6387e-03, 4.8583e-03, 3.4919e-04, 5.2012e-04, 1.1296e-02,\n",
            "        2.4866e-02, 2.4239e-03, 1.3811e-03, 9.7933e-04, 7.0137e-03, 2.7840e-04,\n",
            "        1.6921e-03, 1.3491e-03, 1.3358e-04, 3.3652e-03, 1.2284e-03, 8.4424e-04,\n",
            "        6.8512e-03, 3.1613e-03, 1.9065e-02, 1.5439e-02, 1.4249e-03, 3.8432e-03,\n",
            "        1.1296e-02, 3.0816e-04, 1.0507e-03, 2.6059e-02, 3.8733e-03, 7.0943e-05,\n",
            "        1.4058e-02, 8.1360e-03, 1.0840e-03, 9.7933e-04, 2.8278e-04, 3.1680e-02,\n",
            "        8.4424e-04, 7.2778e-04, 1.4361e-03, 7.8692e-04, 1.0611e-02, 1.2214e-02,\n",
            "        1.3282e-03, 4.4488e-04, 9.5120e-03, 2.6414e-03, 6.2738e-04, 5.2942e-03,\n",
            "        4.5997e-03, 1.5439e-02, 1.3076e-03, 1.7090e-02, 4.8204e-03, 2.8117e-03,\n",
            "        4.9451e-02, 3.2873e-03, 2.9299e-02, 7.2211e-04, 1.3103e-02, 2.1773e-02,\n",
            "        9.4380e-03, 5.1825e-02, 4.8964e-03, 1.1296e-02, 3.9652e-03, 3.7621e-02,\n",
            "        1.5200e-02, 5.9061e-03, 2.7252e-03, 3.7542e-03, 2.4620e-03, 2.9698e-03,\n",
            "        1.1011e-03, 1.5082e-02, 1.0507e-03, 2.2818e-02, 4.4582e-03, 9.3645e-03,\n",
            "        1.3386e-03, 9.5665e-04, 3.0705e-02, 2.8117e-03, 1.4649e-01, 3.5066e-02,\n",
            "        4.8861e-04, 4.2451e-04, 5.6679e-04, 1.1296e-02, 8.1360e-03, 3.6103e-03,\n",
            "        2.4239e-03, 1.1296e-02, 6.3364e-03, 7.8526e-05, 3.2111e-03, 4.3458e-04,\n",
            "        2.4866e-02, 4.9735e-03, 5.1391e-06, 5.5051e-03, 7.1499e-05, 5.8146e-03,\n",
            "        1.9325e-03, 5.5167e-02, 5.0125e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [51]\n",
            "DEBUGGING: logits looks like: tensor([23207.4766, 23292.7598, 23292.8320, 23292.1738, 23292.2734, 23293.0430,\n",
            "        23293.2402, 23292.6582, 23292.5176, 23292.4316, 23292.9238, 23292.1172,\n",
            "        23292.5684, 23292.5117, 23291.9336, 23292.7402, 23292.4883, 23292.3945,\n",
            "        23292.9180, 23292.7246, 23293.1738, 23293.1211, 23292.5254, 23292.7734,\n",
            "        23293.0430, 23292.1426, 23292.4492, 23293.2520, 23292.7754, 23291.7754,\n",
            "        23293.0977, 23292.9609, 23292.4570, 23292.4316, 23292.1211, 23293.3008,\n",
            "        23292.3945, 23292.3574, 23292.5273, 23292.3770, 23293.0273, 23293.0625,\n",
            "        23292.5078, 23292.2344, 23293.0000, 23292.6797, 23292.3203, 23292.8535,\n",
            "        23292.8184, 23293.1211, 23292.5039, 23293.1465, 23292.8301, 23292.6953,\n",
            "        23293.4121, 23292.7344, 23293.2812, 23292.3555, 23293.0801, 23293.2070,\n",
            "        23292.9980, 23293.4238, 23292.8340, 23293.0430, 23292.7812, 23293.3438,\n",
            "        23293.1172, 23292.8809, 23292.6875, 23292.7676, 23292.6621, 23292.7090,\n",
            "        23292.4609, 23293.1152, 23292.4492, 23293.2188, 23292.8105, 23292.9961,\n",
            "        23292.5098, 23292.4258, 23293.2930, 23292.6953, 23293.6836, 23293.3262,\n",
            "        23292.2578, 23292.2227, 23292.2949, 23293.0430, 23292.9609, 23292.7578,\n",
            "        23292.6582, 23293.0430, 23292.8984, 23291.8008, 23292.7285, 23292.2285,\n",
            "        23293.2402, 23292.8379, 23291.1191, 23292.8633, 23291.7773, 23292.8770,\n",
            "        23292.6016, 23293.4395, 23292.8398], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.14946371879250364 and immediate abs rewards look like: [0.0018197951239926624, 0.0020484290453168796, 0.009805356072774885, 0.07084235528373029, 0.008372851106742019, 0.012517200971160491, 0.004003946936791181, 0.00017202422441187082, 0.00012899183593617636, 0.0002346301221223257, 0.0037768709539705014, 0.008482625638862373, 8.50353731038922e-05, 0.0001339707355327846, 0.00024221171270255581, 0.0006711003875352617, 0.00046973874123068526, 0.0017426452654945024, 0.00020010246998936054, 6.316769395198207e-05, 0.0069267498029148555, 0.00014787564850848867, 0.0004099623765796423, 0.0009389969309268054, 0.007042988506782422, 7.745693437755108e-06, 0.0004899904170088121, 0.0017492208212388505, 0.0011482508721201157, 0.00039302796585616306, 5.6577407576696714e-05, 0.0004396247459226288, 0.00011869368063344155, 2.422564193693688e-06, 0.00045144338628233527, 4.82085570183699e-05, 1.0837720765266567e-05, 0.0001115073041546566, 0.00014130259478406515, 0.00046644114081573207, 0.00042382432457088726, 0.0009716276977087546, 2.867879493351211e-05, 0.00015394602496598964, 1.8884775272454135e-06, 0.0003449565347182215, 0.0005392611078605114, 7.576542884635273e-06, 3.182906675647246e-05, 4.5212387703941204e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 4.383406351932021 and immediate relative rewards look like: [0.0058678251582577985, 0.01321784028513575, 0.09496888074636195, 0.9177548212871813, 0.1387706270538436, 0.249643162572333, 0.09355312533507476, 0.004599730150150258, 0.0038804533175933404, 0.007842964004435033, 0.13888500204690707, 0.34071460289564043, 0.003710710009947676, 0.006295995602186206, 0.01219641994480224, 0.036048629288001975, 0.026815410138178657, 0.10534869219606333, 0.0127763840328569, 0.004245766732900742, 0.48886520464985617, 0.010959023544895438, 0.03176479006609896, 0.0759293268036911, 0.5934286964581499, 0.0006803577313142276, 0.04469471363346102, 0.16549290341231676, 0.11258181646773553, 0.03987923417091682, 0.005932866470793674, 0.04758830721723047, 0.013251781772150249, 0.00027867909366847824, 0.053459128399338876, 0.005872776955601152, 0.0013569493580032148, 0.014338788678116178, 0.018649048707332555, 0.06314217637724899, 0.05881674728888366, 0.13814741132504513, 0.004176051070880978, 0.022938331290305595, 0.0002877979136223114, 0.05373853122996927, 0.08584426372717092, 0.001231986576049848, 0.00528341533461206, 0.007658203409709583]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 200 number of matrices\n",
            "DEBUGGING: ACT_MAT has 200 number of matrices\n",
            "DEBUGGING: VAL looks like: [[5.1267434807261685, 5.14923480697675, 5.131761319791692, 5.1299725880603635, 4.8555666011008585, 4.878035542192636, 4.907427602125186, 4.87456906275133, 4.7334782936005135, 4.528247658420194, 4.2366141249398375, 3.6979223592066983, 3.7019525738123176, 3.3499897933937683, 2.949673069095739, 2.7736719289102005, 2.784657828184284, 2.7944905760449155, 2.239855786697324, 2.170151860750956, 2.0038890834145846, 1.6472883554018225, 1.0091186644454142, 0.9918748075809235, 0.9646043499258851, 0.8008275545294865, 0.7431469827209205, 0.7443810648703438, 0.7497477784159227, 0.7268944198672038, 0.723841824576747, 0.6817646104166823, 0.5561349792434305, 0.5113030738952682, 0.5105721862853365, 0.38289698352822393, 0.3729310570438095, 0.35296622278485007, 0.24302012982634158, 0.2326818892118495, 0.20842996677054396, 0.19663404728876194, 0.1810342286935255, 0.11741550429125971, 0.0701968242115294, 0.06784942016127221, 0.03573432908126446, 0.033796166950350225, 0.021983785785957152, 0.0201997016061589], [1.7085855857760313, 1.6653284865324107, 1.595746287525228, 1.5853536125557295, 1.5855399364285512, 1.5801243341232374, 1.4862498705132965, 1.490335788191613, 1.4942824824593457, 1.2802378536969106, 1.2212920517849908, 1.2169085629530771, 1.0077473186153603, 0.9504803118132359, 0.9488772753302778, 0.9457898001088102, 0.9493677996954237, 0.9520306219887492, 0.8674400968792881, 0.8742063973306543, 0.8191245194991262, 0.8271826107137634, 0.8066124321841017, 0.8092730864444654, 0.812511567772127, 0.7358629666207392, 0.6930400981740229, 0.5746176828528092, 0.5707009898911821, 0.4891688916027274, 0.46914097163679647, 0.46213504874217953, 0.3780136306597702, 0.3760550862473346, 0.37180122938173576, 0.2949696183352472, 0.29112649131832435, 0.24675130999605815, 0.2416795232081478, 0.2321674989452312, 0.23143894764234058, 0.22310340011572588, 0.22125768159259157, 0.20907940413614556, 0.12859633488407557, 0.12921878437734266, 0.12024383435745736, 0.035358655139463555, 0.03505567958483401, 0.0242725150067363], [2.4857609359574315, 2.202645404711471, 1.3624613662062164, 1.3653310780281362, 1.3755150131536782, 1.3890889390604955, 1.3979176179296433, 1.1797315179858816, 1.178412009101428, 1.1556243637703225, 0.9579450253798893, 0.6412732084847423, 0.6425623822452325, 0.6399819421338433, 0.6149118639560195, 0.601241357216701, 0.5269861655106813, 0.4077456753661768, 0.40094831887497334, 0.3406353565771716, 0.3426689859490853, 0.3305920488711621, 0.3313967872454112, 0.27196015524011086, 0.2362763766235287, 0.23367088169145067, 0.21059082306984211, 0.1533796180619194, 0.10035969439682163, 0.08453157218967344, 0.08146585248211469, 0.05624385897205204, 0.05469948506298641, 0.051744756708504314, 0.04209711457947874, 0.01391428184312342, 0.013629905494835658, 0.008415847418740706, 0.0074589084148267756, 0.006136468661904228, 0.005435321815544391, 0.004312517576489753, 0.004169316069184776, 0.0037219693130812843, 0.002264774376331411, 0.001371678819697921, 0.0008535226113791294, 0.00043102369611906034, 0.00034283359265399073, 4.486976553522087e-05], [3.722792265388101, 3.754469131545296, 3.779041708343596, 3.721285684441651, 2.8318493567216865, 2.7202815451190334, 2.4955943258047477, 2.4263042428986594, 2.4461661744934435, 2.466955273915, 2.48395182819249, 2.368754369844023, 2.0485250171195784, 2.065468997080435, 2.079972728765908, 2.088662938203137, 2.073347786782965, 2.0672044208533196, 1.9816724531891479, 1.9887839082386778, 2.0045839813189668, 1.531029067342536, 1.5354242866642833, 1.5188479763618026, 1.4574935854122337, 0.8727928171253373, 0.8809216761555788, 0.8446736995172908, 0.6860412081868423, 0.5792519108273806, 0.5448208855115795, 0.5443313323644301, 0.5017606314618178, 0.49344328251481573, 0.4981460640617649, 0.4491787228913395, 0.44778378377347305, 0.45093619637926247, 0.4410074825264104, 0.4266246806253312, 0.36715404469503254, 0.3114518155617666, 0.17505495377446617, 0.17260495222584363, 0.15117840498539195, 0.15241475461794912, 0.09967295291715135, 0.013968372919172148, 0.012865036710224546, 0.007658203409709583]]\n",
            "DEBUGGING: traj_returns = [5.1267434807261685, 1.7085855857760313, 2.4857609359574315, 3.722792265388101]\n",
            "DEBUGGING: actions = [[43], [36], [3], [18], [43], [3], [24], [35], [66], [69], [66], [38], [22], [25], [71], [59], [74], [3], [75], [15], [5], [72], [77], [78], [25], [39], [41], [48], [82], [45], [30], [20], [23], [11], [34], [3], [57], [52], [94], [5], [12], [92], [60], [51], [75], [63], [23], [59], [26], [32], [17], [25], [17], [63], [64], [62], [63], [66], [18], [51], [59], [28], [62], [15], [62], [11], [16], [41], [61], [35], [54], [47], [4], [4], [3], [66], [70], [65], [7], [60], [29], [72], [28], [72], [41], [64], [84], [28], [4], [44], [77], [45], [39], [65], [50], [55], [3], [86], [86], [104], [17], [14], [13], [26], [52], [27], [3], [41], [22], [7], [60], [68], [2], [20], [2], [62], [22], [77], [46], [3], [28], [2], [76], [35], [41], [3], [29], [49], [1], [21], [34], [25], [8], [18], [38], [37], [62], [88], [17], [75], [78], [78], [100], [37], [73], [48], [72], [100], [89], [28], [6], [15], [23], [63], [26], [7], [31], [11], [2], [68], [14], [11], [67], [53], [69], [68], [10], [19], [22], [55], [71], [21], [70], [47], [36], [71], [67], [73], [66], [5], [72], [84], [72], [92], [65], [74], [85], [20], [86], [95], [84], [91], [91], [79], [100], [38], [101], [48], [77], [51]]\n",
            "DEBUGGING: actions length = 200\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[-30.3508,  53.6369, -57.0650,  ...,  45.5264,  58.7737, -28.7640],\n",
            "        [-30.5023,  53.9096, -57.3436,  ...,  45.7531,  59.0653, -28.9120],\n",
            "        [-29.5237,  52.1832, -55.5128,  ...,  44.2938,  57.1832, -27.9870],\n",
            "        ...,\n",
            "        [-30.2083,  53.3904, -56.7982,  ...,  45.3174,  58.5031, -28.6321],\n",
            "        [-30.2079,  53.3897, -56.7975,  ...,  45.3168,  58.5024, -28.6317],\n",
            "        [-30.2081,  53.3902, -56.7980,  ...,  45.3172,  58.5029, -28.6320]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[-30.0960,  53.1939, -56.5872,  ...,  45.1504,  58.2875, -28.5272],\n",
            "        [-30.2073,  53.3887, -56.7963,  ...,  45.3159,  58.5012, -28.6311],\n",
            "        [-30.2074,  53.3888, -56.7965,  ...,  45.3160,  58.5014, -28.6312],\n",
            "        ...,\n",
            "        [-30.2070,  53.3883, -56.7960,  ...,  45.3156,  58.5008, -28.6309],\n",
            "        [-30.2081,  53.3902, -56.7980,  ...,  45.3172,  58.5029, -28.6320],\n",
            "        [-30.2074,  53.3888, -56.7966,  ...,  45.3160,  58.5014, -28.6312]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([23207.4766, 23292.7598, 23292.8320, 23292.1738, 23292.2734, 23293.0430,\n",
            "        23293.2402, 23292.6582, 23292.5176, 23292.4316, 23292.9238, 23292.1172,\n",
            "        23292.5684, 23292.5117, 23291.9336, 23292.7402, 23292.4883, 23292.3945,\n",
            "        23292.9180, 23292.7246, 23293.1738, 23293.1211, 23292.5254, 23292.7734,\n",
            "        23293.0430, 23292.1426, 23292.4492, 23293.2520, 23292.7754, 23291.7754,\n",
            "        23293.0977, 23292.9609, 23292.4570, 23292.4316, 23292.1211, 23293.3008,\n",
            "        23292.3945, 23292.3574, 23292.5273, 23292.3770, 23293.0273, 23293.0625,\n",
            "        23292.5078, 23292.2344, 23293.0000, 23292.6797, 23292.3203, 23292.8535,\n",
            "        23292.8184, 23293.1211, 23292.5039, 23293.1465, 23292.8301, 23292.6953,\n",
            "        23293.4121, 23292.7344, 23293.2812, 23292.3555, 23293.0801, 23293.2070,\n",
            "        23292.9980, 23293.4238, 23292.8340, 23293.0430, 23292.7812, 23293.3438,\n",
            "        23293.1172, 23292.8809, 23292.6875, 23292.7676, 23292.6621, 23292.7090,\n",
            "        23292.4609, 23293.1152, 23292.4492, 23293.2188, 23292.8105, 23292.9961,\n",
            "        23292.5098, 23292.4258, 23293.2930, 23292.6953, 23293.6836, 23293.3262,\n",
            "        23292.2578, 23292.2227, 23292.2949, 23293.0430, 23292.9609, 23292.7578,\n",
            "        23292.6582, 23293.0430, 23292.8984, 23291.8008, 23292.7285, 23292.2285,\n",
            "        23293.2402, 23292.8379, 23291.1191, 23292.8633, 23291.7773, 23292.8770,\n",
            "        23292.6016, 23293.4395, 23292.8398], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[3.26097057 3.19291946 2.96725267 2.95048574 2.66211773 2.64188259\n",
            "  2.57179735 2.49273515 2.46308474 2.35776629 2.22495076 1.98121463\n",
            "  1.85019682 1.75148026 1.64835873 1.60234151 1.5835899  1.55536782\n",
            "  1.37247916 1.34344438 1.29256664 1.08402302 0.92063804 0.89798901\n",
            "  0.86772147 0.66078855 0.6319249  0.57926302 0.52671242 0.4699617\n",
            "  0.45481738 0.43611871 0.37265218 0.35813655 0.35565415 0.2852399\n",
            "  0.28136781 0.26476739 0.23329151 0.22440263 0.20311457 0.18387545\n",
            "  0.14537905 0.12570546 0.08805908 0.08771366 0.06412616 0.02088855\n",
            "  0.01756183 0.01304382]]\n",
            "DEBUGGING: baseline2 looks like: 3.260970566961933\n",
            "DEBUGGING: ADS looks like: [ -7.89221083  -7.83735712  -7.82219404  -7.49236611  -7.5713076\n",
            "  -7.49506184  -7.43092506  -7.05344565  -7.03183937  -6.86782614\n",
            "  -7.18937587  -7.09531491  -6.78706003  -6.57325976  -6.73701161\n",
            "  -6.83423966  -6.27463121  -6.30048951  -6.63076866  -6.3912253\n",
            "  -5.98497073  -6.02744578  -6.68035373  -6.67983827  -6.74559596\n",
            "  -6.93547754  -5.91325503  -5.92461178  -5.55240312  -5.406226\n",
            "  -5.24658134  -5.27959915  -5.43128578  -4.89220217  -4.27932023\n",
            "  -4.42066328  -3.76563525  -3.79643688  -3.93147425  -3.73673186\n",
            "  -3.77439125  -3.05456475  -3.07315519  -3.14407032  -1.97007816\n",
            "  -1.96377765  -1.55950293  -1.56275567  -0.9061008   -0.89375477\n",
            " -11.31036873 -11.32126345 -11.35820908 -11.03698509 -10.84133426\n",
            " -10.79297305 -10.85210279 -10.43767893 -10.27103519 -10.11583595\n",
            " -10.20469794  -9.57632871  -9.48126529  -8.97276924  -8.73780741\n",
            "  -8.66212179  -8.10992124  -8.14294946  -8.00318435  -7.68717076\n",
            "  -7.16973529  -6.84755152  -6.88285996  -6.86243999  -6.89768874\n",
            "  -7.00044213  -5.96336192  -6.09437517  -5.73144991  -5.64395153\n",
            "  -5.5012822   -5.49922871  -5.60940713  -5.02745015  -4.41809118\n",
            "  -4.50859064  -3.84743982  -3.90265179  -3.93281485  -3.73724625\n",
            "  -3.75138227  -3.0280954   -3.03293174  -3.05240642  -1.91167865\n",
            "  -1.90240829  -1.47499343  -1.56119319  -0.89302891  -0.88968196\n",
            " -10.53319338 -10.78394653 -11.591494   -11.25700762 -11.05135919\n",
            " -10.98400844 -10.94043505 -10.7482832  -10.58690566 -10.24044944\n",
            " -10.46804497 -10.15196406  -9.84645022  -9.28326761  -9.07177282\n",
            "  -9.00667024  -8.53230287  -8.68723441  -8.46967612  -8.22074181\n",
            "  -7.64619083  -7.34414208  -7.3580756   -7.39975292  -7.47392393\n",
            "  -7.50263421  -6.44581119  -6.51561323  -6.20179121  -6.04858885\n",
            "  -5.88895731  -5.9051199   -5.93272128  -5.35176048  -4.7477953\n",
            "  -4.78964598  -4.12493641  -4.14098726  -4.16703547  -3.96327728\n",
            "  -3.97738589  -3.24688628  -3.2500201   -3.25776385  -2.03801021\n",
            "  -2.03025539  -1.59438374  -1.59612082  -0.92774176  -0.9139096\n",
            "  -9.29616205  -9.2321228   -9.17491365  -8.90105301  -9.59502484\n",
            "  -9.65281584  -9.84275834  -9.50171047  -9.31915149  -8.92911853\n",
            "  -8.94203817  -8.4244829   -8.44048759  -7.85778056  -7.60671195\n",
            "  -7.51924866  -6.98594125  -7.02777566  -6.88895199  -6.57259325\n",
            "  -5.98427583  -6.14370507  -6.1540481   -6.1528651   -6.25270672\n",
            "  -6.86351228  -5.77548034  -5.82431915  -5.6161097   -5.55386851\n",
            "  -5.42560228  -5.41703243  -5.48566013  -4.91006196  -4.29174635\n",
            "  -4.35438154  -3.69078253  -3.69846691  -3.73348689  -3.54278906\n",
            "  -3.61566717  -2.93974698  -3.07913446  -3.08888087  -1.88909658\n",
            "  -1.87921232  -1.49556431  -1.58258347  -0.91521955  -0.90629627]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(-7.4560, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.0854, -0.1949, -0.2270,  ..., -0.0132, -0.1883, -0.1058],\n",
            "        [ 0.1012, -0.2311, -0.2692,  ..., -0.0156, -0.2233, -0.1246],\n",
            "        [ 0.1161, -0.2650, -0.3087,  ..., -0.0179, -0.2560, -0.1432],\n",
            "        ...,\n",
            "        [ 0.1667, -0.3805, -0.4432,  ..., -0.0257, -0.3676, -0.2042],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0576,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0718,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0828,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0985,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1238,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1420,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1075,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1352,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1543,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0504,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0632,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0728,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0977,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1225,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1406,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1287,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1617,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1859,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0802,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1011,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1154,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0839,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1054,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1199,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1080,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1347,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1559,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0525,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0663,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0759,  0.0000,  0.0000,  0.0000]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.0439,  0.1391, -0.1114,  ..., -0.1840, -0.1237, -0.0226],\n",
            "        [ 0.0516,  0.1634, -0.1309,  ..., -0.2163, -0.1454, -0.0264],\n",
            "        [ 0.0612,  0.1939, -0.1553,  ..., -0.2566, -0.1725, -0.0305],\n",
            "        ...,\n",
            "        [ 0.0873,  0.2764, -0.2214,  ..., -0.3658, -0.2459, -0.0450],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0162,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0114,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0194,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0307,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0226,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0359,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0277,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0196,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0326,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0141,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0102,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0166,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0244,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0167,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0287,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0346,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0248,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0411,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0196,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0123,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0227,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0229,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0162,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0267,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0294,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0201,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0348,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0170,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0126,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0203,  0.0000,  0.0000,  0.0000]])\n",
            "DEBUGGING: training for one iteration takes 0.006418 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 46\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [57]\n",
            "DEBUGGING: logits looks like: tensor([24748.4980, 24805.2090, 24731.3398, 24778.0938, 24717.2070, 24799.1016,\n",
            "        24797.6777, 24740.7402, 24784.3770, 24845.9199, 24797.8242, 24743.5254,\n",
            "        24879.8848, 24802.1465, 24816.6992, 24831.6621, 24812.5312, 24837.8906,\n",
            "        24831.3145, 24747.1270, 24804.6270, 24747.0508, 24795.1621, 24765.9766,\n",
            "        24846.1582, 24821.2617, 24806.4043, 24767.1113, 24839.7656, 24777.5664,\n",
            "        24789.2383, 24799.0527, 24778.5508, 24815.6250, 24806.8125, 24830.9434,\n",
            "        24754.1895, 24750.3418, 24741.9492, 24765.7520, 24759.1016, 24870.9863,\n",
            "        24770.0645, 24773.1855, 24716.8984, 24806.8047, 24833.1660, 24775.2207,\n",
            "        24814.0801, 24838.0117, 24839.6738, 24774.7441, 24824.7109, 24784.7930,\n",
            "        24790.8164, 24861.5723, 24814.6621, 24913.1504, 24823.9160, 24840.7285,\n",
            "        24880.8594, 24814.6875, 24738.1152, 24740.6855, 24820.5430, 24862.1016,\n",
            "        24832.7285, 24852.7500, 24856.0195], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([3.0873e-25, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0113e-22, 0.0000e+00,\n",
            "        2.7468e-36, 6.1125e-42, 3.4942e-33, 3.3990e-35, 0.0000e+00, 8.2695e-06,\n",
            "        1.1012e-36, 1.5306e-02, 5.5154e-24, 5.5491e-43, 0.0000e+00, 1.1939e-42,\n",
            "        8.9551e-35, 2.8467e-19, 1.5562e-35, 0.0000e+00, 8.2695e-06, 4.2039e-45,\n",
            "        0.0000e+00, 7.5183e-29, 4.1482e-22, 5.2835e-37, 5.0671e-42, 1.9982e-35,\n",
            "        7.2607e-27, 0.0000e+00, 5.4370e-42, 1.3246e-41, 2.8026e-45, 8.7608e-38,\n",
            "        1.6816e-44, 0.0000e+00, 5.7732e-32, 9.3089e-24, 1.0419e-40, 1.5585e-12,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8468e-01, 6.1584e-31,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.5712e-23, 1.5608e-15, 1.3590e-40, 6.7474e-21, 2.2224e-29,\n",
            "        1.1715e-40, 1.9089e-27, 4.6180e-23, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.0388e-18, 0.0000e+00, 9.6567e-40, 0.0000e+00, 9.8708e-37,\n",
            "        0.0000e+00, 1.4641e-38, 2.7917e-32, 7.6367e-29, 8.3019e-19, 0.0000e+00],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [46]\n",
            "DEBUGGING: logits looks like: tensor([24948.6113, 24934.9434, 24924.3262, 24906.8613, 24950.3320, 24928.5371,\n",
            "        24942.2500, 24938.9961, 24944.0371, 24942.8789, 24916.2266, 24959.7949,\n",
            "        24942.0215, 24961.6758, 24949.3320, 24938.3965, 24931.6699, 24938.5879,\n",
            "        24943.1211, 24952.0449, 24942.6836, 24930.3008, 24959.7949, 24937.1895,\n",
            "        24925.0957, 24946.5312, 24950.4121, 24941.8379, 24938.9492, 24942.7461,\n",
            "        24947.6738, 24917.6621, 24938.9668, 24939.1895, 24937.0801, 24941.3887,\n",
            "        24937.5195, 24931.3711, 24944.7383, 24949.4629, 24939.7051, 24955.9238,\n",
            "        24932.5156, 24931.7031, 24932.6934, 24928.0195, 24962.7168, 24945.3301,\n",
            "        24922.8145, 24930.2793, 24935.1680, 24928.4883, 24935.5234, 24920.2930,\n",
            "        24926.2910, 24949.5938, 24954.1973, 24939.7715, 24951.1094, 24946.2266,\n",
            "        24939.7344, 24947.3398, 24949.8633, 24921.9609, 24914.8535, 24928.3926,\n",
            "        24916.0820, 24952.5371, 24920.1543, 24940.2617, 24920.8711, 24941.9941,\n",
            "        24936.6309, 24940.9414, 24944.5566, 24946.5352, 24952.3125, 24927.6992],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.6570e-03, 9.4543e-31, 0.0000e+00, 0.0000e+00, 3.3418e-24, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7012e-20, 0.0000e+00,\n",
            "        0.0000e+00, 5.1017e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.0512e-39, 0.0000e+00, 1.4023e-32, 0.0000e+00,\n",
            "        1.3964e-34, 7.2868e-43, 4.2039e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.8637e-43, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7071e-35,\n",
            "        0.0000e+00, 8.2115e-20, 0.0000e+00, 0.0000e+00, 8.0939e-12, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.3244e-19, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9459e-23, 2.3133e-02, 5.8035e-03,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        9.6841e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7775e-27,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [60]\n",
            "DEBUGGING: logits looks like: tensor([24965.2617, 24949.4609, 24939.7031, 24911.1094, 24953.2305, 24902.6816,\n",
            "        24906.4980, 24907.9863, 24904.6602, 24900.1855, 24955.5586, 24848.2637,\n",
            "        24872.9219, 24957.9414, 24939.0312, 24914.0527, 24939.6172, 24908.7070,\n",
            "        24932.9375, 24918.1133, 24944.3066, 24909.6855, 24948.4082, 24876.5781,\n",
            "        24947.2559, 24942.4883, 24941.2051, 24867.3281, 24932.0449, 24920.3574,\n",
            "        24895.5586, 24942.1465, 24938.4629, 24872.3008, 24925.2168, 24946.8457,\n",
            "        24931.5469, 24955.7578, 24909.0684, 24853.9746, 24960.3594, 24913.8652,\n",
            "        24934.2773, 24923.7773, 24895.0312, 24919.4883, 24956.3652, 24872.3672,\n",
            "        24922.5527, 24923.5957, 24934.4355, 24953.8477, 24965.8027, 24965.4570,\n",
            "        24871.7363, 24936.9980, 24904.3457, 24920.4766, 24903.8535, 24882.4160,\n",
            "        24966.7363, 24924.8457, 24905.7266, 24929.4941, 24915.9043, 24951.3457,\n",
            "        24928.3379, 24877.2363, 24890.7031, 24909.4414, 24920.0625, 24898.0371,\n",
            "        24916.1094, 24924.9160, 24895.7812, 24924.7266, 24899.6094, 24900.9160,\n",
            "        24924.9766, 24924.9766, 24925.8730, 24910.6133, 24929.3320, 24933.2637,\n",
            "        24890.2305, 24897.7578], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.4282e-20, 1.0000e+00, 9.2209e-21, 0.0000e+00, 1.4065e-31, 2.0668e-30,\n",
            "        0.0000e+00, 1.3632e-31, 3.5168e-41, 1.7514e-27, 9.2264e-17, 1.5606e-41,\n",
            "        0.0000e+00, 2.9748e-24, 1.3518e-35, 4.3218e-21, 1.3640e-27, 0.0000e+00,\n",
            "        1.5827e-12, 2.4654e-13, 1.2048e-34, 0.0000e+00, 1.4859e-16, 4.9460e-20,\n",
            "        2.5993e-25, 1.0374e-16, 5.9750e-23, 0.0000e+00, 5.0481e-14, 0.0000e+00,\n",
            "        1.3656e-19, 0.0000e+00, 1.5971e-30, 5.7066e-30, 0.0000e+00, 1.0914e-29,\n",
            "        9.6984e-23, 1.3340e-19, 1.4149e-17, 5.0572e-28, 9.7569e-35, 2.4448e-17,\n",
            "        0.0000e+00, 1.2063e-26, 1.1133e-27, 0.0000e+00, 2.7405e-11, 5.5693e-23,\n",
            "        1.9562e-19, 1.1452e-21, 7.9370e-18, 1.6135e-14, 6.1517e-24, 1.6858e-34,\n",
            "        5.6214e-26, 0.0000e+00, 8.4666e-17, 0.0000e+00, 1.2661e-29, 8.8785e-39,\n",
            "        5.6317e-40, 0.0000e+00, 0.0000e+00, 1.5680e-09, 5.5910e-10, 1.2132e-27,\n",
            "        1.3094e-13, 5.9160e-24, 4.7997e-38, 3.5167e-15, 1.5771e-36, 7.2768e-11,\n",
            "        3.0829e-44, 3.0961e-31, 6.2372e-10, 8.3857e-29, 0.0000e+00, 1.3909e-14,\n",
            "        7.9874e-44, 2.2374e-22, 5.6741e-29, 1.5116e-19, 8.8916e-16, 0.0000e+00,\n",
            "        8.9481e-39, 7.6720e-23, 1.0121e-24, 1.4350e-14, 1.7892e-28, 7.5236e-10,\n",
            "        7.4540e-33, 2.4990e-14, 1.6217e-19, 0.0000e+00, 6.1315e-33, 1.3518e-35,\n",
            "        1.8949e-23, 3.6262e-19], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [1]\n",
            "DEBUGGING: logits looks like: tensor([24956.7832, 24968.2070, 24956.6738, 24916.8340, 24950.4473, 24951.1191,\n",
            "        24932.1270, 24950.4395, 24944.9199, 24952.8047, 24958.9766, 24944.7168,\n",
            "        24935.4023, 24954.6641, 24948.1348, 24956.4844, 24952.7422, 24919.3457,\n",
            "        24961.4141, 24960.9492, 24948.6816, 24941.6738, 24959.0957, 24957.0938,\n",
            "        24954.0547, 24959.0059, 24955.4141, 24927.7422, 24960.5527, 24938.8770,\n",
            "        24957.3477, 24926.7949, 24951.0547, 24951.3730, 24935.2773, 24951.5352,\n",
            "        24955.5352, 24957.3418, 24958.5078, 24952.4941, 24948.6289, 24958.6445,\n",
            "        24934.8418, 24953.2871, 24952.6914, 24941.7305, 24962.1270, 24955.3965,\n",
            "        24957.4375, 24956.1523, 24958.3633, 24960.2676, 24954.8457, 24948.7656,\n",
            "        24953.6719, 24941.8613, 24958.9551, 24935.6484, 24951.5723, 24946.3027,\n",
            "        24945.6133, 24937.1543, 24931.8594, 24963.1387, 24962.8809, 24952.7129,\n",
            "        24960.7910, 24954.8359, 24946.7246, 24959.8867, 24947.5977, 24962.3711,\n",
            "        24943.1562, 24950.6445, 24962.9082, 24952.0449, 24910.7129, 24960.2305,\n",
            "        24943.3984, 24955.7441, 24951.9473, 24957.3730, 24959.5430, 24925.0098,\n",
            "        24946.3047, 24955.4766, 24954.3945, 24960.2383, 24952.2344, 24962.9551,\n",
            "        24949.7129, 24960.3770, 24957.3906, 24941.6445, 24949.6641, 24948.1348,\n",
            "        24955.1270, 24957.5918], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 2.0166e-39, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 2.8251e-31, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3862e-37, 1.6824e-36, 6.7852e-23,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3612e-29, 2.5223e-44, 0.0000e+00,\n",
            "        0.0000e+00, 4.3299e-36, 2.4252e-33, 0.0000e+00, 1.8066e-17, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 4.1179e-19, 0.0000e+00, 4.7644e-44, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 9.9408e-42, 0.0000e+00, 3.6047e-34, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 7.5670e-44, 0.0000e+00, 2.2375e-23, 4.9628e-38,\n",
            "        1.1566e-21, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        4.0638e-44, 0.0000e+00, 0.0000e+00, 2.5248e-25, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4687e-30, 1.4687e-30, 4.2182e-41,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9422e-42, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.3113e-41, 0.0000e+00, 9.7722e-39, 1.2818e-39, 0.0000e+00,\n",
            "        0.0000e+00, 5.8855e-44, 0.0000e+00, 5.0000e-01, 5.0000e-01, 0.0000e+00,\n",
            "        0.0000e+00, 1.0665e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8895e-35,\n",
            "        0.0000e+00, 4.8174e-41, 0.0000e+00, 1.1231e-35, 3.8418e-26, 3.6935e-41,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        4.4647e-40, 3.3792e-35, 0.0000e+00, 8.5542e-28, 7.2971e-33],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [81]\n",
            "DEBUGGING: logits looks like: tensor([24936.9434, 24963.8848, 24951.7500, 24956.3574, 24952.3828, 24959.4688,\n",
            "        24959.3340, 24959.3008, 24968.5742, 24926.2402, 24949.2578, 24936.7129,\n",
            "        24938.5820, 24942.1699, 24953.7891, 24965.0781, 24965.5664, 24973.3984,\n",
            "        24918.1992, 24956.2891, 24954.9082, 24969.5430, 24961.0664, 24950.5547,\n",
            "        24941.2246, 24965.8027, 24967.3848, 24957.0605, 24976.5215, 24942.9863,\n",
            "        24954.2520, 24931.2461, 24975.5762, 24949.9512, 24961.2207, 24956.1152,\n",
            "        24921.8379, 24940.0137, 24962.5566, 24948.6836, 24966.9082, 24954.6738,\n",
            "        24946.8633, 24947.2129, 24961.3398, 24957.3418, 24973.1211, 24964.6855,\n",
            "        24974.1074, 24947.8398, 24943.4219, 24958.4766, 24947.6875, 24955.2617,\n",
            "        24961.1816, 24948.2754, 24956.7090, 24972.0000, 24959.1426, 24915.5312,\n",
            "        24955.5527, 24950.3418, 24954.7480, 24969.2012, 24968.9863, 24962.9180,\n",
            "        24940.6055, 24944.8398, 24959.5176, 24962.1484, 24915.8652, 24937.6855,\n",
            "        24937.2598, 24962.7676, 24958.2598, 24964.2793, 24963.7715, 24941.2578,\n",
            "        24946.5918, 24961.2715, 24929.7891, 24985.9863, 24985.9863, 24939.9570,\n",
            "        24957.2090, 24962.5742, 24935.1328, 24943.5293, 24944.3867, 24966.3516,\n",
            "        24954.1699, 24962.9512, 24930.9062, 24966.0410, 24971.5293, 24962.8848,\n",
            "        24959.9336, 24946.9395, 24960.2148, 24955.1367, 24943.6367, 24952.5078,\n",
            "        24963.5078, 24966.3164, 24950.8340, 24970.5781, 24967.6602],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.7058461509404879 and immediate abs rewards look like: [0.7058461509227527, 1.8189894035458565e-12, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 1.3642420526593924e-12, 0.0, 9.094947017729282e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0]\n",
            "DEBUGGING: the total relative reward of the trajectory = 2.608596764528234 and immediate relative rewards look like: [2.608596762540988, 1.8189894035470972e-11, 6.821210263295411e-12, 9.094947017729282e-12, 1.1368683772164188e-11, 1.3642420526593924e-11, 3.1832314562059726e-11, 1.818989403545443e-11, 0.0, 0.0, 2.5011104298755527e-11, 8.185452315954493e-11, 0.0, 6.366462912413393e-11, 0.0, 3.637978807091713e-11, 3.865352482534066e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2295945351943374e-11, 5.4569682106363287e-11, 5.6843418860808015e-11, 5.91171556152269e-11, 0.0, 6.366462912410498e-11, 0.0, 1.3642420526597025e-10, 7.048583938738591e-11, 7.275957614183426e-11, 7.503331289624952e-11, 0.0, 7.958078640513122e-11, 0.0, 0.0, 8.640199666840854e-11, 0.0, 0.0, 9.322320693172514e-11, 9.549694368613575e-11, 0.0, 1.000444171950221e-10, 0.0, 2.0918378140782106e-10, 1.0686562745829477e-10, 1.0913936421275139e-10, 1.1141310096720904e-10, 0.0]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [57]\n",
            "DEBUGGING: logits looks like: tensor([24748.4980, 24805.2090, 24731.3398, 24778.0938, 24717.2070, 24799.1016,\n",
            "        24797.6777, 24740.7402, 24784.3770, 24845.9199, 24797.8242, 24743.5254,\n",
            "        24879.8848, 24802.1465, 24816.6992, 24831.6621, 24812.5312, 24837.8906,\n",
            "        24831.3145, 24747.1270, 24804.6270, 24747.0508, 24795.1621, 24765.9766,\n",
            "        24846.1582, 24821.2617, 24806.4043, 24767.1113, 24839.7656, 24777.5664,\n",
            "        24789.2383, 24799.0527, 24778.5508, 24815.6250, 24806.8125, 24830.9434,\n",
            "        24754.1895, 24750.3418, 24741.9492, 24765.7520, 24759.1016, 24870.9863,\n",
            "        24770.0645, 24773.1855, 24716.8984, 24806.8047, 24833.1660, 24775.2207,\n",
            "        24814.0801, 24838.0117, 24839.6738, 24774.7441, 24824.7109, 24784.7930,\n",
            "        24790.8164, 24861.5723, 24814.6621, 24913.1504, 24823.9160, 24840.7285,\n",
            "        24880.8594, 24814.6875, 24738.1152, 24740.6855, 24820.5430, 24862.1016,\n",
            "        24832.7285, 24852.7500, 24856.0195], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([3.0873e-25, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0113e-22, 0.0000e+00,\n",
            "        2.7468e-36, 6.1125e-42, 3.4942e-33, 3.3990e-35, 0.0000e+00, 8.2695e-06,\n",
            "        1.1012e-36, 1.5306e-02, 5.5154e-24, 5.5491e-43, 0.0000e+00, 1.1939e-42,\n",
            "        8.9551e-35, 2.8467e-19, 1.5562e-35, 0.0000e+00, 8.2695e-06, 4.2039e-45,\n",
            "        0.0000e+00, 7.5183e-29, 4.1482e-22, 5.2835e-37, 5.0671e-42, 1.9982e-35,\n",
            "        7.2607e-27, 0.0000e+00, 5.4370e-42, 1.3246e-41, 2.8026e-45, 8.7608e-38,\n",
            "        1.6816e-44, 0.0000e+00, 5.7732e-32, 9.3089e-24, 1.0419e-40, 1.5585e-12,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8468e-01, 6.1584e-31,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.5712e-23, 1.5608e-15, 1.3590e-40, 6.7474e-21, 2.2224e-29,\n",
            "        1.1715e-40, 1.9089e-27, 4.6180e-23, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.0388e-18, 0.0000e+00, 9.6567e-40, 0.0000e+00, 9.8708e-37,\n",
            "        0.0000e+00, 1.4641e-38, 2.7917e-32, 7.6367e-29, 8.3019e-19, 0.0000e+00],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [46]\n",
            "DEBUGGING: logits looks like: tensor([24948.6113, 24934.9434, 24924.3262, 24906.8613, 24950.3320, 24928.5371,\n",
            "        24942.2500, 24938.9961, 24944.0371, 24942.8789, 24916.2266, 24959.7949,\n",
            "        24942.0215, 24961.6758, 24949.3320, 24938.3965, 24931.6699, 24938.5879,\n",
            "        24943.1211, 24952.0449, 24942.6836, 24930.3008, 24959.7949, 24937.1895,\n",
            "        24925.0957, 24946.5312, 24950.4121, 24941.8379, 24938.9492, 24942.7461,\n",
            "        24947.6738, 24917.6621, 24938.9668, 24939.1895, 24937.0801, 24941.3887,\n",
            "        24937.5195, 24931.3711, 24944.7383, 24949.4629, 24939.7051, 24955.9238,\n",
            "        24932.5156, 24931.7031, 24932.6934, 24928.0195, 24962.7168, 24945.3301,\n",
            "        24922.8145, 24930.2793, 24935.1680, 24928.4883, 24935.5234, 24920.2930,\n",
            "        24926.2910, 24949.5938, 24954.1973, 24939.7715, 24951.1094, 24946.2266,\n",
            "        24939.7344, 24947.3398, 24949.8633, 24921.9609, 24914.8535, 24928.3926,\n",
            "        24916.0820, 24952.5371, 24920.1543, 24940.2617, 24920.8711, 24941.9941,\n",
            "        24936.6309, 24940.9414, 24944.5566, 24946.5352, 24952.3125, 24927.6992],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.6570e-03, 9.4543e-31, 0.0000e+00, 0.0000e+00, 3.3418e-24, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7012e-20, 0.0000e+00,\n",
            "        0.0000e+00, 5.1017e-16, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.0512e-39, 0.0000e+00, 1.4023e-32, 0.0000e+00,\n",
            "        1.3964e-34, 7.2868e-43, 4.2039e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 1.8637e-43, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7071e-35,\n",
            "        0.0000e+00, 8.2115e-20, 0.0000e+00, 0.0000e+00, 8.0939e-12, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.3244e-19, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9459e-23, 2.3133e-02, 5.8035e-03,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        9.6841e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7775e-27,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [60]\n",
            "DEBUGGING: logits looks like: tensor([24965.2617, 24949.4609, 24939.7031, 24911.1094, 24953.2305, 24902.6816,\n",
            "        24906.4980, 24907.9863, 24904.6602, 24900.1855, 24955.5586, 24848.2637,\n",
            "        24872.9219, 24957.9414, 24939.0312, 24914.0527, 24939.6172, 24908.7070,\n",
            "        24932.9375, 24918.1133, 24944.3066, 24909.6855, 24948.4082, 24876.5781,\n",
            "        24947.2559, 24942.4883, 24941.2051, 24867.3281, 24932.0449, 24920.3574,\n",
            "        24895.5586, 24942.1465, 24938.4629, 24872.3008, 24925.2168, 24946.8457,\n",
            "        24931.5469, 24955.7578, 24909.0684, 24853.9746, 24960.3594, 24913.8652,\n",
            "        24934.2773, 24923.7773, 24895.0312, 24919.4883, 24956.3652, 24872.3672,\n",
            "        24922.5527, 24923.5957, 24934.4355, 24953.8477, 24965.8027, 24965.4570,\n",
            "        24871.7363, 24936.9980, 24904.3457, 24920.4766, 24903.8535, 24882.4160,\n",
            "        24966.7363, 24924.8457, 24905.7266, 24929.4941, 24915.9043, 24951.3457,\n",
            "        24928.3379, 24877.2363, 24890.7031, 24909.4414, 24920.0625, 24898.0371,\n",
            "        24916.1094, 24924.9160, 24895.7812, 24924.7266, 24899.6094, 24900.9160,\n",
            "        24924.9766, 24924.9766, 24925.8730, 24910.6133, 24929.3320, 24933.2637,\n",
            "        24890.2305, 24897.7578], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.4282e-20, 1.0000e+00, 9.2209e-21, 0.0000e+00, 1.4065e-31, 2.0668e-30,\n",
            "        0.0000e+00, 1.3632e-31, 3.5168e-41, 1.7514e-27, 9.2264e-17, 1.5606e-41,\n",
            "        0.0000e+00, 2.9748e-24, 1.3518e-35, 4.3218e-21, 1.3640e-27, 0.0000e+00,\n",
            "        1.5827e-12, 2.4654e-13, 1.2048e-34, 0.0000e+00, 1.4859e-16, 4.9460e-20,\n",
            "        2.5993e-25, 1.0374e-16, 5.9750e-23, 0.0000e+00, 5.0481e-14, 0.0000e+00,\n",
            "        1.3656e-19, 0.0000e+00, 1.5971e-30, 5.7066e-30, 0.0000e+00, 1.0914e-29,\n",
            "        9.6984e-23, 1.3340e-19, 1.4149e-17, 5.0572e-28, 9.7569e-35, 2.4448e-17,\n",
            "        0.0000e+00, 1.2063e-26, 1.1133e-27, 0.0000e+00, 2.7405e-11, 5.5693e-23,\n",
            "        1.9562e-19, 1.1452e-21, 7.9370e-18, 1.6135e-14, 6.1517e-24, 1.6858e-34,\n",
            "        5.6214e-26, 0.0000e+00, 8.4666e-17, 0.0000e+00, 1.2661e-29, 8.8785e-39,\n",
            "        5.6317e-40, 0.0000e+00, 0.0000e+00, 1.5680e-09, 5.5910e-10, 1.2132e-27,\n",
            "        1.3094e-13, 5.9160e-24, 4.7997e-38, 3.5167e-15, 1.5771e-36, 7.2768e-11,\n",
            "        3.0829e-44, 3.0961e-31, 6.2372e-10, 8.3857e-29, 0.0000e+00, 1.3909e-14,\n",
            "        7.9874e-44, 2.2374e-22, 5.6741e-29, 1.5116e-19, 8.8916e-16, 0.0000e+00,\n",
            "        8.9481e-39, 7.6720e-23, 1.0121e-24, 1.4350e-14, 1.7892e-28, 7.5236e-10,\n",
            "        7.4540e-33, 2.4990e-14, 1.6217e-19, 0.0000e+00, 6.1315e-33, 1.3518e-35,\n",
            "        1.8949e-23, 3.6262e-19], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [1]\n",
            "DEBUGGING: logits looks like: tensor([24956.7832, 24968.2070, 24956.6738, 24916.8340, 24950.4473, 24951.1191,\n",
            "        24932.1270, 24950.4395, 24944.9199, 24952.8047, 24958.9766, 24944.7168,\n",
            "        24935.4023, 24954.6641, 24948.1348, 24956.4844, 24952.7422, 24919.3457,\n",
            "        24961.4141, 24960.9492, 24948.6816, 24941.6738, 24959.0957, 24957.0938,\n",
            "        24954.0547, 24959.0059, 24955.4141, 24927.7422, 24960.5527, 24938.8770,\n",
            "        24957.3477, 24926.7949, 24951.0547, 24951.3730, 24935.2773, 24951.5352,\n",
            "        24955.5352, 24957.3418, 24958.5078, 24952.4941, 24948.6289, 24958.6445,\n",
            "        24934.8418, 24953.2871, 24952.6914, 24941.7305, 24962.1270, 24955.3965,\n",
            "        24957.4375, 24956.1523, 24958.3633, 24960.2676, 24954.8457, 24948.7656,\n",
            "        24953.6719, 24941.8613, 24958.9551, 24935.6484, 24951.5723, 24946.3027,\n",
            "        24945.6133, 24937.1543, 24931.8594, 24963.1387, 24962.8809, 24952.7129,\n",
            "        24960.7910, 24954.8359, 24946.7246, 24959.8867, 24947.5977, 24962.3711,\n",
            "        24943.1562, 24950.6445, 24962.9082, 24952.0449, 24910.7129, 24960.2305,\n",
            "        24943.3984, 24955.7441, 24951.9473, 24957.3730, 24959.5430, 24925.0098,\n",
            "        24946.3047, 24955.4766, 24954.3945, 24960.2383, 24952.2344, 24962.9551,\n",
            "        24949.7129, 24960.3770, 24957.3906, 24941.6445, 24949.6641, 24948.1348,\n",
            "        24955.1270, 24957.5918], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 2.0166e-39, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 2.8251e-31, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3862e-37, 1.6824e-36, 6.7852e-23,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3612e-29, 2.5223e-44, 0.0000e+00,\n",
            "        0.0000e+00, 4.3299e-36, 2.4252e-33, 0.0000e+00, 1.8066e-17, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 4.1179e-19, 0.0000e+00, 4.7644e-44, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 9.9408e-42, 0.0000e+00, 3.6047e-34, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 7.5670e-44, 0.0000e+00, 2.2375e-23, 4.9628e-38,\n",
            "        1.1566e-21, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        4.0638e-44, 0.0000e+00, 0.0000e+00, 2.5248e-25, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 3.4687e-30, 1.4687e-30, 4.2182e-41,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9422e-42, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 2.3113e-41, 0.0000e+00, 9.7722e-39, 1.2818e-39, 0.0000e+00,\n",
            "        0.0000e+00, 5.8855e-44, 0.0000e+00, 5.0000e-01, 5.0000e-01, 0.0000e+00,\n",
            "        0.0000e+00, 1.0665e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.8895e-35,\n",
            "        0.0000e+00, 4.8174e-41, 0.0000e+00, 1.1231e-35, 3.8418e-26, 3.6935e-41,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        4.4647e-40, 3.3792e-35, 0.0000e+00, 8.5542e-28, 7.2971e-33],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [82]\n",
            "DEBUGGING: logits looks like: tensor([24936.9434, 24963.8848, 24951.7500, 24956.3574, 24952.3828, 24959.4688,\n",
            "        24959.3340, 24959.3008, 24968.5742, 24926.2402, 24949.2578, 24936.7129,\n",
            "        24938.5820, 24942.1699, 24953.7891, 24965.0781, 24965.5664, 24973.3984,\n",
            "        24918.1992, 24956.2891, 24954.9082, 24969.5430, 24961.0664, 24950.5547,\n",
            "        24941.2246, 24965.8027, 24967.3848, 24957.0605, 24976.5215, 24942.9863,\n",
            "        24954.2520, 24931.2461, 24975.5762, 24949.9512, 24961.2207, 24956.1152,\n",
            "        24921.8379, 24940.0137, 24962.5566, 24948.6836, 24966.9082, 24954.6738,\n",
            "        24946.8633, 24947.2129, 24961.3398, 24957.3418, 24973.1211, 24964.6855,\n",
            "        24974.1074, 24947.8398, 24943.4219, 24958.4766, 24947.6875, 24955.2617,\n",
            "        24961.1816, 24948.2754, 24956.7090, 24972.0000, 24959.1426, 24915.5312,\n",
            "        24955.5527, 24950.3418, 24954.7480, 24969.2012, 24968.9863, 24962.9180,\n",
            "        24940.6055, 24944.8398, 24959.5176, 24962.1484, 24915.8652, 24937.6855,\n",
            "        24937.2598, 24962.7676, 24958.2598, 24964.2793, 24963.7715, 24941.2578,\n",
            "        24946.5918, 24961.2715, 24929.7891, 24985.9863, 24985.9863, 24939.9570,\n",
            "        24957.2090, 24962.5742, 24935.1328, 24943.5293, 24944.3867, 24966.3516,\n",
            "        24954.1699, 24962.9512, 24930.9062, 24966.0410, 24971.5293, 24962.8848,\n",
            "        24959.9336, 24946.9395, 24960.2148, 24955.1367, 24943.6367, 24952.5078,\n",
            "        24963.5078, 24966.3164, 24950.8340, 24970.5781, 24967.6602],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.7058461509404879 and immediate abs rewards look like: [0.7058461509227527, 1.8189894035458565e-12, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 1.3642420526593924e-12, 0.0, 9.094947017729282e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 9.094947017729282e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0]\n",
            "DEBUGGING: the total relative reward of the trajectory = 2.608596764528234 and immediate relative rewards look like: [2.608596762540988, 1.8189894035470972e-11, 6.821210263295411e-12, 9.094947017729282e-12, 1.1368683772164188e-11, 1.3642420526593924e-11, 3.1832314562059726e-11, 1.818989403545443e-11, 0.0, 0.0, 2.5011104298755527e-11, 8.185452315954493e-11, 0.0, 6.366462912413393e-11, 0.0, 3.637978807091713e-11, 3.865352482534066e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2295945351943374e-11, 5.4569682106363287e-11, 5.6843418860808015e-11, 5.91171556152269e-11, 0.0, 6.366462912410498e-11, 0.0, 1.3642420526597025e-10, 7.048583938738591e-11, 7.275957614183426e-11, 7.503331289624952e-11, 0.0, 7.958078640513122e-11, 0.0, 0.0, 8.640199666840854e-11, 0.0, 0.0, 9.322320693172514e-11, 9.549694368613575e-11, 0.0, 1.000444171950221e-10, 0.0, 2.0918378140782106e-10, 1.0686562745829477e-10, 1.0913936421275139e-10, 1.1141310096720904e-10, 0.0]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([6.4761e-33, 0.0000e+00, 4.7152e-13, 3.7167e-37, 1.3930e-17, 5.6554e-38,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.5027e-17, 8.8810e-24,\n",
            "        0.0000e+00, 6.7198e-08, 0.0000e+00, 2.8651e-27, 0.0000e+00, 8.6596e-10,\n",
            "        3.4752e-43, 8.0161e-17, 2.0599e-43, 1.0000e+00, 6.9562e-25, 2.1420e-39,\n",
            "        3.4696e-40, 7.5460e-42, 9.4425e-32, 1.0559e-15, 1.4243e-25, 1.9918e-29,\n",
            "        3.7991e-34, 1.3930e-17, 0.0000e+00, 1.2649e-22, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.9086e-27, 1.8582e-36, 0.0000e+00, 0.0000e+00,\n",
            "        4.1054e-38, 2.2543e-37, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3440e-44,\n",
            "        1.6217e-19, 0.0000e+00, 5.4289e-24, 0.0000e+00, 1.3955e-31, 3.0444e-39,\n",
            "        3.4904e-26, 0.0000e+00, 0.0000e+00, 6.3585e-38, 0.0000e+00, 2.4887e-42,\n",
            "        0.0000e+00, 1.9456e-29, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        4.7522e-13], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [21]\n",
            "DEBUGGING: logits looks like: tensor([24824.4297, 24803.3418, 24835.8633, 24821.9883, 24833.2559, 24821.5176,\n",
            "        24806.5957, 24807.9902, 24800.3359, 24762.8496, 24833.4023, 24829.6895,\n",
            "        24809.4062, 24838.8301, 24814.5879, 24827.6797, 24808.7578, 24837.7422,\n",
            "        24818.5176, 24833.6934, 24818.3867, 24842.9590, 24829.0527, 24820.6992,\n",
            "        24820.2441, 24819.2871, 24825.0996, 24834.3379, 24828.6562, 24826.4375,\n",
            "        24823.7207, 24833.2559, 24815.1445, 24830.3535, 24810.2461, 24805.6777,\n",
            "        24808.9395, 24800.9805, 24827.5781, 24822.3906, 24813.9102, 24806.1211,\n",
            "        24821.4375, 24821.8633, 24815.7988, 24812.1719, 24809.5918, 24817.9941,\n",
            "        24832.1426, 24778.0625, 24829.5664, 24803.2422, 24825.1973, 24820.7871,\n",
            "        24828.3047, 24812.2266, 24808.8203, 24821.5469, 24792.0215, 24819.0098,\n",
            "        24813.3047, 24826.4316, 24808.6191, 24809.1152, 24804.2480, 24800.3379,\n",
            "        24835.8652], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 3.4155e-14, 9.0555e-11, 2.7453e-25, 1.0458e-27, 1.8047e-35,\n",
            "        1.3116e-42, 7.5685e-22, 0.0000e+00, 3.3054e-11, 0.0000e+00, 1.1864e-19,\n",
            "        1.8806e-34, 1.0489e-33, 2.3595e-19, 8.2008e-21, 1.2501e-09, 0.0000e+00,\n",
            "        9.2703e-11, 1.0747e-14, 5.4876e-30, 5.8803e-38, 4.0918e-43, 8.2379e-30,\n",
            "        5.0996e-24, 1.8999e-18, 1.4410e-38, 1.2595e-24, 0.0000e+00, 2.6857e-28,\n",
            "        9.9128e-20, 5.3188e-30, 3.8948e-37, 2.4557e-26, 8.6332e-30, 2.6306e-23,\n",
            "        9.2900e-36, 4.1773e-26, 1.1314e-23, 1.4013e-45, 2.8996e-25, 0.0000e+00,\n",
            "        9.3573e-40, 1.9708e-34, 1.2501e-09, 9.9994e-01, 5.7010e-23, 4.3908e-06,\n",
            "        8.5146e-18, 3.2995e-23, 3.3788e-34, 3.6555e-30, 3.2445e-31, 5.3701e-18,\n",
            "        5.0116e-36, 9.8595e-30, 0.0000e+00, 2.2192e-37, 2.1769e-09, 3.4145e-29,\n",
            "        1.5423e-28, 3.0497e-27, 1.6353e-15, 3.5369e-42, 2.0555e-14, 8.1224e-33,\n",
            "        5.4760e-05, 2.7868e-29, 7.0781e-39, 0.0000e+00, 6.9036e-10, 8.8724e-17,\n",
            "        8.7217e-14, 1.0197e-13], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [45]\n",
            "DEBUGGING: logits looks like: tensor([24777.5957, 24863.8691, 24865.8398, 24857.4824, 24856.0898, 24851.6211,\n",
            "        24847.5117, 24859.4629, 24845.4766, 24865.5879, 24836.8984, 24860.7266,\n",
            "        24852.2070, 24852.6367, 24860.8984, 24860.0586, 24866.4961, 24791.1133,\n",
            "        24865.8457, 24863.5801, 24854.7773, 24850.1895, 24847.2207, 24854.8789,\n",
            "        24858.2129, 24861.4199, 24849.8379, 24857.8633, 24837.1230, 24855.7500,\n",
            "        24860.6816, 24854.7695, 24850.6621, 24856.8789, 24854.8906, 24858.6230,\n",
            "        24851.4551, 24857.0117, 24858.4121, 24845.6484, 24857.4961, 24844.9512,\n",
            "        24849.1543, 24852.2188, 24866.4961, 24871.6211, 24858.8164, 24868.5371,\n",
            "        24861.7949, 24858.6797, 24852.3535, 24854.6758, 24854.0703, 24861.6797,\n",
            "        24851.3008, 24854.9238, 24837.0059, 24850.5215, 24866.6348, 24855.2344,\n",
            "        24855.6113, 24856.3574, 24863.1094, 24847.7598, 24863.7422, 24853.1484,\n",
            "        24869.1680, 24855.1836, 24849.6602, 24834.5859, 24866.3477, 24862.3809,\n",
            "        24864.1035, 24864.1426], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 2.0354e-35, 1.9618e-44, 1.8333e-29, 1.0275e-22, 8.2883e-36,\n",
            "        0.0000e+00, 5.4371e-21, 3.4633e-20, 0.0000e+00, 0.0000e+00, 1.4013e-45,\n",
            "        1.0124e-29, 2.5013e-15, 0.0000e+00, 2.3853e-19, 6.8628e-18, 8.5667e-24,\n",
            "        0.0000e+00, 3.2002e-39, 1.2718e-06, 0.0000e+00, 0.0000e+00, 2.7021e-34,\n",
            "        1.9121e-35, 2.9964e-22, 8.1867e-27, 2.4998e-19, 5.0573e-22, 3.7900e-18,\n",
            "        1.4669e-31, 1.4201e-13, 5.7152e-27, 3.7000e-22, 1.2479e-15, 7.3805e-28,\n",
            "        6.0038e-11, 3.7168e-31, 0.0000e+00, 4.5909e-16, 0.0000e+00, 0.0000e+00,\n",
            "        9.5914e-26, 0.0000e+00, 2.3259e-31, 5.0665e-36, 3.1581e-23, 2.9340e-32,\n",
            "        2.7405e-05, 2.8669e-17, 4.1116e-35, 9.1688e-40, 6.2225e-20, 4.1675e-10,\n",
            "        6.3718e-05, 1.3731e-29, 4.6271e-42, 7.0572e-01, 0.0000e+00, 2.2523e-24,\n",
            "        1.3102e-29, 0.0000e+00, 7.7185e-29, 4.2003e-36, 0.0000e+00, 2.9419e-01,\n",
            "        2.5966e-42, 1.5639e-34, 4.6717e-30, 0.0000e+00, 5.1865e-10, 0.0000e+00,\n",
            "        3.5306e-22, 1.3665e-35, 0.0000e+00, 7.1362e-18, 4.7969e-36, 1.0170e-38,\n",
            "        9.7804e-13, 4.0784e-24, 0.0000e+00, 2.0526e-31, 1.6760e-42, 2.0625e-25,\n",
            "        1.2566e-34, 2.6706e-21, 1.8549e-16, 0.0000e+00, 2.8600e-33],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [57]\n",
            "DEBUGGING: logits looks like: tensor([24795.2441, 24861.9375, 24856.7480, 24865.3652, 24869.2500, 24861.7129,\n",
            "        24845.9043, 24870.2422, 24870.7051, 24854.8125, 24841.4492, 24856.1523,\n",
            "        24865.2168, 24873.5020, 24852.8633, 24871.1875, 24872.0273, 24868.6289,\n",
            "        24853.7363, 24859.7480, 24878.5137, 24851.2871, 24821.7637, 24862.5840,\n",
            "        24861.9219, 24869.5176, 24866.8906, 24871.1992, 24869.6484, 24871.8789,\n",
            "        24864.1582, 24874.5117, 24866.8008, 24869.5703, 24873.3281, 24866.2891,\n",
            "        24876.0234, 24864.3906, 24836.3223, 24873.0781, 24838.0312, 24851.6602,\n",
            "        24867.5059, 24847.1074, 24864.2734, 24861.5898, 24868.9551, 24863.7559,\n",
            "        24879.2812, 24872.3848, 24862.1133, 24859.4355, 24870.8516, 24876.5078,\n",
            "        24879.4922, 24865.2930, 24858.1133, 24881.8203, 24820.9375, 24868.2949,\n",
            "        24865.2812, 24846.4473, 24865.7246, 24861.5430, 24851.7188, 24881.6016,\n",
            "        24857.9688, 24862.4473, 24865.0234, 24844.3926, 24876.5625, 24848.1230,\n",
            "        24869.5586, 24861.8379, 24842.6660, 24872.0371, 24861.5762, 24860.0371,\n",
            "        24874.9941, 24868.4434, 24851.1465, 24864.2422, 24857.8594, 24867.6973,\n",
            "        24862.3926, 24870.0645, 24872.8516, 24854.2031, 24863.1738],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 3.3381e-07, 3.7139e-12, 8.1094e-01, 4.3694e-09, 1.1210e-44,\n",
            "        1.4835e-10, 1.9695e-09, 8.2570e-11, 7.1524e-31, 0.0000e+00, 3.2893e-14,\n",
            "        0.0000e+00, 1.6094e-01, 0.0000e+00, 2.8390e-06, 2.7516e-06, 1.6619e-08,\n",
            "        2.1768e-32, 1.5091e-13, 3.3451e-06, 2.6726e-05, 1.3139e-12, 3.3907e-07,\n",
            "        6.8309e-12, 7.9909e-08, 1.5949e-09, 4.5271e-07, 2.0640e-09, 8.9253e-26,\n",
            "        1.1693e-08, 1.5830e-20, 4.0899e-07, 1.8062e-13, 2.5974e-26, 7.3815e-16,\n",
            "        1.9279e-08, 5.8008e-08, 2.1709e-11, 2.7674e-07, 7.3131e-13, 6.1786e-04,\n",
            "        1.8991e-04, 3.5716e-12, 3.8804e-06, 3.6072e-11, 6.0409e-11, 8.0707e-33,\n",
            "        1.8821e-12, 2.5966e-15, 1.6352e-12, 1.0239e-08, 7.0118e-07, 3.7017e-21,\n",
            "        2.6542e-12, 3.6486e-13, 3.9617e-11, 1.0388e-16, 1.5214e-24, 3.1948e-13,\n",
            "        4.1718e-05, 1.8952e-31, 0.0000e+00, 9.7349e-07, 4.5149e-12, 3.7803e-11,\n",
            "        2.2929e-37, 2.5663e-02, 2.4383e-43, 1.3585e-11, 3.8537e-13, 1.5892e-07,\n",
            "        2.4986e-11, 6.0192e-09, 3.4545e-13, 1.5792e-10, 2.7516e-06, 7.3616e-21,\n",
            "        3.6949e-07, 2.3012e-13, 1.8138e-11, 6.9469e-30, 1.6396e-07, 2.3878e-14,\n",
            "        1.0416e-11, 2.1643e-05, 2.7212e-15, 5.5869e-11, 8.5937e-18, 1.5173e-03,\n",
            "        1.0319e-08, 5.6529e-24, 3.1491e-05, 1.8952e-31],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [13]\n",
            "DEBUGGING: logits looks like: tensor([24807.0664, 24888.8691, 24886.0176, 24892.5449, 24887.7852, 24867.3027,\n",
            "        24886.9395, 24887.5859, 24886.7930, 24875.2441, 24860.1719, 24884.8359,\n",
            "        24858.2812, 24892.1406, 24863.6914, 24889.4043, 24889.3965, 24888.1191,\n",
            "        24874.3711, 24885.2168, 24889.4453, 24889.9648, 24885.7578, 24888.8730,\n",
            "        24886.1699, 24888.5117, 24887.5332, 24888.9453, 24887.5977, 24878.1777,\n",
            "        24888.0312, 24881.1992, 24888.9199, 24885.2617, 24877.8691, 24883.8867,\n",
            "        24888.1562, 24888.4316, 24886.4590, 24888.8223, 24885.6113, 24890.7500,\n",
            "        24890.4551, 24886.0078, 24889.4824, 24886.5859, 24886.7148, 24874.1230,\n",
            "        24885.8477, 24884.2012, 24885.8125, 24887.9980, 24889.0547, 24880.8359,\n",
            "        24885.9336, 24885.4375, 24886.6094, 24883.3965, 24878.8867, 24885.4043,\n",
            "        24890.0762, 24874.9121, 24866.1719, 24889.1367, 24886.0664, 24886.5977,\n",
            "        24871.5059, 24891.6816, 24868.0664, 24886.3418, 24885.4512, 24888.6836,\n",
            "        24886.4941, 24887.8652, 24885.4238, 24886.9551, 24889.3965, 24881.0078,\n",
            "        24888.8945, 24885.3223, 24886.4141, 24875.8125, 24888.6914, 24884.7559,\n",
            "        24886.2754, 24889.9121, 24884.2129, 24886.6953, 24882.7734, 24890.9746,\n",
            "        24888.0000, 24879.2148, 24890.0059, 24874.9121],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 3.6113e-04, 2.9079e-03, 1.2053e-02, 1.1404e-06, 2.9519e-07,\n",
            "        2.0989e-02, 3.2743e-06, 1.2904e-03, 3.4191e-04, 7.7050e-04, 2.8835e-07,\n",
            "        5.9540e-04, 4.1892e-04, 9.5145e-04, 1.1791e-05, 8.3311e-04, 2.0100e-04,\n",
            "        1.0592e-04, 1.2904e-03, 1.0346e-04, 1.9260e-02, 5.3677e-05, 7.0155e-04,\n",
            "        1.6829e-03, 2.4627e-04, 2.3919e-03, 1.3736e-03, 3.0346e-05, 8.9005e-06,\n",
            "        5.6933e-03, 1.3736e-03, 2.0142e-03, 1.5687e-03, 4.1892e-04, 3.2694e-03,\n",
            "        1.9481e-04, 3.8662e-05, 8.8498e-05, 4.8493e-05, 9.3867e-03, 8.8312e-06,\n",
            "        5.4637e-04, 1.6312e-03, 3.0713e-03, 3.7047e-03, 1.9676e-03, 2.0781e-03,\n",
            "        3.3782e-06, 1.1766e-06, 7.1970e-03, 1.4172e-03, 9.3136e-03, 4.0921e-04,\n",
            "        2.0944e-03, 2.2122e-03, 6.7083e-03, 5.8039e-05, 2.7706e-26, 6.8964e-01,\n",
            "        3.4532e-03, 1.7364e-03, 1.4395e-03, 4.6832e-03, 3.0954e-03, 5.4326e-03,\n",
            "        7.3677e-03, 1.0974e-02, 1.1275e-04, 5.5381e-05, 1.2122e-03, 1.5054e-04,\n",
            "        3.1688e-03, 4.6832e-03, 6.2887e-04, 7.7608e-08, 2.3919e-03, 7.9496e-04,\n",
            "        4.6832e-03, 7.6015e-03, 1.1411e-02, 1.0720e-02, 1.7058e-04, 7.4255e-03,\n",
            "        2.9245e-04, 1.3707e-04, 7.3677e-03, 7.9044e-03, 8.1381e-04, 5.2245e-03,\n",
            "        6.0605e-03, 1.5499e-05, 5.8740e-03, 1.0049e-03, 2.6215e-04, 3.4191e-04,\n",
            "        8.4801e-03, 1.0968e-06, 1.6312e-03, 5.9077e-04, 8.8180e-03, 3.2187e-03,\n",
            "        5.1838e-03, 6.5766e-05, 8.9380e-04, 4.3994e-03, 2.2075e-04, 7.1970e-03,\n",
            "        5.4752e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [59]\n",
            "DEBUGGING: logits looks like: tensor([24808.5527, 24899.9395, 24900.4609, 24900.8164, 24898.5000, 24898.1621,\n",
            "        24900.9551, 24898.7637, 24900.2578, 24899.9258, 24900.1289, 24898.1562,\n",
            "        24900.0645, 24899.9766, 24900.1816, 24899.0840, 24900.1484, 24899.7930,\n",
            "        24899.6328, 24900.2578, 24899.6270, 24900.9336, 24899.4629, 24900.1055,\n",
            "        24900.3242, 24899.8438, 24900.4121, 24900.2734, 24899.3203, 24899.0137,\n",
            "        24900.6289, 24900.2734, 24900.3691, 24900.3066, 24899.9766, 24900.4902,\n",
            "        24899.7852, 24899.3809, 24899.5879, 24899.4375, 24900.7539, 24899.0117,\n",
            "        24900.0430, 24900.3164, 24900.4746, 24900.5215, 24900.3633, 24900.3770,\n",
            "        24898.7715, 24898.5078, 24900.6875, 24900.2812, 24900.7520, 24899.9707,\n",
            "        24900.3789, 24900.3926, 24900.6699, 24899.4824, 24887.2090, 24901.8281,\n",
            "        24900.5039, 24900.3320, 24900.2852, 24900.5801, 24900.4766, 24900.6172,\n",
            "        24900.6934, 24900.7930, 24899.6484, 24899.4707, 24900.2422, 24899.7207,\n",
            "        24900.4824, 24900.5801, 24900.0781, 24897.8281, 24900.4121, 24900.1367,\n",
            "        24900.5801, 24900.7012, 24900.8027, 24900.7871, 24899.7520, 24900.6953,\n",
            "        24899.8867, 24899.6973, 24900.6934, 24900.7109, 24900.1426, 24900.6074,\n",
            "        24900.6445, 24899.1523, 24900.6367, 24900.1953, 24899.8594, 24899.9258,\n",
            "        24900.7285, 24898.4902, 24900.3164, 24900.0625, 24900.7383, 24900.4863,\n",
            "        24900.6055, 24899.5137, 24900.1660, 24900.5645, 24899.8164, 24900.6875,\n",
            "        24900.6191], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.1751922274811477 and immediate abs rewards look like: [0.0018197951239926624, 0.0020484290453168796, 0.009805356072774885, 0.07084235528373029, 0.008372851106742019, 0.012517200971160491, 0.004003946936791181, 6.371648260028451e-05, 0.00010270279153701267, 6.717394762745243e-05, 0.00016388236690545455, 0.00022016765387888881, 0.02020632116636989, 0.008210149514070508, 3.7250592413329287e-05, 0.0068469148213807784, 0.0030738879245291173, 0.011502959450353956, 0.000563982151561504, 0.00037500004827961675, 0.0006873805709801672, 6.913828656252008e-06, 0.00017810360304792994, 0.00039971373098524055, 3.5193229450669605e-06, 3.181151532771764e-05, 0.001101624462990003, 3.6663868741015904e-05, 0.005118447693348571, 9.685811482995632e-05, 0.00017680276641840464, 9.19802596399677e-06, 4.0515625187254045e-05, 6.993900251472951e-05, 1.3938766642240807e-05, 8.236770327130216e-05, 0.0003749489524125238, 0.00011449978319433285, 0.00023650295952393208, 0.002919828960330051, 0.0002931838384938601, 0.001636820499697933, 5.744590680478723e-05, 9.84428875199228e-05, 0.0003138539977953769, 6.551394017151324e-05, 4.849900233239168e-05, 5.155869303052896e-05, 8.04849464657309e-05, 2.80105950878351e-06]\n",
            "DEBUGGING: the total relative reward of the trajectory = 5.755264039288428 and immediate relative rewards look like: [0.0058678251582577985, 0.01321784028513575, 0.09496888074636195, 0.9177548212871813, 0.1387706270538436, 0.249643162572333, 0.09355312533507476, 0.0017037055512387977, 0.003089489795343613, 0.0022453176348035454, 0.006025756532791232, 0.008831718523219064, 0.8781587370553151, 0.3868701006056724, 0.001885872292911707, 0.36975001892297404, 0.17678077613962673, 0.7011840558064284, 0.036430403600943816, 0.02550290306550828, 0.049090813670188284, 0.0005174001037437371, 0.013934352124766139, 0.03263419174829312, 0.00029934412505981423, 0.002814037200994398, 0.10119852102037535, 0.0034941050576995547, 0.5052209195886727, 0.009907397466990297, 0.01868819737756693, 0.001003661936178598, 0.0045591165131063606, 0.008108650048532985, 0.0016636154916343585, 0.010111651323610353, 0.047309536768094664, 0.014839477923124908, 0.03145926037575886, 0.398382046222954, 0.04104298996349129, 0.23475180016437847, 0.00843973751027153, 0.014799496460390872, 0.04825748733135489, 0.010298231581423106, 0.007789534192514932, 0.008457288781930496, 0.013477409201713477, 0.00047863004864943275]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 3\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 2.1133e-38, 7.4339e-38, 1.4428e-30, 1.7556e-37, 1.9627e-36,\n",
            "        5.6052e-45, 1.0000e+00, 2.8334e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 8.0088e-10, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.4128e-40, 0.0000e+00, 0.0000e+00, 3.7189e-33,\n",
            "        0.0000e+00, 2.9242e-21, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.2348e-24,\n",
            "        1.8421e-29, 8.8518e-33, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.6117e-12,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5007e-24, 2.9650e-33, 8.0645e-29,\n",
            "        0.0000e+00, 0.0000e+00, 1.1410e-19, 2.9277e-13, 0.0000e+00, 1.3452e-43,\n",
            "        3.1711e-42, 2.8659e-12, 7.0679e-36, 2.1622e-42, 7.5950e-43, 1.1210e-42,\n",
            "        0.0000e+00, 1.8677e-15, 0.0000e+00, 1.0963e-12, 0.0000e+00, 3.0785e-30,\n",
            "        0.0000e+00, 0.0000e+00, 5.6418e-28, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 3.1848e-25, 0.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [7]\n",
            "DEBUGGING: logits looks like: tensor([24726.9590, 24759.8887, 24760.2031, 24764.3984, 24760.4180, 24761.0215,\n",
            "        24756.0703, 24781.5762, 24776.0801, 24746.9180, 24716.0566, 24715.9121,\n",
            "        24752.5293, 24674.5371, 24776.3398, 24752.8125, 24754.3262, 24723.4238,\n",
            "        24754.5371, 24747.9609, 24758.6367, 24724.3477, 24748.0273, 24762.9082,\n",
            "        24747.3457, 24769.7559, 24742.0176, 24754.0996, 24738.3516, 24768.3164,\n",
            "        24765.0352, 24763.1250, 24721.9707, 24748.4883, 24746.1680, 24775.1406,\n",
            "        24748.9688, 24748.2598, 24734.9766, 24768.1367, 24762.8516, 24765.4043,\n",
            "        24715.9336, 24733.1641, 24770.6719, 24774.3613, 24719.5762, 24756.8965,\n",
            "        24757.6875, 24774.9316, 24761.3418, 24757.5918, 24757.3301, 24757.4277,\n",
            "        24742.5000, 24773.0977, 24734.0879, 24774.6914, 24741.0508, 24764.5879,\n",
            "        24740.7852, 24752.6270, 24765.8906, 24746.6875, 24752.5430, 24740.8906,\n",
            "        24721.7383, 24767.4746, 24745.7871], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 8.3563e-09, 6.7044e-06, 6.9276e-09, 6.4146e-01, 4.6776e-10,\n",
            "        2.7831e-08, 2.5143e-08, 3.2187e-02, 2.6105e-05, 5.0319e-05, 5.3985e-05,\n",
            "        5.1189e-08, 9.4206e-04, 5.2026e-04, 1.7637e-02, 9.3473e-04, 2.7515e-06,\n",
            "        6.4475e-06, 3.1870e-03, 6.9819e-09, 5.5464e-07, 3.3854e-04, 3.6870e-08,\n",
            "        2.8167e-06, 3.9248e-08, 3.3570e-08, 2.7301e-06, 6.6662e-05, 8.2962e-05,\n",
            "        3.6737e-06, 2.7416e-04, 4.8188e-07, 3.5055e-06, 3.2168e-06, 2.2763e-07,\n",
            "        5.7105e-08, 8.8260e-09, 3.5478e-04, 8.4751e-06, 6.6004e-06, 3.9555e-08,\n",
            "        1.2923e-05, 1.7526e-05, 9.1253e-08, 8.7626e-05, 1.1884e-04, 2.9061e-06,\n",
            "        2.9289e-06, 4.0034e-06, 1.8696e-04, 3.3070e-04, 1.8979e-08, 5.6780e-07,\n",
            "        1.5346e-05, 3.3590e-04, 2.7031e-07, 1.2977e-03, 4.7441e-07, 2.4575e-04,\n",
            "        2.0521e-08, 4.3810e-04, 3.0092e-08, 4.3942e-10, 7.6889e-04, 7.5970e-06,\n",
            "        6.5392e-03, 1.9481e-03, 1.6445e-13, 7.9616e-06, 6.6522e-06, 2.7805e-01,\n",
            "        2.7915e-14, 2.5957e-04, 6.4108e-05, 2.4056e-03, 6.7570e-06, 8.6631e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [4]\n",
            "DEBUGGING: logits looks like: tensor([24732.8984, 24782.7402, 24784.4121, 24782.6934, 24787.2793, 24782.0195,\n",
            "        24783.0410, 24783.0156, 24786.5312, 24784.7520, 24784.9160, 24784.9336,\n",
            "        24783.1934, 24785.6484, 24785.5000, 24786.3809, 24785.6465, 24784.1895,\n",
            "        24784.4023, 24785.9531, 24782.6953, 24783.7891, 24785.3926, 24783.1113,\n",
            "        24784.1953, 24783.1270, 24783.0879, 24784.1875, 24784.9863, 24785.0410,\n",
            "        24784.2617, 24785.3398, 24783.7539, 24784.2500, 24784.2285, 24783.5664,\n",
            "        24783.2207, 24782.7539, 24785.4043, 24784.4707, 24784.4082, 24783.1289,\n",
            "        24784.5762, 24784.6523, 24783.3379, 24785.0547, 24785.1309, 24784.2031,\n",
            "        24784.2051, 24784.2832, 24785.2441, 24785.3867, 24782.9453, 24783.7949,\n",
            "        24784.6191, 24785.3906, 24783.6094, 24785.7285, 24783.7500, 24785.3125,\n",
            "        24782.9648, 24785.4570, 24783.0605, 24782.0039, 24785.5977, 24784.4434,\n",
            "        24786.1328, 24785.8301, 24780.0312, 24784.4551, 24784.4102, 24787.0703,\n",
            "        24779.5879, 24785.3262, 24784.9766, 24785.8828, 24784.4141, 24786.2031],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.0263e-02, 2.5401e-02, 1.8877e-02, 1.1630e-02, 7.7470e-03,\n",
            "        2.8723e-03, 2.9867e-03, 1.8877e-02, 3.1057e-03, 4.1231e-02, 2.1224e-02,\n",
            "        4.7728e-03, 1.9588e-03, 7.0686e-02, 3.3320e-03, 6.1765e-03, 1.8877e-02,\n",
            "        1.1360e-02, 4.2208e-02, 2.8440e-04, 1.5739e-03, 3.5266e-02, 6.4729e-03,\n",
            "        1.0104e-02, 1.6659e-02, 7.9307e-03, 3.7249e-02, 3.9568e-03, 8.5752e-03,\n",
            "        3.1794e-03, 1.7595e-02, 1.2380e-02, 6.1284e-03, 1.1184e-02, 5.4083e-03,\n",
            "        7.8525e-04, 7.9762e-04, 9.0572e-03, 4.2120e-03, 2.2242e-02, 3.4377e-03,\n",
            "        2.2023e-03, 1.5407e-02, 2.2545e-03, 6.9988e-03, 9.0382e-04, 1.0322e-03,\n",
            "        7.3923e-03, 1.6112e-03, 2.0732e-02, 6.3725e-03, 3.9568e-03, 7.8078e-03,\n",
            "        2.3812e-03, 1.0756e-02, 3.8954e-03, 4.3119e-03, 9.6965e-04, 2.5747e-03,\n",
            "        1.6021e-02, 1.3596e-02, 2.7040e-02, 1.1074e-03, 1.5977e-07, 6.9298e-04,\n",
            "        1.6273e-02, 6.9444e-03, 2.1300e-04, 7.5517e-04, 5.7003e-04, 5.5365e-03,\n",
            "        4.9913e-04, 3.1123e-02, 9.3644e-02, 2.3863e-02, 5.4507e-03, 3.0102e-03,\n",
            "        2.3080e-03, 4.3548e-02, 7.9307e-03, 5.3244e-03, 1.9025e-02, 1.3919e-02,\n",
            "        2.1513e-03, 3.8651e-03, 2.6358e-03, 2.4903e-04, 3.0816e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [38]\n",
            "DEBUGGING: logits looks like: tensor([24737.3203, 24789.7559, 24789.9824, 24789.9082, 24789.7871, 24789.6855,\n",
            "        24789.4375, 24789.4473, 24789.9082, 24789.4570, 24790.1035, 24789.9375,\n",
            "        24789.5645, 24789.3418, 24790.2383, 24789.4746, 24789.6289, 24789.9082,\n",
            "        24789.7812, 24790.1094, 24788.8594, 24789.2871, 24790.0645, 24789.6406,\n",
            "        24789.7520, 24789.8770, 24789.6914, 24790.0781, 24789.5176, 24789.7109,\n",
            "        24789.4629, 24789.8906, 24789.8027, 24789.6270, 24789.7773, 24789.5957,\n",
            "        24789.1133, 24789.1172, 24789.7246, 24789.5332, 24789.9492, 24789.4824,\n",
            "        24789.3711, 24789.8574, 24789.3770, 24789.6602, 24789.1484, 24789.1816,\n",
            "        24789.6738, 24789.2930, 24789.9316, 24789.6367, 24789.5176, 24789.6875,\n",
            "        24789.3906, 24789.7676, 24789.5137, 24789.5391, 24789.1660, 24789.4102,\n",
            "        24789.8672, 24789.8262, 24789.9980, 24789.1992, 24786.9883, 24789.0820,\n",
            "        24789.8711, 24789.6582, 24788.7871, 24789.1035, 24789.0332, 24789.6016,\n",
            "        24789.0000, 24790.0332, 24790.3086, 24789.9668, 24789.5977, 24789.4492,\n",
            "        24789.3828, 24790.1172, 24789.6914, 24789.5918, 24789.9102, 24789.8320,\n",
            "        24789.3652, 24789.5117, 24789.4160, 24788.8262, 24789.4551],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000, 0.0087, 0.0119, 0.0113, 0.0106, 0.0087, 0.0140, 0.0015, 0.0177,\n",
            "        0.0163, 0.0137, 0.0180, 0.0163, 0.0104, 0.0128, 0.0096, 0.0095, 0.0052,\n",
            "        0.0054, 0.0083, 0.0116, 0.0140, 0.0117, 0.0190, 0.0076, 0.0094, 0.0131,\n",
            "        0.0086, 0.0052, 0.0005, 0.0139, 0.0106, 0.0083, 0.0108, 0.0094, 0.0094,\n",
            "        0.0116, 0.0167, 0.0083, 0.0042, 0.0113, 0.0047, 0.0131, 0.0100, 0.0190,\n",
            "        0.0041, 0.0073, 0.0046, 0.0141, 0.0123, 0.0078, 0.0023, 0.0069, 0.0136,\n",
            "        0.0121, 0.0155, 0.0113, 0.0114, 0.0163, 0.0144, 0.0070, 0.0113, 0.0071,\n",
            "        0.0140, 0.0122, 0.0140, 0.0111, 0.0119, 0.0091, 0.0079, 0.0096, 0.0086,\n",
            "        0.0189, 0.0087, 0.0183, 0.0110, 0.0183, 0.0086, 0.0154, 0.0086, 0.0125,\n",
            "        0.0066, 0.0154, 0.0109, 0.0070, 0.0131, 0.0119, 0.0104, 0.0040, 0.0083,\n",
            "        0.0050, 0.0132, 0.0055, 0.0011, 0.0087, 0.0089],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [54]\n",
            "DEBUGGING: logits looks like: tensor([24740.7090, 24791.9590, 24792.0371, 24792.0234, 24792.0078, 24791.9590,\n",
            "        24792.0781, 24791.5195, 24792.1367, 24792.1152, 24792.0723, 24792.1406,\n",
            "        24792.1152, 24792.0020, 24792.0547, 24791.9824, 24791.9805, 24791.8301,\n",
            "        24791.8379, 24791.9453, 24792.0312, 24792.0781, 24792.0332, 24792.1543,\n",
            "        24791.9238, 24791.9766, 24792.0605, 24791.9570, 24791.8301, 24791.2559,\n",
            "        24792.0762, 24792.0078, 24791.9453, 24792.0117, 24791.9766, 24791.9766,\n",
            "        24792.0312, 24792.1211, 24791.9473, 24791.7773, 24792.0234, 24791.8027,\n",
            "        24792.0605, 24791.9922, 24792.1543, 24791.7734, 24791.9141, 24791.7988,\n",
            "        24792.0801, 24792.0449, 24791.9297, 24791.6270, 24791.9023, 24792.0703,\n",
            "        24792.0410, 24792.1035, 24792.0234, 24792.0254, 24792.1152, 24792.0840,\n",
            "        24791.9043, 24792.0234, 24791.9082, 24792.0781, 24792.0430, 24792.0781,\n",
            "        24792.0195, 24792.0371, 24791.9688, 24791.9336, 24791.9824, 24791.9570,\n",
            "        24792.1523, 24791.9590, 24792.1445, 24792.0176, 24792.1445, 24791.9551,\n",
            "        24792.1016, 24791.9551, 24792.0488, 24791.8887, 24792.1016, 24792.0156,\n",
            "        24791.9043, 24792.0605, 24792.0371, 24792.0020, 24791.7617, 24791.9473,\n",
            "        24791.8203, 24792.0625, 24791.8418, 24791.4453, 24791.9590, 24791.9648],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000, 0.0095, 0.0067, 0.0116, 0.0091, 0.0092, 0.0099, 0.0081, 0.0088,\n",
            "        0.0104, 0.0074, 0.0101, 0.0095, 0.0085, 0.0072, 0.0110, 0.0100, 0.0081,\n",
            "        0.0063, 0.0081, 0.0091, 0.0075, 0.0119, 0.0109, 0.0095, 0.0107, 0.0089,\n",
            "        0.0078, 0.0105, 0.0117, 0.0057, 0.0111, 0.0110, 0.0085, 0.0072, 0.0065,\n",
            "        0.0095, 0.0067, 0.0046, 0.0095, 0.0088, 0.0107, 0.0073, 0.0119, 0.0073,\n",
            "        0.0085, 0.0102, 0.0105, 0.0084, 0.0062, 0.0105, 0.0082, 0.0095, 0.0090,\n",
            "        0.0072, 0.0101, 0.0090, 0.0088, 0.0104, 0.0117, 0.0088, 0.0076, 0.0104,\n",
            "        0.0059, 0.0088, 0.0088, 0.0112, 0.0069, 0.0104, 0.0097, 0.0061, 0.0161,\n",
            "        0.0161, 0.0112, 0.0090, 0.0084, 0.0085, 0.0109, 0.0091, 0.0124, 0.0097,\n",
            "        0.0094, 0.0078, 0.0081, 0.0109, 0.0067, 0.0094, 0.0101, 0.0120, 0.0104,\n",
            "        0.0101, 0.0104, 0.0104, 0.0084, 0.0073, 0.0082, 0.0122, 0.0094, 0.0125,\n",
            "        0.0113, 0.0094, 0.0105, 0.0101, 0.0116, 0.0096, 0.0101, 0.0094, 0.0063],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [20]\n",
            "DEBUGGING: logits looks like: tensor([24743.4316, 24794.7246, 24794.6348, 24794.7734, 24794.7129, 24794.7148,\n",
            "        24794.7344, 24794.6836, 24794.7051, 24794.7461, 24794.6621, 24794.7383,\n",
            "        24794.7246, 24794.6953, 24794.6543, 24794.7598, 24794.7363, 24794.6836,\n",
            "        24794.6230, 24794.6836, 24794.7129, 24794.6660, 24794.7793, 24794.7578,\n",
            "        24794.7246, 24794.7539, 24794.7070, 24794.6758, 24794.7480, 24794.7754,\n",
            "        24794.5957, 24794.7617, 24794.7598, 24794.6953, 24794.6543, 24794.6289,\n",
            "        24794.7246, 24794.6367, 24794.5430, 24794.7227, 24794.7051, 24794.7539,\n",
            "        24794.6582, 24794.7793, 24794.6582, 24794.6953, 24794.7422, 24794.7480,\n",
            "        24794.6934, 24794.6152, 24794.7480, 24794.6875, 24794.7246, 24794.7109,\n",
            "        24794.6543, 24794.7383, 24794.7109, 24794.7051, 24794.7461, 24794.7754,\n",
            "        24794.7051, 24794.6680, 24794.7461, 24794.6055, 24794.7051, 24794.7051,\n",
            "        24794.7656, 24794.6445, 24794.7461, 24794.7285, 24794.6133, 24794.8555,\n",
            "        24794.8555, 24794.7656, 24794.7109, 24794.6934, 24794.6953, 24794.7578,\n",
            "        24794.7129, 24794.7910, 24794.7285, 24794.7207, 24794.6738, 24794.6836,\n",
            "        24794.7578, 24794.6367, 24794.7207, 24794.7402, 24794.7812, 24794.7461,\n",
            "        24794.7402, 24794.7461, 24794.7461, 24794.6934, 24794.6582, 24794.6875,\n",
            "        24794.7871, 24794.7207, 24794.7930, 24794.7676, 24794.7207, 24794.7480,\n",
            "        24794.7383, 24794.7734, 24794.7266, 24794.7383, 24794.7207, 24794.6230],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.3001056878313193 and immediate abs rewards look like: [0.1100722757364565, 0.14929593634997218, 0.0012034063638566295, 0.0002987925056459062, 2.121358875228907e-05, 0.00028725664196826983, 0.010993433698104127, 0.0005462698982228176, 0.001272452237571997, 0.006908467604489488, 0.009769924919282857, 0.0001419619934495131, 0.00022909584413355333, 0.0007394952071990701, 0.00043505392659426434, 0.0016476759874421987, 0.003444710028134068, 0.0002552299772560218, 7.778876511110866e-05, 0.00013657001909450628, 0.0005960221310488123, 3.0210631393856602e-05, 0.00012300265780140762, 4.9383663053959026e-05, 0.0003674521260563779, 1.6008206102924305e-05, 2.438200090182363e-05, 0.00035439058683550684, 5.518061470866087e-06, 1.583234029567393e-05, 0.00013085403452350874, 5.318834155332297e-07, 5.3864722985963454e-05, 4.5534163973570685e-05, 0.00014651740866611362, 6.884978347443393e-05, 1.0540581570239738e-05, 7.884856131568085e-05, 1.5924595118121943e-05, 2.7146825232193805e-07, 8.162975518644089e-06, 3.3055564472306287e-06, 1.990891087189084e-05, 7.115650191735767e-05, 9.209054724124144e-06, 5.2496334319585e-06, 1.9107841353616095e-05, 1.1606451380430372e-05, 2.400897733423335e-05, 2.3021027345748735e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 2.5337374951906213 and immediate relative rewards look like: [0.3051419852930756, 0.8538086521673165, 0.010783598958361664, 0.0035712150059946657, 0.0003169634837876518, 0.005150497310148532, 0.22998341512362058, 0.013103628975467713, 0.0343438889688088, 0.20725878864423208, 0.3230845489799944, 0.005136450061962186, 0.008980259532727691, 0.031219196817384068, 0.019682920311485413, 0.07952505336112647, 0.1767378943370736, 0.013879825787028736, 0.004465640893273422, 0.008252943868586392, 0.0378201396039327, 0.0020086402057628446, 0.008549997061981647, 0.0035820720831027802, 0.02776431952210271, 0.0012580865225499003, 0.001989892904591511, 0.02999438807725115, 0.00048376100124801117, 0.001435864365199811, 0.01226303412415544, 5.1455610226374586e-05, 0.005373840179096787, 0.004680472867660142, 0.015503747968335426, 0.00749382840061778, 0.0011791634321207322, 0.009059129317418988, 0.0018778134651932102, 3.283224441008098e-05, 0.001011938035935327, 0.00041977494120745045, 0.0025884455476653475, 0.009466576656683507, 0.0012530332664111652, 0.0007301684330210021, 0.002715478802780402, 0.0016845353740987457, 0.00355721985107403, 0.0034804774433299483]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 200 number of matrices\n",
            "DEBUGGING: ACT_MAT has 200 number of matrices\n",
            "DEBUGGING: VAL looks like: [[2.608596763991333, 1.4649948558634888e-09, 1.4614191533616341e-09, 1.4692908516144837e-09, 1.4749453581785398e-09, 1.4783602771781572e-09, 1.4795129865167305e-09, 1.4623037090451221e-09, 1.4587008232420886e-09, 1.4734351749920088e-09, 1.4883183585777866e-09, 1.478088135635385e-09, 1.4103369822988283e-09, 1.4245828104028568e-09, 1.3746648295744676e-09, 1.3885503329035025e-09, 1.3658288331642276e-09, 1.3405811195342292e-09, 1.354122342963868e-09, 1.3678003464281494e-09, 1.3816165115435852e-09, 1.3955722338824092e-09, 1.4096689231135447e-09, 1.3710838159208095e-09, 1.3298122563782285e-09, 1.285827108603455e-09, 1.2391009626143719e-09, 1.251617133953911e-09, 1.1999520250806123e-09, 1.2120727526066791e-09, 1.0865136841825342e-09, 1.0262907523183317e-09, 9.631628042186843e-10, 8.971004962852876e-10, 9.061621174598865e-10, 8.349306374290457e-10, 8.433642802313593e-10, 8.518831113448074e-10, 7.732132471478777e-10, 7.810234819675533e-10, 7.889126080480336e-10, 7.0271656678415e-10, 6.133531546444589e-10, 6.19548641055009e-10, 5.247517412727141e-10, 5.300522639118324e-10, 3.2410957828688023e-10, 2.1943833417028834e-10, 1.1141310096720904e-10, 0.0], [2.608596763991333, 1.4649948558634888e-09, 1.4614191533616341e-09, 1.4692908516144837e-09, 1.4749453581785398e-09, 1.4783602771781572e-09, 1.4795129865167305e-09, 1.4623037090451221e-09, 1.4587008232420886e-09, 1.4734351749920088e-09, 1.4883183585777866e-09, 1.478088135635385e-09, 1.4103369822988283e-09, 1.4245828104028568e-09, 1.3746648295744676e-09, 1.3885503329035025e-09, 1.3658288331642276e-09, 1.3405811195342292e-09, 1.354122342963868e-09, 1.3678003464281494e-09, 1.3816165115435852e-09, 1.3955722338824092e-09, 1.4096689231135447e-09, 1.3710838159208095e-09, 1.3298122563782285e-09, 1.285827108603455e-09, 1.2391009626143719e-09, 1.251617133953911e-09, 1.1999520250806123e-09, 1.2120727526066791e-09, 1.0865136841825342e-09, 1.0262907523183317e-09, 9.631628042186843e-10, 8.971004962852876e-10, 9.061621174598865e-10, 8.349306374290457e-10, 8.433642802313593e-10, 8.518831113448074e-10, 7.732132471478777e-10, 7.810234819675533e-10, 7.889126080480336e-10, 7.0271656678415e-10, 6.133531546444589e-10, 6.19548641055009e-10, 5.247517412727141e-10, 5.300522639118324e-10, 3.2410957828688023e-10, 2.1943833417028834e-10, 1.1141310096720904e-10, 0.0], [4.881341692141079, 4.924721077760426, 4.961114381288172, 4.915298485395768, 4.037922893038976, 3.9385376424092247, 3.726156040239285, 3.6692958736406163, 3.704638553625634, 3.7389384483134247, 3.774437505735981, 3.8064765143466563, 3.8360048442660983, 2.9877233406169528, 2.627124484859879, 2.651756174310068, 2.305056722613226, 2.149773683306666, 1.4632218459598358, 1.441203477130194, 1.4300005798633189, 1.394858349690031, 1.4084252016023104, 1.4085766156338833, 1.389840832207667, 1.403577260689502, 1.4149123469580887, 1.3269836625633467, 1.336858138894593, 0.8400375952585053, 0.8385153513045606, 0.8281082362898926, 0.8354591660138525, 0.839292979293683, 0.8395801305506565, 0.8463803182414364, 0.8447158251695213, 0.8054608973751783, 0.7986074943960136, 0.7748972060810655, 0.38031834329102165, 0.34270237709851553, 0.10904098680215867, 0.10161742352715872, 0.08769487582501803, 0.0398357459531951, 0.029835873102799997, 0.022269029202308145, 0.013951252949876414, 0.00047863004864943275], [2.3588419573513324, 2.0744444162204614, 1.2329654182355, 1.2345270901789278, 1.2433897729019527, 1.255629100422389, 1.2631097001133742, 1.043561904030054, 1.0408669444995822, 1.0166899550815893, 0.8176072388256135, 0.4995178685309284, 0.49937517017067296, 0.4953483945837831, 0.46881737148121116, 0.4536711627977028, 0.37792536306724883, 0.2032196653840154, 0.19125236322927947, 0.1886734569050566, 0.18224294246108103, 0.14588161904762456, 0.14532624125440577, 0.13815782241659003, 0.1359351013469568, 0.1092634159847011, 0.10909629238601132, 0.10818828230446445, 0.0789837315426397, 0.07929289953675928, 0.07864346987026209, 0.06705094519808752, 0.06767625210895065, 0.0629317292220746, 0.058839652883246926, 0.04377364132819344, 0.03664627568441985, 0.035825365911413255, 0.02703660262019623, 0.02541291833838689, 0.025636450599976573, 0.024873245014183077, 0.024700474821187503, 0.022335383104567834, 0.012998794391802349, 0.011864405177162812, 0.011246703781961423, 0.008617398968869719, 0.0070028925199706795, 0.0034804774433299483]]\n",
            "DEBUGGING: traj_returns = [2.608596763991333, 2.608596763991333, 4.881341692141079, 2.3588419573513324]\n",
            "DEBUGGING: actions = [[0], [5], [17], [62], [18], [0], [11], [11], [17], [57], [1], [69], [66], [0], [44], [19], [22], [3], [10], [46], [12], [66], [22], [17], [57], [17], [11], [7], [85], [60], [52], [27], [15], [66], [15], [1], [88], [14], [80], [1], [86], [4], [51], [16], [50], [102], [72], [4], [104], [81], [0], [5], [17], [17], [18], [0], [11], [11], [17], [57], [1], [69], [66], [0], [44], [19], [22], [3], [10], [46], [12], [66], [22], [17], [57], [82], [11], [7], [85], [60], [52], [27], [15], [66], [15], [1], [88], [14], [80], [1], [86], [4], [51], [16], [50], [102], [72], [4], [104], [82], [6], [15], [23], [63], [26], [7], [31], [2], [2], [21], [69], [69], [21], [52], [12], [49], [6], [4], [60], [45], [71], [5], [78], [74], [3], [31], [77], [3], [79], [57], [74], [3], [57], [30], [49], [80], [35], [7], [66], [13], [47], [66], [78], [4], [90], [40], [38], [101], [27], [59], [17], [14], [13], [26], [52], [27], [3], [41], [22], [7], [60], [68], [2], [20], [2], [62], [19], [22], [71], [4], [74], [36], [73], [2], [5], [36], [54], [60], [8], [38], [13], [16], [26], [50], [40], [29], [62], [59], [26], [54], [98], [56], [15], [93], [68], [84], [13], [28], [67], [20]]\n",
            "DEBUGGING: actions length = 200\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[-31.6480,  55.7456, -59.2850,  ...,  47.3685,  61.0620, -29.9901],\n",
            "        [-31.5187,  55.5240, -59.0512,  ...,  47.1851,  60.8241, -29.8683],\n",
            "        [-31.6343,  55.7198, -59.2707,  ...,  47.3543,  61.0432, -29.9720],\n",
            "        ...,\n",
            "        [-31.2212,  54.9926, -58.4905,  ...,  46.7323,  60.2431, -29.5848],\n",
            "        [-31.2209,  54.9921, -58.4901,  ...,  46.7319,  60.2426, -29.5846],\n",
            "        [-31.2210,  54.9923, -58.4902,  ...,  46.7320,  60.2427, -29.5846]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[-31.1560,  54.8790, -58.3685,  ...,  46.6357,  60.1185, -29.5239],\n",
            "        [-31.2210,  54.9923, -58.4902,  ...,  46.7321,  60.2428, -29.5846],\n",
            "        [-31.2209,  54.9921, -58.4900,  ...,  46.7319,  60.2426, -29.5845],\n",
            "        ...,\n",
            "        [-31.2211,  54.9923, -58.4903,  ...,  46.7321,  60.2428, -29.5847],\n",
            "        [-31.2210,  54.9923, -58.4902,  ...,  46.7321,  60.2428, -29.5846],\n",
            "        [-31.2209,  54.9921, -58.4900,  ...,  46.7319,  60.2425, -29.5845]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([24743.4316, 24794.7246, 24794.6348, 24794.7734, 24794.7129, 24794.7148,\n",
            "        24794.7344, 24794.6836, 24794.7051, 24794.7461, 24794.6621, 24794.7383,\n",
            "        24794.7246, 24794.6953, 24794.6543, 24794.7598, 24794.7363, 24794.6836,\n",
            "        24794.6230, 24794.6836, 24794.7129, 24794.6660, 24794.7793, 24794.7578,\n",
            "        24794.7246, 24794.7539, 24794.7070, 24794.6758, 24794.7480, 24794.7754,\n",
            "        24794.5957, 24794.7617, 24794.7598, 24794.6953, 24794.6543, 24794.6289,\n",
            "        24794.7246, 24794.6367, 24794.5430, 24794.7227, 24794.7051, 24794.7539,\n",
            "        24794.6582, 24794.7793, 24794.6582, 24794.6953, 24794.7422, 24794.7480,\n",
            "        24794.6934, 24794.6152, 24794.7480, 24794.6875, 24794.7246, 24794.7109,\n",
            "        24794.6543, 24794.7383, 24794.7109, 24794.7051, 24794.7461, 24794.7754,\n",
            "        24794.7051, 24794.6680, 24794.7461, 24794.6055, 24794.7051, 24794.7051,\n",
            "        24794.7656, 24794.6445, 24794.7461, 24794.7285, 24794.6133, 24794.8555,\n",
            "        24794.8555, 24794.7656, 24794.7109, 24794.6934, 24794.6953, 24794.7578,\n",
            "        24794.7129, 24794.7910, 24794.7285, 24794.7207, 24794.6738, 24794.6836,\n",
            "        24794.7578, 24794.6367, 24794.7207, 24794.7402, 24794.7812, 24794.7461,\n",
            "        24794.7402, 24794.7461, 24794.7461, 24794.6934, 24794.6582, 24794.6875,\n",
            "        24794.7871, 24794.7207, 24794.7930, 24794.7676, 24794.7207, 24794.7480,\n",
            "        24794.7383, 24794.7734, 24794.7266, 24794.7383, 24794.7207, 24794.6230],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[3.11434429e+00 1.74979137e+00 1.54851995e+00 1.53745639e+00\n",
            "  1.32032817e+00 1.29854169e+00 1.24731644e+00 1.17821445e+00\n",
            "  1.18637638e+00 1.18890710e+00 1.14801119e+00 1.07649860e+00\n",
            "  1.08384500e+00 8.70767935e-01 7.73985465e-01 7.76356835e-01\n",
            "  6.70745522e-01 5.88248338e-01 4.13618553e-01 4.07469234e-01\n",
            "  4.03060881e-01 3.85184993e-01 3.88437861e-01 3.86683610e-01\n",
            "  3.81443984e-01 3.78210170e-01 3.81002160e-01 3.58792987e-01\n",
            "  3.53960468e-01 2.29832624e-01 2.29289706e-01 2.23789796e-01\n",
            "  2.25783855e-01 2.25556178e-01 2.24604946e-01 2.22538490e-01\n",
            "  2.20340526e-01 2.10321566e-01 2.06411025e-01 2.00077531e-01\n",
            "  1.01488699e-01 9.18939059e-02 3.34353657e-02 3.09882020e-02\n",
            "  2.51734178e-02 1.29250380e-02 1.02706444e-02 7.72160715e-03\n",
            "  5.23853642e-03 9.89776873e-04]]\n",
            "DEBUGGING: baseline2 looks like: 3.114344294368769\n",
            "DEBUGGING: ADS looks like: [-10.19962117 -12.74751107 -12.71128652 -12.38649014 -12.19056471\n",
            " -12.13746854 -12.10237317 -11.69929556 -11.54023381 -11.17890004\n",
            " -11.20730959 -10.58649815 -10.28890265  -9.73064356  -9.49705278\n",
            "  -9.42000617  -8.88080939  -8.91398579  -8.69068815  -8.38788976\n",
            "  -7.82745984  -7.51963734  -7.53413123  -7.51671245  -7.55426932\n",
            "  -7.57974988  -6.52288287  -6.53473328  -6.17559366  -6.00751855\n",
            "  -5.84827139  -5.83928772  -5.86483274  -5.29333611  -4.69275863\n",
            "  -4.70609171  -4.0551998   -4.06559286  -4.09006707  -3.8892151\n",
            "  -3.90023967  -3.18397954  -3.18566273  -3.19275183  -1.99740048\n",
            "  -1.98867596  -1.56151457  -1.56274694  -0.90844957  -0.89452969\n",
            " -10.19962117 -12.74751107 -12.71128652 -12.38649014 -12.19056471\n",
            " -12.13746854 -12.10237317 -11.69929556 -11.54023381 -11.17890004\n",
            " -11.20730959 -10.58649815 -10.28890265  -9.73064356  -9.49705278\n",
            "  -9.42000617  -8.88080939  -8.91398579  -8.69068815  -8.38788976\n",
            "  -7.82745984  -7.51963734  -7.53413123  -7.51671245  -7.55426932\n",
            "  -7.57974988  -6.52288287  -6.53473328  -6.17559366  -6.00751855\n",
            "  -5.84827139  -5.83928772  -5.86483274  -5.29333611  -4.69275863\n",
            "  -4.70609171  -4.0551998   -4.06559286  -4.09006707  -3.8892151\n",
            "  -3.90023967  -3.18397954  -3.18566273  -3.19275183  -1.99740048\n",
            "  -1.98867596  -1.56151457  -1.56274694  -0.90844957  -0.89452969\n",
            "  -7.92687624  -7.82278999  -7.75017214  -7.47119165  -8.15264182\n",
            "  -8.1989309   -8.37621713  -8.02999969  -7.83559526  -7.43996159\n",
            "  -7.43287209  -6.78002164  -6.45289781  -6.74292022  -6.8699283\n",
            "  -6.76825     -6.57575267  -6.76421211  -7.2274663   -6.94668628\n",
            "  -6.39745926  -6.12477899  -6.12570603  -6.10813583  -6.16442849\n",
            "  -6.17617262  -5.10797052  -5.20774962  -4.83873552  -5.16748096\n",
            "  -5.00975604  -5.01117948  -5.02937358  -4.45404313  -3.8531785\n",
            "  -3.8597114   -3.21048398  -3.26013196  -3.29145958  -3.1143179\n",
            "  -3.51992133  -2.84127717  -3.07662175  -3.09113441  -1.9097056\n",
            "  -1.94884022  -1.53167869  -1.54047791  -0.89449831  -0.89405106\n",
            " -10.44937597 -10.67306665 -11.47832111 -11.15196305 -10.94717494\n",
            " -10.88183944 -10.83926347 -10.65573366 -10.49936687 -10.16221009\n",
            " -10.38970236 -10.08698028  -9.78952749  -9.23529517  -9.02823541\n",
            "  -8.96633501  -8.50288403  -8.71076613  -8.49943578  -8.1992163\n",
            "  -7.64521689  -7.37375572  -7.38880499  -7.37855463  -7.41833422\n",
            "  -7.47048647  -6.41378658  -6.426545    -6.09660993  -5.92822565\n",
            "  -5.76962792  -5.77223677  -5.79715649  -5.23040438  -4.63391898\n",
            "  -4.66231807  -4.01855353  -4.02976749  -4.06303047  -3.86380218\n",
            "  -3.87460322  -3.1591063   -3.16096226  -3.17041645  -1.98440168\n",
            "  -1.97681156  -1.55026786  -1.55412954  -0.90144668  -0.89104921]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(-3.6560, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.0439,  0.1391, -0.1114,  ..., -0.1840, -0.1237, -0.0226],\n",
            "        [ 0.0516,  0.1634, -0.1309,  ..., -0.2163, -0.1454, -0.0264],\n",
            "        [ 0.0612,  0.1939, -0.1553,  ..., -0.2566, -0.1725, -0.0305],\n",
            "        ...,\n",
            "        [ 0.0873,  0.2764, -0.2214,  ..., -0.3658, -0.2459, -0.0450],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0162,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0114,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0194,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0307,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0226,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0359,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0277,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0196,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0326,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0141,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0102,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0166,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0244,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0167,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0287,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0346,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0248,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0411,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0196,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0123,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0227,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0229,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0162,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0267,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0294,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0201,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0348,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0170,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0126,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0203,  0.0000,  0.0000,  0.0000]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.2687,  0.0290,  0.0617,  ..., -0.0955, -0.0987,  0.0743],\n",
            "        [ 0.3121,  0.0337,  0.0716,  ..., -0.1109, -0.1147,  0.0864],\n",
            "        [ 0.3832,  0.0413,  0.0880,  ..., -0.1362, -0.1408,  0.1052],\n",
            "        ...,\n",
            "        [ 0.5426,  0.0585,  0.1246,  ..., -0.1929, -0.1994,  0.1497],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0467,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0484,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0597,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0832,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0872,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1070,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0851,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0882,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1091,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0417,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0434,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0535,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0800,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0841,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1029,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1047,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1086,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1345,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0644,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0669,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0829,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0703,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0732,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0898,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0898,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0944,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1158,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0455,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0477,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0585,  0.0000,  0.0000,  0.0000]])\n",
            "DEBUGGING: training for one iteration takes 0.006007 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 47\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4959e-02, 0.0000e+00, 4.9478e-09,\n",
            "        1.4007e-37, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6774e-33,\n",
            "        5.7516e-08, 1.7616e-32, 4.8962e-40, 5.8283e-24, 0.0000e+00, 4.5898e-41,\n",
            "        0.0000e+00, 0.0000e+00, 9.4005e-01, 8.0457e-23, 2.0669e-34, 0.0000e+00,\n",
            "        9.6758e-17, 0.0000e+00, 0.0000e+00, 6.9005e-18, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 2.6413e-40, 0.0000e+00, 0.0000e+00, 2.9983e-02,\n",
            "        3.6714e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.8026e-45, 0.0000e+00, 1.4013e-45,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.6122e-42, 1.9622e-29, 4.0664e-28,\n",
            "        0.0000e+00, 1.0189e-10, 0.0000e+00, 1.1999e-40, 4.4380e-31, 3.9047e-25,\n",
            "        2.1326e-34, 0.0000e+00, 0.0000e+00, 2.7655e-33, 0.0000e+00, 0.0000e+00,\n",
            "        5.6168e-23, 2.1293e-05, 2.1293e-05, 1.4959e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [20]\n",
            "DEBUGGING: logits looks like: tensor([26000.2070, 26036.6426, 26017.2070, 26068.1055, 26033.8770, 26064.3750,\n",
            "        26047.9414, 26036.3418, 26024.3066, 26041.1973, 25888.1133, 26050.2891,\n",
            "        26064.9883, 26050.8770, 26046.5273, 26055.7812, 26020.2676, 26045.9355,\n",
            "        26034.1133, 26031.9766, 26069.1406, 26056.4375, 26049.7656, 26027.2246,\n",
            "        26059.9375, 26036.6934, 26027.3379, 26059.2773, 26031.8906, 26017.7207,\n",
            "        26037.6680, 26040.5410, 26046.3730, 26037.4785, 26033.1055, 26068.2793,\n",
            "        26066.0273, 26032.9062, 26040.4668, 25973.0020, 26042.6934, 26038.0605,\n",
            "        26034.1680, 26018.3262, 26042.6191, 26043.4590, 26036.6133, 26043.3828,\n",
            "        26033.1738, 26015.4336, 26037.7617, 26045.4102, 26052.6309, 26053.3887,\n",
            "        26036.6855, 26063.4043, 26041.4238, 26046.1758, 26051.6836, 26055.1055,\n",
            "        26049.7734, 26033.5039, 25956.4141, 26050.4141, 26034.1152, 26027.6777,\n",
            "        26056.3477, 26066.4668, 26066.4668, 26068.1055],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 2.2333e-11, 3.6921e-06, 1.2326e-15, 7.4314e-04, 3.7537e-13,\n",
            "        5.5110e-05, 1.8487e-08, 1.9154e-06, 2.2523e-33, 8.1644e-15, 6.5366e-13,\n",
            "        6.9707e-01, 2.1974e-15, 1.0290e-08, 2.5868e-08, 7.6466e-09, 7.6974e-17,\n",
            "        1.1562e-12, 2.3307e-13, 1.3308e-12, 2.0323e-15, 3.7695e-11, 8.2556e-06,\n",
            "        8.5101e-25, 2.5993e-28, 1.1918e-05, 1.2345e-18, 1.4035e-09, 1.9456e-06,\n",
            "        2.5721e-07, 4.8810e-07, 9.3100e-12, 1.4277e-12, 2.7290e-16, 3.5209e-10,\n",
            "        5.5559e-16, 7.8327e-05, 3.8810e-12, 7.7788e-12, 6.4258e-36, 1.6562e-12,\n",
            "        4.3295e-12, 7.5101e-25, 2.8815e-05, 4.8271e-16, 2.3975e-07, 8.2333e-11,\n",
            "        1.4489e-05, 4.6324e-17, 1.7972e-14, 1.5299e-20, 3.7774e-10, 7.4249e-23,\n",
            "        1.2600e-12, 3.3587e-25, 1.8824e-18, 1.9183e-09, 4.2039e-45, 4.1686e-04,\n",
            "        1.4136e-13, 2.6602e-17, 1.8421e-06, 5.1152e-07, 4.9862e-08, 3.3146e-09,\n",
            "        6.4334e-28, 1.2012e-05, 1.8487e-08, 1.1486e-04, 3.8973e-10, 9.9522e-10,\n",
            "        2.3272e-10, 1.2596e-01, 3.9255e-14, 8.3203e-06, 1.9305e-06, 9.9014e-05,\n",
            "        1.1092e-02, 1.6428e-01], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [79]\n",
            "DEBUGGING: logits looks like: tensor([25999.4453, 26075.8066, 26078.8105, 26073.3555, 26080.1367, 26074.7852,\n",
            "        26079.4863, 26077.4863, 26078.6465, 26063.1445, 26073.8281, 26074.9238,\n",
            "        26081.8477, 26073.5000, 26077.3398, 26077.5703, 26077.2656, 26072.6621,\n",
            "        26075.0664, 26074.6660, 26075.1016, 26073.4805, 26075.9375, 26079.0117,\n",
            "        26068.0820, 26066.0586, 26079.1035, 26071.6289, 26076.8418, 26078.6504,\n",
            "        26078.1445, 26078.3047, 26075.5879, 26075.1191, 26072.9785, 26076.4961,\n",
            "        26073.1562, 26079.5742, 26075.3691, 26075.5430, 26061.6797, 26075.1562,\n",
            "        26075.3965, 26068.0508, 26079.3242, 26073.1211, 26078.1270, 26076.1328,\n",
            "        26079.1523, 26072.5352, 26074.0254, 26070.5312, 26076.5137, 26069.1992,\n",
            "        26075.0879, 26067.8496, 26071.7344, 26076.9199, 26056.4023, 26079.9922,\n",
            "        26074.5410, 26072.3965, 26078.6367, 26078.3164, 26077.7344, 26077.0566,\n",
            "        26066.2852, 26079.1055, 26077.4863, 26079.6699, 26076.5215, 26076.7559,\n",
            "        26076.3926, 26081.4199, 26074.2207, 26079.0137, 26078.6484, 26079.6328,\n",
            "        26080.8125, 26081.4863], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.6031e-07, 1.7162e-08, 3.3430e-03, 1.2265e-08, 2.2003e-05,\n",
            "        7.3813e-09, 9.7086e-31, 6.8946e-08, 4.0788e-05, 1.0491e-08, 6.8451e-04,\n",
            "        1.7580e-04, 1.0519e-03, 5.8849e-09, 8.4044e-03, 4.3146e-08, 2.8534e-04,\n",
            "        3.0057e-09, 2.2003e-05, 0.0000e+00, 1.0350e-07, 3.6827e-09, 2.6597e-04,\n",
            "        9.7640e-06, 4.3983e-10, 4.4129e-01, 5.1561e-05, 5.9132e-03, 4.3484e-08,\n",
            "        1.4016e-04, 1.1481e-06, 2.2431e-07, 2.9547e-06, 3.1142e-07, 1.5537e-07,\n",
            "        8.3416e-14, 2.3907e-25, 4.0911e-11, 7.4392e-09, 2.1423e-14, 3.7564e-07,\n",
            "        8.5190e-30, 8.7156e-08, 4.9407e-03, 4.7215e-06, 5.1561e-05, 1.1134e-02,\n",
            "        1.5209e-06, 6.7006e-03, 2.5114e-09, 2.6005e-11, 2.1799e-02, 5.2043e-08,\n",
            "        1.1788e-12, 1.3330e-13, 8.9977e-04, 6.6865e-04, 2.1040e-04, 2.2750e-04,\n",
            "        2.2096e-03, 4.4010e-06, 1.5692e-06, 9.2194e-11, 1.6835e-06, 4.5053e-06,\n",
            "        4.9126e-02, 1.2051e-43, 5.5317e-05, 1.2689e-03, 1.7996e-04, 1.3167e-04,\n",
            "        6.4672e-05, 6.8657e-10, 2.4986e-04, 4.3785e-01, 1.5848e-05, 6.8946e-08,\n",
            "        1.2151e-05, 8.2866e-06, 1.4016e-04, 1.5155e-04, 3.0659e-07, 2.1911e-07,\n",
            "        1.7996e-04, 7.1392e-10, 5.7452e-13, 4.8612e-07, 1.7162e-08, 6.0681e-13],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [26]\n",
            "DEBUGGING: logits looks like: tensor([26005.5176, 26084.7949, 26084.2363, 26087.2812, 26084.1523, 26086.0254,\n",
            "        26084.0254, 26071.4297, 26084.5840, 26086.1797, 26084.1133, 26086.8848,\n",
            "        26086.5449, 26086.9922, 26083.9688, 26087.5117, 26084.4668, 26086.6660,\n",
            "        26083.8008, 26086.0254, 26061.8535, 26084.6855, 26083.8516, 26086.6484,\n",
            "        26085.8223, 26083.3203, 26088.5020, 26086.2383, 26087.4238, 26084.4688,\n",
            "        26086.4883, 26085.2871, 26084.8789, 26085.5234, 26084.9609, 26084.7871,\n",
            "        26081.1777, 26074.5332, 26082.7266, 26084.0273, 26080.8379, 26085.0078,\n",
            "        26071.9727, 26084.6426, 26087.3789, 26085.6406, 26086.2383, 26087.5820,\n",
            "        26085.3574, 26087.4551, 26083.7559, 26082.6133, 26087.7500, 26084.5137,\n",
            "        26081.8398, 26081.2949, 26086.9531, 26086.8789, 26086.5898, 26086.6094,\n",
            "        26087.1777, 26085.6230, 26085.3652, 26082.9297, 26085.3828, 26085.6289,\n",
            "        26087.9531, 26064.0000, 26086.2559, 26087.0391, 26086.5508, 26086.4727,\n",
            "        26086.2949, 26083.4316, 26086.6328, 26088.5000, 26085.9434, 26084.5840,\n",
            "        26085.8770, 26085.7812, 26086.4883, 26086.5078, 26084.9570, 26084.8730,\n",
            "        26086.5508, 26083.4414, 26081.6602, 26085.0723, 26084.2363, 26081.6738],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 3.1573e-02, 8.1894e-02, 2.4767e-06, 1.9604e-02, 1.4905e-06,\n",
            "        9.9708e-05, 3.3378e-09, 1.1258e-02, 1.0362e-08, 1.8853e-02, 3.3782e-07,\n",
            "        1.8131e-02, 1.3502e-01, 2.9412e-06, 7.1709e-02, 1.8433e-09, 7.1666e-06,\n",
            "        1.0804e-03, 6.1079e-04, 1.1500e-03, 3.6472e-04, 1.4652e-03, 1.9411e-03,\n",
            "        3.3802e-03, 6.1873e-09, 2.9830e-03, 2.3783e-03, 2.5862e-04, 1.4201e-03,\n",
            "        1.6890e-06, 4.0371e-04, 1.9358e-08, 1.0171e-02, 2.8852e-04, 7.0449e-03,\n",
            "        1.2757e-02, 4.5842e-03, 2.1995e-03, 4.7297e-03, 9.3330e-03, 4.3651e-04,\n",
            "        1.4798e-02, 1.8522e-03, 2.3414e-03, 2.0976e-07, 4.1006e-04, 6.9608e-05,\n",
            "        1.7990e-02, 1.7990e-02, 5.3902e-04, 8.6810e-04, 1.8667e-03, 6.5903e-05,\n",
            "        1.5564e-04, 2.8082e-02, 1.2242e-03, 6.9608e-05, 1.9871e-03, 3.0953e-04,\n",
            "        2.0027e-03, 4.5037e-04, 3.8004e-03, 2.5316e-03, 2.6764e-10, 3.2880e-05,\n",
            "        9.5085e-09, 6.7995e-05, 9.1168e-03, 2.6270e-04, 6.4881e-05, 1.7094e-04,\n",
            "        5.2875e-02, 2.1916e-01, 5.2875e-02, 3.3378e-09, 9.0268e-04, 2.6065e-04,\n",
            "        3.8742e-05, 2.6065e-04, 3.5275e-05, 4.6271e-06, 8.6135e-04, 1.2078e-02,\n",
            "        1.0911e-02, 1.0331e-02, 2.4106e-04, 5.2764e-03, 3.2254e-03, 6.1079e-04,\n",
            "        2.0226e-02, 8.6135e-04, 1.5204e-04, 5.7378e-04, 2.4976e-02, 1.3901e-02,\n",
            "        3.1018e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [74]\n",
            "DEBUGGING: logits looks like: tensor([26010.5586, 26094.3027, 26094.5410, 26091.9395, 26094.1836, 26091.8125,\n",
            "        26092.8633, 26090.2871, 26094.0449, 26090.5703, 26094.1738, 26091.4414,\n",
            "        26094.1641, 26094.6660, 26091.9824, 26094.5078, 26090.1387, 26092.2051,\n",
            "        26093.4590, 26093.3164, 26093.4746, 26093.1875, 26093.5352, 26093.6055,\n",
            "        26093.7441, 26090.4414, 26093.7129, 26093.6562, 26093.1016, 26093.5273,\n",
            "        26091.8438, 26093.2129, 26090.7266, 26094.0195, 26093.1289, 26093.9277,\n",
            "        26094.0762, 26093.8203, 26093.6367, 26093.8281, 26093.9980, 26093.2324,\n",
            "        26094.1133, 26093.5938, 26093.6523, 26091.3223, 26093.2168, 26092.7734,\n",
            "        26094.1621, 26094.1621, 26093.2852, 26093.4043, 26093.5957, 26092.7598,\n",
            "        26092.9746, 26094.2734, 26093.4902, 26092.7734, 26093.6113, 26093.1465,\n",
            "        26093.6133, 26093.2402, 26093.7734, 26093.6719, 26089.6562, 26092.5859,\n",
            "        26090.5488, 26092.7676, 26093.9922, 26093.1055, 26092.7559, 26092.9980,\n",
            "        26094.4316, 26094.7871, 26094.4316, 26090.2871, 26093.4141, 26093.1035,\n",
            "        26092.6270, 26093.1035, 26092.6035, 26092.0957, 26093.4023, 26094.0625,\n",
            "        26094.0371, 26094.0234, 26093.0840, 26093.8555, 26093.7324, 26093.3164,\n",
            "        26094.1914, 26093.4023, 26092.9688, 26093.3008, 26094.2441, 26094.0977,\n",
            "        26093.7227], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 8.8231e-05, 8.3235e-03, 2.4413e-03, 1.3793e-07, 5.7534e-04,\n",
            "        5.6608e-08, 7.1002e-08, 8.1332e-14, 5.5647e-05, 8.4140e-09, 6.6082e-05,\n",
            "        2.0725e-14, 1.7684e-04, 1.3657e-08, 2.3428e-04, 7.4298e-05, 1.4434e-04,\n",
            "        1.2027e-09, 7.8758e-07, 1.1027e-02, 4.1828e-07, 4.0081e-05, 4.7870e-06,\n",
            "        1.4416e-12, 3.5371e-05, 1.9341e-06, 2.2837e-05, 8.3711e-04, 4.0202e-11,\n",
            "        1.8853e-07, 6.6221e-04, 3.3479e-20, 7.2012e-05, 5.5965e-06, 2.9750e-13,\n",
            "        7.9543e-06, 1.0331e-07, 2.3477e-03, 2.0825e-08, 2.4939e-04, 1.0396e-04,\n",
            "        7.6380e-03, 2.5770e-07, 1.3531e-05, 4.5417e-05, 1.4019e-03, 1.4661e-04,\n",
            "        9.0704e-03, 3.5446e-04, 3.4697e-03, 1.7861e-03, 1.5420e-06, 3.2187e-09,\n",
            "        4.2334e-05, 7.4254e-09, 4.3338e-05, 1.6160e-06, 3.1328e-07, 8.0844e-02,\n",
            "        2.8260e-04, 7.7420e-04, 9.0841e-06, 3.3751e-05, 1.1966e-04, 1.9300e-07,\n",
            "        1.4129e-03, 3.8464e-06, 4.2975e-09, 1.4434e-04, 3.4355e-04, 5.5764e-04,\n",
            "        2.3379e-05, 6.6043e-09, 5.7776e-02, 5.3547e-01, 8.7729e-04, 8.1332e-14,\n",
            "        5.5647e-05, 3.2831e-07, 1.6648e-03, 1.4291e-05, 5.4899e-04, 1.2684e-06,\n",
            "        1.9883e-04, 5.7655e-03, 1.8001e-03, 1.6613e-04, 8.7492e-09, 5.7534e-04,\n",
            "        9.5601e-04, 1.1991e-03, 6.4551e-05, 2.4693e-05, 2.0806e-01, 7.3146e-05,\n",
            "        6.7264e-04, 2.3477e-03, 5.6523e-05, 5.4472e-04, 9.5544e-08, 1.0390e-08,\n",
            "        7.7258e-05, 1.0396e-04, 1.3273e-03, 3.5724e-04, 1.0500e-03, 4.1941e-02,\n",
            "        6.6600e-05], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [75]\n",
            "DEBUGGING: logits looks like: tensor([26014.8184, 26097.6523, 26098.7891, 26098.4824, 26096.0371, 26098.1211,\n",
            "        26095.8145, 26095.8711, 26092.4512, 26097.5371, 26095.3379, 26097.5801,\n",
            "        26092.1094, 26097.8262, 26095.4590, 26097.8965, 26097.6094, 26097.7754,\n",
            "        26094.8516, 26096.4727, 26098.8594, 26096.3145, 26097.4551, 26096.9238,\n",
            "        26093.1699, 26097.4238, 26096.6973, 26097.3145, 26098.2148, 26094.0020,\n",
            "        26096.1152, 26098.1562, 26088.7754, 26097.6016, 26096.9629, 26092.7754,\n",
            "        26097.0508, 26095.9648, 26098.4727, 26095.5645, 26097.9121, 26097.6934,\n",
            "        26098.7676, 26096.1934, 26097.1836, 26097.4863, 26098.3438, 26097.7793,\n",
            "        26098.8105, 26098.0000, 26098.5703, 26098.4043, 26096.6406, 26095.0977,\n",
            "        26097.4688, 26095.3066, 26097.4746, 26096.6523, 26096.2422, 26099.3574,\n",
            "        26097.9434, 26098.1953, 26097.0840, 26097.4121, 26097.7285, 26096.1211,\n",
            "        26098.3457, 26096.8691, 26095.1699, 26097.7754, 26097.9922, 26098.1133,\n",
            "        26097.3203, 26095.2773, 26099.2734, 26099.8301, 26098.2266, 26092.4512,\n",
            "        26097.5371, 26096.2539, 26098.3867, 26097.1973, 26098.1094, 26096.5918,\n",
            "        26097.8555, 26098.6973, 26098.4062, 26097.8105, 26095.3477, 26098.1211,\n",
            "        26098.2480, 26098.3047, 26097.5742, 26097.3340, 26099.5938, 26097.6055,\n",
            "        26098.1602, 26098.4727, 26097.5410, 26098.1074, 26095.9453, 26095.3906,\n",
            "        26097.6191, 26097.6934, 26098.3301, 26098.0020, 26098.2715, 26099.1934,\n",
            "        26097.5820], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.1505244760169262 and immediate abs rewards look like: [0.010754348344562459, 0.012717792419607576, 0.0065206662161472195, 0.029698524268951587, 0.0019199828384444118, 0.0011962372022935597, 0.0042497824883867, 0.008576207812438952, 0.010111354340097023, 0.007122450360839139, 0.010013290521783347, 0.024833489592765545, 0.0006717220530845225, 0.0014102867908150074, 0.016298175485644606, 9.798543032957241e-06, 1.0130883765668841e-05, 1.0480422588443616e-05, 1.084837140297168e-05, 1.1236041245865636e-05, 0.00014031656428414863, 0.000320506824664335, 1.1868185083585558e-05, 1.2104886991437525e-05, 1.2348742529866286e-05, 0.00012414018738127197, 0.0001097137655960978, 0.0010096892101500998, 1.444735153199872e-05, 5.480988875206094e-06, 4.8874152980715735e-05, 1.682872925812262e-05, 0.0001906060560941114, 9.279546702600783e-06, 9.933226010616636e-06, 0.00012847806146965013, 5.165394804862444e-05, 1.189792374134413e-05, 3.378490828254144e-05, 0.00015574907911286573, 0.000742673956665385, 7.018257838353748e-05, 2.415226845187135e-05, 7.172639607233577e-05, 0.00011058124709961703, 2.023068373091519e-05, 2.3046383375913138e-05, 0.00023724569655314554, 0.0005213837248447817, 0.00013874574506189674]\n",
            "DEBUGGING: the total relative reward of the trajectory = 3.577172804322992 and immediate relative rewards look like: [0.029001021819185686, 0.06879110038297566, 0.0530884576119323, 0.3229616529705132, 0.026311414330148514, 0.019682216088701875, 0.08160423000137006, 0.188425552086821, 0.2505131117645211, 0.19661587866456123, 0.3046585647062922, 0.8265466831717765, 0.024388386644631457, 0.05515273693002286, 0.6831765754823313, 0.0004401155591248093, 0.00048348464273992265, 0.0005295890106399761, 0.0005786381837716458, 0.0006308608631548998, 0.008272178025159999, 0.019795601630746507, 0.0007664078937017952, 0.0008156826990334703, 0.0008667891975317063, 0.009062290842106396, 0.008317489753415444, 0.07938281852630187, 0.001176766104255376, 0.00046183394433972716, 0.004255467528389532, 0.0015125634675692181, 0.017667088841420372, 0.0008862235529046508, 0.000976555887190643, 0.012991862895710193, 0.005368597831551717, 0.001270037970588726, 0.003701269687701157, 0.017500601659440403, 0.08553986368239393, 0.008282391018779001, 0.002918179938070452, 0.008867890432044789, 0.013982711020197365, 0.002615045636174178, 0.0030437851145729195, 0.03200042469753793, 0.07179573834067597, 0.019498375588270476]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 2.3697e-17, 0.0000e+00, 0.0000e+00, 8.8099e-13, 4.1603e-28,\n",
            "        5.1807e-24, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0380e-33,\n",
            "        5.5098e-17, 1.3856e-27, 1.0961e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0551e-34, 0.0000e+00,\n",
            "        7.8571e-34, 1.3221e-27, 0.0000e+00, 1.2989e-28, 2.7763e-16, 0.0000e+00,\n",
            "        4.4246e-21, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3773e-38,\n",
            "        0.0000e+00, 5.3067e-20, 3.5488e-07, 1.0994e-33, 0.0000e+00, 1.6809e-28,\n",
            "        4.4460e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        3.6494e-16, 0.0000e+00, 2.1963e-16, 8.8949e-01, 0.0000e+00, 0.0000e+00,\n",
            "        3.2772e-04, 0.0000e+00, 5.7516e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        5.6528e-42, 0.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [51]\n",
            "DEBUGGING: logits looks like: tensor([26181.2500, 26246.3633, 26127.9004, 26119.9922, 26248.9941, 26240.1719,\n",
            "        26242.5293, 26199.8223, 26159.2812, 26152.7324, 26099.5449, 26237.1152,\n",
            "        26246.5742, 26240.4727, 26255.3809, 26080.3438, 26174.3027, 26096.5469,\n",
            "        26166.5723, 26196.6230, 26079.3945, 26190.1992, 26236.3750, 26010.9824,\n",
            "        26236.8770, 26240.4609, 26192.2734, 26239.8809, 26246.9785, 26191.1387,\n",
            "        26244.2168, 26215.9570, 26228.2031, 26195.3809, 26214.9707, 26234.3633,\n",
            "        26148.6152, 26244.8379, 26252.2207, 26236.9609, 26216.9199, 26239.9453,\n",
            "        26232.7051, 26179.1777, 26169.0801, 26213.3398, 26108.7988, 26162.8262,\n",
            "        26247.0469, 26160.1016, 26246.9199, 26255.9043, 26224.2871, 26204.1016,\n",
            "        26253.9277, 26217.5586, 26254.0684, 26214.1484, 26207.0059, 26196.6230,\n",
            "        26232.1895, 26221.6152], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.4263e-06, 3.0653e-10, 3.0478e-09, 1.7148e-15, 3.4299e-16,\n",
            "        4.4842e-26, 1.6857e-12, 7.9390e-33, 5.1135e-23, 1.8908e-28, 5.1180e-04,\n",
            "        9.8416e-20, 2.5116e-23, 2.4973e-22, 6.0905e-03, 2.1036e-07, 1.2281e-14,\n",
            "        8.3753e-41, 1.0249e-22, 2.5890e-16, 9.1321e-11, 5.1165e-19, 1.0625e-16,\n",
            "        3.1192e-24, 5.3992e-12, 0.0000e+00, 2.6015e-10, 1.9211e-13, 0.0000e+00,\n",
            "        1.9321e-14, 3.8047e-41, 5.4253e-32, 2.8205e-05, 4.3896e-25, 5.2489e-18,\n",
            "        3.0296e-23, 9.9276e-01, 3.6129e-21, 1.8376e-23, 6.0943e-25, 5.3685e-11,\n",
            "        1.6300e-28, 3.9236e-44, 3.1475e-16, 4.3790e-15, 0.0000e+00, 1.1779e-19,\n",
            "        0.0000e+00, 2.1214e-29, 6.1757e-41, 2.6978e-15, 2.9665e-07, 7.4580e-33,\n",
            "        1.4148e-21, 0.0000e+00, 2.5774e-07, 9.5188e-21, 4.4067e-12, 1.6872e-19,\n",
            "        1.0451e-09, 4.2062e-23, 1.2576e-25, 2.6656e-17, 3.4247e-13, 2.2138e-05,\n",
            "        9.8182e-36, 4.2164e-33, 5.8449e-04, 2.4921e-23, 2.1986e-12, 5.4383e-16,\n",
            "        5.2980e-21, 1.3504e-06, 0.0000e+00, 0.0000e+00, 1.0966e-27, 1.5755e-07],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [37]\n",
            "DEBUGGING: logits looks like: tensor([26208.4922, 26275.8418, 26273.7305, 26274.3047, 26270.7070, 26270.3047,\n",
            "        26264.6152, 26272.4297, 26260.7285, 26266.3750, 26263.2480, 26277.3125,\n",
            "        26268.2656, 26266.1973, 26266.7715, 26277.9316, 26275.3633, 26271.1992,\n",
            "        26256.1367, 26266.5488, 26270.2344, 26273.4277, 26268.6777, 26270.0117,\n",
            "        26265.6758, 26272.7207, 26251.0684, 26273.6895, 26271.8867, 26249.9336,\n",
            "        26271.3125, 26255.9395, 26261.2090, 26276.5879, 26265.1855, 26269.2598,\n",
            "        26266.2441, 26279.2051, 26267.4395, 26266.1191, 26265.2676, 26273.2949,\n",
            "        26263.2109, 26254.2188, 26270.2832, 26270.9414, 26251.7285, 26268.3105,\n",
            "        26228.5703, 26262.7012, 26256.0605, 26270.8203, 26275.4492, 26260.7129,\n",
            "        26267.2051, 26233.1328, 26275.4141, 26267.6816, 26272.6699, 26268.4004,\n",
            "        26274.0371, 26266.3262, 26264.8730, 26269.6660, 26272.0312, 26276.5273,\n",
            "        26259.0547, 26260.5703, 26277.3457, 26266.1953, 26272.4961, 26270.4199,\n",
            "        26267.5352, 26275.8281, 26251.9629, 26250.6816, 26263.6875, 26275.2910],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 5.3792e-19, 6.1413e-08, 1.0083e-09, 8.4626e-19, 1.8612e-11,\n",
            "        8.2840e-18, 3.8628e-13, 2.2900e-09, 9.6183e-25, 4.0458e-17, 4.0886e-12,\n",
            "        2.1218e-23, 4.5872e-13, 1.8562e-16, 6.6985e-15, 9.9593e-01, 6.3554e-14,\n",
            "        3.0429e-15, 6.2138e-21, 1.3143e-13, 4.3864e-12, 1.0743e-16, 6.3154e-17,\n",
            "        9.6386e-24, 3.6661e-23, 6.7918e-27, 2.7424e-05, 1.2391e-15, 0.0000e+00,\n",
            "        2.7024e-12, 2.0838e-13, 4.7456e-08, 2.8219e-10, 2.8586e-15, 1.5763e-12,\n",
            "        4.4904e-12, 4.8074e-13, 1.3005e-18, 1.6789e-08, 2.3820e-20, 5.5968e-15,\n",
            "        1.9974e-22, 4.3445e-24, 4.0385e-03, 8.6243e-10, 1.9088e-25, 8.1091e-17,\n",
            "        0.0000e+00, 1.4079e-10, 3.8710e-12, 6.6704e-17, 8.3064e-13, 5.4425e-06,\n",
            "        8.9196e-20, 1.6507e-42, 6.1248e-13, 1.6815e-11, 8.8183e-18, 1.0450e-18,\n",
            "        4.9362e-19, 3.5801e-12, 7.3569e-15, 1.1031e-22, 4.1244e-19, 1.1949e-10,\n",
            "        1.9025e-34, 1.1381e-22, 9.2804e-16, 7.2364e-34, 1.1154e-13, 4.0204e-20,\n",
            "        3.6727e-11, 1.8854e-16, 4.2642e-18, 2.2056e-12, 2.4993e-12, 7.8999e-22,\n",
            "        3.9237e-13, 5.2498e-12, 1.9884e-13, 0.0000e+00, 6.9842e-10, 1.1090e-12,\n",
            "        2.1135e-10, 1.9324e-08, 5.6510e-29, 6.9842e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [16]\n",
            "DEBUGGING: logits looks like: tensor([26240.3652, 26287.2773, 26293.6426, 26292.6152, 26287.3906, 26291.6172,\n",
            "        26287.9609, 26290.6484, 26292.8203, 26283.9688, 26288.3574, 26291.2383,\n",
            "        26284.7422, 26290.6914, 26288.7383, 26289.6348, 26297.7930, 26290.1973,\n",
            "        26289.4375, 26286.1621, 26290.3789, 26291.2559, 26288.6016, 26288.4688,\n",
            "        26284.5449, 26284.8789, 26282.7305, 26295.1680, 26289.2129, 26269.4160,\n",
            "        26291.1348, 26290.4941, 26293.5781, 26292.2969, 26289.4219, 26291.0000,\n",
            "        26291.2617, 26290.7031, 26287.4980, 26293.3184, 26286.4980, 26289.5898,\n",
            "        26285.3027, 26284.3457, 26296.4160, 26292.5762, 26283.5645, 26288.5312,\n",
            "        26270.9297, 26292.1230, 26291.2246, 26288.4824, 26290.8398, 26294.7637,\n",
            "        26286.8281, 26273.7422, 26290.7637, 26291.5918, 26287.9766, 26287.4434,\n",
            "        26287.2559, 26291.2051, 26289.6582, 26285.1543, 26287.2109, 26292.0820,\n",
            "        26278.3828, 26285.1621, 26289.1406, 26278.7168, 26290.3379, 26286.6289,\n",
            "        26291.7871, 26288.7422, 26287.7949, 26291.0840, 26291.1152, 26285.6465,\n",
            "        26290.6523, 26291.3008, 26290.4824, 26242.5176, 26292.5234, 26290.9121,\n",
            "        26292.2246, 26293.3535, 26281.5332, 26292.5234],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.0738e-05, 6.3737e-20, 1.7710e-16, 3.8611e-02, 6.5228e-09,\n",
            "        1.3574e-05, 8.0886e-07, 3.0334e-09, 7.4337e-10, 1.7093e-18, 3.9055e-04,\n",
            "        2.8088e-01, 2.3788e-02, 4.1988e-03, 7.2376e-19, 3.3953e-26, 6.2148e-06,\n",
            "        3.2524e-13, 1.8305e-04, 8.2506e-05, 6.9289e-10, 4.0126e-06, 6.4255e-05,\n",
            "        3.4074e-02, 1.2300e-11, 1.6607e-02, 6.8936e-05, 2.1278e-03, 1.6398e-08,\n",
            "        2.3091e-05, 6.9769e-03, 5.4500e-09, 3.7480e-05, 1.6597e-06, 8.1692e-06,\n",
            "        8.4158e-03, 2.2380e-05, 5.5043e-08, 4.1699e-10, 3.8369e-05, 9.8954e-04,\n",
            "        6.4759e-05, 3.6744e-07, 4.1900e-04, 1.7294e-05, 4.1486e-05, 8.4462e-05,\n",
            "        1.0030e-04, 1.3554e-02, 3.0655e-04, 1.5354e-17, 2.3476e-12, 2.9944e-04,\n",
            "        6.2598e-10, 7.6788e-02, 1.8097e-02, 5.7477e-06, 1.7268e-02, 8.7302e-19,\n",
            "        1.7294e-05, 1.4056e-07, 1.6607e-02, 4.5047e-03, 2.0643e-10, 2.1465e-10,\n",
            "        5.4304e-07, 2.7878e-12, 4.8883e-05, 2.4528e-06, 8.1520e-07, 1.6096e-02,\n",
            "        5.5592e-07, 5.7621e-42, 1.4624e-03, 2.4825e-04, 2.6331e-02, 6.8936e-05,\n",
            "        5.2365e-02, 2.3603e-02, 8.0256e-07, 0.0000e+00, 1.7640e-03, 2.0463e-03,\n",
            "        8.1692e-06, 1.6028e-04, 1.6349e-02, 2.2333e-06, 8.2879e-14, 3.1790e-09,\n",
            "        2.9207e-01, 7.3647e-07, 1.4064e-03, 6.8072e-11, 5.4533e-05, 4.9163e-06,\n",
            "        1.0845e-04, 1.1583e-21], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [55]\n",
            "DEBUGGING: logits looks like: tensor([26256.6875, 26310.6797, 26302.4902, 26304.4727, 26312.7266, 26308.8281,\n",
            "        26310.7383, 26310.0332, 26308.6367, 26308.2852, 26303.3125, 26311.5781,\n",
            "        26313.2227, 26312.6055, 26312.1719, 26303.0977, 26298.8789, 26310.5430,\n",
            "        26306.3516, 26311.3887, 26311.1895, 26308.2676, 26310.4336, 26311.1270,\n",
            "        26312.6953, 26307.2598, 26312.5156, 26311.1445, 26312.0020, 26309.0586,\n",
            "        26310.8711, 26312.2988, 26308.7832, 26310.9922, 26310.2129, 26310.6113,\n",
            "        26312.3457, 26310.8633, 26309.3613, 26308.1406, 26310.9980, 26311.8105,\n",
            "        26311.1289, 26309.8359, 26311.5957, 26310.7988, 26311.0176, 26311.1953,\n",
            "        26311.2383, 26312.4648, 26311.5176, 26303.8613, 26306.8457, 26311.5117,\n",
            "        26308.2422, 26312.8984, 26312.5371, 26310.5234, 26312.5254, 26303.1445,\n",
            "        26310.7988, 26309.5957, 26312.5156, 26312.1895, 26307.9648, 26307.9746,\n",
            "        26309.9336, 26306.8887, 26311.0586, 26310.3105, 26310.0352, 26312.5078,\n",
            "        26309.9395, 26289.8008, 26311.9082, 26311.4648, 26312.6309, 26311.1445,\n",
            "        26312.8027, 26312.6035, 26310.0312, 26281.5020, 26311.9551, 26311.9922,\n",
            "        26310.6113, 26311.3555, 26312.5117, 26310.2871, 26306.0098, 26308.6484,\n",
            "        26313.2324, 26310.0098, 26311.8984, 26307.6875, 26311.0859, 26310.4844,\n",
            "        26311.2578, 26301.4883], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 4.0553e-02, 1.2961e-02, 2.0391e-02, 1.5881e-02, 5.9467e-02,\n",
            "        1.7038e-02, 2.7597e-03, 2.7439e-02, 1.3421e-04, 3.5159e-03, 3.6275e-03,\n",
            "        1.2465e-02, 3.7505e-02, 1.2465e-02, 2.2700e-03, 1.6479e-03, 4.0699e-04,\n",
            "        2.1492e-03, 2.8090e-02, 7.7396e-03, 6.5685e-03, 7.2141e-03, 2.5576e-02,\n",
            "        2.2002e-03, 8.2860e-04, 1.3138e-03, 3.9305e-02, 1.7038e-02, 1.6005e-02,\n",
            "        2.1877e-02, 7.3277e-03, 1.2734e-03, 1.3063e-02, 8.1111e-03, 7.8615e-03,\n",
            "        2.2002e-03, 1.5757e-02, 2.0075e-02, 8.3034e-03, 6.7243e-03, 7.5015e-03,\n",
            "        6.1226e-03, 2.4931e-03, 4.3078e-03, 3.6275e-03, 3.7135e-03, 9.6669e-05,\n",
            "        1.5448e-04, 2.1877e-02, 1.0334e-02, 1.3138e-03, 4.9582e-03, 1.2176e-02,\n",
            "        6.4667e-03, 6.8838e-03, 6.5685e-03, 2.6333e-03, 8.0770e-05, 4.2410e-03,\n",
            "        2.9902e-02, 9.7077e-03, 1.1173e-02, 1.3185e-05, 1.1000e-02, 5.3611e-03,\n",
            "        3.7135e-03, 7.9853e-03, 3.1516e-03, 1.3739e-04, 2.1661e-03, 3.6199e-04,\n",
            "        9.4090e-03, 1.2272e-02, 7.3852e-03, 4.3078e-03, 1.6131e-02, 6.9922e-03,\n",
            "        8.5670e-03, 2.6747e-03, 4.3415e-03, 2.8921e-03, 1.4919e-02, 1.2081e-02,\n",
            "        1.0723e-03, 5.4882e-03, 4.5499e-03, 4.8433e-03, 6.1226e-03, 1.7368e-04,\n",
            "        3.7135e-03, 1.0334e-02, 2.9438e-02, 3.8314e-03, 9.4828e-03, 1.2272e-02,\n",
            "        5.5746e-03, 6.2190e-03, 2.3605e-03, 1.0830e-02, 1.8383e-03, 2.5777e-02,\n",
            "        5.4882e-03, 1.1173e-02, 1.0094e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [82]\n",
            "DEBUGGING: logits looks like: tensor([26269.8398, 26324.3125, 26324.0273, 26324.1406, 26324.0781, 26324.4082,\n",
            "        26324.0957, 26323.6406, 26324.2148, 26322.8848, 26323.7012, 26323.7090,\n",
            "        26324.0176, 26324.2930, 26324.0176, 26323.5918, 26323.5117, 26323.1621,\n",
            "        26323.5781, 26324.2207, 26323.8984, 26323.8574, 26323.8809, 26324.1973,\n",
            "        26323.5840, 26323.3398, 26323.4551, 26324.3047, 26324.0957, 26324.0801,\n",
            "        26324.1582, 26323.8848, 26323.4473, 26324.0293, 26323.9102, 26323.9023,\n",
            "        26323.5840, 26324.0762, 26324.1367, 26323.9160, 26323.8633, 26323.8906,\n",
            "        26323.8398, 26323.6152, 26323.7520, 26323.7090, 26323.7148, 26322.8027,\n",
            "        26322.9199, 26324.1582, 26323.9707, 26323.4551, 26323.7871, 26324.0117,\n",
            "        26323.8535, 26323.8691, 26323.8574, 26323.6289, 26322.7578, 26323.7480,\n",
            "        26324.2363, 26323.9551, 26323.9902, 26322.3047, 26323.9863, 26323.8066,\n",
            "        26323.7148, 26323.9062, 26323.6738, 26322.8906, 26323.5801, 26323.1328,\n",
            "        26323.9473, 26324.0137, 26323.8867, 26323.7520, 26324.0820, 26323.8730,\n",
            "        26323.9238, 26323.6328, 26323.7539, 26323.6523, 26324.0625, 26324.0098,\n",
            "        26323.4043, 26323.8125, 26323.7656, 26323.7812, 26323.8398, 26322.9492,\n",
            "        26323.7148, 26323.9707, 26324.2324, 26323.7227, 26323.9492, 26324.0137,\n",
            "        26323.8164, 26323.8438, 26323.6016, 26323.9824, 26323.5391, 26324.1992,\n",
            "        26323.8125, 26323.9902, 26323.9648], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.0915907699309173 and immediate abs rewards look like: [0.017294578184191778, 0.012272575242604944, 0.0024996665515573113, 0.0011182527596247382, 0.0012108692526453524, 0.0051692562142307, 0.0004399879649099603, 0.00039128852858993923, 0.00717427568815765, 0.0020203175113238103, 0.0004812379011127632, 0.00099843107182096, 0.0008665209397804574, 0.0001279271718885866, 0.00016299257094942732, 3.7427234474307625e-05, 0.0006087523502174008, 0.010717636594563373, 0.0059321042813280656, 0.005520548954336846, 0.0023635219640709693, 0.0018660357663975446, 0.0011920596934942296, 2.8631414352275897e-05, 8.521568361175014e-06, 0.0009772117014108517, 0.0033484581895208976, 0.0003220767798666202, 0.0002967315076602972, 0.0011244256897953164, 0.0008457713624920871, 5.18820520483132e-05, 0.0006086564712859399, 2.729849802562967e-05, 0.00047749799114171765, 9.876437934508431e-05, 4.4210031319380505e-05, 0.0012070539150954573, 4.163137100476888e-05, 3.253591557950131e-05, 1.5576444639009424e-05, 5.2778089411731344e-05, 0.00012692936707026092, 0.0003020444642061193, 0.0005256324911897536, 3.959007699450012e-05, 0.00012963320750714047, 0.000231540817367204, 3.537834345479496e-07, 0.00015906795852060895]\n",
            "DEBUGGING: the total relative reward of the trajectory = 3.968604428153384 and immediate relative rewards look like: [0.05991038410894446, 0.08553966188243509, 0.026246211095055864, 0.015669075491463853, 0.021216845646546138, 0.10873696231507382, 0.010817440203599685, 0.0109961305568608, 0.2268470072994042, 0.07115872242976956, 0.018658218370975307, 0.04223676701079044, 0.03972524964120065, 0.006317827833886248, 0.008624930821197295, 0.0021126582224149327, 0.03651042012953594, 0.6807569325572448, 0.3992349251183, 0.39191503542367545, 0.17652672695159963, 0.14613000495874662, 0.097658749815132, 0.002448633610894323, 0.0007591607298330572, 0.09053938061230436, 0.32228153027063383, 0.032185696975191636, 0.03071546234662475, 0.12041855484123844, 0.09363332057772733, 0.00593081086163068, 0.07175318506180281, 0.003316401557024196, 0.059716352097411635, 0.012706636943905105, 0.005846092161531168, 0.16393067932531805, 0.005805273522159221, 0.004653362171622447, 0.0022835003164161745, 0.007926003454089775, 0.019515966691057964, 0.04752288157843507, 0.08459035257144067, 0.006514062819548015, 0.021793553016262235, 0.03975601559750947, 6.201597823504803e-05, 0.02845265457968408]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 6.0570e-27, 0.0000e+00, 0.0000e+00, 9.0653e-21, 8.4220e-30,\n",
            "        1.1412e-22, 1.4096e-33, 4.8787e-37, 0.0000e+00, 0.0000e+00, 2.0620e-23,\n",
            "        3.6059e-21, 1.3711e-09, 2.5686e-30, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        3.3966e-16, 0.0000e+00, 7.6821e-18, 4.0555e-32, 1.0611e-38, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.9592e-36, 2.2633e-01, 3.9437e-23, 6.4574e-30,\n",
            "        3.6870e-29, 1.4414e-41, 1.5532e-24, 1.4013e-45, 0.0000e+00, 8.0411e-26,\n",
            "        4.2886e-24, 4.3483e-36, 6.6145e-26, 5.7588e-25, 1.8362e-15, 5.0486e-17,\n",
            "        4.2039e-45, 8.9035e-37, 0.0000e+00, 1.6190e-34, 5.6052e-45, 5.4719e-01,\n",
            "        2.4895e-30, 1.9122e-18, 8.0945e-34, 5.6525e-19, 5.2560e-09, 3.1310e-25,\n",
            "        0.0000e+00, 1.7301e-21, 1.0545e-41, 0.0000e+00, 7.4010e-06, 3.4668e-36,\n",
            "        4.7200e-23, 1.3422e-08, 0.0000e+00, 7.1884e-05, 0.0000e+00, 3.2862e-28,\n",
            "        7.1884e-05, 2.2633e-01], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [27]\n",
            "DEBUGGING: logits looks like: tensor([26181.2383, 26244.2969, 26222.7383, 26229.2559, 26247.8516, 26242.6523,\n",
            "        26246.7578, 26240.4785, 26238.4863, 26220.9902, 26222.6016, 26246.3301,\n",
            "        26247.6211, 26254.2871, 26242.3555, 26213.6836, 26217.1543, 26156.1094,\n",
            "        26250.4844, 26190.3027, 26249.5371, 26241.3184, 26237.5293, 26227.7148,\n",
            "        26216.3633, 26219.2031, 26239.0098, 26259.0176, 26246.4922, 26242.5859,\n",
            "        26243.0215, 26235.8789, 26245.6836, 26233.5371, 26232.1641, 26244.9434,\n",
            "        26245.9375, 26239.0332, 26244.8945, 26245.4355, 26250.9062, 26250.0078,\n",
            "        26233.8848, 26238.6367, 26214.0547, 26239.9375, 26233.9434, 26259.2383,\n",
            "        26242.3477, 26249.1895, 26240.3398, 26248.8848, 26254.6230, 26245.2832,\n",
            "        26212.2812, 26247.4375, 26235.8008, 26228.9375, 26256.4355, 26238.9766,\n",
            "        26246.5371, 26254.8574, 26179.1328, 26257.0039, 26232.4102, 26243.5684,\n",
            "        26257.0039, 26259.0176], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 8.5214e-04, 3.1594e-04, 1.2620e-02, 2.7450e-04, 1.1781e-05,\n",
            "        1.1640e-07, 3.8190e-03, 5.7417e-06, 3.1039e-05, 1.2251e-05, 2.1780e-10,\n",
            "        7.3570e-07, 1.1061e-09, 9.3928e-06, 2.1636e-02, 6.6505e-03, 8.1483e-03,\n",
            "        6.4691e-05, 1.5398e-04, 1.4314e-09, 1.5575e-06, 2.2956e-11, 8.0172e-07,\n",
            "        9.5063e-04, 3.3774e-02, 2.9203e-08, 1.1114e-03, 9.1945e-05, 1.4232e-08,\n",
            "        3.7227e-04, 6.1989e-03, 6.9550e-04, 4.0483e-05, 2.3212e-02, 3.8351e-01,\n",
            "        3.1264e-09, 5.1685e-04, 1.3630e-10, 1.9813e-03, 7.9262e-05, 1.7862e-04,\n",
            "        5.3599e-09, 2.3784e-09, 9.0330e-06, 1.1402e-02, 1.4839e-03, 9.1752e-06,\n",
            "        1.1242e-05, 2.7376e-09, 7.2169e-05, 7.7147e-03, 7.0858e-10, 2.7882e-04,\n",
            "        4.1120e-05, 5.3438e-03, 2.6951e-09, 1.1533e-04, 9.0194e-03, 5.3438e-03,\n",
            "        3.8030e-05, 1.7044e-04, 3.8490e-03, 1.9659e-03, 5.9240e-06, 3.2295e-01,\n",
            "        8.9627e-06, 1.1696e-01, 9.1230e-05, 6.6745e-05, 1.3617e-03, 9.8643e-05,\n",
            "        3.2208e-06, 6.6885e-04, 2.4799e-04, 1.7622e-03, 3.3331e-12, 1.0834e-04,\n",
            "        1.4271e-03, 4.0168e-05], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [65]\n",
            "DEBUGGING: logits looks like: tensor([26220.1211, 26281.3711, 26281.1230, 26282.0449, 26281.0879, 26280.3008,\n",
            "        26279.1465, 26281.7461, 26280.1211, 26280.5430, 26280.3105, 26277.5762,\n",
            "        26279.6074, 26277.9824, 26280.2441, 26282.1797, 26281.8848, 26281.9355,\n",
            "        26280.7266, 26280.9434, 26278.0469, 26279.7949, 26277.0137, 26279.6289,\n",
            "        26281.3984, 26282.2910, 26278.8008, 26281.4375, 26280.8145, 26278.6211,\n",
            "        26281.1641, 26281.8672, 26281.3203, 26280.6094, 26282.1973, 26282.8984,\n",
            "        26278.2422, 26281.2461, 26277.4590, 26281.5820, 26280.7773, 26280.9805,\n",
            "        26278.3770, 26278.1738, 26280.2344, 26282.0195, 26281.5098, 26280.2383,\n",
            "        26280.2891, 26278.2090, 26280.7539, 26281.9219, 26277.8711, 26281.0918,\n",
            "        26280.6133, 26281.8301, 26278.2051, 26280.8711, 26281.9609, 26281.8301,\n",
            "        26280.5938, 26280.9688, 26281.7480, 26281.5801, 26280.1289, 26282.8555,\n",
            "        26280.2324, 26282.6016, 26280.8125, 26280.7344, 26281.4883, 26280.8320,\n",
            "        26279.9766, 26281.3105, 26281.0625, 26281.5527, 26276.5312, 26280.8555,\n",
            "        26281.5000, 26280.6074], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 6.0540e-03, 2.8434e-02, 2.7935e-03, 9.8267e-03, 1.1025e-03,\n",
            "        4.0645e-03, 9.3037e-03, 2.2098e-03, 2.3390e-02, 3.3889e-04, 2.9781e-06,\n",
            "        3.3504e-02, 6.7701e-13, 1.1112e-03, 4.2023e-02, 6.1976e-03, 5.4268e-03,\n",
            "        2.8882e-02, 3.4692e-04, 3.5366e-06, 7.5344e-03, 8.5196e-04, 3.7885e-03,\n",
            "        2.2930e-04, 6.6351e-04, 3.6930e-04, 2.3794e-05, 6.9682e-03, 9.7502e-03,\n",
            "        4.3948e-03, 1.2204e-03, 1.8648e-02, 4.6418e-03, 6.3446e-03, 9.8830e-04,\n",
            "        2.2670e-02, 3.8784e-03, 4.8543e-04, 4.4292e-03, 8.4052e-03, 8.8086e-03,\n",
            "        6.3446e-03, 1.6847e-02, 1.2618e-02, 1.5101e-02, 3.6150e-03, 5.7526e-05,\n",
            "        3.5515e-04, 2.3708e-03, 8.3876e-04, 6.1976e-03, 7.1894e-03, 2.1086e-03,\n",
            "        1.2325e-02, 1.2917e-02, 1.3750e-02, 3.2153e-03, 4.9695e-04, 1.4410e-02,\n",
            "        1.7555e-01, 2.8987e-04, 1.6329e-02, 1.6681e-03, 7.7131e-03, 2.0716e-04,\n",
            "        7.9412e-04, 9.8267e-03, 2.5093e-02, 2.5581e-04, 8.5865e-04, 2.8434e-02,\n",
            "        7.8960e-03, 1.0460e-02, 1.7618e-03, 1.1159e-01, 3.3243e-02, 9.2313e-03,\n",
            "        1.9269e-05, 3.9823e-09, 1.6201e-02, 3.8482e-03, 6.9828e-02, 1.1310e-02,\n",
            "        1.4743e-06, 8.5865e-04, 5.8678e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [2]\n",
            "DEBUGGING: logits looks like: tensor([26241.1406, 26301.7266, 26302.1133, 26301.5332, 26301.8477, 26301.3008,\n",
            "        26301.6270, 26301.8340, 26301.4746, 26302.0645, 26301.0059, 26299.8223,\n",
            "        26302.1543, 26295.9980, 26301.3027, 26302.2109, 26301.7324, 26301.6992,\n",
            "        26302.1172, 26301.0117, 26299.8652, 26301.7812, 26301.2363, 26301.6094,\n",
            "        26300.9082, 26301.1738, 26301.0273, 26300.3418, 26301.7617, 26301.8457,\n",
            "        26301.6465, 26301.3262, 26302.0078, 26301.6602, 26301.7383, 26301.2734,\n",
            "        26302.0566, 26301.6152, 26301.0957, 26301.6484, 26301.8086, 26301.8203,\n",
            "        26301.7383, 26301.9824, 26301.9102, 26301.9551, 26301.5977, 26300.5625,\n",
            "        26301.0176, 26301.4922, 26301.2324, 26301.7324, 26301.7695, 26301.4629,\n",
            "        26301.9043, 26301.9160, 26301.9316, 26301.5684, 26301.1016, 26301.9434,\n",
            "        26302.5684, 26300.9668, 26301.9746, 26301.4043, 26301.7871, 26300.8828,\n",
            "        26301.2188, 26301.8477, 26302.0820, 26300.9355, 26301.2383, 26302.1133,\n",
            "        26301.7930, 26301.8633, 26301.4180, 26302.4551, 26302.1523, 26301.8320,\n",
            "        26300.2891, 26298.1680, 26301.9727, 26301.6133, 26302.3379, 26301.8828,\n",
            "        26299.6465, 26301.2383, 26301.7188], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.7201e-02, 0.0000e+00, 0.0000e+00, 4.6393e-02, 9.4992e-03,\n",
            "        2.0110e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8891e-02, 1.8168e-02,\n",
            "        1.0680e-02, 3.5294e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.9445e-16,\n",
            "        0.0000e+00, 0.0000e+00, 1.4039e-02, 0.0000e+00, 9.2070e-03, 5.6281e-03,\n",
            "        0.0000e+00, 3.2987e-23, 1.3396e-02, 3.0664e-02, 0.0000e+00, 8.6883e-12,\n",
            "        0.0000e+00, 0.0000e+00, 1.5419e-02, 0.0000e+00, 0.0000e+00, 1.9491e-02,\n",
            "        8.6649e-17, 0.0000e+00, 1.1822e-02, 1.2165e-33, 1.0352e-02, 0.0000e+00,\n",
            "        8.8543e-03, 7.6927e-03, 1.7201e-02, 1.9040e-02, 1.2584e-02, 5.3704e-03,\n",
            "        1.3501e-02, 0.0000e+00, 0.0000e+00, 2.1588e-24, 0.0000e+00, 8.0619e-03,\n",
            "        0.0000e+00, 0.0000e+00, 1.0112e-02, 0.0000e+00, 2.5822e-02, 9.8158e-32,\n",
            "        2.1915e-02, 5.1755e-02, 6.9498e-03, 4.1586e-02, 5.4977e-03, 2.6228e-02,\n",
            "        1.9798e-02, 1.2102e-02, 4.6757e-02, 6.4779e-03, 8.6492e-03, 2.6228e-02,\n",
            "        7.0043e-03, 3.0664e-02, 4.4871e-03, 1.9040e-02, 7.2833e-03, 4.9668e-03,\n",
            "        1.3607e-02, 1.0352e-02, 1.4372e-02, 1.6934e-02, 1.0112e-02, 6.4779e-03,\n",
            "        6.9498e-03, 6.2298e-03, 3.7570e-02, 5.7167e-03, 2.3461e-03, 8.9237e-03,\n",
            "        4.9178e-04, 3.2573e-03, 5.0846e-03, 1.2487e-02, 1.2584e-02, 1.4039e-02,\n",
            "        3.5220e-03, 2.7061e-02, 0.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [78]\n",
            "DEBUGGING: logits looks like: tensor([26257.7402, 26317.4922, 26175.8770, 26189.2812, 26317.7402, 26317.3438,\n",
            "        26317.5312, 26254.0938, 26217.5664, 26164.2383, 26317.5156, 26317.5059,\n",
            "        26317.3730, 26317.6719, 26143.8125, 26239.2773, 26142.9629, 26309.6406,\n",
            "        26279.7266, 26277.2617, 26317.4414, 26217.5254, 26317.3359, 26317.2129,\n",
            "        26071.9023, 26305.5664, 26317.4297, 26317.6367, 26275.9238, 26312.1406,\n",
            "        26288.0000, 26288.1797, 26317.4648, 26280.0859, 26238.4512, 26317.5234,\n",
            "        26309.2617, 26226.0312, 26317.3984, 26299.5605, 26317.3652, 26227.1270,\n",
            "        26317.3262, 26317.2910, 26317.4922, 26317.5176, 26317.4141, 26317.2012,\n",
            "        26317.4316, 26290.5586, 26261.9941, 26304.8848, 26201.6738, 26317.3027,\n",
            "        26242.1719, 26254.5273, 26317.3594, 26116.5840, 26317.5938, 26300.6582,\n",
            "        26317.5527, 26317.7676, 26317.2656, 26317.7129, 26317.2070, 26317.5977,\n",
            "        26317.5273, 26317.4043, 26317.7422, 26317.2480, 26317.3203, 26317.5977,\n",
            "        26317.2676, 26317.6367, 26317.1562, 26317.5176, 26317.2773, 26317.1816,\n",
            "        26317.4336, 26317.3652, 26317.4473, 26317.4883, 26317.3594, 26317.2480,\n",
            "        26317.2656, 26317.2383, 26317.6875, 26317.2168, 26316.9941, 26317.3281,\n",
            "        26316.6035, 26317.0762, 26317.1875, 26317.4121, 26317.4141, 26317.4414,\n",
            "        26317.0957, 26317.6055, 26254.0957], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000, 0.0171, 0.0070, 0.0046, 0.0136, 0.0131, 0.0127, 0.0084, 0.0098,\n",
            "        0.0072, 0.0034, 0.0154, 0.0144, 0.0072, 0.0019, 0.0033, 0.0081, 0.0047,\n",
            "        0.0045, 0.0100, 0.0149, 0.0122, 0.0092, 0.0150, 0.0072, 0.0056, 0.0024,\n",
            "        0.0053, 0.0112, 0.0053, 0.0079, 0.0153, 0.0115, 0.0083, 0.0125, 0.0106,\n",
            "        0.0112, 0.0107, 0.0045, 0.0141, 0.0103, 0.0044, 0.0143, 0.0144, 0.0122,\n",
            "        0.0099, 0.0090, 0.0101, 0.0114, 0.0042, 0.0150, 0.0042, 0.0145, 0.0045,\n",
            "        0.0157, 0.0114, 0.0099, 0.0034, 0.0122, 0.0050, 0.0057, 0.0105, 0.0077,\n",
            "        0.0021, 0.0059, 0.0053, 0.0121, 0.0209, 0.0125, 0.0129, 0.0166, 0.0090,\n",
            "        0.0171, 0.0041, 0.0142, 0.0105, 0.0056, 0.0150, 0.0136, 0.0121, 0.0101,\n",
            "        0.0037, 0.0122, 0.0045, 0.0024, 0.0056, 0.0110, 0.0129, 0.0023, 0.0017,\n",
            "        0.0095, 0.0134, 0.0080, 0.0118, 0.0070, 0.0106, 0.0104, 0.0127, 0.0127,\n",
            "        0.0047, 0.0099, 0.0083, 0.0012, 0.0065, 0.0105, 0.0120, 0.0134],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [5]\n",
            "DEBUGGING: logits looks like: tensor([26271.1543, 26329.8594, 26329.6367, 26329.5293, 26329.8027, 26329.7930,\n",
            "        26329.7852, 26329.6816, 26329.7207, 26329.6426, 26329.4590, 26329.8340,\n",
            "        26329.8164, 26329.6426, 26329.3066, 26329.4492, 26329.6738, 26329.5352,\n",
            "        26329.5234, 26329.7246, 26329.8242, 26329.7754, 26329.7051, 26329.8262,\n",
            "        26329.6426, 26329.5801, 26329.3711, 26329.5645, 26329.7539, 26329.5664,\n",
            "        26329.6660, 26329.8320, 26329.7598, 26329.6797, 26329.7812, 26329.7402,\n",
            "        26329.7539, 26329.7422, 26329.5273, 26329.8105, 26329.7324, 26329.5176,\n",
            "        26329.8145, 26329.8164, 26329.7754, 26329.7227, 26329.6992, 26329.7285,\n",
            "        26329.7578, 26329.5078, 26329.8262, 26329.5078, 26329.8184, 26329.5234,\n",
            "        26329.8379, 26329.7578, 26329.7227, 26329.4570, 26329.7754, 26329.5527,\n",
            "        26329.5840, 26329.7363, 26329.6602, 26329.3379, 26329.5938, 26329.5664,\n",
            "        26329.7734, 26329.9102, 26329.7812, 26329.7891, 26329.8516, 26329.6992,\n",
            "        26329.8594, 26329.5039, 26329.8125, 26329.7363, 26329.5820, 26329.8262,\n",
            "        26329.8027, 26329.7734, 26329.7285, 26329.4746, 26329.7754, 26329.5254,\n",
            "        26329.3730, 26329.5820, 26329.7480, 26329.7891, 26329.3594, 26329.2891,\n",
            "        26329.7129, 26329.7988, 26329.6699, 26329.7656, 26329.6348, 26329.7402,\n",
            "        26329.7344, 26329.7852, 26329.7852, 26329.5391, 26329.7227, 26329.6797,\n",
            "        26329.1973, 26329.6191, 26329.7383, 26329.7715, 26329.7988],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.06028491068173025 and immediate abs rewards look like: [0.017294578184191778, 0.012272575242604944, 0.0024996665515573113, 0.0011182527596247382, 0.0012108692526453524, 0.0051692562142307, 0.0004399879649099603, 0.00039128852858993923, 0.00012716052606265293, 0.00013129724811733468, 0.00014829715382802533, 0.004995641777441051, 0.0005313190199558449, 0.0014357685085997218, 0.004463270451196877, 6.618805127800442e-05, 0.0023141806213970995, 3.9674767322139814e-05, 7.024250180620584e-05, 7.316084702324588e-05, 0.001810992305763648, 0.0007057335774334206, 0.0004502905053413997, 0.0005943647306594357, 3.1729494821775006e-05, 9.431771331946948e-05, 6.9787847678526305e-06, 9.232285037796828e-05, 1.883495633592247e-05, 1.7262223082070705e-06, 0.0001001311316031206, 1.1032097972929478e-06, 0.00017262212895730045, 1.8785800421028398e-05, 4.2683881019911496e-05, 5.542518329093582e-05, 0.00017450958284825902, 5.444254702524631e-05, 0.0001388293635500304, 0.00013008224550503655, 0.0003299626969237579, 1.2117032838432351e-05, 6.159731947263936e-05, 1.6453613170597237e-05, 8.162480071405298e-05, 5.0077669584425166e-05, 3.103390872638556e-05, 4.6537472826457815e-05, 9.848304716797429e-05, 6.844073277534335e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 1.5880593875449585 and immediate relative rewards look like: [0.05991038410894446, 0.08553966188243509, 0.026246211095055864, 0.015669075491463853, 0.021216845646546138, 0.10873696231507382, 0.010817440203599685, 0.0109961305568608, 0.004020752203814228, 0.004613043071362047, 0.005731620424855216, 0.21064302608360347, 0.024312872796926534, 0.07076707610245819, 0.2358211961768531, 0.003736123830981638, 0.1387963354799246, 0.0025215840209785283, 0.004712444044395279, 0.005166686687983041, 0.13429211855035184, 0.05486001236004282, 0.0366033956297958, 0.05042363425843831, 0.0028045571357450724, 0.008670269737059469, 0.0006662297920063393, 0.009140054556708025, 0.0019313382636651688, 0.00018311191349587935, 0.010975636231548555, 0.00012483097181291357, 0.02014303192010841, 0.0022586532542383767, 0.005282941146936655, 0.007056023551189896, 0.02283388974194438, 0.007316573323763193, 0.019148731054845616, 0.01840320230831083, 0.0478502340840034, 0.0018002450654636688, 0.009369538161847376, 0.00256101037479561, 0.012993751421441692, 0.008149188973908159, 0.005160056740345557, 0.007902580742929054, 0.017072204985384705, 0.012106869068716192]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 3\n",
            "DEBUGGING: the action_prob is: tensor([7.3495e-36, 0.0000e+00, 4.9311e-14, 2.0123e-39, 1.2657e-18, 1.8283e-40,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3058e-18, 5.3640e-26,\n",
            "        0.0000e+00, 2.1221e-10, 0.0000e+00, 1.5913e-28, 0.0000e+00, 6.9581e-10,\n",
            "        0.0000e+00, 2.2740e-18, 0.0000e+00, 1.0000e+00, 3.0803e-26, 6.7543e-43,\n",
            "        4.7224e-42, 7.0065e-45, 8.0888e-35, 2.7273e-17, 3.4560e-27, 2.8859e-31,\n",
            "        1.7731e-36, 8.7670e-19, 0.0000e+00, 1.7488e-24, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 1.1987e-29, 1.5952e-38, 0.0000e+00, 0.0000e+00,\n",
            "        2.3660e-40, 2.8097e-40, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        4.3648e-20, 0.0000e+00, 2.0402e-25, 0.0000e+00, 1.1980e-33, 6.0172e-42,\n",
            "        6.9813e-27, 0.0000e+00, 0.0000e+00, 4.0796e-41, 0.0000e+00, 5.6052e-45,\n",
            "        0.0000e+00, 2.6690e-31, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        4.9311e-14], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [21]\n",
            "DEBUGGING: logits looks like: tensor([26206.4883, 26184.5684, 26219.0527, 26204.4375, 26216.4102, 26203.8379,\n",
            "        26187.7910, 26189.9336, 26181.2383, 26141.6992, 26216.4180, 26212.1660,\n",
            "        26191.2305, 26221.1445, 26196.4258, 26210.7109, 26190.1055, 26221.4414,\n",
            "        26200.6641, 26216.5566, 26200.5586, 26226.7129, 26212.0273, 26202.4375,\n",
            "        26202.9238, 26201.2793, 26207.0879, 26217.1777, 26211.4805, 26209.1328,\n",
            "        26206.1328, 26216.3184, 26197.0215, 26213.0371, 26191.2188, 26186.4316,\n",
            "        26191.1484, 26182.1504, 26210.0645, 26204.9551, 26196.0566, 26187.3242,\n",
            "        26203.9023, 26203.9453, 26197.7363, 26194.1895, 26190.5039, 26199.9023,\n",
            "        26215.5684, 26157.7168, 26212.5000, 26184.9336, 26207.7617, 26202.9844,\n",
            "        26211.6562, 26194.0684, 26190.3848, 26203.4629, 26172.5195, 26201.2383,\n",
            "        26195.1367, 26209.1133, 26190.4746, 26190.8945, 26185.2891, 26181.2383,\n",
            "        26219.0527], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 5.9772e-09, 1.1573e-17, 3.3039e-16, 9.9438e-01, 7.4231e-10,\n",
            "        0.0000e+00, 4.2039e-45, 1.7202e-18, 0.0000e+00, 4.7641e-24, 0.0000e+00,\n",
            "        2.1045e-15, 2.7136e-13, 0.0000e+00, 1.3185e-07, 3.6384e-11, 6.1172e-24,\n",
            "        3.7002e-03, 0.0000e+00, 5.2654e-21, 1.3835e-25, 1.1050e-13, 0.0000e+00,\n",
            "        1.5068e-29, 6.6601e-17, 8.2810e-10, 8.1552e-21, 1.0223e-24, 4.4127e-27,\n",
            "        0.0000e+00, 5.2622e-25, 1.5895e-11, 9.7988e-34, 0.0000e+00, 9.0624e-34,\n",
            "        2.3976e-05, 6.2246e-12, 2.3869e-22, 2.2941e-26, 0.0000e+00, 2.8150e-29,\n",
            "        0.0000e+00, 1.3864e-24, 3.8108e-15, 1.1353e-15, 2.3891e-29, 4.2717e-09,\n",
            "        1.9729e-16, 3.0364e-19, 1.4932e-37, 6.4999e-10, 6.1657e-43, 7.1496e-39,\n",
            "        8.4064e-14, 1.9417e-31, 0.0000e+00, 3.7618e-10, 5.9093e-07, 1.5323e-21,\n",
            "        3.4892e-43, 9.9322e-35, 5.2402e-27, 1.8899e-03, 4.6023e-33, 2.7267e-07,\n",
            "        3.4231e-14, 8.5184e-30, 0.0000e+00, 1.3818e-07, 6.3742e-23, 2.1402e-07,\n",
            "        1.0876e-28, 1.6658e-37, 3.1149e-18, 9.4772e-09],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [4]\n",
            "DEBUGGING: logits looks like: tensor([26155.6641, 26249.0215, 26244.0059, 26244.8438, 26253.7539, 26248.5000,\n",
            "        26218.2461, 26228.2461, 26243.5293, 26210.6680, 26240.3301, 26221.1699,\n",
            "        26245.3066, 26246.5215, 26221.4355, 26249.7949, 26247.7461, 26240.3926,\n",
            "        26252.3555, 26216.6797, 26242.0820, 26239.4453, 26246.2969, 26227.6465,\n",
            "        26237.1641, 26244.4434, 26248.5273, 26242.1914, 26239.9453, 26238.5840,\n",
            "        26215.3105, 26239.7793, 26247.5391, 26234.7539, 26220.9355, 26234.7344,\n",
            "        26251.0957, 26247.3047, 26241.3086, 26238.9961, 26211.9844, 26237.3203,\n",
            "        26211.8457, 26240.0215, 26245.4551, 26245.1523, 26237.2793, 26248.9375,\n",
            "        26244.7148, 26243.0957, 26232.5566, 26248.4668, 26229.4570, 26231.7969,\n",
            "        26246.2285, 26236.0762, 26224.4199, 26248.3301, 26250.1699, 26241.7734,\n",
            "        26229.3145, 26234.1816, 26238.6270, 26252.1875, 26235.1406, 26249.9766,\n",
            "        26246.0039, 26237.0215, 26212.8418, 26249.8066, 26240.9785, 26249.9160,\n",
            "        26237.6582, 26232.5840, 26243.6777, 26249.1367],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 6.5622e-09, 2.2870e-05, 9.9761e-03, 5.5726e-05, 4.7223e-02,\n",
            "        7.4717e-03, 1.0213e-02, 8.9937e-04, 1.3570e-08, 1.1958e-05, 2.8849e-06,\n",
            "        1.7710e-04, 4.4216e-11, 4.3399e-05, 8.3654e-05, 5.1352e-03, 4.8415e-05,\n",
            "        9.2070e-04, 7.6766e-05, 1.0411e-04, 2.4447e-03, 1.7672e-05, 1.0658e-04,\n",
            "        6.6555e-06, 3.2135e-03, 2.0310e-02, 2.0183e-05, 4.5387e-06, 1.0213e-02,\n",
            "        6.8195e-13, 8.6804e-06, 8.8038e-03, 3.9599e-04, 1.1328e-01, 1.3113e-02,\n",
            "        6.5425e-03, 5.5226e-13, 6.8277e-05, 5.1646e-04, 1.2729e-05, 5.5726e-05,\n",
            "        1.4290e-02, 2.5621e-03, 6.2918e-03, 2.5969e-04, 2.1562e-07, 1.7747e-03,\n",
            "        1.6567e-06, 1.1386e-06, 1.6863e-05, 3.3799e-05, 6.2711e-12, 2.7388e-01,\n",
            "        3.3607e-04, 6.2297e-04, 3.6700e-03, 2.3098e-04, 2.6268e-06, 1.5629e-04,\n",
            "        5.9570e-03, 1.0308e-05, 1.3003e-06, 1.0411e-04, 3.4998e-07, 6.4237e-08,\n",
            "        5.9106e-03, 6.8957e-04, 5.6570e-09, 1.9189e-03, 7.4717e-03, 2.6850e-03,\n",
            "        1.0559e-01, 3.8542e-02, 5.7616e-04, 7.4717e-03, 9.8776e-04, 5.6011e-10,\n",
            "        2.2120e-06, 2.1901e-07, 2.8849e-06, 2.2179e-01, 2.8300e-04, 1.0597e-03,\n",
            "        2.8198e-02, 4.6393e-03, 3.7200e-04], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [81]\n",
            "DEBUGGING: logits looks like: tensor([26163.4180, 26267.2051, 26269.2441, 26270.7637, 26269.4668, 26271.1523,\n",
            "        26270.6914, 26270.7695, 26270.1621, 26267.3867, 26269.0820, 26268.7266,\n",
            "        26269.7559, 26265.9551, 26269.4043, 26269.5684, 26270.5977, 26269.4316,\n",
            "        26270.1680, 26269.5469, 26269.6230, 26270.4121, 26269.1797, 26269.6289,\n",
            "        26268.9355, 26270.4805, 26270.9414, 26269.2129, 26268.8398, 26270.7695,\n",
            "        26264.9121, 26269.0020, 26270.7324, 26269.9570, 26271.3711, 26270.8320,\n",
            "        26270.6582, 26264.8594, 26269.5176, 26270.0234, 26269.0977, 26269.4668,\n",
            "        26270.8535, 26270.4238, 26270.6484, 26269.8516, 26268.0781, 26270.3320,\n",
            "        26268.5879, 26268.4941, 26269.1680, 26269.3418, 26265.4668, 26271.5918,\n",
            "        26269.9160, 26270.0703, 26270.5137, 26269.8223, 26268.7031, 26269.7246,\n",
            "        26270.6348, 26269.0449, 26268.5273, 26269.6230, 26268.1992, 26267.7754,\n",
            "        26270.6328, 26270.0957, 26267.1680, 26270.3516, 26270.6914, 26270.4355,\n",
            "        26271.3535, 26271.1016, 26270.0508, 26270.6914, 26270.1855, 26266.5898,\n",
            "        26268.6602, 26268.0820, 26268.7266, 26271.5391, 26269.8730, 26270.2031,\n",
            "        26271.0234, 26270.5723, 26269.9414], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 4.5825e-08, 1.3260e-07, 2.4721e-08, 1.2360e-07, 1.5262e-07,\n",
            "        1.6777e-14, 6.3221e-11, 4.3884e-10, 1.6622e-11, 9.2903e-10, 3.1790e-11,\n",
            "        6.6675e-08, 4.3634e-09, 2.4010e-07, 6.0109e-09, 1.2554e-07, 1.6858e-08,\n",
            "        2.0451e-09, 1.1465e-13, 6.3488e-09, 3.5539e-10, 1.5502e-07, 2.0134e-09,\n",
            "        9.9880e-09, 1.9241e-12, 5.2855e-07, 1.0305e-08, 4.6715e-10, 9.4565e-09,\n",
            "        2.2414e-10, 9.0751e-10, 2.6882e-09, 1.4056e-09, 2.6110e-08, 7.3074e-09,\n",
            "        3.1316e-07, 5.5592e-09, 2.4047e-10, 4.6715e-10, 8.6413e-11, 3.3627e-14,\n",
            "        7.4225e-09, 4.5182e-11, 1.0716e-08, 4.2958e-09, 2.0019e-08, 1.2798e-09,\n",
            "        1.6339e-08, 2.9756e-09, 5.9821e-15, 4.8780e-08, 1.4005e-07, 5.4190e-10,\n",
            "        3.9503e-08, 3.9897e-07, 1.5262e-07, 9.8332e-09, 5.3158e-08, 8.0716e-10,\n",
            "        2.0451e-09, 4.6087e-09, 1.9864e-08, 1.0572e-07, 1.6339e-08, 3.8507e-09,\n",
            "        1.0000e+00, 2.2333e-08, 1.9403e-08, 1.2600e-09, 2.6713e-12, 1.4784e-11,\n",
            "        1.4616e-09, 2.2113e-09, 2.0176e-08, 5.8260e-09, 2.3610e-15, 9.3829e-09,\n",
            "        1.9403e-08, 6.0236e-08, 6.7056e-09, 8.7458e-09, 1.3681e-07, 1.6178e-09,\n",
            "        1.3364e-07, 6.3488e-09, 1.8476e-09, 4.2803e-07, 6.3986e-09, 8.3278e-10,\n",
            "        5.6467e-09, 1.1954e-08, 3.3385e-10, 4.1624e-24, 1.6330e-12, 0.0000e+00,\n",
            "        1.3759e-08, 8.0885e-09], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [66]\n",
            "DEBUGGING: logits looks like: tensor([26176.2051, 26281.9824, 26282.2480, 26281.8281, 26282.2305, 26282.2832,\n",
            "        26278.2773, 26280.3359, 26280.8203, 26280.0020, 26281.0078, 26280.1641,\n",
            "        26282.0762, 26281.3945, 26282.3965, 26281.4746, 26282.2344, 26281.7324,\n",
            "        26281.2051, 26278.7578, 26281.4883, 26280.7676, 26282.2871, 26281.2012,\n",
            "        26281.6016, 26279.4629, 26282.5938, 26281.6094, 26280.8359, 26281.5879,\n",
            "        26280.6523, 26281.0020, 26281.2734, 26281.1113, 26281.8418, 26281.5234,\n",
            "        26282.4629, 26281.4551, 26280.6699, 26280.8359, 26280.4141, 26278.4512,\n",
            "        26281.5273, 26280.2520, 26281.6191, 26281.3906, 26281.7754, 26281.0879,\n",
            "        26281.7246, 26281.2988, 26278.0195, 26281.9980, 26282.2617, 26280.8730,\n",
            "        26281.9453, 26282.5234, 26282.2832, 26281.5977, 26282.0195, 26280.9727,\n",
            "        26281.2051, 26281.4082, 26281.7734, 26282.1914, 26281.7246, 26281.3633,\n",
            "        26286.2070, 26281.8027, 26281.7676, 26281.0840, 26279.5449, 26279.9727,\n",
            "        26281.1211, 26281.2246, 26281.7773, 26281.4668, 26277.7871, 26281.5859,\n",
            "        26281.7676, 26282.0508, 26281.5020, 26281.5684, 26282.2559, 26281.1465,\n",
            "        26282.2500, 26281.4883, 26281.1797, 26282.5410, 26281.4902, 26280.9805,\n",
            "        26281.4590, 26281.6465, 26280.7520, 26272.7480, 26279.4219, 26259.3359,\n",
            "        26281.6816, 26281.5488], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 3.3755e-03, 1.2347e-02, 7.8482e-03, 1.1509e-02, 1.2444e-02,\n",
            "        7.3727e-03, 9.3200e-03, 1.3143e-02, 6.6607e-03, 4.8731e-03, 1.8975e-02,\n",
            "        9.0332e-03, 1.0982e-02, 2.2011e-02, 6.6607e-03, 1.0644e-02, 9.0332e-03,\n",
            "        9.7673e-03, 4.1682e-03, 9.7673e-03, 6.1601e-03, 2.2567e-05, 1.0621e-03,\n",
            "        1.6745e-02, 7.0351e-03, 1.1967e-02, 7.7871e-03, 9.0332e-03, 8.5525e-03,\n",
            "        7.5476e-03, 8.7553e-03, 7.1459e-03, 1.1509e-02, 1.3350e-02, 9.4668e-03,\n",
            "        1.3246e-02, 7.1459e-03, 7.7871e-03, 1.0156e-02, 7.9718e-03, 6.5574e-03,\n",
            "        1.2541e-02, 8.2894e-03, 7.0351e-03, 4.5778e-03, 8.7553e-03, 6.1122e-03,\n",
            "        9.0332e-03, 1.1967e-02, 6.9260e-03, 1.9273e-02, 7.3727e-03, 1.2739e-02,\n",
            "        1.0397e-02, 9.0332e-03, 7.7265e-03, 1.4101e-02, 7.7265e-03, 7.7871e-03,\n",
            "        7.0351e-03, 1.4893e-02, 9.6913e-03, 1.2347e-02, 8.5525e-03, 6.9260e-03,\n",
            "        1.2541e-02, 9.6158e-03, 1.1690e-02, 1.6615e-02, 8.2894e-03, 4.1983e-07,\n",
            "        9.4668e-03, 1.9885e-02, 7.4888e-03, 8.1609e-03, 9.8439e-03, 1.1782e-02,\n",
            "        5.1874e-03, 9.1041e-03, 5.7419e-03, 7.4888e-03, 5.5971e-04, 1.1242e-02,\n",
            "        4.9498e-03, 1.5608e-02, 4.2008e-03, 8.8932e-03, 3.4286e-03, 6.1601e-03,\n",
            "        6.1601e-03, 1.1509e-02, 6.6607e-03, 5.1069e-03, 1.3246e-02, 1.0727e-02,\n",
            "        6.6089e-03, 1.1967e-02, 5.9241e-03, 6.3062e-03, 7.7265e-03, 8.2894e-03,\n",
            "        7.4305e-03, 8.1609e-03, 6.0646e-03, 5.1069e-03, 1.1690e-02, 2.0198e-02,\n",
            "        1.5487e-02, 7.9098e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [77]\n",
            "DEBUGGING: logits looks like: tensor([26186.5293, 26291.3945, 26291.7188, 26291.6055, 26291.7012, 26291.7207,\n",
            "        26291.5898, 26291.6484, 26291.7344, 26291.5645, 26291.4863, 26291.8262,\n",
            "        26291.6406, 26291.6895, 26291.8633, 26291.5645, 26291.6816, 26291.6406,\n",
            "        26291.6602, 26291.4473, 26291.6602, 26291.5449, 26290.1426, 26291.1055,\n",
            "        26291.7949, 26291.5781, 26291.7109, 26291.6035, 26291.6406, 26291.6270,\n",
            "        26291.5957, 26291.6328, 26291.5820, 26291.7012, 26291.7383, 26291.6523,\n",
            "        26291.7363, 26291.5820, 26291.6035, 26291.6699, 26291.6094, 26291.5605,\n",
            "        26291.7227, 26291.6191, 26291.5781, 26291.4707, 26291.6328, 26291.5430,\n",
            "        26291.6406, 26291.7109, 26291.5742, 26291.8301, 26291.5898, 26291.7266,\n",
            "        26291.6758, 26291.6406, 26291.6016, 26291.7520, 26291.6016, 26291.6035,\n",
            "        26291.5781, 26291.7656, 26291.6582, 26291.7188, 26291.6270, 26291.5742,\n",
            "        26291.7227, 26291.6562, 26291.7051, 26291.7930, 26291.6191, 26289.1465,\n",
            "        26291.6523, 26291.8379, 26291.5938, 26291.6152, 26291.6621, 26291.7070,\n",
            "        26291.5020, 26291.6426, 26291.5273, 26291.5938, 26290.9453, 26291.6953,\n",
            "        26291.4902, 26291.7773, 26291.4492, 26291.6367, 26291.3984, 26291.5449,\n",
            "        26291.5449, 26291.7012, 26291.5645, 26291.4980, 26291.7363, 26291.6836,\n",
            "        26291.5625, 26291.7109, 26291.5352, 26291.5508, 26291.6016, 26291.6191,\n",
            "        26291.5918, 26291.6152, 26291.5410, 26291.4980, 26291.7051, 26291.8418,\n",
            "        26291.7754, 26291.6074], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.16855327509574636 and immediate abs rewards look like: [0.0018197951239926624, 0.0020484290453168796, 0.009805356072774885, 0.07084235528373029, 0.008372851106742019, 0.012517200971160491, 0.004003946936791181, 6.371648260028451e-05, 0.00010270279153701267, 6.717394762745243e-05, 0.00016388236690545455, 0.00022016765387888881, 0.02020632116636989, 0.008210149514070508, 3.7250592413329287e-05, 0.0068469148213807784, 0.0006660456383542623, 0.0024078422866296023, 0.006764786644453125, 0.000599993670675758, 0.000813006400676386, 0.006333537774935394, 8.953517499321606e-05, 0.0005057771559222601, 4.2407624277984723e-05, 0.0001817537431634264, 0.0013414737018138112, 0.0007395340580842458, 7.615381582581904e-05, 0.0002994767933159892, 0.00013845217472407967, 0.0002328296327505086, 0.00040015061449594214, 9.494516416452825e-05, 0.0001832950970310776, 1.898524715215899e-07, 3.563315021892777e-05, 6.807270347053418e-05, 0.00044408488383851363, 5.7913880027626874e-05, 0.00027541673534869915, 3.344500373714254e-05, 5.471656550071202e-05, 0.00011753396120184334, 5.8825612541113514e-06, 4.4980245547776576e-05, 4.88444584334502e-06, 0.00014675798593088984, 2.1718772586609703e-05, 2.8333051886875182e-06]\n",
            "DEBUGGING: the total relative reward of the trajectory = 4.96833432729038 and immediate relative rewards look like: [0.0058678251582577985, 0.01321784028513575, 0.09496888074636195, 0.9177548212871813, 0.1387706270538436, 0.249643162572333, 0.09355312533507476, 0.0017037055512387977, 0.003089489795343613, 0.0022453176348035454, 0.006025756532791232, 0.008831718523219064, 0.8781587370553151, 0.3868701006056724, 0.001885872292911707, 0.36975001892297404, 0.038304605692712955, 0.14665487201292557, 0.4352689051380209, 0.04073077416066186, 0.05796258078932786, 0.4731767400663804, 0.007008272059250507, 0.04131170459131014, 0.0036087880667088363, 0.01608571636913594, 0.12329813064052597, 0.07052208532243497, 0.007523293403211642, 0.030606525303128136, 0.014622963105022584, 0.025385319078392116, 0.044995209344507334, 0.011001194301916106, 0.02186356678146712, 2.32942111024194e-05, 0.0044935049229013965, 0.008816397215925613, 0.05903033218535769, 0.007896834254756261, 0.03849400745539101, 0.0047889495220823815, 0.008021432939784804, 0.017631482219128417, 0.0009025455906871074, 0.007054572508699091, 0.0007827279913827376, 0.024018252823482848, 0.0036287038157832106, 0.000483044054416018]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 200 number of matrices\n",
            "DEBUGGING: ACT_MAT has 200 number of matrices\n",
            "DEBUGGING: VAL looks like: [[3.156625351686504, 3.1592164948154733, 3.1216418125580785, 3.099548843379946, 2.8046335256660937, 2.806385971046409, 2.8148522777350578, 2.760856613872412, 2.5984152139248393, 2.3716182850104226, 2.1969721276220824, 1.911427841329081, 1.0958395536942471, 1.082273906110723, 1.0374961304855557, 0.3578985404072973, 0.36106911600825503, 0.3642279104702173, 0.3673720418783609, 0.37049838757029224, 0.3736035623304418, 0.36902160030836545, 0.3527535340177969, 0.35554255164050014, 0.3583099686277441, 0.3610537165961742, 0.3555468947010786, 0.3507367726744072, 0.2740949031799044, 0.27567488593499906, 0.27799298180874676, 0.27650253967712857, 0.2777676527369286, 0.26272784231869517, 0.26448648360180865, 0.26617164415617983, 0.2557371527883532, 0.25289753025939543, 0.2541691841301078, 0.2529978933761683, 0.23787605223911906, 0.15387493793608598, 0.14706317870435048, 0.14560100885482832, 0.1381142610331147, 0.12538540405345186, 0.12401046304775523, 0.12218856356887103, 0.09109913017306374, 0.019498375588270476], [3.23896579856663, 3.2111670853107936, 3.157199417604403, 3.162578996474088, 3.1786968898814387, 3.1893737820554473, 3.1117543633741147, 3.1322595183540556, 3.152791300805247, 2.9554992863695384, 2.9134753171108776, 2.9240576754948506, 2.9109302105899597, 2.9002070312613726, 2.9231204075025112, 2.9439348249306203, 2.9715375421295, 2.9646738606060246, 2.3069867960088684, 1.927022091808655, 1.5506131882676562, 1.3879661225414712, 1.254379916750227, 1.1684052191263585, 1.1777339247630951, 1.1888633980133962, 1.1094181993950425, 0.7950875445701098, 0.7706079268635536, 0.7473661257746756, 0.6332803746802397, 0.5450980344469821, 0.5446133571569206, 0.47763653746981594, 0.47911124839675934, 0.4236312083831795, 0.4150753246861358, 0.41336286113596427, 0.25195169879863255, 0.24863275280451852, 0.24644382892211728, 0.24662659455121325, 0.2411117081789126, 0.22383408231096427, 0.1780921219520497, 0.09444623169758491, 0.08882037260407767, 0.06770385816951054, 0.028230144012122284, 0.02845265457968408], [1.3535900852283251, 1.3067471728478592, 1.2335429403691154, 1.2194916457313734, 1.2159823941817267, 1.2068338874092732, 1.109188813226464, 1.1094660333564286, 1.1095655583834017, 1.1167119254339266, 1.123332204406631, 1.1288894787694705, 0.9275216693796636, 0.9123321177603405, 0.8500656986443256, 0.6204489923913864, 0.6229422914751563, 0.48903631918710283, 0.49142902542032757, 0.49163291048073965, 0.4913800240330875, 0.3606948540229653, 0.30892408248780046, 0.27507140086667137, 0.2269169359679122, 0.22637614023451227, 0.21990491969439677, 0.2214532221236267, 0.21445774501708958, 0.21467313813477212, 0.21665659214270327, 0.2077585413243987, 0.20973102055816747, 0.19150301882632229, 0.1911559248202868, 0.18775048855893955, 0.18251966162398955, 0.1612987594768133, 0.15553756177075767, 0.13776649567263843, 0.1205689831962905, 0.07345328193160312, 0.07237680491529239, 0.0636437037913586, 0.061699690319760594, 0.049197918079110003, 0.04146336273252712, 0.03667000605270865, 0.029058005363413734, 0.012106869068716192], [4.3423734343815035, 4.3803086961850966, 4.411202884747436, 4.359832327273812, 3.4768459656430615, 3.3717932713022405, 3.1536869785150583, 3.0910442961413978, 3.120546051101171, 3.148946021521038, 3.178485559481045, 3.2045048514628824, 3.227952659535014, 2.3735292146259583, 2.0067263777982687, 2.0250914197023806, 1.6720620209892998, 1.6502600154510978, 1.518793074179972, 1.0944688576181323, 1.0643819024822934, 1.016585173427238, 0.5488974074352098, 0.5473627630060195, 0.5111626852673832, 0.5126807042431054, 0.5016110988625955, 0.38213431133542375, 0.3147598242555442, 0.3103399301538713, 0.2825589947987305, 0.2706424562562706, 0.24773448199785703, 0.20478714409429263, 0.19574338362866317, 0.17563617863353137, 0.17738675194184741, 0.17463964345348082, 0.16749822852278304, 0.109563531653965, 0.10269363373657449, 0.06484810735473079, 0.060665815992574146, 0.05317614449776702, 0.035903699271352126, 0.03535470068754042, 0.02858598805943569, 0.028084101078841364, 0.004106917429655068, 0.000483044054416018]]\n",
            "DEBUGGING: traj_returns = [3.156625351686504, 3.23896579856663, 1.3535900852283251, 4.3423734343815035]\n",
            "DEBUGGING: actions = [[43], [36], [3], [18], [43], [3], [24], [3], [3], [20], [11], [7], [5], [66], [8], [25], [24], [75], [77], [79], [12], [68], [28], [42], [82], [84], [77], [2], [74], [26], [84], [17], [85], [75], [44], [86], [40], [74], [74], [74], [53], [72], [36], [13], [101], [74], [37], [70], [11], [75], [17], [25], [17], [63], [64], [62], [63], [63], [18], [51], [61], [57], [68], [39], [61], [45], [19], [13], [2], [37], [77], [37], [74], [18], [12], [20], [35], [16], [79], [16], [51], [54], [65], [86], [77], [90], [17], [31], [45], [55], [17], [88], [16], [41], [21], [36], [91], [89], [6], [82], [17], [25], [17], [63], [64], [62], [63], [63], [63], [27], [67], [18], [61], [28], [3], [61], [69], [27], [62], [65], [10], [63], [66], [31], [62], [27], [17], [69], [19], [2], [25], [18], [51], [70], [61], [44], [6], [68], [7], [78], [66], [2], [78], [11], [7], [81], [98], [83], [88], [5], [6], [15], [23], [63], [26], [7], [31], [2], [40], [21], [69], [69], [21], [52], [12], [49], [28], [6], [4], [4], [55], [5], [4], [38], [27], [42], [59], [46], [12], [81], [81], [31], [74], [82], [84], [4], [25], [52], [30], [66], [54], [24], [82], [96], [79], [53], [98], [105], [56], [77]]\n",
            "DEBUGGING: actions length = 200\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[-32.4142,  56.9494, -60.5761,  ...,  48.4335,  62.3762, -30.6956],\n",
            "        [-32.5800,  57.2461, -60.8801,  ...,  48.6812,  62.6940, -30.8570],\n",
            "        [-31.5328,  55.4092, -58.9325,  ...,  47.1253,  60.6920, -29.8677],\n",
            "        ...,\n",
            "        [-32.2651,  56.6932, -60.2988,  ...,  48.2158,  62.0950, -30.5576],\n",
            "        [-32.2652,  56.6934, -60.2990,  ...,  48.2160,  62.0952, -30.5577],\n",
            "        [-32.2649,  56.6929, -60.2984,  ...,  48.2155,  62.0946, -30.5574]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[-32.1354,  56.4671, -60.0563,  ...,  48.0233,  61.8471, -30.4364],\n",
            "        [-32.2646,  56.6925, -60.2980,  ...,  48.2152,  62.0942, -30.5572],\n",
            "        [-32.2650,  56.6932, -60.2987,  ...,  48.2158,  62.0950, -30.5576],\n",
            "        ...,\n",
            "        [-32.2652,  56.6935, -60.2990,  ...,  48.2160,  62.0953, -30.5578],\n",
            "        [-32.2651,  56.6933, -60.2989,  ...,  48.2159,  62.0951, -30.5577],\n",
            "        [-32.2649,  56.6929, -60.2985,  ...,  48.2156,  62.0947, -30.5575]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([26186.5293, 26291.3945, 26291.7188, 26291.6055, 26291.7012, 26291.7207,\n",
            "        26291.5898, 26291.6484, 26291.7344, 26291.5645, 26291.4863, 26291.8262,\n",
            "        26291.6406, 26291.6895, 26291.8633, 26291.5645, 26291.6816, 26291.6406,\n",
            "        26291.6602, 26291.4473, 26291.6602, 26291.5449, 26290.1426, 26291.1055,\n",
            "        26291.7949, 26291.5781, 26291.7109, 26291.6035, 26291.6406, 26291.6270,\n",
            "        26291.5957, 26291.6328, 26291.5820, 26291.7012, 26291.7383, 26291.6523,\n",
            "        26291.7363, 26291.5820, 26291.6035, 26291.6699, 26291.6094, 26291.5605,\n",
            "        26291.7227, 26291.6191, 26291.5781, 26291.4707, 26291.6328, 26291.5430,\n",
            "        26291.6406, 26291.7109, 26291.5742, 26291.8301, 26291.5898, 26291.7266,\n",
            "        26291.6758, 26291.6406, 26291.6016, 26291.7520, 26291.6016, 26291.6035,\n",
            "        26291.5781, 26291.7656, 26291.6582, 26291.7188, 26291.6270, 26291.5742,\n",
            "        26291.7227, 26291.6562, 26291.7051, 26291.7930, 26291.6191, 26289.1465,\n",
            "        26291.6523, 26291.8379, 26291.5938, 26291.6152, 26291.6621, 26291.7070,\n",
            "        26291.5020, 26291.6426, 26291.5273, 26291.5938, 26290.9453, 26291.6953,\n",
            "        26291.4902, 26291.7773, 26291.4492, 26291.6367, 26291.3984, 26291.5449,\n",
            "        26291.5449, 26291.7012, 26291.5645, 26291.4980, 26291.7363, 26291.6836,\n",
            "        26291.5625, 26291.7109, 26291.5352, 26291.5508, 26291.6016, 26291.6191,\n",
            "        26291.5918, 26291.6152, 26291.5410, 26291.4980, 26291.7051, 26291.8418,\n",
            "        26291.7754, 26291.6074], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[3.02288867 3.01435986 2.98089676 2.96036295 2.66903969 2.64359673\n",
            "  2.54737061 2.52340662 2.49532953 2.39819388 2.3530663  2.29221996\n",
            "  2.04056102 1.81708557 1.70435215 1.48684344 1.40690274 1.36704953\n",
            "  1.17114523 0.97090556 0.86999467 0.78356694 0.61623874 0.58659548\n",
            "  0.56853088 0.57224349 0.54662028 0.43735296 0.3934801  0.38701352\n",
            "  0.35262224 0.32500039 0.31996163 0.28416364 0.28262426 0.26329738\n",
            "  0.25767972 0.2505497  0.20728917 0.18724017 0.17689562 0.13470073\n",
            "  0.13030438 0.12156373 0.10345244 0.07609606 0.07072005 0.06366163\n",
            "  0.03812355 0.01513524]]\n",
            "DEBUGGING: baseline2 looks like: 3.0228886674657405\n",
            "DEBUGGING: ADS looks like: [ -9.44773155  -9.38552059  -9.38692826  -9.09056365  -9.18756608\n",
            "  -9.13329357  -9.08845834  -8.7472746   -8.75338309  -8.62435038\n",
            "  -8.82587407  -8.50227285  -9.02122265  -8.48350387  -8.29720872\n",
            "  -8.89683341  -8.36403389  -8.39253004  -8.16665896  -7.86287087\n",
            "  -7.30890908  -7.01028094  -7.03725493  -7.01679246  -7.05042314\n",
            "  -7.07270645  -6.04283051  -6.05696775  -5.78103806  -5.61474981\n",
            "  -5.45578572  -5.44790419  -5.47154694  -4.92625051  -4.33639435\n",
            "  -4.34736186  -3.72034765  -3.73321526  -3.75500668  -3.55909273\n",
            "  -3.58479395  -2.96657796  -2.97494626  -2.98316774  -1.81982897\n",
            "  -1.82344515  -1.40644589  -1.40932743  -0.79921865  -0.8567106\n",
            "  -9.36539111  -9.33357     -9.35137065  -9.02753349  -8.81350271\n",
            "  -8.75030576  -8.79155625  -8.37587169  -8.199007    -8.04046938\n",
            "  -8.10937088  -7.48964301  -7.20613199  -6.66557074  -6.41158445\n",
            "  -6.31079712  -5.75356546  -5.79208409  -6.22704421  -6.30634716\n",
            "  -6.13189946  -5.99133642  -6.13562855  -6.20392979  -6.23099918\n",
            "  -6.24489677  -5.2889592   -5.61261698  -5.28452503  -5.14305857\n",
            "  -5.10049833  -5.1793087   -5.20470124  -4.71134181  -4.12176959\n",
            "  -4.18990229  -3.56100948  -3.57274993  -3.75722417  -3.56345787\n",
            "  -3.57622617  -2.87382631  -2.88089773  -2.90493466  -1.77985111\n",
            "  -1.85438432  -1.44163598  -1.46381214  -0.86208763  -0.84775632\n",
            " -11.25076682 -11.23798991 -11.27502713 -10.97062084 -10.77621721\n",
            " -10.73284566 -10.7941218  -10.39866518 -10.24223275  -9.87925674\n",
            "  -9.89951399  -9.28481121  -9.18954054  -8.65344565  -8.48463915\n",
            "  -8.63428296  -8.10216071  -8.26772163  -8.04260198  -7.74173634\n",
            "  -7.19113262  -7.01860769  -7.08108439  -7.09726361  -7.18181617\n",
            "  -7.20738403  -6.17847248  -6.1862513   -5.84067522  -5.67575156\n",
            "  -5.51712211  -5.51664819  -5.53958358  -4.99747533  -4.40972491\n",
            "  -4.42578301  -3.79356514  -3.82481403  -3.8536383   -3.67432413\n",
            "  -3.70210102  -3.04699962  -3.04963263  -3.06512504  -1.89624354\n",
            "  -1.89963263  -1.48899299  -1.49484599  -0.86125977  -0.86410211\n",
            "  -8.26198347  -8.16442839  -8.09736719  -7.83028016  -8.51535364\n",
            "  -8.56788627  -8.74962364  -8.41708691  -8.23125225  -7.84702264\n",
            "  -7.84436063  -7.20919584  -6.88910955  -7.19224856  -7.32797847\n",
            "  -7.22964053  -7.05304098  -7.10649794  -7.01523793  -7.1389004\n",
            "  -6.61813074  -6.36271737  -6.84111106  -6.82497225  -6.89757042\n",
            "  -6.92107946  -5.8967663   -6.02557021  -5.74037314  -5.58008477\n",
            "  -5.45121971  -5.45376428  -5.50158011  -4.98419121  -4.40513745\n",
            "  -4.43789732  -3.79869805  -3.81147315  -3.84167764  -3.70252709\n",
            "  -3.71997637  -3.05560479  -3.06134362  -3.0755926   -1.92203953\n",
            "  -1.91347585  -1.50187036  -1.5034319   -0.88621086  -0.87572593]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(-5.4573, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.2687,  0.0290,  0.0617,  ..., -0.0955, -0.0987,  0.0743],\n",
            "        [ 0.3121,  0.0337,  0.0716,  ..., -0.1109, -0.1147,  0.0864],\n",
            "        [ 0.3832,  0.0413,  0.0880,  ..., -0.1362, -0.1408,  0.1052],\n",
            "        ...,\n",
            "        [ 0.5426,  0.0585,  0.1246,  ..., -0.1929, -0.1994,  0.1497],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0467,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0484,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0597,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0832,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0872,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1070,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0851,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0882,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1091,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0417,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0434,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0535,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0800,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0841,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1029,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1047,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1086,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1345,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0644,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0669,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0829,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0703,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0732,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0898,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0898,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0944,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1158,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0455,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0477,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0585,  0.0000,  0.0000,  0.0000]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.0404, -0.1247, -0.1078,  ...,  0.1513,  0.0211,  0.1320],\n",
            "        [ 0.0465, -0.1436, -0.1241,  ...,  0.1742,  0.0243,  0.1522],\n",
            "        [ 0.0587, -0.1812, -0.1566,  ...,  0.2197,  0.0306,  0.1908],\n",
            "        ...,\n",
            "        [ 0.0830, -0.2562, -0.2214,  ...,  0.3108,  0.0433,  0.2729],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0813,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0882,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1034,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1464,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1584,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1858,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1518,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1657,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1938,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0740,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0802,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0946,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1408,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1535,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1792,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1860,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.2021,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.2363,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1141,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1236,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1452,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1222,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1332,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1561,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1585,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1718,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.2016,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0790,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0858,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1005,  0.0000,  0.0000,  0.0000]])\n",
            "DEBUGGING: training for one iteration takes 0.005054 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 48\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [57]\n",
            "DEBUGGING: logits looks like: tensor([27134.6133, 27198.0430, 27117.2402, 27169.3438, 27100.8477, 27191.9277,\n",
            "        27191.6484, 27127.3379, 27172.8223, 27244.4219, 27187.5449, 27129.8633,\n",
            "        27280.0801, 27197.0273, 27213.0801, 27228.8594, 27205.8203, 27233.3379,\n",
            "        27229.3672, 27133.4824, 27197.9844, 27132.8965, 27186.1777, 27159.3770,\n",
            "        27246.3320, 27216.0527, 27201.8184, 27156.7754, 27238.2480, 27165.8750,\n",
            "        27179.8809, 27192.7148, 27171.9023, 27211.8027, 27199.7754, 27228.2285,\n",
            "        27140.4883, 27136.5430, 27130.7754, 27155.1504, 27148.1230, 27270.3301,\n",
            "        27161.6230, 27164.4023, 27101.9551, 27199.8633, 27226.9492, 27164.9395,\n",
            "        27208.7637, 27233.1133, 27234.6172, 27166.1797, 27217.9414, 27176.5137,\n",
            "        27186.0234, 27258.6348, 27210.3125, 27315.1367, 27219.2871, 27236.9082,\n",
            "        27283.4512, 27208.7773, 27126.2109, 27127.6523, 27215.5254, 27262.4160,\n",
            "        27228.6035, 27251.7344, 27250.9316], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([3.9578e-28, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0576e-24, 0.0000e+00,\n",
            "        3.4594e-40, 2.8026e-45, 3.1271e-36, 1.7197e-38, 0.0000e+00, 3.2031e-06,\n",
            "        2.9589e-40, 2.9349e-03, 1.0531e-26, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        5.4966e-39, 5.2385e-21, 3.1318e-39, 0.0000e+00, 3.2031e-06, 0.0000e+00,\n",
            "        0.0000e+00, 3.6659e-31, 1.2173e-24, 1.3337e-40, 1.4013e-45, 6.5785e-39,\n",
            "        2.9350e-29, 0.0000e+00, 1.4013e-45, 1.4013e-45, 0.0000e+00, 3.4791e-41,\n",
            "        0.0000e+00, 0.0000e+00, 1.2761e-35, 7.4253e-26, 2.8026e-45, 5.7481e-14,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9706e-01, 9.4488e-34,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 6.0603e-26, 1.2872e-16, 5.6052e-45, 1.5063e-23, 3.2792e-32,\n",
            "        1.2612e-44, 1.7218e-30, 3.6549e-25, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 7.0640e-20, 0.0000e+00, 4.2039e-45, 0.0000e+00, 1.0885e-40,\n",
            "        0.0000e+00, 3.7415e-43, 1.3906e-35, 5.0896e-31, 1.2965e-20, 0.0000e+00],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [46]\n",
            "DEBUGGING: logits looks like: tensor([27355.6035, 27341.1934, 27329.2852, 27309.9805, 27357.5762, 27333.8359,\n",
            "        27348.6621, 27345.6895, 27350.9395, 27349.6387, 27320.4297, 27368.2148,\n",
            "        27348.6230, 27369.9199, 27356.4238, 27344.6621, 27337.0625, 27344.4023,\n",
            "        27349.3535, 27359.7031, 27349.2129, 27335.3223, 27368.2148, 27342.7812,\n",
            "        27330.0918, 27353.8574, 27357.6113, 27348.4238, 27345.4805, 27349.3984,\n",
            "        27354.9531, 27321.8164, 27345.6543, 27345.5117, 27343.2852, 27348.0879,\n",
            "        27344.1875, 27335.9805, 27351.2910, 27356.9121, 27345.6895, 27363.7559,\n",
            "        27337.5254, 27337.1211, 27338.8984, 27333.0098, 27371.3770, 27352.3672,\n",
            "        27327.0195, 27336.0352, 27341.0449, 27333.6582, 27341.5059, 27324.3672,\n",
            "        27330.7500, 27356.8613, 27362.2305, 27345.8770, 27358.2402, 27353.2539,\n",
            "        27346.1074, 27354.2441, 27357.3105, 27326.9746, 27318.7949, 27333.6074,\n",
            "        27320.4629, 27360.3535, 27324.3301, 27345.8535, 27324.8477, 27348.3730,\n",
            "        27342.7812, 27346.9551, 27351.3125, 27353.9395, 27359.9297, 27332.9844],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 0.0000e+00, 8.5485e-31, 0.0000e+00, 0.0000e+00, 5.9948e-40,\n",
            "        0.0000e+00, 5.1739e-06, 0.0000e+00, 1.8184e-24, 2.1549e-25, 2.5148e-11,\n",
            "        0.0000e+00, 0.0000e+00, 7.6651e-42, 6.4897e-32, 1.6970e-42, 1.2945e-11,\n",
            "        2.6236e-28, 0.0000e+00, 0.0000e+00, 1.1039e-31, 8.7590e-12, 0.0000e+00,\n",
            "        0.0000e+00, 9.9999e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2289e-06, 1.7940e-23, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.6004e-29, 5.9178e-35, 3.3952e-28, 8.6910e-38, 1.3938e-39, 2.1718e-25,\n",
            "        2.2699e-30, 0.0000e+00, 0.0000e+00, 2.4878e-31, 1.6009e-40, 1.1304e-16,\n",
            "        2.0955e-16, 1.6497e-22, 3.2613e-36, 0.0000e+00, 4.4097e-30, 0.0000e+00,\n",
            "        0.0000e+00, 2.3251e-26, 4.0514e-22, 4.2701e-23, 3.4695e-14, 2.6585e-18,\n",
            "        8.0210e-39, 6.9644e-17, 5.2333e-08, 1.1639e-17, 0.0000e+00, 1.6697e-20,\n",
            "        6.7218e-19, 5.1896e-38, 9.4879e-26, 1.3149e-11, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [25]\n",
            "DEBUGGING: logits looks like: tensor([27330.9570, 27289.8340, 27349.5117, 27306.3711, 27194.3965, 27344.2422,\n",
            "        27216.1719, 27363.7773, 27241.6426, 27353.1543, 27352.6211, 27360.7188,\n",
            "        27321.9219, 27333.3457, 27343.1523, 27348.8672, 27342.7754, 27360.5527,\n",
            "        27350.9434, 27306.7812, 27296.1074, 27349.0000, 27360.4551, 27330.5430,\n",
            "        27284.1426, 27366.8203, 27248.8066, 27323.5527, 27317.6172, 27320.4531,\n",
            "        27289.2812, 27324.9805, 27306.4746, 27297.9688, 27294.3906, 27333.0391,\n",
            "        27286.9102, 27333.6855, 27328.4277, 27363.4180, 27353.7266, 27263.8145,\n",
            "        27339.2441, 27303.3633, 27306.5195, 27327.2812, 27337.6074, 27319.1230,\n",
            "        27350.2441, 27347.1172, 27351.0078, 27345.4863, 27344.4531, 27352.6230,\n",
            "        27349.7559, 27259.1426, 27330.9570, 27349.2031, 27343.9121, 27357.6406,\n",
            "        27357.7949, 27354.2812, 27346.3926, 27327.6094, 27349.9219, 27339.8926,\n",
            "        27340.2188, 27352.0645, 27354.5059, 27353.9434, 27359.0723, 27356.7031,\n",
            "        27344.8906, 27357.5195, 27362.6289, 27357.0723, 27336.0078, 27355.4355,\n",
            "        27356.3594, 27345.3574, 27352.4160, 27360.5566, 27322.8535, 27305.9375,\n",
            "        27275.9980, 27257.0918], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.9569e-23, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8897e-39, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.0053e-31, 6.1774e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.1958e-42, 0.0000e+00, 0.0000e+00, 1.0553e-30, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6712e-38, 0.0000e+00,\n",
            "        3.3046e-37, 0.0000e+00, 9.9431e-37, 0.0000e+00, 4.7922e-20, 4.4388e-23,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2033e-01, 3.3911e-43,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4948e-13, 0.0000e+00, 0.0000e+00,\n",
            "        1.6197e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3541e-08,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0651e-07, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4519e-38, 9.8509e-34, 9.8509e-34,\n",
            "        7.3008e-39, 3.7863e-02, 0.0000e+00, 8.4181e-01, 0.0000e+00, 0.0000e+00,\n",
            "        6.2428e-28, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [87]\n",
            "DEBUGGING: logits looks like: tensor([27374.7871, 27327.1348, 27359.5879, 27351.8105, 27365.4648, 27350.7324,\n",
            "        27249.6699, 27356.1777, 27285.6406, 27333.4980, 27336.7656, 27282.9492,\n",
            "        27349.7773, 27370.2578, 27384.1816, 27313.9766, 27360.8945, 27347.3457,\n",
            "        27355.5605, 27329.0000, 27272.9375, 27350.2871, 27313.9688, 27357.2832,\n",
            "        27363.7754, 27269.5547, 27348.6738, 27370.5000, 27324.0762, 27337.1309,\n",
            "        27316.1230, 27319.7188, 27299.8301, 27341.7871, 27366.0098, 27334.3789,\n",
            "        27366.7559, 27339.9082, 27367.0312, 27339.0781, 27376.6348, 27374.8887,\n",
            "        27335.3789, 27360.4883, 27339.6406, 27335.2402, 27387.2266, 27363.3086,\n",
            "        27354.4922, 27355.2148, 27321.3477, 27355.4336, 27320.8086, 27353.2617,\n",
            "        27339.4199, 27355.7754, 27262.4453, 27380.3730, 27325.8848, 27335.7090,\n",
            "        27380.9688, 27352.0703, 27343.3105, 27340.3555, 27330.3184, 27383.2266,\n",
            "        27307.7051, 27325.9668, 27335.1016, 27335.5098, 27319.7012, 27318.5117,\n",
            "        27313.1523, 27330.2051, 27332.3711, 27327.2168, 27383.7422, 27356.3086,\n",
            "        27351.5156, 27350.9199, 27360.9512, 27365.9746, 27368.7559, 27368.7559,\n",
            "        27365.8027, 27386.9375, 27351.1289, 27387.7129, 27358.5977, 27352.9297,\n",
            "        27372.0957, 27331.1992, 27343.3691, 27338.2168, 27340.1699, 27358.9277,\n",
            "        27351.8086, 27334.2246], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.7027e-17, 6.4920e-01, 8.3862e-13, 5.6251e-06, 2.4864e-19, 1.2499e-08,\n",
            "        7.1495e-22, 1.8791e-11, 1.5318e-19, 3.1755e-29, 1.0977e-14, 4.0529e-17,\n",
            "        4.5870e-25, 4.6958e-25, 1.5136e-21, 6.3647e-29, 3.6189e-30, 1.6829e-30,\n",
            "        1.5149e-02, 8.6473e-17, 6.2060e-15, 2.4857e-08, 8.6058e-23, 4.7000e-06,\n",
            "        7.2446e-12, 7.1668e-32, 8.7282e-20, 0.0000e+00, 1.4036e-16, 3.8976e-17,\n",
            "        3.9519e-29, 1.2092e-20, 4.6022e-16, 1.2361e-17, 9.7633e-15, 2.6468e-19,\n",
            "        8.6473e-17, 5.9934e-13, 1.1000e-13, 1.5167e-20, 4.9582e-14, 4.7598e-26,\n",
            "        7.4276e-15, 5.8792e-11, 1.8813e-03, 4.1703e-22, 2.1045e-24, 7.5332e-12,\n",
            "        0.0000e+00, 2.4887e-26, 3.3934e-16, 1.2394e-12, 8.4015e-27, 2.3761e-22,\n",
            "        7.2598e-11, 0.0000e+00, 4.8551e-24, 2.3941e-37, 6.5314e-39, 5.4488e-10,\n",
            "        8.5055e-10, 9.9679e-20, 6.3455e-23, 2.7972e-15, 3.3158e-01, 7.4701e-16,\n",
            "        2.3393e-22, 4.1216e-09, 7.4276e-15, 4.3521e-24, 1.5871e-17, 2.0558e-24,\n",
            "        1.8001e-24, 1.3649e-33, 8.4799e-04, 1.6268e-35, 8.0480e-14, 1.7301e-28,\n",
            "        1.8323e-23, 0.0000e+00, 1.2730e-03, 5.9201e-30, 5.1838e-30, 5.1838e-30,\n",
            "        2.1147e-18, 1.0601e-12, 1.2480e-31, 1.3620e-08, 2.0925e-23, 1.8967e-14,\n",
            "        1.1788e-21, 4.7612e-37, 7.2296e-39, 1.2574e-20, 1.8617e-08, 5.6456e-34,\n",
            "        2.6484e-15, 8.7361e-27, 6.9420e-10, 2.1083e-12, 2.7497e-12, 1.9139e-06,\n",
            "        1.7706e-17, 1.6131e-13, 5.9075e-05, 6.5667e-29, 2.9554e-26],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [64]\n",
            "DEBUGGING: logits looks like: tensor([27394.8203, 27404.3652, 27397.5215, 27401.4512, 27393.7637, 27399.9238,\n",
            "        27392.3008, 27398.2988, 27393.6426, 27388.0684, 27396.4375, 27395.0371,\n",
            "        27390.4629, 27390.4688, 27392.4883, 27388.2422, 27387.5254, 27387.3340,\n",
            "        27403.4258, 27395.2266, 27396.2949, 27400.0957, 27391.7715, 27401.4062,\n",
            "        27398.0605, 27386.5449, 27393.5020, 27374.5781, 27395.3477, 27395.0273,\n",
            "        27388.1230, 27393.0078, 27395.6445, 27394.7402, 27396.4082, 27393.7793,\n",
            "        27395.2266, 27397.4375, 27397.0137, 27393.0645, 27396.8145, 27389.8965,\n",
            "        27396.3398, 27398.5840, 27402.9043, 27392.1660, 27390.8438, 27398.0703,\n",
            "        27371.2285, 27389.7344, 27395.5684, 27397.6191, 27389.4629, 27392.0254,\n",
            "        27398.6367, 27375.4082, 27391.0527, 27383.3926, 27382.4922, 27399.1406,\n",
            "        27399.2520, 27393.5352, 27391.6953, 27396.0957, 27404.1973, 27395.7656,\n",
            "        27392.0215, 27399.6465, 27396.3398, 27391.0254, 27394.8027, 27390.8379,\n",
            "        27390.8047, 27385.5547, 27402.7051, 27384.4473, 27396.9355, 27388.4922,\n",
            "        27391.3848, 27362.1543, 27402.8066, 27387.6484, 27387.6152, 27387.6152,\n",
            "        27394.2988, 27397.5801, 27386.6836, 27399.9453, 27391.4180, 27396.5742,\n",
            "        27392.4258, 27383.5645, 27382.5176, 27393.0176, 27400.0234, 27385.3340,\n",
            "        27396.0820, 27389.4727, 27399.2012, 27397.7520, 27397.8184, 27401.1816,\n",
            "        27394.8301, 27397.1094, 27402.0391, 27388.2500, 27389.7773],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.7058461509377594 and immediate abs rewards look like: [0.7058461509227527, 1.8189894035458565e-12, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 1.3642420526593924e-12, 0.0, 9.094947017729282e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 0.0]\n",
            "DEBUGGING: the total relative reward of the trajectory = 2.608596764009822 and immediate relative rewards look like: [2.608596762540988, 1.8189894035470972e-11, 6.821210263295411e-12, 9.094947017729282e-12, 1.1368683772164188e-11, 1.3642420526593924e-11, 3.1832314562059726e-11, 1.818989403545443e-11, 0.0, 0.0, 2.5011104298755527e-11, 8.185452315954493e-11, 0.0, 6.366462912413393e-11, 0.0, 3.637978807091713e-11, 3.865352482534066e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2295945351943374e-11, 5.4569682106363287e-11, 5.6843418860808015e-11, 5.911715561525378e-11, 0.0, 6.366462912410498e-11, 0.0, 0.0, 7.048583938738591e-11, 0.0, 7.503331289626658e-11, 7.730704965068132e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.322320693172514e-11, 9.549694368617918e-11, 0.0, 1.000444171950221e-10, 1.0231815394947769e-10, 1.0459189070388675e-10, 0.0, 1.0913936421272657e-10, 0.0, 0.0]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 5.5559e-13, 2.2360e-26, 4.5894e-11, 1.9282e-37, 1.3587e-14,\n",
            "        3.7548e-21, 1.9668e-09, 1.0000e+00, 1.8125e-33, 1.5771e-36, 2.5315e-19,\n",
            "        5.8895e-41, 0.0000e+00, 1.2183e-25, 1.6073e-42, 1.0755e-36, 0.0000e+00,\n",
            "        1.2996e-24, 3.4737e-32, 1.6009e-14, 8.9641e-27, 5.7582e-22, 9.4909e-37,\n",
            "        4.2946e-24, 0.0000e+00, 8.4948e-34, 6.3623e-34, 4.5682e-43, 1.3031e-19,\n",
            "        0.0000e+00, 2.8026e-45, 2.6339e-15, 4.2791e-22, 0.0000e+00, 2.0274e-28,\n",
            "        4.9046e-24, 0.0000e+00, 2.7479e-32, 1.1379e-24, 0.0000e+00, 2.0414e-21,\n",
            "        1.4717e-28, 1.5573e-16, 2.3119e-25, 8.3931e-10, 2.5613e-06, 5.9393e-37,\n",
            "        5.3398e-17, 1.6627e-22, 5.7477e-08, 1.0950e-20, 1.4239e-40, 9.1712e-31,\n",
            "        6.8999e-14, 2.3810e-37, 2.2401e-14, 1.0399e-26, 5.7479e-34, 2.7029e-25,\n",
            "        4.5784e-27, 0.0000e+00, 2.3307e-36, 6.3394e-32, 2.9819e-08, 2.5713e-19,\n",
            "        1.0127e-20], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [8]\n",
            "DEBUGGING: logits looks like: tensor([27111.9941, 27165.5156, 27157.8047, 27166.6191, 27151.4355, 27164.5879,\n",
            "        27160.8125, 27167.5586, 27172.5703, 27153.7227, 27151.9609, 27161.8652,\n",
            "        27149.4121, 27138.4902, 27158.2285, 27148.5117, 27151.8652, 27137.5352,\n",
            "        27158.8203, 27154.4609, 27164.6289, 27157.5762, 27160.3438, 27151.8340,\n",
            "        27159.1191, 27117.9238, 27153.5332, 27153.4609, 27148.1973, 27161.6992,\n",
            "        27146.0273, 27146.8711, 27164.1777, 27160.2695, 27137.3633, 27156.6289,\n",
            "        27159.1523, 27139.6113, 27154.4023, 27158.7871, 27140.9473, 27160.6602,\n",
            "        27156.5488, 27163.4707, 27158.3887, 27167.3457, 27169.3516, 27151.7168,\n",
            "        27163.2031, 27160.0332, 27168.4023, 27161.0801, 27149.6328, 27155.2793,\n",
            "        27164.9941, 27151.4883, 27164.7129, 27157.6133, 27153.4355, 27158.4277,\n",
            "        27157.4082, 27144.5625, 27152.0586, 27154.6113, 27168.2383, 27161.8691,\n",
            "        27161.0605], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 2.1812e-04, 7.4680e-02, 3.9413e-05, 3.7103e-04, 1.4223e-03,\n",
            "        2.8328e-06, 1.1834e-05, 7.0008e-03, 7.3899e-07, 4.0202e-03, 1.0266e-02,\n",
            "        9.1583e-09, 1.2324e-08, 1.6117e-03, 3.0936e-05, 1.3814e-02, 5.0213e-05,\n",
            "        5.4572e-10, 4.2132e-03, 8.1162e-07, 8.3087e-07, 3.1555e-03, 6.9861e-04,\n",
            "        3.9496e-04, 2.7473e-02, 6.5353e-06, 9.3473e-03, 2.7672e-06, 3.5276e-02,\n",
            "        5.1188e-07, 4.3718e-04, 3.4243e-05, 1.5532e-02, 1.7802e-04, 4.0287e-02,\n",
            "        3.9579e-03, 6.4475e-05, 7.0008e-03, 8.6761e-05, 2.1858e-03, 1.1275e-02,\n",
            "        1.3210e-01, 3.4855e-04, 1.5692e-12, 3.1489e-04, 1.9030e-02, 3.0649e-02,\n",
            "        5.0425e-03, 3.5404e-04, 2.3485e-06, 5.2702e-08, 1.5402e-06, 8.1971e-06,\n",
            "        1.0669e-06, 9.3473e-03, 6.3839e-06, 8.1040e-04, 2.4768e-03, 4.3902e-02,\n",
            "        5.2924e-06, 1.8696e-03, 4.3942e-09, 1.4491e-09, 2.3170e-05, 5.3564e-04,\n",
            "        3.8223e-01, 2.0844e-07, 4.9050e-05, 1.4045e-09, 6.3877e-02, 4.2132e-03,\n",
            "        7.8008e-37, 2.6160e-03, 4.4634e-09, 2.4820e-02, 8.9838e-07, 2.1812e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [66]\n",
            "DEBUGGING: logits looks like: tensor([27118.7188, 27176.0254, 27177.4844, 27175.5977, 27176.1582, 27176.4941,\n",
            "        27174.9395, 27175.2969, 27176.8926, 27174.6035, 27176.7539, 27176.9883,\n",
            "        27173.5059, 27173.5801, 27176.5254, 27175.5371, 27177.0625, 27175.6582,\n",
            "        27172.8008, 27176.7656, 27174.6270, 27174.6328, 27176.6934, 27176.3164,\n",
            "        27176.1738, 27177.2344, 27175.1484, 27176.9648, 27174.9336, 27177.2969,\n",
            "        27174.5117, 27176.1992, 27175.5625, 27177.0918, 27175.9746, 27177.3301,\n",
            "        27176.7500, 27175.7207, 27176.8926, 27175.7949, 27176.6016, 27177.0117,\n",
            "        27177.6270, 27176.1426, 27171.3379, 27176.1172, 27177.1426, 27177.2617,\n",
            "        27176.8105, 27176.1465, 27174.8926, 27173.9434, 27174.7871, 27175.2051,\n",
            "        27174.6953, 27176.9648, 27175.1426, 27176.3535, 27176.6328, 27177.3516,\n",
            "        27175.0957, 27176.5625, 27173.3223, 27173.0449, 27175.4648, 27176.2500,\n",
            "        27177.8926, 27174.2871, 27175.6523, 27173.0371, 27177.4453, 27176.7656,\n",
            "        27157.3477, 27176.6465, 27173.3262, 27177.2090, 27174.6523, 27176.0254],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.7724e-02, 1.4925e-02, 2.7667e-02, 1.5455e-04, 1.7826e-03,\n",
            "        5.3106e-04, 9.5213e-05, 2.3850e-02, 2.3333e-05, 7.1612e-03, 5.2392e-03,\n",
            "        2.6085e-04, 6.8046e-05, 1.3069e-02, 8.6018e-05, 9.5070e-02, 5.3217e-03,\n",
            "        8.4862e-04, 5.0279e-04, 3.1597e-02, 2.4124e-04, 3.5728e-03, 3.0496e-04,\n",
            "        9.8442e-04, 2.6703e-04, 4.9500e-04, 3.6291e-03, 8.4862e-04, 2.3987e-03,\n",
            "        4.4371e-04, 9.8649e-03, 6.6330e-06, 1.5367e-03, 3.3493e-04, 2.0840e-03,\n",
            "        1.7863e-02, 3.7152e-03, 9.6916e-04, 3.4164e-02, 3.8713e-02, 2.2615e-05,\n",
            "        6.5715e-03, 1.6138e-02, 4.9500e-04, 4.4813e-03, 7.9267e-03, 1.5764e-02,\n",
            "        4.1658e-08, 1.1533e-02, 5.3635e-03, 1.5357e-07, 6.6330e-06, 2.8247e-07,\n",
            "        4.1533e-02, 2.9620e-03, 1.2766e-02, 4.2429e-03, 1.2156e-03, 8.4862e-04,\n",
            "        4.9993e-03, 1.4466e-02, 2.2806e-01, 2.8145e-05, 4.2761e-03, 1.3295e-05,\n",
            "        1.8430e-02, 4.7063e-02, 2.2486e-04, 3.6576e-03, 3.5101e-04, 6.5715e-03,\n",
            "        2.8995e-02, 1.3014e-04, 3.7286e-05, 2.0840e-03, 1.3455e-03, 1.8003e-02,\n",
            "        9.7471e-05, 4.5165e-03, 4.4212e-02, 3.8713e-02, 4.1359e-04, 2.1213e-02,\n",
            "        1.1354e-02, 4.2314e-08, 4.5424e-04, 4.4479e-14, 5.2883e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [14]\n",
            "DEBUGGING: logits looks like: tensor([27123.8223, 27181.5684, 27181.5254, 27181.6797, 27180.3828, 27180.9941,\n",
            "        27180.6914, 27180.2617, 27181.6426, 27179.9102, 27181.3418, 27181.2637,\n",
            "        27180.5137, 27180.1777, 27181.4922, 27180.2363, 27181.9883, 27181.2676,\n",
            "        27180.8086, 27180.6777, 27181.7129, 27180.4941, 27181.1680, 27180.5527,\n",
            "        27180.8457, 27180.5195, 27180.6738, 27181.1719, 27180.8086, 27181.0684,\n",
            "        27180.6465, 27181.4219, 27179.5957, 27180.9570, 27180.5762, 27181.0332,\n",
            "        27181.5703, 27181.1777, 27180.8418, 27181.7324, 27181.7637, 27179.9023,\n",
            "        27181.3203, 27181.5449, 27180.6738, 27181.2246, 27181.3672, 27181.5391,\n",
            "        27178.3281, 27181.4609, 27181.2695, 27178.6543, 27179.5957, 27178.8066,\n",
            "        27181.7812, 27181.1211, 27181.4863, 27181.2109, 27180.8984, 27180.8086,\n",
            "        27181.2520, 27181.5176, 27182.2070, 27179.9570, 27181.2129, 27179.7695,\n",
            "        27181.5781, 27181.8125, 27180.4766, 27181.1738, 27180.5879, 27181.3203,\n",
            "        27181.6914, 27180.3398, 27180.0273, 27181.0332, 27180.9238, 27181.5723,\n",
            "        27180.2676, 27181.2266, 27181.7969, 27181.7637, 27180.6289, 27181.6133,\n",
            "        27181.4570, 27178.3320, 27180.6523, 27174.8906, 27179.5391],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000, 0.0298, 0.0102, 0.0048, 0.0101, 0.0014, 0.0117, 0.0025, 0.0170,\n",
            "        0.0008, 0.0128, 0.0103, 0.0096, 0.0078, 0.0053, 0.0091, 0.0484, 0.0025,\n",
            "        0.0073, 0.0289, 0.0095, 0.0113, 0.0158, 0.0090, 0.0114, 0.0129, 0.0017,\n",
            "        0.0081, 0.0042, 0.0016, 0.0121, 0.0011, 0.0059, 0.0117, 0.0108, 0.0102,\n",
            "        0.0111, 0.0051, 0.0125, 0.0125, 0.0095, 0.0075, 0.0058, 0.0103, 0.0131,\n",
            "        0.0021, 0.0042, 0.0349, 0.0048, 0.0121, 0.0084, 0.0158, 0.0124, 0.0024,\n",
            "        0.0133, 0.0165, 0.0053, 0.0086, 0.0116, 0.0084, 0.0098, 0.0122, 0.0074,\n",
            "        0.0039, 0.0090, 0.0078, 0.0070, 0.0098, 0.0058, 0.0122, 0.0103, 0.0095,\n",
            "        0.0160, 0.0078, 0.0122, 0.0025, 0.0089, 0.0112, 0.0091, 0.0101, 0.0080,\n",
            "        0.0130, 0.0121, 0.0178, 0.0035, 0.0125, 0.0166, 0.0103, 0.0088, 0.0069,\n",
            "        0.0095, 0.0156, 0.0070, 0.0101, 0.0113, 0.0218, 0.0160],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [41]\n",
            "DEBUGGING: logits looks like: tensor([27127.7422, 27184.6562, 27184.3887, 27184.1973, 27184.3848, 27183.8984,\n",
            "        27184.4219, 27184.0410, 27184.5156, 27183.7656, 27184.4453, 27184.3906,\n",
            "        27184.3730, 27184.3223, 27184.2266, 27184.3594, 27184.7773, 27184.0352,\n",
            "        27184.3027, 27184.6484, 27184.3711, 27184.4141, 27184.4980, 27184.3555,\n",
            "        27184.4160, 27184.4473, 27183.9336, 27184.3301, 27184.1660, 27183.9316,\n",
            "        27184.4316, 27183.8281, 27184.2520, 27184.4219, 27184.4023, 27184.3887,\n",
            "        27184.4082, 27184.2148, 27184.4395, 27184.4395, 27184.3711, 27184.3125,\n",
            "        27184.2480, 27184.3906, 27184.4512, 27183.9922, 27184.1641, 27184.6953,\n",
            "        27184.1992, 27184.4316, 27184.3379, 27184.4980, 27184.4375, 27184.0234,\n",
            "        27184.4551, 27184.5078, 27184.2227, 27184.3457, 27184.4199, 27184.3379,\n",
            "        27184.3770, 27184.4336, 27184.3086, 27184.1445, 27184.3555, 27184.3223,\n",
            "        27184.2949, 27184.3770, 27184.2480, 27184.4336, 27184.3906, 27184.3711,\n",
            "        27184.5000, 27184.3223, 27184.4336, 27184.0410, 27184.3535, 27184.4121,\n",
            "        27184.3594, 27184.3848, 27184.3281, 27184.4492, 27184.4297, 27184.5273,\n",
            "        27184.1211, 27184.4395, 27184.5098, 27184.3906, 27184.3516, 27184.2910,\n",
            "        27184.3691, 27184.4941, 27184.2949, 27184.3848, 27184.4141, 27184.5781,\n",
            "        27184.5000], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000, 0.0105, 0.0098, 0.0098, 0.0099, 0.0070, 0.0117, 0.0033, 0.0173,\n",
            "        0.0044, 0.0109, 0.0127, 0.0095, 0.0071, 0.0090, 0.0094, 0.0083, 0.0109,\n",
            "        0.0066, 0.0157, 0.0072, 0.0111, 0.0077, 0.0084, 0.0077, 0.0071, 0.0102,\n",
            "        0.0103, 0.0117, 0.0087, 0.0135, 0.0104, 0.0103, 0.0071, 0.0026, 0.0040,\n",
            "        0.0069, 0.0053, 0.0104, 0.0059, 0.0167, 0.0110, 0.0092, 0.0092, 0.0048,\n",
            "        0.0132, 0.0127, 0.0097, 0.0151, 0.0084, 0.0045, 0.0109, 0.0088, 0.0064,\n",
            "        0.0109, 0.0077, 0.0167, 0.0055, 0.0133, 0.0120, 0.0117, 0.0077, 0.0095,\n",
            "        0.0084, 0.0123, 0.0056, 0.0163, 0.0052, 0.0075, 0.0038, 0.0104, 0.0115,\n",
            "        0.0080, 0.0152, 0.0087, 0.0117, 0.0038, 0.0080, 0.0117, 0.0109, 0.0126,\n",
            "        0.0036, 0.0084, 0.0128, 0.0127, 0.0083, 0.0092, 0.0129, 0.0056, 0.0080,\n",
            "        0.0117, 0.0080, 0.0075, 0.0082, 0.0072, 0.0110, 0.0108, 0.0118, 0.0120,\n",
            "        0.0135, 0.0058, 0.0103, 0.0105, 0.0040, 0.0088, 0.0105, 0.0090],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [26]\n",
            "DEBUGGING: logits looks like: tensor([27131.3633, 27187.7539, 27187.7344, 27187.7344, 27187.7383, 27187.6523,\n",
            "        27187.7793, 27187.4648, 27187.8770, 27187.5371, 27187.7617, 27187.8008,\n",
            "        27187.7285, 27187.6543, 27187.7148, 27187.7246, 27187.6934, 27187.7617,\n",
            "        27187.6367, 27187.8535, 27187.6582, 27187.7676, 27187.6738, 27187.6973,\n",
            "        27187.6738, 27187.6562, 27187.7461, 27187.7480, 27187.7793, 27187.7051,\n",
            "        27187.8164, 27187.7500, 27187.7480, 27187.6543, 27187.4082, 27187.5098,\n",
            "        27187.6465, 27187.5820, 27187.7500, 27187.6094, 27187.8691, 27187.7637,\n",
            "        27187.7207, 27187.7207, 27187.5566, 27187.8105, 27187.8008, 27187.7324,\n",
            "        27187.8438, 27187.6973, 27187.5410, 27187.7617, 27187.7090, 27187.6309,\n",
            "        27187.7617, 27187.6738, 27187.8691, 27187.5918, 27187.8125, 27187.7871,\n",
            "        27187.7793, 27187.6738, 27187.7285, 27187.6973, 27187.7930, 27187.5938,\n",
            "        27187.8633, 27187.5762, 27187.6699, 27187.4961, 27187.7500, 27187.7754,\n",
            "        27187.6836, 27187.8457, 27187.7070, 27187.7793, 27187.4961, 27187.6855,\n",
            "        27187.7793, 27187.7617, 27187.7988, 27187.4883, 27187.6973, 27187.8027,\n",
            "        27187.8008, 27187.6953, 27187.7188, 27187.8047, 27187.5938, 27187.6855,\n",
            "        27187.7793, 27187.6855, 27187.6699, 27187.6895, 27187.6582, 27187.7637,\n",
            "        27187.7598, 27187.7812, 27187.7852, 27187.8164, 27187.6055, 27187.7480,\n",
            "        27187.7539, 27187.5098, 27187.7090, 27187.7539, 27187.7148],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.300988057558925 and immediate abs rewards look like: [0.1100722757364565, 0.14929593634997218, 0.0015701585562055698, 0.011233944242121652, 0.0005462698982228176, 0.001272452237571997, 0.006908467604489488, 0.010719152047158786, 0.0008111922238640545, 0.0004152135979893501, 0.001387698928510872, 0.0004947823736074497, 0.0005987850040582998, 7.752741407784924e-05, 1.0076707212647307e-05, 0.0003118111635558307, 0.00034353961018496193, 0.0006855350638943492, 0.0001600000443886529, 0.0003613309711454349, 0.0004865961921041162, 0.00015496181526941655, 0.0006761317094969854, 7.747866266072378e-05, 3.0579203894376406e-05, 7.392492307189968e-06, 3.3798250115069095e-05, 0.0002520305279176682, 0.0003995102688350016, 0.00025304018208771595, 3.741401656043308e-05, 3.65606788363948e-05, 0.0001935121595124656, 0.00022104476011008956, 0.00010209799324911728, 9.707753088150639e-05, 7.470341461157659e-05, 3.9784060390957166e-05, 0.00017648756329435855, 0.00014819464126958337, 1.6600182789261453e-05, 7.018698397587286e-06, 9.202205546898767e-06, 1.4495335335595882e-05, 3.6416392958926735e-06, 8.797110240266193e-08, 4.1352723201271147e-07, 1.4886214330545045e-05, 2.1571714114543283e-05, 0.00012559417268676043]\n",
            "DEBUGGING: the total relative reward of the trajectory = 2.299853361719656 and immediate relative rewards look like: [0.3051419852930756, 0.8538086521673165, 0.014070027116109107, 0.1342845837153998, 0.00818976810966732, 0.022895925979205867, 0.14508115205096248, 0.2577998711326462, 0.022019139303885292, 0.012525984931880936, 0.046055622653362806, 0.017921405128153687, 0.023499343199539613, 0.0032772026877295577, 0.00045639411283257244, 0.0150640968301131, 0.017635918655088324, 0.03726658367140247, 0.009182924881292315, 0.021830490914402593, 0.03087192608113351, 0.010301179406292892, 0.046991472143203025, 0.0056200736672602095, 0.002310601250618412, 0.0005809343597415413, 0.002758174790147096, 0.0213294384642606, 0.03502089739359214, 0.02294903991564089, 0.0035065741471285777, 0.0035371716889966765, 0.019307182916125872, 0.022723815944648184, 0.010805289294072198, 0.010567829038983872, 0.008358329403121822, 0.004571722047944567, 0.02081474310149937, 0.017927016229644755, 0.002058409188739393, 0.0008915445230414693, 0.001196736322330955, 0.00192894675188773, 0.000495622073628555, 1.2238819906429417e-05, 5.878190575370157e-05, 0.002161062110912097, 0.0031968660197739234, 0.0189926701855593]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2019e-02, 0.0000e+00, 7.1273e-10,\n",
            "        3.2544e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2779e-36,\n",
            "        1.6222e-08, 3.6404e-36, 2.3809e-41, 5.0526e-25, 0.0000e+00, 1.0229e-43,\n",
            "        0.0000e+00, 0.0000e+00, 8.2951e-01, 8.3478e-24, 4.2560e-36, 0.0000e+00,\n",
            "        1.0709e-16, 0.0000e+00, 0.0000e+00, 4.9697e-18, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 9.6690e-43, 0.0000e+00, 0.0000e+00, 1.4642e-01,\n",
            "        2.9729e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.6485e-43, 1.7967e-30, 5.8576e-29,\n",
            "        0.0000e+00, 7.9966e-11, 0.0000e+00, 4.0638e-43, 7.9560e-32, 3.8139e-25,\n",
            "        1.7098e-35, 0.0000e+00, 0.0000e+00, 4.9193e-34, 0.0000e+00, 0.0000e+00,\n",
            "        8.1545e-24, 1.3963e-05, 1.3963e-05, 1.2019e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [20]\n",
            "DEBUGGING: logits looks like: tensor([27000.1250, 27041.0684, 27020.4902, 27074.5586, 27038.6035, 27070.3984,\n",
            "        27052.3574, 27040.9082, 27028.5117, 27047.5273, 26884.0098, 27055.0020,\n",
            "        27071.1797, 27055.2637, 27052.2793, 27061.6777, 27025.1875, 27050.9160,\n",
            "        27038.6582, 27035.8203, 27075.6172, 27062.3789, 27055.3027, 27031.4316,\n",
            "        27066.4707, 27041.8125, 27031.6777, 27065.7031, 27036.6211, 27020.5918,\n",
            "        27042.1660, 27045.7695, 27051.4785, 27042.3867, 27037.7715, 27075.1836,\n",
            "        27072.4824, 27037.7754, 27045.3633, 26975.4043, 27047.7676, 27043.4551,\n",
            "        27039.3086, 27021.5859, 27047.8926, 27049.4668, 27041.3457, 27048.5547,\n",
            "        27037.9570, 27020.5312, 27042.8184, 27051.1543, 27058.5410, 27059.4121,\n",
            "        27041.9160, 27069.8516, 27047.2031, 27051.2617, 27057.7617, 27061.6074,\n",
            "        27055.6504, 27038.3223, 26955.9805, 27056.4902, 27038.6602, 27032.8867,\n",
            "        27062.3730, 27072.8691, 27072.8691, 27074.5586],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 2.4353e-23, 3.8185e-06, 7.2529e-13, 1.1223e-05, 8.7093e-04,\n",
            "        5.2603e-06, 2.8540e-07, 1.8960e-12, 2.9928e-29, 3.3871e-11, 2.2354e-08,\n",
            "        2.9587e-01, 5.0164e-10, 3.3456e-02, 3.1120e-29, 4.7537e-17, 2.0341e-12,\n",
            "        1.6389e-07, 7.0742e-10, 4.2753e-08, 2.0563e-18, 2.2754e-07, 4.4070e-01,\n",
            "        9.8897e-03, 0.0000e+00, 5.2131e-14, 2.2502e-16, 1.5274e-43, 5.2272e-09,\n",
            "        6.6456e-10, 3.7504e-22, 5.1032e-39, 1.2771e-03, 1.3797e-22, 2.5783e-07,\n",
            "        2.2598e-40, 1.1390e-24, 1.9317e-18, 1.2547e-30, 3.1166e-06, 9.9344e-12,\n",
            "        8.8544e-11, 3.1458e-09, 1.3280e-03, 4.3466e-15, 2.4960e-15, 2.2087e-10,\n",
            "        4.6033e-10, 2.8080e-11, 2.9614e-08, 5.4616e-03, 1.6369e-15, 6.4315e-07,\n",
            "        7.6536e-06, 6.1888e-03, 1.6174e-17, 0.0000e+00, 1.0377e-20, 7.7649e-14,\n",
            "        2.6948e-12, 7.5805e-18, 3.0380e-07, 4.5702e-06, 5.5878e-07, 2.4397e-11,\n",
            "        5.8261e-02, 5.5526e-10, 1.6183e-13, 7.1405e-13, 2.6403e-18, 2.0987e-12,\n",
            "        4.7537e-17, 9.9105e-02, 4.7551e-02, 6.3318e-07, 8.4540e-07],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [66]\n",
            "DEBUGGING: logits looks like: tensor([26999.3477, 27074.2246, 27084.1230, 27080.2539, 27084.3926, 27085.4805,\n",
            "        27084.2031, 27083.4746, 27080.4941, 27070.8223, 27081.2148, 27082.8379,\n",
            "        27086.9375, 27081.8887, 27086.3926, 27070.8320, 27077.8457, 27080.5117,\n",
            "        27083.3359, 27081.9746, 27083.0000, 27077.0605, 27083.4180, 27087.0371,\n",
            "        27086.0879, 27055.9551, 27079.5957, 27078.2344, 27062.5957, 27082.4746,\n",
            "        27081.9590, 27074.9082, 27065.1992, 27085.5762, 27074.6582, 27083.4492,\n",
            "        27064.4199, 27073.4590, 27077.0449, 27070.0293, 27084.0723, 27080.9082,\n",
            "        27081.4551, 27082.3477, 27085.5859, 27078.9746, 27078.8359, 27081.6836,\n",
            "        27081.8672, 27081.1680, 27082.9082, 27085.9395, 27078.7305, 27083.6777,\n",
            "        27084.2969, 27085.9707, 27077.5762, 27060.2812, 27075.7383, 27079.6953,\n",
            "        27080.5820, 27077.3867, 27083.4902, 27084.1680, 27083.6426, 27081.1328,\n",
            "        27086.5312, 27081.9141, 27079.8789, 27080.2500, 27077.1230, 27080.5195,\n",
            "        27077.8457, 27086.6641, 27086.4805, 27083.6738, 27083.7461],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 4.4492e-04, 4.1534e-07, 1.5133e-19, 6.9744e-02, 2.0972e-05,\n",
            "        5.3362e-03, 4.9635e-04, 4.8689e-02, 7.1056e-08, 7.9030e-02, 3.2856e-07,\n",
            "        1.2069e-04, 2.9790e-09, 5.3668e-04, 2.3179e-02, 4.2124e-04, 2.4299e-13,\n",
            "        2.9363e-01, 1.9056e-06, 2.7411e-04, 3.5558e-14, 1.5722e-12, 6.6032e-02,\n",
            "        2.7626e-04, 0.0000e+00, 7.5095e-04, 2.5789e-07, 6.9849e-05, 3.5547e-03,\n",
            "        8.3900e-07, 4.7405e-11, 4.1884e-03, 1.4140e-03, 3.2114e-03, 2.7059e-25,\n",
            "        1.6887e-04, 2.5550e-04, 2.3082e-04, 3.9264e-04, 2.2419e-03, 8.6615e-03,\n",
            "        3.1730e-05, 4.6894e-05, 1.3211e-13, 1.5422e-10, 9.5274e-32, 6.3008e-02,\n",
            "        1.2561e-11, 6.5243e-04, 5.0039e-15, 1.6022e-03, 8.0760e-14, 9.5673e-04,\n",
            "        2.0647e-05, 1.5921e-06, 6.8231e-05, 6.4367e-03, 7.2218e-04, 1.4444e-04,\n",
            "        1.7772e-02, 1.5065e-10, 3.3655e-03, 1.3676e-04, 4.9575e-12, 4.9575e-12,\n",
            "        5.5589e-17, 6.0214e-05, 3.8959e-04, 2.4139e-05, 2.5898e-05, 7.6714e-05,\n",
            "        4.9814e-06, 1.8287e-07, 2.4002e-04, 2.1593e-06, 1.8811e-01, 3.1304e-04,\n",
            "        2.5010e-03, 4.5383e-02, 3.3183e-06, 1.6913e-07, 8.0565e-04, 3.4797e-02,\n",
            "        1.8919e-02, 6.4059e-09], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [18]\n",
            "DEBUGGING: logits looks like: tensor([27005.6270, 27091.8711, 27090.1270, 27082.9668, 27093.1348, 27091.1074,\n",
            "        27092.4922, 27091.8984, 27093.0449, 27089.6855, 27093.1660, 27090.0684,\n",
            "        27091.5449, 27088.8926, 27091.9180, 27092.8594, 27091.8574, 27086.5391,\n",
            "        27093.4941, 27090.5078, 27091.7500, 27086.0586, 27087.0059, 27093.1211,\n",
            "        27091.7520, 27060.4121, 27092.0020, 27090.0078, 27091.4082, 27092.3906,\n",
            "        27090.3027, 27087.8574, 27092.4316, 27092.1602, 27092.3652, 27079.6582,\n",
            "        27091.6289, 27091.7324, 27091.7070, 27091.8398, 27092.2754, 27092.6133,\n",
            "        27091.2109, 27091.3086, 27086.3867, 27088.1523, 27075.9434, 27093.1094,\n",
            "        27087.5254, 27091.9668, 27085.5684, 27092.1914, 27086.2637, 27092.0625,\n",
            "        27091.1035, 27090.4629, 27091.4023, 27092.5391, 27091.9922, 27091.5898,\n",
            "        27092.7930, 27088.1465, 27092.3770, 27091.5762, 27087.2930, 27087.2930,\n",
            "        27084.4434, 27091.3711, 27091.8379, 27091.1426, 27091.1602, 27091.4316,\n",
            "        27090.7480, 27089.9219, 27091.7168, 27090.5391, 27093.3828, 27091.7832,\n",
            "        27092.3027, 27093.0273, 27090.6465, 27089.9023, 27092.0195, 27092.9609,\n",
            "        27092.8086, 27089.0840], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 4.9114e-07, 1.7836e-02, 2.8933e-06, 7.6873e-02, 2.4088e-04,\n",
            "        3.5674e-03, 1.1789e-02, 2.1683e-02, 1.6555e-04, 2.5153e-02, 4.0656e-04,\n",
            "        1.6114e-02, 4.8834e-06, 1.2994e-04, 2.8280e-02, 1.8287e-05, 1.7761e-04,\n",
            "        2.9407e-02, 2.2936e-05, 8.6249e-03, 1.2181e-05, 1.6520e-05, 2.3396e-03,\n",
            "        3.0624e-05, 7.3618e-04, 2.0972e-03, 7.5523e-03, 2.6305e-03, 3.2297e-02,\n",
            "        4.0424e-03, 5.7007e-03, 9.6973e-03, 1.0221e-03, 3.7600e-04, 2.6249e-04,\n",
            "        1.0795e-03, 8.1659e-03, 1.0689e-04, 3.6807e-03, 7.9433e-05, 1.0545e-03,\n",
            "        1.8692e-02, 7.8531e-03, 2.6567e-02, 8.4912e-03, 3.5954e-03, 4.0424e-03,\n",
            "        1.2595e-04, 2.7197e-02, 1.2329e-03, 1.4527e-03, 4.3709e-03, 7.3199e-03,\n",
            "        1.7836e-02, 3.0994e-03, 4.6069e-04, 2.4748e-06, 7.1503e-03, 1.8402e-02,\n",
            "        1.6625e-02, 6.6648e-03, 3.0994e-03, 2.0054e-02, 2.0054e-02, 3.3322e-02,\n",
            "        4.8179e-05, 3.7680e-03, 3.8273e-03, 1.4496e-04, 1.5431e-04, 3.9571e-02,\n",
            "        1.7019e-02, 1.4871e-03, 1.6755e-02, 9.6016e-04, 1.9437e-02, 6.1603e-07,\n",
            "        1.4109e-02, 4.7304e-10, 3.1464e-07, 9.4726e-03, 1.3774e-06, 2.7410e-02,\n",
            "        5.4511e-02, 2.6360e-02, 1.5740e-02, 2.5153e-02, 1.0818e-02, 3.0578e-02,\n",
            "        1.5137e-02, 1.0988e-02, 2.5549e-02, 4.8179e-05, 5.2313e-03, 7.9147e-03,\n",
            "        3.0177e-12, 6.9303e-03, 2.5350e-02, 4.3369e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [65]\n",
            "DEBUGGING: logits looks like: tensor([27010.6152, 27094.7949, 27097.4199, 27095.2383, 27097.7852, 27096.3438,\n",
            "        27097.0176, 27097.3164, 27097.4688, 27096.2500, 27097.5059, 27096.4746,\n",
            "        27097.3945, 27095.3691, 27096.1895, 27097.5352, 27095.6992, 27096.2676,\n",
            "        27097.5449, 27095.7559, 27097.2383, 27095.5977, 27095.6738, 27096.9121,\n",
            "        27095.8281, 27096.6230, 27096.8848, 27097.2051, 27096.9414, 27097.5684,\n",
            "        27097.0488, 27097.1348, 27097.2676, 27096.7051, 27096.4551, 27096.3652,\n",
            "        27096.7188, 27097.2246, 27096.1406, 27097.0254, 27096.0664, 27096.7129,\n",
            "        27097.4316, 27097.2148, 27097.5195, 27097.2344, 27097.0195, 27097.0488,\n",
            "        27096.1816, 27097.5254, 27096.7520, 27096.7930, 27097.0684, 27097.1973,\n",
            "        27097.4199, 27096.9824, 27096.5059, 27095.1992, 27097.1914, 27097.4277,\n",
            "        27097.4023, 27097.1738, 27096.9824, 27097.4492, 27097.4492, 27097.5762,\n",
            "        27095.9414, 27097.0312, 27097.0352, 27096.2168, 27096.2324, 27097.6191,\n",
            "        27097.4082, 27096.7988, 27097.4043, 27096.6895, 27097.4414, 27094.8516,\n",
            "        27097.3613, 27093.0586, 27094.6836, 27097.2617, 27095.0527, 27097.5273,\n",
            "        27097.6992, 27097.5176, 27097.3887, 27097.5059, 27097.2949, 27097.5547,\n",
            "        27097.3789, 27097.2988, 27097.5098, 27095.9414, 27097.1133, 27097.2168,\n",
            "        27091.7949, 27097.1836, 27097.5078, 27097.0664],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000, 0.0066, 0.0102, 0.0111, 0.0084, 0.0099, 0.0091, 0.0122, 0.0087,\n",
            "        0.0033, 0.0127, 0.0077, 0.0098, 0.0088, 0.0087, 0.0072, 0.0106, 0.0091,\n",
            "        0.0072, 0.0118, 0.0079, 0.0091, 0.0078, 0.0105, 0.0089, 0.0101, 0.0084,\n",
            "        0.0077, 0.0072, 0.0080, 0.0084, 0.0108, 0.0099, 0.0101, 0.0099, 0.0120,\n",
            "        0.0095, 0.0087, 0.0092, 0.0145, 0.0102, 0.0065, 0.0113, 0.0104, 0.0092,\n",
            "        0.0108, 0.0075, 0.0120, 0.0060, 0.0084, 0.0096, 0.0121, 0.0056, 0.0115,\n",
            "        0.0095, 0.0111, 0.0084, 0.0084, 0.0108, 0.0096, 0.0119, 0.0113, 0.0051,\n",
            "        0.0108, 0.0113, 0.0078, 0.0111, 0.0108, 0.0078, 0.0108, 0.0059, 0.0120,\n",
            "        0.0101, 0.0099, 0.0046, 0.0070, 0.0074, 0.0069, 0.0064, 0.0074, 0.0054,\n",
            "        0.0057, 0.0093, 0.0108, 0.0101, 0.0105, 0.0099, 0.0096, 0.0091, 0.0101,\n",
            "        0.0091, 0.0101, 0.0092, 0.0111, 0.0108, 0.0128, 0.0083, 0.0094, 0.0091,\n",
            "        0.0128, 0.0101, 0.0091, 0.0087, 0.0091, 0.0072, 0.0083, 0.0060, 0.0103,\n",
            "        0.0111], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [1]\n",
            "DEBUGGING: logits looks like: tensor([27014.6484, 27101.4297, 27101.5391, 27101.5605, 27101.4902, 27101.5312,\n",
            "        27101.5098, 27101.5840, 27101.4980, 27101.2578, 27101.5938, 27101.4688,\n",
            "        27101.5293, 27101.5020, 27101.4980, 27101.4512, 27101.5488, 27101.5098,\n",
            "        27101.4512, 27101.5742, 27101.4746, 27101.5098, 27101.4707, 27101.5449,\n",
            "        27101.5039, 27101.5352, 27101.4902, 27101.4688, 27101.4512, 27101.4785,\n",
            "        27101.4902, 27101.5527, 27101.5312, 27101.5371, 27101.5312, 27101.5801,\n",
            "        27101.5215, 27101.4980, 27101.5137, 27101.6270, 27101.5391, 27101.4258,\n",
            "        27101.5645, 27101.5430, 27101.5137, 27101.5527, 27101.4629, 27101.5801,\n",
            "        27101.4062, 27101.4902, 27101.5234, 27101.5820, 27101.3867, 27101.5684,\n",
            "        27101.5215, 27101.5605, 27101.4902, 27101.4902, 27101.5527, 27101.5234,\n",
            "        27101.5762, 27101.5645, 27101.3633, 27101.5527, 27101.5645, 27101.4727,\n",
            "        27101.5605, 27101.5527, 27101.4707, 27101.5527, 27101.4023, 27101.5801,\n",
            "        27101.5371, 27101.5312, 27101.3379, 27101.4453, 27101.4570, 27101.4395,\n",
            "        27101.4238, 27101.4570, 27101.3789, 27101.3945, 27101.5156, 27101.5527,\n",
            "        27101.5352, 27101.5449, 27101.5312, 27101.5234, 27101.5098, 27101.5371,\n",
            "        27101.5098, 27101.5352, 27101.5137, 27101.5605, 27101.5527, 27101.5957,\n",
            "        27101.4883, 27101.5176, 27101.5098, 27101.5957, 27101.5352, 27101.5098,\n",
            "        27101.4980, 27101.5098, 27101.4512, 27101.4883, 27101.4062, 27101.5410,\n",
            "        27101.5605], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.1456366999018428 and immediate abs rewards look like: [0.010754348344562459, 0.012717792419607576, 0.0065206662161472195, 0.029698524268951587, 0.0019199828384444118, 0.0011962372022935597, 0.0042497824883867, 0.008576207812438952, 0.010111354340097023, 0.007122450360839139, 0.0004129480162191612, 0.014111223467807577, 0.0005507872824637161, 0.015565254841476417, 0.0009180166266560263, 7.548842586402316e-05, 0.0012599699302882073, 0.004780525523528922, 0.0051716254638449755, 0.0029993326611474913, 0.00019626196399258333, 0.00013961118338556844, 0.0007160296536312671, 0.00017785758927857387, 0.00026344397565480904, 0.0005576579583248531, 0.00033033663385140244, 0.0012680775898843422, 0.0015377143877230992, 0.00039006202678137925, 7.550890268248622e-05, 9.618879994377494e-05, 0.000232623941883503, 1.2863537904195255e-05, 3.676046208056505e-05, 0.00030537399516106234, 9.860249519988429e-06, 0.0004347345566202421, 1.856097287600278e-05, 9.195446182275191e-07, 1.500921462138649e-05, 1.4581473806174472e-06, 3.5004177334485576e-06, 9.261589639208978e-06, 3.2467560231452808e-06, 4.2403701172588626e-05, 3.1140693863562774e-05, 2.25180610868847e-06, 1.4187857232172973e-05, 1.2732612049148884e-06]\n",
            "DEBUGGING: the total relative reward of the trajectory = 3.6850465170484528 and immediate relative rewards look like: [0.029001021819185686, 0.06879110038297566, 0.0530884576119323, 0.3229616529705132, 0.026311414330148514, 0.019682216088701875, 0.08160423000137006, 0.188425552086821, 0.2505131117645211, 0.19661587866456123, 0.012564116625394204, 0.46842429616726555, 0.01988471428340943, 0.6052611582330636, 0.038413333125515196, 0.0033701697073704132, 0.05976813007999128, 0.24019359806524435, 0.2746463685464864, 0.1679098050277714, 0.011546267763813777, 0.008605041275130317, 0.046140882905141095, 0.011961835696143213, 0.01845712766543978, 0.04063583167098224, 0.025000936977981607, 0.0995359250324652, 0.12505587135791285, 0.032830134241858065, 0.006567878539543143, 0.008636722106652922, 0.021540438176568817, 0.0012273088887527523, 0.0036104813491739107, 0.03084999737658957, 0.0010238761511169952, 0.046362490737500185, 0.002031783049705758, 0.00010323977529083176, 0.0017272539275162348, 0.00017189644948134724, 0.0004224785877004421, 0.0011438129504115402, 0.00041009086579247124, 0.005474947010318942, 0.004108181620540559, 0.00030338878217214094, 0.0019513737230053472, 0.00017869681150771183]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 3\n",
            "DEBUGGING: the action_prob is: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [57]\n",
            "DEBUGGING: logits looks like: tensor([27134.6133, 27198.0430, 27117.2402, 27169.3438, 27100.8477, 27191.9277,\n",
            "        27191.6484, 27127.3379, 27172.8223, 27244.4219, 27187.5449, 27129.8633,\n",
            "        27280.0801, 27197.0273, 27213.0801, 27228.8594, 27205.8203, 27233.3379,\n",
            "        27229.3672, 27133.4824, 27197.9844, 27132.8965, 27186.1777, 27159.3770,\n",
            "        27246.3320, 27216.0527, 27201.8184, 27156.7754, 27238.2480, 27165.8750,\n",
            "        27179.8809, 27192.7148, 27171.9023, 27211.8027, 27199.7754, 27228.2285,\n",
            "        27140.4883, 27136.5430, 27130.7754, 27155.1504, 27148.1230, 27270.3301,\n",
            "        27161.6230, 27164.4023, 27101.9551, 27199.8633, 27226.9492, 27164.9395,\n",
            "        27208.7637, 27233.1133, 27234.6172, 27166.1797, 27217.9414, 27176.5137,\n",
            "        27186.0234, 27258.6348, 27210.3125, 27315.1367, 27219.2871, 27236.9082,\n",
            "        27283.4512, 27208.7773, 27126.2109, 27127.6523, 27215.5254, 27262.4160,\n",
            "        27228.6035, 27251.7344, 27250.9316], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([3.9578e-28, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0576e-24, 0.0000e+00,\n",
            "        3.4594e-40, 2.8026e-45, 3.1271e-36, 1.7197e-38, 0.0000e+00, 3.2031e-06,\n",
            "        2.9589e-40, 2.9349e-03, 1.0531e-26, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        5.4966e-39, 5.2385e-21, 3.1318e-39, 0.0000e+00, 3.2031e-06, 0.0000e+00,\n",
            "        0.0000e+00, 3.6659e-31, 1.2173e-24, 1.3337e-40, 1.4013e-45, 6.5785e-39,\n",
            "        2.9350e-29, 0.0000e+00, 1.4013e-45, 1.4013e-45, 0.0000e+00, 3.4791e-41,\n",
            "        0.0000e+00, 0.0000e+00, 1.2761e-35, 7.4253e-26, 2.8026e-45, 5.7481e-14,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9706e-01, 9.4488e-34,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 6.0603e-26, 1.2872e-16, 5.6052e-45, 1.5063e-23, 3.2792e-32,\n",
            "        1.2612e-44, 1.7218e-30, 3.6549e-25, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 7.0640e-20, 0.0000e+00, 4.2039e-45, 0.0000e+00, 1.0885e-40,\n",
            "        0.0000e+00, 3.7415e-43, 1.3906e-35, 5.0896e-31, 1.2965e-20, 0.0000e+00],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [46]\n",
            "DEBUGGING: logits looks like: tensor([27355.6035, 27341.1934, 27329.2852, 27309.9805, 27357.5762, 27333.8359,\n",
            "        27348.6621, 27345.6895, 27350.9395, 27349.6387, 27320.4297, 27368.2148,\n",
            "        27348.6230, 27369.9199, 27356.4238, 27344.6621, 27337.0625, 27344.4023,\n",
            "        27349.3535, 27359.7031, 27349.2129, 27335.3223, 27368.2148, 27342.7812,\n",
            "        27330.0918, 27353.8574, 27357.6113, 27348.4238, 27345.4805, 27349.3984,\n",
            "        27354.9531, 27321.8164, 27345.6543, 27345.5117, 27343.2852, 27348.0879,\n",
            "        27344.1875, 27335.9805, 27351.2910, 27356.9121, 27345.6895, 27363.7559,\n",
            "        27337.5254, 27337.1211, 27338.8984, 27333.0098, 27371.3770, 27352.3672,\n",
            "        27327.0195, 27336.0352, 27341.0449, 27333.6582, 27341.5059, 27324.3672,\n",
            "        27330.7500, 27356.8613, 27362.2305, 27345.8770, 27358.2402, 27353.2539,\n",
            "        27346.1074, 27354.2441, 27357.3105, 27326.9746, 27318.7949, 27333.6074,\n",
            "        27320.4629, 27360.3535, 27324.3301, 27345.8535, 27324.8477, 27348.3730,\n",
            "        27342.7812, 27346.9551, 27351.3125, 27353.9395, 27359.9297, 27332.9844],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 0.0000e+00, 8.5485e-31, 0.0000e+00, 0.0000e+00, 5.9948e-40,\n",
            "        0.0000e+00, 5.1739e-06, 0.0000e+00, 1.8184e-24, 2.1549e-25, 2.5148e-11,\n",
            "        0.0000e+00, 0.0000e+00, 7.6651e-42, 6.4897e-32, 1.6970e-42, 1.2945e-11,\n",
            "        2.6236e-28, 0.0000e+00, 0.0000e+00, 1.1039e-31, 8.7590e-12, 0.0000e+00,\n",
            "        0.0000e+00, 9.9999e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2289e-06, 1.7940e-23, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.6004e-29, 5.9178e-35, 3.3952e-28, 8.6910e-38, 1.3938e-39, 2.1718e-25,\n",
            "        2.2699e-30, 0.0000e+00, 0.0000e+00, 2.4878e-31, 1.6009e-40, 1.1304e-16,\n",
            "        2.0955e-16, 1.6497e-22, 3.2613e-36, 0.0000e+00, 4.4097e-30, 0.0000e+00,\n",
            "        0.0000e+00, 2.3251e-26, 4.0514e-22, 4.2701e-23, 3.4695e-14, 2.6585e-18,\n",
            "        8.0210e-39, 6.9644e-17, 5.2333e-08, 1.1639e-17, 0.0000e+00, 1.6697e-20,\n",
            "        6.7218e-19, 5.1896e-38, 9.4879e-26, 1.3149e-11, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [25]\n",
            "DEBUGGING: logits looks like: tensor([27330.9570, 27289.8340, 27349.5117, 27306.3711, 27194.3965, 27344.2422,\n",
            "        27216.1719, 27363.7773, 27241.6426, 27353.1543, 27352.6211, 27360.7188,\n",
            "        27321.9219, 27333.3457, 27343.1523, 27348.8672, 27342.7754, 27360.5527,\n",
            "        27350.9434, 27306.7812, 27296.1074, 27349.0000, 27360.4551, 27330.5430,\n",
            "        27284.1426, 27366.8203, 27248.8066, 27323.5527, 27317.6172, 27320.4531,\n",
            "        27289.2812, 27324.9805, 27306.4746, 27297.9688, 27294.3906, 27333.0391,\n",
            "        27286.9102, 27333.6855, 27328.4277, 27363.4180, 27353.7266, 27263.8145,\n",
            "        27339.2441, 27303.3633, 27306.5195, 27327.2812, 27337.6074, 27319.1230,\n",
            "        27350.2441, 27347.1172, 27351.0078, 27345.4863, 27344.4531, 27352.6230,\n",
            "        27349.7559, 27259.1426, 27330.9570, 27349.2031, 27343.9121, 27357.6406,\n",
            "        27357.7949, 27354.2812, 27346.3926, 27327.6094, 27349.9219, 27339.8926,\n",
            "        27340.2188, 27352.0645, 27354.5059, 27353.9434, 27359.0723, 27356.7031,\n",
            "        27344.8906, 27357.5195, 27362.6289, 27357.0723, 27336.0078, 27355.4355,\n",
            "        27356.3594, 27345.3574, 27352.4160, 27360.5566, 27322.8535, 27305.9375,\n",
            "        27275.9980, 27257.0918], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.9569e-23, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8897e-39, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 4.0053e-31, 6.1774e-07, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.1958e-42, 0.0000e+00, 0.0000e+00, 1.0553e-30, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6712e-38, 0.0000e+00,\n",
            "        3.3046e-37, 0.0000e+00, 9.9431e-37, 0.0000e+00, 4.7922e-20, 4.4388e-23,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2033e-01, 3.3911e-43,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4948e-13, 0.0000e+00, 0.0000e+00,\n",
            "        1.6197e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3541e-08,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0651e-07, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4519e-38, 9.8509e-34, 9.8509e-34,\n",
            "        7.3008e-39, 3.7863e-02, 0.0000e+00, 8.4181e-01, 0.0000e+00, 0.0000e+00,\n",
            "        6.2428e-28, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [85]\n",
            "DEBUGGING: logits looks like: tensor([27374.7871, 27327.1348, 27359.5879, 27351.8105, 27365.4648, 27350.7324,\n",
            "        27249.6699, 27356.1777, 27285.6406, 27333.4980, 27336.7656, 27282.9492,\n",
            "        27349.7773, 27370.2578, 27384.1816, 27313.9766, 27360.8945, 27347.3457,\n",
            "        27355.5605, 27329.0000, 27272.9375, 27350.2871, 27313.9688, 27357.2832,\n",
            "        27363.7754, 27269.5547, 27348.6738, 27370.5000, 27324.0762, 27337.1309,\n",
            "        27316.1230, 27319.7188, 27299.8301, 27341.7871, 27366.0098, 27334.3789,\n",
            "        27366.7559, 27339.9082, 27367.0312, 27339.0781, 27376.6348, 27374.8887,\n",
            "        27335.3789, 27360.4883, 27339.6406, 27335.2402, 27387.2266, 27363.3086,\n",
            "        27354.4922, 27355.2148, 27321.3477, 27355.4336, 27320.8086, 27353.2617,\n",
            "        27339.4199, 27355.7754, 27262.4453, 27380.3730, 27325.8848, 27335.7090,\n",
            "        27380.9688, 27352.0703, 27343.3105, 27340.3555, 27330.3184, 27383.2266,\n",
            "        27307.7051, 27325.9668, 27335.1016, 27335.5098, 27319.7012, 27318.5117,\n",
            "        27313.1523, 27330.2051, 27332.3711, 27327.2168, 27383.7422, 27356.3086,\n",
            "        27351.5156, 27350.9199, 27360.9512, 27365.9746, 27368.7559, 27368.7559,\n",
            "        27365.8027, 27386.9375, 27351.1289, 27387.7129, 27358.5977, 27352.9297,\n",
            "        27372.0957, 27331.1992, 27343.3691, 27338.2168, 27340.1699, 27358.9277,\n",
            "        27351.8086, 27334.2246], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.7025e-17, 6.4910e-01, 8.3850e-13, 5.6243e-06, 2.4861e-19, 1.2497e-08,\n",
            "        7.1484e-22, 1.8788e-11, 1.5316e-19, 3.1750e-29, 1.0976e-14, 4.0523e-17,\n",
            "        4.5864e-25, 4.6223e-25, 1.5133e-21, 6.4136e-29, 3.6183e-30, 1.6959e-30,\n",
            "        1.5265e-02, 8.6460e-17, 6.2537e-15, 2.4853e-08, 8.6045e-23, 4.6993e-06,\n",
            "        7.3003e-12, 7.2785e-32, 8.7269e-20, 0.0000e+00, 1.4255e-16, 3.8970e-17,\n",
            "        3.9823e-29, 1.2091e-20, 4.6015e-16, 1.2359e-17, 9.7619e-15, 2.6464e-19,\n",
            "        8.6460e-17, 5.9925e-13, 1.0913e-13, 1.5165e-20, 4.9575e-14, 4.7590e-26,\n",
            "        7.3686e-15, 5.9244e-11, 1.8958e-03, 4.1696e-22, 2.1042e-24, 7.5320e-12,\n",
            "        0.0000e+00, 2.4883e-26, 3.3929e-16, 1.2392e-12, 8.4002e-27, 2.3758e-22,\n",
            "        7.3157e-11, 0.0000e+00, 4.8543e-24, 2.3937e-37, 6.5816e-39, 5.4480e-10,\n",
            "        8.4380e-10, 9.9664e-20, 6.3446e-23, 2.7968e-15, 3.3153e-01, 7.5275e-16,\n",
            "        2.3390e-22, 4.1210e-09, 7.4264e-15, 4.3514e-24, 1.5869e-17, 2.0555e-24,\n",
            "        1.7998e-24, 1.3647e-33, 8.4786e-04, 1.6265e-35, 7.9842e-14, 1.7434e-28,\n",
            "        1.8320e-23, 0.0000e+00, 1.2928e-03, 5.9192e-30, 5.1830e-30, 5.1830e-30,\n",
            "        2.1143e-18, 1.0600e-12, 1.2381e-31, 1.3618e-08, 2.0922e-23, 1.8670e-14,\n",
            "        1.1878e-21, 4.7605e-37, 7.2285e-39, 1.2572e-20, 1.8614e-08, 5.6890e-34,\n",
            "        2.6897e-15, 8.7348e-27, 6.8869e-10, 2.1245e-12, 1.3545e-18, 5.6839e-27,\n",
            "        1.2237e-18, 1.6382e-13, 5.9066e-05, 6.5146e-29, 2.9550e-26],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [64]\n",
            "DEBUGGING: logits looks like: tensor([27394.5977, 27404.1426, 27397.2988, 27401.2285, 27393.5410, 27399.7012,\n",
            "        27392.0781, 27398.0762, 27393.4199, 27387.8457, 27396.2148, 27394.8145,\n",
            "        27390.2402, 27390.2422, 27392.2656, 27388.0215, 27387.3027, 27387.1133,\n",
            "        27403.2051, 27395.0039, 27396.0742, 27399.8730, 27391.5488, 27401.1836,\n",
            "        27397.8398, 27386.3262, 27393.2793, 27374.3555, 27395.1289, 27394.8047,\n",
            "        27387.9023, 27392.7852, 27395.4219, 27394.5176, 27396.1855, 27393.5566,\n",
            "        27395.0039, 27397.2148, 27396.7891, 27392.8418, 27396.5918, 27389.6738,\n",
            "        27396.1152, 27398.3633, 27402.6836, 27391.9434, 27390.6211, 27397.8477,\n",
            "        27371.0078, 27389.5117, 27395.3457, 27397.3965, 27389.2402, 27391.8027,\n",
            "        27398.4160, 27375.1875, 27390.8301, 27383.1699, 27382.2715, 27398.9180,\n",
            "        27399.0273, 27393.3125, 27391.4727, 27395.8730, 27403.9746, 27395.5449,\n",
            "        27391.7988, 27399.4238, 27396.1172, 27390.8027, 27394.5801, 27390.6152,\n",
            "        27390.5820, 27385.3320, 27402.4824, 27384.2246, 27396.7109, 27388.2715,\n",
            "        27391.1621, 27361.9316, 27402.5879, 27387.4258, 27387.3926, 27387.3926,\n",
            "        27394.0762, 27397.3574, 27386.4590, 27399.7227, 27391.1953, 27396.3477,\n",
            "        27392.2051, 27383.3418, 27382.2949, 27392.7949, 27399.8008, 27385.1133,\n",
            "        27395.8633, 27389.2500, 27398.9766, 27397.5312, 27393.9648, 27389.1426,\n",
            "        27393.9395, 27396.8906, 27401.8164, 27388.0254, 27389.5547],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.7058461509368499 and immediate abs rewards look like: [0.7058461509227527, 1.8189894035458565e-12, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 9.094947017729282e-13, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 1.3642420526593924e-12, 0.0, 9.094947017729282e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 0.0, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.547473508864641e-13, 4.547473508864641e-13, 4.547473508864641e-13, 0.0, 4.547473508864641e-13, 0.0, 0.0]\n",
            "DEBUGGING: the total relative reward of the trajectory = 2.608596763821102 and immediate relative rewards look like: [2.608596762540988, 1.8189894035470972e-11, 6.821210263295411e-12, 9.094947017729282e-12, 1.1368683772164188e-11, 1.3642420526593924e-11, 3.1832314562059726e-11, 1.818989403545443e-11, 0.0, 0.0, 2.5011104298755527e-11, 8.185452315954493e-11, 0.0, 6.366462912413393e-11, 0.0, 3.637978807091713e-11, 3.865352482534066e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2295945351943374e-11, 5.4569682106363287e-11, 5.6843418860808015e-11, 5.911715561525378e-11, 0.0, 6.366462912410498e-11, 0.0, 0.0, 7.048583938738591e-11, 0.0, 7.503331289626658e-11, 7.730704965068132e-11, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.000444171950221e-10, 1.0231815394947769e-10, 1.0459189070388675e-10, 0.0, 1.0913936421272657e-10, 0.0, 0.0]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 200 number of matrices\n",
            "DEBUGGING: ACT_MAT has 200 number of matrices\n",
            "DEBUGGING: VAL looks like: [[2.6085967636386185, 1.108717390622331e-09, 1.1015429258453132e-09, 1.105779510688907e-09, 1.1077621855264422e-09, 1.1074681835901796e-09, 1.104874508145036e-09, 1.083881003619168e-09, 1.0764556662461754e-09, 1.0873289558042175e-09, 1.0983120765699166e-09, 1.084142396233496e-09, 1.012411993003991e-09, 1.022638376771708e-09, 9.686603511591658e-10, 9.784447991506725e-10, 9.515808192724802e-10, 9.22148782269838e-10, 9.314634164341798e-10, 9.408721378123028e-10, 9.503758967801038e-10, 9.599756533132363e-10, 9.69672377084077e-10, 9.266428603354886e-10, 8.808819982112377e-10, 8.323622013640704e-10, 7.810556017664815e-10, 7.889450522893752e-10, 7.326064880457275e-10, 7.400065535815429e-10, 7.474813672540838e-10, 6.838338665320181e-10, 6.907412793252708e-10, 6.219272388171759e-10, 5.501214031984794e-10, 5.556781850489692e-10, 5.612910960090598e-10, 5.669607030394544e-10, 5.726875788277317e-10, 5.784723018461937e-10, 5.843154564102966e-10, 4.960527772510823e-10, 4.0460185208576073e-10, 4.086887394805664e-10, 3.1176194170256996e-10, 2.1155938156878005e-10, 1.080479705705993e-10, 1.0913936421272657e-10, 0.0, 0.0], [2.1448043271192323, 1.8582447897233905, 1.0145819571273476, 1.010618111122463, 0.8851853812192558, 0.88585415465615, 0.8716749784615597, 0.7339331579905023, 0.48094271399783445, 0.4635591663575244, 0.45558907214711464, 0.41367015100378973, 0.3997462079551879, 0.38004733813701846, 0.3805758943932211, 0.38395909119231164, 0.3726212064264632, 0.3585709977488635, 0.32454991320955656, 0.3185525134628932, 0.29971921469544505, 0.2715629177922339, 0.2639007458443849, 0.2191002764658403, 0.21563656848341423, 0.21548077498262203, 0.21707054608371765, 0.21647714272077834, 0.19711889318840176, 0.1637353492876865, 0.14220839330509655, 0.14010284763431108, 0.1379451272174893, 0.1198363073751146, 0.09809342568733981, 0.08816983474067436, 0.0783858643451419, 0.07073488377981826, 0.06683147649684212, 0.0464815488841846, 0.028842962277312978, 0.027055104129872307, 0.026427837986697816, 0.025485961277138244, 0.023794964166919712, 0.02353468898312238, 0.023760050669915104, 0.023940675519354953, 0.02199960950347763, 0.0189926701855593], [3.2260389669962555, 3.229331257754616, 3.1924648054258995, 3.1710872200141083, 2.8768945121652476, 2.8793768665001, 2.888580454961008, 2.8353295201612507, 2.6736403717923536, 2.4476032929574068, 2.2737246609018644, 2.2840005497742126, 1.8339154076837847, 1.832354235757955, 1.23948795709585, 1.213206690879126, 1.2220570920926823, 1.1740292545582738, 0.9432683398919489, 0.6753757286317803, 0.5125918420242515, 0.5061066406671089, 0.5025268680727056, 0.4609959446137016, 0.45356980698743266, 0.4395077568909019, 0.4029009345655754, 0.3817171692803978, 0.2850315598463966, 0.161591604533822, 0.13006209120400394, 0.1247416289540008, 0.11727768368418978, 0.09670428839153633, 0.09644139343715513, 0.0937685980686679, 0.06355414211321044, 0.06316188481019538, 0.01696908492191435, 0.015088183709301607, 0.015136307004051289, 0.013544498057106115, 0.01350767839154017, 0.013217373539232049, 0.012195515746283341, 0.011904469576253405, 0.00649446723831764, 0.0024103895129061427, 0.002128283566397982, 0.00017869681150771183], [2.6085967635130087, 9.818390032962338e-10, 9.73382938647235e-10, 9.763249781655955e-10, 9.77000031462491e-10, 9.753851996871988e-10, 9.714573526874797e-10, 9.491162001266868e-10, 9.40329602112356e-10, 9.498278809215717e-10, 9.594221019409816e-10, 9.43849492567905e-10, 8.707019893013739e-10, 8.794969588902766e-10, 8.240730603698411e-10, 8.323970306766072e-10, 8.040578208138284e-10, 7.73135652513624e-10, 7.809451035491152e-10, 7.888334379283991e-10, 7.968014524529284e-10, 8.04849951972655e-10, 8.129797494673283e-10, 7.683674789044292e-10, 7.210078755536019e-10, 6.708731885785797e-10, 6.179353868316423e-10, 6.241771584158003e-10, 5.661742720118135e-10, 5.718932040523369e-10, 5.776699030831686e-10, 5.123071350462451e-10, 5.174819545921667e-10, 4.4691781989484865e-10, 3.7334421236784577e-10, 3.7711536602812705e-10, 3.809246121496233e-10, 3.8477233550467e-10, 3.8865892475219194e-10, 3.9258477247696154e-10, 3.9655027522925406e-10, 4.005558335649031e-10, 4.0460185208576073e-10, 4.086887394805664e-10, 3.1176194170256996e-10, 2.1155938156878005e-10, 1.080479705705993e-10, 1.0913936421272657e-10, 0.0, 0.0]]\n",
            "DEBUGGING: traj_returns = [2.6085967636386185, 2.1448043271192323, 3.2260389669962555, 2.6085967635130087]\n",
            "DEBUGGING: actions = [[0], [5], [17], [17], [18], [0], [11], [65], [17], [57], [1], [69], [66], [0], [44], [19], [22], [3], [10], [46], [12], [66], [22], [17], [44], [78], [13], [7], [17], [25], [81], [7], [16], [0], [79], [92], [3], [86], [53], [87], [0], [99], [32], [19], [84], [31], [64], [63], [47], [64], [17], [14], [41], [3], [41], [22], [7], [65], [58], [8], [23], [8], [8], [3], [2], [3], [14], [1], [49], [66], [76], [3], [23], [14], [79], [58], [1], [76], [76], [14], [42], [49], [25], [83], [89], [22], [11], [18], [92], [41], [18], [2], [2], [9], [54], [23], [104], [46], [1], [26], [43], [36], [3], [18], [43], [3], [24], [3], [65], [20], [17], [18], [56], [16], [20], [27], [13], [24], [69], [66], [75], [38], [73], [30], [32], [76], [4], [16], [37], [18], [36], [89], [78], [24], [91], [5], [31], [10], [65], [65], [61], [67], [25], [30], [93], [59], [70], [34], [90], [1], [0], [5], [17], [62], [18], [0], [11], [11], [17], [57], [1], [1], [66], [0], [44], [19], [22], [3], [10], [46], [12], [66], [22], [17], [44], [78], [13], [7], [82], [25], [17], [7], [16], [0], [79], [92], [3], [86], [53], [85], [91], [78], [32], [33], [84], [31], [64], [63], [47], [64]]\n",
            "DEBUGGING: actions length = 200\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[-32.1346,  56.3997, -60.0018,  ...,  47.9761,  61.7711, -30.4085],\n",
            "        [-32.4963,  57.0417, -60.6768,  ...,  48.5210,  62.4701, -30.7534],\n",
            "        [-33.3561,  58.5644, -62.2800,  ...,  49.8127,  64.1282, -31.5718],\n",
            "        ...,\n",
            "        [-32.9905,  57.9128, -61.6007,  ...,  49.2620,  63.4220, -31.2207],\n",
            "        [-32.9891,  57.9105, -61.5982,  ...,  49.2601,  63.4194, -31.2194],\n",
            "        [-32.9884,  57.9090, -61.5968,  ...,  49.2588,  63.4179, -31.2186]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[-32.9765,  57.8878, -61.5744,  ...,  49.2408,  63.3948, -31.2072],\n",
            "        [-32.9879,  57.9081, -61.5958,  ...,  49.2580,  63.4168, -31.2181],\n",
            "        [-32.9796,  57.8936, -61.5804,  ...,  49.2457,  63.4010, -31.2103],\n",
            "        ...,\n",
            "        [-32.9851,  57.9031, -61.5906,  ...,  49.2538,  63.4115, -31.2154],\n",
            "        [-32.9685,  57.8739, -61.5597,  ...,  49.2290,  63.3796, -31.1997],\n",
            "        [-32.9703,  57.8771, -61.5631,  ...,  49.2317,  63.3831, -31.2015]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([27394.5977, 27404.1426, 27397.2988, 27401.2285, 27393.5410, 27399.7012,\n",
            "        27392.0781, 27398.0762, 27393.4199, 27387.8457, 27396.2148, 27394.8145,\n",
            "        27390.2402, 27390.2422, 27392.2656, 27388.0215, 27387.3027, 27387.1133,\n",
            "        27403.2051, 27395.0039, 27396.0742, 27399.8730, 27391.5488, 27401.1836,\n",
            "        27397.8398, 27386.3262, 27393.2793, 27374.3555, 27395.1289, 27394.8047,\n",
            "        27387.9023, 27392.7852, 27395.4219, 27394.5176, 27396.1855, 27393.5566,\n",
            "        27395.0039, 27397.2148, 27396.7891, 27392.8418, 27396.5918, 27389.6738,\n",
            "        27396.1152, 27398.3633, 27402.6836, 27391.9434, 27390.6211, 27397.8477,\n",
            "        27371.0078, 27389.5117, 27395.3457, 27397.3965, 27389.2402, 27391.8027,\n",
            "        27398.4160, 27375.1875, 27390.8301, 27383.1699, 27382.2715, 27398.9180,\n",
            "        27399.0273, 27393.3125, 27391.4727, 27395.8730, 27403.9746, 27395.5449,\n",
            "        27391.7988, 27399.4238, 27396.1172, 27390.8027, 27394.5801, 27390.6152,\n",
            "        27390.5820, 27385.3320, 27402.4824, 27384.2246, 27396.7109, 27388.2715,\n",
            "        27391.1621, 27361.9316, 27402.5879, 27387.4258, 27387.3926, 27387.3926,\n",
            "        27394.0762, 27397.3574, 27386.4590, 27399.7227, 27391.1953, 27396.3477,\n",
            "        27392.2051, 27383.3418, 27382.2949, 27392.7949, 27399.8008, 27385.1133,\n",
            "        27395.8633, 27389.2500, 27398.9766, 27397.5312, 27393.9648, 27389.1426,\n",
            "        27393.9395, 27396.8906, 27401.8164, 27388.0254, 27389.5547],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[2.64700921 1.27189401 1.05176169 1.04542633 0.94051997 0.94130776\n",
            "  0.94006386 0.89231567 0.78864577 0.72779062 0.68232843 0.67441768\n",
            "  0.5584154  0.55310039 0.40501596 0.39929145 0.39866958 0.38315006\n",
            "  0.31695456 0.24848206 0.20307776 0.19441739 0.1916069  0.17002406\n",
            "  0.16730159 0.16374713 0.15499287 0.14954858 0.12053761 0.08133174\n",
            "  0.06806762 0.06621112 0.0638057  0.05413515 0.04863371 0.04548461\n",
            "  0.035485   0.03347419 0.02095014 0.01539243 0.01099482 0.0101499\n",
            "  0.00998388 0.00967583 0.00899762 0.00885979 0.00756363 0.00658777\n",
            "  0.00603197 0.00479284]]\n",
            "DEBUGGING: baseline2 looks like: 2.647009205316779\n",
            "DEBUGGING: ADS looks like: [ -9.79254896 -12.31467906 -12.27475765 -11.96266991 -11.76665512\n",
            " -11.71522297 -11.67957089 -11.29148191 -11.13622376 -10.78641401\n",
            " -10.81181522 -10.21493981  -9.92198778  -9.38184558  -9.1524663\n",
            "  -9.07400867  -8.55517579  -8.58586799  -8.36633557  -8.07041237\n",
            "  -7.52987112  -7.23267223  -7.24310231  -7.22534907  -7.26094879\n",
            "  -7.28539255  -6.27096139  -6.27998705  -5.93401877  -5.77187178\n",
            "  -5.61815194  -5.60893335  -5.6332838   -5.08418563  -4.50797783\n",
            "  -4.52030801  -3.8956644   -3.9054467   -3.9277835   -3.73460699\n",
            "  -3.74488071  -3.05697733  -3.05849871  -3.06511379  -1.91816883\n",
            "  -1.90923931  -1.4993769   -1.50039501  -0.87227113  -0.85842497\n",
            " -10.2563414  -10.45643427 -11.2601757  -10.9520518  -10.88146974\n",
            " -10.82936882 -10.80789591 -10.55754875 -10.65528105 -10.32285484\n",
            " -10.35622615  -9.80126966  -9.52224157  -9.00179824  -8.77189041\n",
            "  -8.69004958  -8.18255458  -8.227297    -8.04178565  -7.75185986\n",
            "  -7.2301519   -6.96110932  -6.97920157  -7.0062488   -7.04531222\n",
            "  -7.06991178  -6.05389084  -6.06350991  -5.73689988  -5.60813643\n",
            "  -5.47594355  -5.46883051  -5.49533867  -4.96434933  -4.40988441\n",
            "  -4.43213818  -3.81727854  -3.83471181  -3.86095203  -3.68812544\n",
            "  -3.71603775  -3.02992223  -3.03207087  -3.03962783  -1.89437386\n",
            "  -1.88570462  -1.47561685  -1.47645434  -0.85027152  -0.8394323\n",
            "  -9.17510676  -9.08534781  -9.08229285  -8.7915827   -8.88976061\n",
            "  -8.83584611  -8.79099043  -8.45615239  -8.46258339  -8.33881072\n",
            "  -8.53809056  -7.93093926  -8.08807237  -7.54949134  -7.91297835\n",
            "  -7.86080198  -7.3331187   -7.41183874  -7.42306723  -7.39503664\n",
            "  -7.01727928  -6.72656559  -6.74057545  -6.76435313  -6.80737898\n",
            "  -6.8458848   -5.86806045  -5.89826988  -5.64898721  -5.61028017\n",
            "  -5.48808985  -5.48419172  -5.51600612  -4.98748134  -4.41153644\n",
            "  -4.42653941  -3.83211026  -3.84228481  -3.91081442  -3.7195188\n",
            "  -3.72974441  -3.04343283  -3.04499103  -3.05189642  -1.90597331\n",
            "  -1.89733484  -1.49288244  -1.49798462  -0.87014284  -0.85824627\n",
            "  -9.79254896 -12.31467906 -12.27475765 -11.96266991 -11.76665512\n",
            " -11.71522297 -11.67957089 -11.29148191 -11.13622376 -10.78641401\n",
            " -10.81181522 -10.21493981  -9.92198778  -9.38184558  -9.1524663\n",
            "  -9.07400867  -8.55517579  -8.58586799  -8.36633557  -8.07041237\n",
            "  -7.52987112  -7.23267223  -7.24310231  -7.22534907  -7.26094879\n",
            "  -7.28539256  -6.27096139  -6.27998705  -5.93401877  -5.77187178\n",
            "  -5.61815194  -5.60893335  -5.6332838   -5.08418563  -4.50797783\n",
            "  -4.52030801  -3.8956644   -3.9054467   -3.9277835   -3.73460699\n",
            "  -3.74488071  -3.05697733  -3.05849871  -3.06511379  -1.91816883\n",
            "  -1.90923931  -1.4993769   -1.50039501  -0.87227113  -0.85842497]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(-4.9644, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.0404, -0.1247, -0.1078,  ...,  0.1513,  0.0211,  0.1320],\n",
            "        [ 0.0465, -0.1436, -0.1241,  ...,  0.1742,  0.0243,  0.1522],\n",
            "        [ 0.0587, -0.1812, -0.1566,  ...,  0.2197,  0.0306,  0.1908],\n",
            "        ...,\n",
            "        [ 0.0830, -0.2562, -0.2214,  ...,  0.3108,  0.0433,  0.2729],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0813,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0882,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1034,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1464,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1584,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1858,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1518,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.1657,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1938,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0740,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0802,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0946,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1408,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1535,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1792,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.1860,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.2021,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.2363,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1141,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1236,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1452,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1222,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1332,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.1561,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1585,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.1718,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.2016,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0790,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0858,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.1005,  0.0000,  0.0000,  0.0000]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.0662, -0.1594,  0.0373,  ...,  0.0384, -0.0553,  0.0109],\n",
            "        [ 0.0756, -0.1821,  0.0426,  ...,  0.0439, -0.0632,  0.0117],\n",
            "        [ 0.0978, -0.2353,  0.0550,  ...,  0.0567, -0.0816,  0.0170],\n",
            "        ...,\n",
            "        [ 0.1381, -0.3323,  0.0777,  ...,  0.0801, -0.1153,  0.0204],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0104,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0028,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0075,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0223,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0095,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0171,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0181,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0025,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0112,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0099,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0036,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0074,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0175,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0047,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0126,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0263,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0078,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0196,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0136,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0023,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0084,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0182,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0067,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0137,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0230,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0089,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0175,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0122,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0052,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0101,  0.0000,  0.0000,  0.0000]])\n",
            "DEBUGGING: training for one iteration takes 0.008222 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 49\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([1.8283e-40, 0.0000e+00, 2.6964e-15, 2.1790e-42, 9.3128e-20, 1.2612e-44,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1607e-20, 2.8309e-29,\n",
            "        0.0000e+00, 4.5155e-15, 0.0000e+00, 2.8249e-30, 0.0000e+00, 1.2117e-09,\n",
            "        0.0000e+00, 2.1107e-20, 0.0000e+00, 1.0000e+00, 2.3022e-27, 0.0000e+00,\n",
            "        5.1848e-44, 0.0000e+00, 2.9050e-39, 6.9207e-20, 2.1875e-29, 7.5554e-34,\n",
            "        1.5428e-39, 2.9076e-20, 0.0000e+00, 5.6536e-27, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 9.9523e-33, 2.7604e-41, 0.0000e+00, 0.0000e+00,\n",
            "        4.9045e-43, 1.2612e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.7102e-20, 0.0000e+00, 6.2093e-27, 0.0000e+00, 1.4137e-36, 0.0000e+00,\n",
            "        1.8355e-27, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 5.4420e-34, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        2.7388e-15], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [21]\n",
            "DEBUGGING: logits looks like: tensor([28169.8457, 28146.9629, 28184.3340, 28168.7383, 28181.7656, 28167.4629,\n",
            "        28150.0371, 28153.4805, 28142.9980, 28100.8398, 28181.4004, 28176.2871,\n",
            "        28154.6113, 28184.4629, 28159.7441, 28175.7109, 28152.5195, 28187.5879,\n",
            "        28164.2285, 28181.3945, 28164.6641, 28192.7207, 28177.3867, 28165.2676,\n",
            "        28167.8008, 28164.8496, 28170.5371, 28181.6914, 28176.2227, 28173.6543,\n",
            "        28170.3789, 28181.4746, 28160.3027, 28177.6113, 28152.9746, 28147.6816,\n",
            "        28155.4082, 28144.0410, 28174.2988, 28169.3730, 28159.6055, 28149.5117,\n",
            "        28168.3652, 28167.4531, 28161.2500, 28157.7930, 28152.0137, 28163.3203,\n",
            "        28181.4570, 28117.5469, 28177.6348, 28148.2480, 28172.0840, 28166.6738,\n",
            "        28177.3301, 28157.6191, 28153.3906, 28166.7148, 28133.6914, 28165.1875,\n",
            "        28158.3848, 28173.5723, 28153.8691, 28154.0938, 28147.0137, 28142.9961,\n",
            "        28184.3379], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 2.6424e-09, 3.8240e-19, 4.8065e-18, 9.9844e-01, 2.3089e-10,\n",
            "        0.0000e+00, 0.0000e+00, 4.4963e-20, 0.0000e+00, 4.4054e-26, 0.0000e+00,\n",
            "        6.8850e-18, 5.9263e-15, 0.0000e+00, 3.1692e-08, 4.8675e-12, 9.0911e-27,\n",
            "        1.3351e-03, 0.0000e+00, 3.5902e-23, 3.1846e-28, 4.1050e-15, 0.0000e+00,\n",
            "        4.0233e-32, 4.4014e-19, 1.0246e-10, 9.9906e-23, 3.1664e-27, 1.6197e-30,\n",
            "        0.0000e+00, 2.8770e-28, 8.8644e-13, 1.2824e-37, 0.0000e+00, 2.0176e-37,\n",
            "        5.4138e-06, 1.9976e-12, 2.1226e-24, 2.7182e-29, 0.0000e+00, 2.9666e-32,\n",
            "        0.0000e+00, 1.8509e-26, 4.8925e-17, 3.7806e-17, 2.4787e-32, 5.0432e-10,\n",
            "        1.1263e-17, 2.6792e-21, 2.0643e-41, 6.5637e-11, 0.0000e+00, 7.1746e-43,\n",
            "        6.1494e-16, 9.9937e-34, 0.0000e+00, 2.0979e-11, 6.1089e-08, 2.1776e-23,\n",
            "        0.0000e+00, 3.2936e-38, 1.1691e-29, 2.2312e-04, 1.8266e-36, 5.6941e-08,\n",
            "        8.5376e-16, 1.4832e-31, 0.0000e+00, 2.1907e-09, 7.1657e-25, 7.0313e-08,\n",
            "        1.5755e-32, 6.6633e-41, 2.6849e-20, 6.1661e-11],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [4]\n",
            "DEBUGGING: logits looks like: tensor([28110.9434, 28218.6289, 28212.9648, 28213.5977, 28223.5664, 28218.0195,\n",
            "        28184.2344, 28196.0469, 28212.4297, 28176.1270, 28208.9707, 28187.6270,\n",
            "        28213.6875, 28215.3770, 28188.0352, 28219.2500, 28217.0547, 28208.5762,\n",
            "        28221.9121, 28182.3789, 28210.6465, 28207.7383, 28215.2852, 28194.9688,\n",
            "        28205.4941, 28213.0000, 28217.8164, 28210.9023, 28208.3125, 28206.4180,\n",
            "        28181.4238, 28207.7129, 28216.6289, 28202.3301, 28187.7539, 28202.4434,\n",
            "        28220.5352, 28216.8320, 28209.9395, 28207.1230, 28177.6895, 28205.4180,\n",
            "        28178.2910, 28208.7539, 28214.1777, 28214.1133, 28205.3730, 28218.2148,\n",
            "        28213.8105, 28211.7246, 28200.1465, 28217.7051, 28197.3223, 28199.3066,\n",
            "        28214.8105, 28204.5703, 28191.5410, 28217.4199, 28219.4141, 28210.5215,\n",
            "        28197.2559, 28201.9902, 28206.9121, 28221.4648, 28202.9941, 28219.3965,\n",
            "        28214.8926, 28205.8203, 28178.6113, 28218.5820, 28209.6680, 28219.4492,\n",
            "        28205.2598, 28200.4395, 28212.3008, 28217.6895],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.2282e-07, 2.6618e-07, 6.2074e-13, 3.1410e-10, 7.5123e-04,\n",
            "        6.5524e-17, 3.1063e-19, 7.4763e-10, 7.4831e-17, 9.9372e-01, 5.6046e-17,\n",
            "        3.4518e-06, 5.2115e-07, 1.3730e-06, 1.4359e-07, 1.5761e-11, 6.4432e-25,\n",
            "        3.1410e-10, 8.3404e-10, 1.2194e-03, 1.8790e-24, 8.2013e-18, 8.5126e-04,\n",
            "        6.3852e-07, 1.0816e-08, 1.5861e-08, 1.0632e-05, 2.7720e-10, 1.6101e-12,\n",
            "        3.7752e-08, 1.5818e-13, 2.8394e-06, 6.2168e-16, 1.5048e-07, 2.7504e-10,\n",
            "        3.1790e-08, 1.6043e-10, 7.0381e-09, 1.3546e-05, 1.1332e-23, 4.6715e-07,\n",
            "        3.0035e-09, 2.3441e-08, 9.5337e-17, 3.4768e-10, 2.2220e-26, 6.2242e-08,\n",
            "        9.1218e-12, 1.4806e-11, 3.0162e-07, 8.8650e-07, 7.7625e-07, 2.3946e-09,\n",
            "        3.1260e-16, 4.8752e-09, 3.5041e-10, 1.7446e-11, 1.8717e-11, 4.9669e-15,\n",
            "        2.9972e-10, 1.9716e-42, 1.5139e-19, 2.2994e-06, 2.6826e-07, 1.1076e-19,\n",
            "        1.6101e-12, 3.0316e-12, 2.3140e-03, 3.4446e-07, 4.9460e-17, 7.6261e-08,\n",
            "        1.2341e-27, 2.9190e-04, 1.2457e-04, 1.2937e-12, 5.0724e-05, 1.4846e-06,\n",
            "        2.6506e-09, 6.1628e-09, 4.1525e-11, 2.3441e-08, 5.9606e-10, 2.6443e-25,\n",
            "        8.6988e-16, 1.8807e-05, 6.1314e-04, 9.4368e-07, 7.7277e-24],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [10]\n",
            "DEBUGGING: logits looks like: tensor([28119.6523, 28239.0625, 28239.2559, 28236.0137, 28237.5703, 28241.2422,\n",
            "        28233.7246, 28232.3867, 28237.7871, 28233.7578, 28243.0391, 28233.6855,\n",
            "        28239.8965, 28239.4238, 28239.6660, 28239.1016, 28236.8223, 28229.1152,\n",
            "        28237.5703, 28237.8145, 28241.3633, 28229.3828, 28233.2051, 28241.2734,\n",
            "        28239.4746, 28238.4551, 28238.5508, 28240.1777, 28237.5391, 28236.2520,\n",
            "        28238.7676, 28235.6719, 28239.8477, 28234.2871, 28239.1133, 28237.5371,\n",
            "        28238.7246, 28237.4023, 28238.3477, 28240.2383, 28229.8320, 28239.3965,\n",
            "        28238.1348, 28238.6484, 28233.8184, 28237.5957, 28228.2734, 28238.8926,\n",
            "        28236.6855, 28236.8066, 28239.2871, 28239.5566, 28239.5234, 28238.0781,\n",
            "        28234.1152, 28238.2559, 28237.5977, 28236.8477, 28236.8652, 28234.8066,\n",
            "        28237.5586, 28219.0332, 28232.2070, 28239.7949, 28239.2578, 28232.1289,\n",
            "        28236.2520, 28236.4102, 28241.5234, 28239.3203, 28233.6543, 28238.9434,\n",
            "        28227.5508, 28241.0059, 28240.7930, 28236.1973, 28240.5684, 28239.6855,\n",
            "        28238.1035, 28238.3145, 28237.0645, 28238.6484, 28237.7305, 28228.8926,\n",
            "        28234.3711, 28240.3203, 28241.1914, 28239.5723, 28229.7363],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.9781e-08, 4.0783e-02, 3.1543e-09, 3.8312e-02, 8.8014e-04,\n",
            "        8.1866e-05, 8.4287e-06, 3.6591e-09, 5.1897e-10, 4.6255e-09, 5.5045e-08,\n",
            "        1.5080e-07, 1.2423e-10, 6.2149e-06, 6.3394e-04, 2.0655e-06, 1.3110e-03,\n",
            "        9.1191e-02, 4.6283e-05, 6.2038e-18, 2.7637e-05, 3.0877e-08, 6.3394e-04,\n",
            "        5.5344e-24, 4.3115e-09, 1.0559e-13, 2.9252e-04, 5.5710e-06, 9.1851e-06,\n",
            "        1.9282e-09, 2.5506e-06, 0.0000e+00, 6.7971e-08, 4.7480e-04, 4.0783e-02,\n",
            "        3.9731e-07, 5.6147e-06, 9.0617e-05, 6.5841e-12, 2.7307e-07, 4.3166e-01,\n",
            "        1.0490e-05, 3.0655e-04, 1.8672e-02, 1.8344e-03, 1.0738e-05, 1.5559e-07,\n",
            "        6.9835e-10, 2.8089e-01, 4.5116e-06, 8.8518e-05, 6.2863e-08, 4.1575e-04,\n",
            "        7.6171e-17, 8.9535e-07, 7.5441e-03, 1.0655e-05, 5.5710e-06, 0.0000e+00,\n",
            "        6.0801e-09, 1.5048e-08, 8.3330e-04, 4.9938e-06, 1.4205e-02, 5.6192e-43,\n",
            "        5.0939e-04, 3.5200e-20, 3.7991e-06, 4.5374e-07, 1.2600e-07, 4.7182e-07,\n",
            "        1.5415e-04, 8.5384e-11, 5.8966e-05, 7.0129e-08, 2.6411e-08, 2.6166e-05,\n",
            "        5.6232e-09, 4.7480e-04, 2.1279e-03, 3.1676e-07, 3.5284e-04, 2.9357e-06,\n",
            "        3.8508e-07, 5.9055e-08, 1.3129e-06, 1.4775e-13, 8.4948e-06, 5.6673e-09,\n",
            "        3.0859e-12, 3.9731e-07, 2.6770e-09, 3.7481e-05, 6.6578e-29, 2.4163e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [4]\n",
            "DEBUGGING: logits looks like: tensor([28124.7402, 28251.9590, 28255.5938, 28251.5000, 28255.5781, 28254.6348,\n",
            "        28254.0410, 28253.4727, 28251.5371, 28251.0488, 28251.5957, 28252.2148,\n",
            "        28252.4668, 28250.6914, 28253.3965, 28254.5527, 28253.1211, 28254.7344,\n",
            "        28255.7949, 28253.8984, 28246.4883, 28253.7695, 28252.0703, 28254.5527,\n",
            "        28243.0059, 28251.5781, 28248.9238, 28254.3594, 28253.3691, 28253.4941,\n",
            "        28251.3770, 28253.1738, 28217.6113, 28252.2676, 28254.4805, 28255.5938,\n",
            "        28252.7090, 28253.3711, 28254.0664, 28249.9570, 28252.6152, 28256.1836,\n",
            "        28253.5273, 28254.3711, 28255.3984, 28254.8184, 28253.5332, 28252.4746,\n",
            "        28251.1230, 28256.0762, 28253.3164, 28254.0605, 28252.2480, 28254.4473,\n",
            "        28247.1152, 28252.9121, 28255.1719, 28253.5312, 28253.3691, 28220.9727,\n",
            "        28251.6641, 28251.8906, 28254.6211, 28253.3418, 28255.3301, 28232.0723,\n",
            "        28254.4980, 28245.1953, 28253.2734, 28252.7422, 28252.4219, 28252.7520,\n",
            "        28254.1992, 28250.5977, 28253.9590, 28252.2754, 28252.0312, 28253.7559,\n",
            "        28251.6445, 28254.4805, 28254.8555, 28252.6523, 28254.4062, 28253.2090,\n",
            "        28252.7012, 28252.2324, 28253.0078, 28249.0078, 28253.4746, 28251.6465,\n",
            "        28249.7676, 28252.7090, 28251.4590, 28253.8457, 28240.1738, 28255.4629],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000, 0.0156, 0.0033, 0.0176, 0.0129, 0.0032, 0.0022, 0.0044, 0.0032,\n",
            "        0.0014, 0.0087, 0.0067, 0.0095, 0.0093, 0.0019, 0.0027, 0.0110, 0.0072,\n",
            "        0.0003, 0.0156, 0.0050, 0.0034, 0.0005, 0.0110, 0.0063, 0.0081, 0.0092,\n",
            "        0.0032, 0.0082, 0.0074, 0.0029, 0.0140, 0.0051, 0.0163, 0.0008, 0.0002,\n",
            "        0.0174, 0.0029, 0.0032, 0.0101, 0.0058, 0.0343, 0.0036, 0.0104, 0.0098,\n",
            "        0.0032, 0.0049, 0.0011, 0.0295, 0.0103, 0.0098, 0.0221, 0.0091, 0.0106,\n",
            "        0.0070, 0.0056, 0.0006, 0.0017, 0.0126, 0.0265, 0.0140, 0.0014, 0.0269,\n",
            "        0.0009, 0.0356, 0.0052, 0.0078, 0.0127, 0.0107, 0.0077, 0.0149, 0.0143,\n",
            "        0.0001, 0.0112, 0.0065, 0.0074, 0.0075, 0.0070, 0.0056, 0.0135, 0.0127,\n",
            "        0.0714, 0.0194, 0.0023, 0.0153, 0.0128, 0.0064, 0.0034, 0.0032, 0.0132,\n",
            "        0.0022, 0.0024, 0.0021, 0.0036, 0.0098, 0.0110, 0.0046, 0.0028, 0.0085,\n",
            "        0.0042, 0.0237, 0.0114, 0.0036, 0.0145, 0.0194, 0.0017, 0.0078, 0.0055],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [78]\n",
            "DEBUGGING: logits looks like: tensor([28136.1152, 28266.6836, 28266.2930, 28266.7148, 28266.6367, 28266.2910,\n",
            "        28266.1953, 28266.3691, 28266.2891, 28266.0801, 28266.5391, 28266.4727,\n",
            "        28266.5605, 28266.5547, 28266.1582, 28266.2480, 28266.5957, 28266.4902,\n",
            "        28265.6543, 28266.6836, 28266.3984, 28266.3027, 28265.8418, 28266.5977,\n",
            "        28266.4590, 28266.5215, 28266.5508, 28266.2871, 28266.5234, 28266.4980,\n",
            "        28266.2598, 28266.6562, 28266.4023, 28266.6953, 28265.9355, 28265.5605,\n",
            "        28266.7109, 28266.2656, 28266.2871, 28266.5762, 28266.4355, 28266.8809,\n",
            "        28266.3164, 28266.5820, 28266.5684, 28266.2891, 28266.3945, 28266.0273,\n",
            "        28266.8438, 28266.5801, 28266.5684, 28266.7715, 28266.5488, 28266.5879,\n",
            "        28266.4824, 28266.4297, 28265.8848, 28266.1348, 28266.6309, 28266.8164,\n",
            "        28266.6562, 28266.0801, 28266.8203, 28265.9609, 28266.8906, 28266.4082,\n",
            "        28266.5098, 28266.6328, 28266.5898, 28266.5078, 28266.6719, 28266.6621,\n",
            "        28265.4297, 28266.6016, 28266.4648, 28266.4980, 28266.5020, 28266.4824,\n",
            "        28266.4258, 28266.6484, 28266.6328, 28267.0645, 28266.7383, 28266.2070,\n",
            "        28266.6797, 28266.6348, 28266.4609, 28266.3066, 28266.2871, 28266.6426,\n",
            "        28266.1953, 28266.2129, 28266.1836, 28266.3164, 28266.5684, 28266.5957,\n",
            "        28266.3809, 28266.2520, 28266.5312, 28266.3555, 28266.7891, 28266.6055,\n",
            "        28266.3203, 28266.6660, 28266.7383, 28266.1367, 28266.5098, 28266.4219],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.17089444808698318 and immediate abs rewards look like: [0.0018197951239926624, 0.0020484290453168796, 0.009805356072774885, 0.07084235528373029, 0.008372851106742019, 0.012517200971160491, 0.004003946936791181, 6.371648260028451e-05, 0.00010270279153701267, 6.717394762745243e-05, 0.00016388236690545455, 0.00022016765387888881, 0.02020632116636989, 0.008210149514070508, 3.7250592413329287e-05, 0.0068469148213807784, 0.0006660456383542623, 0.0024078422866296023, 0.006764786644453125, 0.000599993670675758, 0.00714654417561178, 8.953517499321606e-05, 0.0005057771559222601, 4.2407624277984723e-05, 0.00015929234950817772, 0.00021391250720625976, 0.001062494547568349, 0.00011585388574530953, 0.001289132468173193, 1.7847514754976146e-06, 0.00016715099945940892, 2.2644578166364226e-05, 4.882681832896196e-05, 0.0007774147197778802, 7.3829733082675375e-06, 0.0029011346159677487, 2.5791813641262706e-05, 2.483211392245721e-05, 0.0002026573674811516, 7.1437598307966255e-06, 1.4030782040208578e-05, 2.1933333300694358e-06, 3.554875866029761e-05, 7.1325207500194665e-06, 0.00014181914912114735, 1.695576565907686e-05, 9.335849017588771e-05, 1.6367721400456503e-08, 4.683578026742907e-06, 1.1282372724963352e-07]\n",
            "DEBUGGING: the total relative reward of the trajectory = 5.217005979575694 and immediate relative rewards look like: [0.0058678251582577985, 0.01321784028513575, 0.09496888074636195, 0.9177548212871813, 0.1387706270538436, 0.249643162572333, 0.09355312533507476, 0.0017037055512387977, 0.003089489795343613, 0.0022453176348035454, 0.006025756532791232, 0.008831718523219064, 0.8781587370553151, 0.3868701006056724, 0.001885872292911707, 0.36975001892297404, 0.038304605692712955, 0.14665487201292557, 0.4352689051380209, 0.04073077416066186, 0.509506621102583, 0.006703564578413528, 0.039590383566672216, 0.003464436544040483, 0.013555596146003768, 0.01893288382789649, 0.0976628388779142, 0.011047515636782105, 0.12732352953274986, 0.00018243276748248165, 0.01765528683429475, 0.0024691248714719055, 0.005490407225482891, 0.09006811924609869, 0.0008807523748783432, 0.35598029195290426, 0.003255883351187331, 0.003219484518662399, 0.026966199045198806, 0.0009750111868013357, 0.0019628610418939802, 0.0003143256543481428, 0.005215778266062176, 0.0010708464785996416, 0.021776091801853137, 0.002661514297418438, 0.014972963173298213, 2.6810158172129554e-06, 0.0007831478444609182, 1.9250457644164464e-05]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.1737e-13, 5.9249e-27, 7.3184e-12, 1.8756e-39, 4.1762e-15,\n",
            "        3.2300e-22, 9.9671e-10, 1.0000e+00, 1.9063e-35, 4.9909e-38, 4.5387e-20,\n",
            "        5.1288e-43, 0.0000e+00, 4.5428e-27, 1.4013e-44, 6.6637e-38, 0.0000e+00,\n",
            "        3.3306e-26, 8.7645e-34, 1.3039e-15, 5.3834e-28, 1.9550e-23, 1.1762e-38,\n",
            "        3.9946e-25, 0.0000e+00, 2.2113e-35, 4.7082e-36, 2.8026e-45, 7.7648e-21,\n",
            "        0.0000e+00, 0.0000e+00, 4.2997e-16, 4.0114e-23, 0.0000e+00, 1.5272e-29,\n",
            "        3.1354e-25, 0.0000e+00, 6.7726e-34, 7.0509e-26, 0.0000e+00, 1.7978e-22,\n",
            "        3.2262e-30, 4.7866e-17, 2.2536e-26, 2.9233e-10, 1.4824e-06, 1.4753e-38,\n",
            "        6.3775e-18, 2.4714e-23, 1.4307e-08, 6.7320e-22, 2.3009e-42, 2.0262e-32,\n",
            "        6.5701e-15, 1.6945e-39, 3.8025e-15, 2.5629e-28, 4.6450e-35, 1.3352e-26,\n",
            "        8.7198e-29, 0.0000e+00, 6.6637e-38, 1.1980e-33, 1.0884e-08, 4.4335e-20,\n",
            "        4.3806e-22], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [8]\n",
            "DEBUGGING: logits looks like: tensor([28054.2109, 28109.7383, 28102.0840, 28110.7715, 28094.8887, 28108.9043,\n",
            "        28104.8105, 28112.0000, 28117.1816, 28097.1953, 28095.7090, 28106.0469,\n",
            "        28092.8379, 28081.2715, 28102.0176, 28091.9434, 28095.7812, 28080.3379,\n",
            "        28102.5156, 28098.1523, 28108.6133, 28101.4844, 28104.1094, 28095.3477,\n",
            "        28103.1367, 28059.7051, 28097.2324, 28096.8457, 28091.5410, 28105.6055,\n",
            "        28089.3340, 28090.2383, 28108.3359, 28104.2891, 28080.4141, 28100.5938,\n",
            "        28103.0762, 28082.5117, 28098.0879, 28102.7031, 28084.0859, 28104.6641,\n",
            "        28100.2051, 28107.7871, 28102.4180, 28111.6934, 28113.8262, 28095.4043,\n",
            "        28107.2832, 28104.1680, 28112.6660, 28104.9941, 28093.2129, 28098.9375,\n",
            "        28109.0176, 28094.8633, 28108.8809, 28101.2988, 28097.4180, 28102.2871,\n",
            "        28101.0293, 28087.9766, 28095.7812, 28098.2305, 28112.5977, 28106.0410,\n",
            "        28104.8867], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 2.3009e-08, 5.0001e-03, 2.4092e-01, 8.8842e-12, 4.8608e-09,\n",
            "        1.6738e-07, 9.0485e-07, 6.0658e-04, 8.6654e-09, 2.1038e-06, 3.7449e-03,\n",
            "        2.3626e-14, 5.2149e-09, 7.3013e-05, 2.9008e-13, 3.1384e-09, 1.4015e-06,\n",
            "        8.4215e-04, 8.6109e-12, 3.3619e-06, 5.1263e-06, 1.4972e-08, 1.3016e-04,\n",
            "        1.9889e-03, 6.0658e-04, 8.6031e-05, 6.9775e-08, 2.7738e-12, 1.6469e-11,\n",
            "        1.8995e-10, 3.2772e-07, 5.6099e-04, 2.5415e-09, 2.2288e-12, 3.5106e-04,\n",
            "        7.6541e-16, 1.5972e-07, 5.7068e-07, 3.5392e-15, 9.9948e-08, 2.0306e-08,\n",
            "        2.5777e-06, 2.6619e-13, 3.3288e-07, 2.8413e-08, 4.2168e-06, 1.2563e-06,\n",
            "        2.4092e-01, 2.3190e-08, 1.0474e-07, 7.5762e-06, 1.4074e-04, 1.9347e-05,\n",
            "        2.9253e-09, 1.8098e-07, 6.6740e-18, 1.7615e-05, 6.8158e-08, 1.5578e-04,\n",
            "        3.5509e-06, 1.3036e-07, 2.5127e-07, 1.0116e-05, 2.8592e-05, 3.4739e-09,\n",
            "        3.1716e-04, 4.8186e-02, 1.7207e-05, 1.0337e-17, 1.0768e-05, 5.7845e-08,\n",
            "        4.5691e-05, 1.4573e-06, 2.1428e-01, 2.4092e-01, 7.2664e-11, 3.2448e-08,\n",
            "        7.1990e-08, 5.1759e-20], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [48]\n",
            "DEBUGGING: logits looks like: tensor([28061.2207, 28119.5352, 28122.6074, 28123.5762, 28117.5703, 28119.1465,\n",
            "        28120.0312, 28120.4531, 28122.0801, 28119.2910, 28120.6641, 28122.5352,\n",
            "        28116.0879, 28119.1641, 28121.5508, 28116.7148, 28119.0371, 28120.5625,\n",
            "        28122.1621, 28117.5625, 28120.7812, 28120.8867, 28119.4277, 28121.6953,\n",
            "        28122.3770, 28122.0801, 28121.5918, 28119.8125, 28117.2793, 28117.7246,\n",
            "        28118.3359, 28120.1992, 28122.0605, 28118.9844, 28117.2246, 28121.9434,\n",
            "        28115.2305, 28120.0195, 28120.3379, 28115.6133, 28119.9023, 28119.5039,\n",
            "        28120.7148, 28116.6934, 28120.2031, 28119.5879, 28120.8379, 28120.5352,\n",
            "        28123.5762, 28119.5371, 28119.9141, 28120.9844, 28121.7148, 28121.2188,\n",
            "        28119.0195, 28120.0508, 28114.0449, 28121.1953, 28119.8066, 28121.7402,\n",
            "        28120.7949, 28119.9688, 28120.1328, 28121.0566, 28121.3164, 28119.0625,\n",
            "        28121.9180, 28123.1738, 28121.1895, 28114.1543, 28121.0723, 28119.7656,\n",
            "        28121.4336, 28120.5723, 28123.5469, 28123.5762, 28118.0957, 28119.6211,\n",
            "        28119.8203, 28112.8301], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 3.0511e-02, 2.4326e-02, 1.3329e-02, 1.2191e-11, 5.2199e-03,\n",
            "        3.0797e-05, 5.9113e-07, 2.0763e-03, 3.0862e-04, 5.0989e-03, 7.0241e-03,\n",
            "        7.0241e-03, 1.4495e-03, 3.3520e-13, 7.2080e-13, 3.8489e-03, 1.2819e-02,\n",
            "        1.4465e-04, 3.9402e-03, 4.5707e-03, 4.3274e-03, 5.5133e-03, 5.3212e-05,\n",
            "        2.9510e-03, 1.0941e-03, 2.0807e-02, 5.3021e-03, 8.0847e-03, 8.4067e-03,\n",
            "        6.8614e-03, 2.0794e-06, 1.6078e-02, 1.0710e-02, 1.7937e-02, 1.4870e-02,\n",
            "        5.3021e-03, 1.0381e-02, 2.9510e-03, 3.1038e-05, 2.1760e-03, 1.6684e-03,\n",
            "        2.7449e-04, 9.1611e-03, 1.4412e-02, 4.9317e-04, 6.2474e-03, 5.7329e-03,\n",
            "        8.7627e-13, 1.8758e-03, 1.4631e-06, 1.3406e-03, 4.5351e-03, 1.1763e-02,\n",
            "        3.3702e-03, 4.1292e-03, 3.6157e-03, 1.5886e-04, 4.6790e-03, 5.0989e-03,\n",
            "        6.3457e-03, 5.4589e-04, 7.6544e-03, 7.7750e-03, 4.3614e-03, 6.5060e-06,\n",
            "        3.9402e-03, 1.7374e-06, 6.1987e-03, 9.0898e-03, 9.7111e-05, 4.0421e-02,\n",
            "        1.0964e-02, 6.4962e-03, 2.6660e-03, 4.1119e-05, 1.9854e-02, 4.6134e-06,\n",
            "        4.5351e-03, 7.4771e-03, 8.2590e-04, 1.0850e-07, 8.6736e-03, 1.1738e-03,\n",
            "        4.5351e-03, 2.6247e-03, 2.0124e-03, 1.0040e-03, 1.1763e-02, 4.8479e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [71]\n",
            "DEBUGGING: logits looks like: tensor([28066.6992, 28128.5000, 28128.4434, 28128.2930, 28123.0898, 28128.0586,\n",
            "        28126.7754, 28125.7871, 28127.8281, 28127.3516, 28128.0527, 28128.1328,\n",
            "        28128.1328, 28127.7383, 28122.1914, 28122.3828, 28127.9824, 28128.2832,\n",
            "        28127.1621, 28127.9883, 28128.0254, 28128.0117, 28128.0723, 28126.9121,\n",
            "        28127.9160, 28127.6680, 28128.4043, 28128.0625, 28128.1680, 28128.1777,\n",
            "        28128.1270, 28126.1016, 28128.3398, 28128.2383, 28128.3672, 28128.3203,\n",
            "        28128.0625, 28128.2305, 28127.9160, 28126.7773, 28127.8398, 28127.7734,\n",
            "        28127.3223, 28128.1992, 28128.3125, 28127.4688, 28128.1035, 28128.0820,\n",
            "        28122.4316, 28127.8027, 28126.0137, 28127.7188, 28128.0234, 28128.2617,\n",
            "        28127.9492, 28128.0000, 28127.9668, 28127.1855, 28128.0312, 28128.0527,\n",
            "        28128.1074, 28127.4941, 28128.1543, 28128.1582, 28128.0137, 28126.3867,\n",
            "        28127.9883, 28126.0566, 28128.1016, 28128.1973, 28127.0625, 28128.5703,\n",
            "        28128.2441, 28128.1133, 28127.8906, 28126.8477, 28128.3926, 28126.3008,\n",
            "        28128.0234, 28128.1484, 28127.5977, 28125.3633, 28128.1855, 28127.6855,\n",
            "        28128.0234, 28127.8867, 28127.8203, 28127.6465, 28128.2617, 28129.1914],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 9.9855e-03, 4.4404e-02, 8.7436e-03, 1.3485e-04, 7.3055e-03,\n",
            "        2.0931e-03, 1.3304e-03, 7.7324e-02, 1.6783e-04, 1.0797e-02, 7.6561e-03,\n",
            "        4.3965e-03, 0.0000e+00, 2.3071e-05, 3.3117e-04, 1.0465e-02, 3.1421e-03,\n",
            "        1.3727e-03, 6.0094e-03, 9.3075e-03, 4.7983e-06, 6.1519e-03, 3.2418e-03,\n",
            "        3.9328e-04, 9.4541e-03, 3.3447e-03, 5.0210e-03, 6.3701e-05, 1.4643e-02,\n",
            "        3.2418e-03, 9.3075e-03, 5.6895e-03, 2.9982e-03, 5.7791e-03, 3.4240e-03,\n",
            "        2.4611e-04, 3.6165e-03, 1.5108e-02, 7.8377e-03, 4.9432e-03, 4.4658e-03,\n",
            "        1.4873e-02, 3.8497e-03, 6.1519e-03, 7.6400e-04, 8.7436e-03, 1.6687e-03,\n",
            "        1.2401e-03, 1.8432e-04, 4.5171e-05, 7.2749e-05, 1.9058e-03, 8.2138e-03,\n",
            "        6.1741e-05, 4.5717e-03, 3.8497e-03, 6.2487e-03, 1.9734e-05, 1.1951e-02,\n",
            "        1.2895e-03, 4.1626e-03, 1.7181e-04, 2.1889e-04, 6.7809e-05, 7.1470e-06,\n",
            "        4.2947e-03, 7.8377e-03, 1.1858e-02, 7.1363e-03, 9.0919e-03, 4.9047e-03,\n",
            "        3.0454e-03, 3.7606e-03, 8.4746e-03, 3.2790e-05, 3.2050e-01, 8.1499e-03,\n",
            "        5.4290e-03, 8.4746e-03, 5.3032e-03, 3.9719e-03, 2.5247e-03, 9.1825e-02,\n",
            "        1.0645e-05, 7.0404e-02, 4.0031e-03, 1.9358e-03, 1.1926e-03, 1.8185e-03,\n",
            "        8.7436e-03, 3.9328e-04, 5.8702e-03, 4.7168e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [76]\n",
            "DEBUGGING: logits looks like: tensor([28070.9883, 28132.2129, 28132.5859, 28132.1797, 28131.1367, 28132.1348,\n",
            "        28131.8223, 28131.7090, 28132.7246, 28131.1914, 28132.2324, 28132.1465,\n",
            "        28132.0078, 28103.8281, 28130.6953, 28131.3613, 28132.2246, 28131.9238,\n",
            "        28131.7168, 28132.0859, 28132.1953, 28130.3027, 28132.0918, 28131.9316,\n",
            "        28131.4043, 28132.1992, 28131.9395, 28132.0410, 28130.9492, 28132.3086,\n",
            "        28131.9316, 28132.1953, 28132.0723, 28131.9121, 28132.0762, 28131.9453,\n",
            "        28131.2871, 28131.9590, 28132.3164, 28132.1523, 28132.0371, 28132.0117,\n",
            "        28132.3125, 28131.9746, 28132.0918, 28131.5703, 28132.1797, 28131.7656,\n",
            "        28131.6914, 28131.2148, 28130.8633, 28130.9824, 28131.7988, 28132.1641,\n",
            "        28130.9414, 28132.0176, 28131.9746, 28132.0957, 28130.6562, 28132.2578,\n",
            "        28131.7012, 28131.9941, 28131.1973, 28131.2578, 28130.9648, 28130.4023,\n",
            "        28132.0020, 28132.1523, 28132.2559, 28132.1289, 28132.1895, 28132.0352,\n",
            "        28131.9160, 28131.9688, 28132.1719, 28130.7832, 28133.0801, 28132.1621,\n",
            "        28132.0605, 28132.1719, 28132.0547, 28131.9824, 28131.8691, 28132.7676,\n",
            "        28130.5020, 28132.7012, 28131.9844, 28131.8027, 28131.6816, 28131.7871,\n",
            "        28132.1797, 28131.4043, 28132.0801, 28132.0254],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000, 0.0106, 0.0106, 0.0090, 0.0102, 0.0098, 0.0111, 0.0106, 0.0094,\n",
            "        0.0105, 0.0089, 0.0107, 0.0094, 0.0074, 0.0099, 0.0100, 0.0096, 0.0075,\n",
            "        0.0106, 0.0095, 0.0094, 0.0106, 0.0077, 0.0094, 0.0111, 0.0082, 0.0095,\n",
            "        0.0105, 0.0094, 0.0099, 0.0083, 0.0066, 0.0100, 0.0094, 0.0094, 0.0095,\n",
            "        0.0092, 0.0094, 0.0106, 0.0108, 0.0107, 0.0084, 0.0098, 0.0130, 0.0111,\n",
            "        0.0111, 0.0105, 0.0090, 0.0070, 0.0095, 0.0105, 0.0100, 0.0084, 0.0107,\n",
            "        0.0098, 0.0094, 0.0090, 0.0077, 0.0095, 0.0102, 0.0084, 0.0100, 0.0102,\n",
            "        0.0102, 0.0096, 0.0106, 0.0108, 0.0073, 0.0078, 0.0098, 0.0100, 0.0106,\n",
            "        0.0099, 0.0104, 0.0095, 0.0091, 0.0073, 0.0099, 0.0095, 0.0098, 0.0089,\n",
            "        0.0099, 0.0102, 0.0106, 0.0095, 0.0089, 0.0099, 0.0096, 0.0089, 0.0086,\n",
            "        0.0096, 0.0095, 0.0091, 0.0096, 0.0114, 0.0102, 0.0104, 0.0090, 0.0108,\n",
            "        0.0100, 0.0067, 0.0104, 0.0088, 0.0099, 0.0094],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [34]\n",
            "DEBUGGING: logits looks like: tensor([28074.4727, 28135.4062, 28135.4082, 28135.3672, 28135.3984, 28135.3867,\n",
            "        28135.4180, 28135.4062, 28135.3770, 28135.4043, 28135.3633, 28135.4102,\n",
            "        28135.3770, 28135.3164, 28135.3906, 28135.3926, 28135.3828, 28135.3203,\n",
            "        28135.4062, 28135.3809, 28135.3770, 28135.4062, 28135.3281, 28135.3770,\n",
            "        28135.4180, 28135.3438, 28135.3789, 28135.4043, 28135.3770, 28135.3906,\n",
            "        28135.3457, 28135.2891, 28135.3926, 28135.3770, 28135.3770, 28135.3809,\n",
            "        28135.3711, 28135.3770, 28135.4062, 28135.4121, 28135.4102, 28135.3477,\n",
            "        28135.3867, 28135.4590, 28135.4180, 28135.4180, 28135.4043, 28135.3672,\n",
            "        28135.3027, 28135.3789, 28135.4043, 28135.3926, 28135.3477, 28135.4102,\n",
            "        28135.3867, 28135.3770, 28135.3652, 28135.3281, 28135.3809, 28135.3965,\n",
            "        28135.3477, 28135.3926, 28135.3965, 28135.3984, 28135.3828, 28135.4062,\n",
            "        28135.4121, 28135.3125, 28135.3301, 28135.3867, 28135.3926, 28135.4062,\n",
            "        28135.3906, 28135.4023, 28135.3809, 28135.3691, 28135.3125, 28135.3906,\n",
            "        28135.3809, 28135.3867, 28135.3633, 28135.3906, 28135.3965, 28135.4062,\n",
            "        28135.3809, 28135.3633, 28135.3906, 28135.3828, 28135.3633, 28135.3555,\n",
            "        28135.3828, 28135.3789, 28135.3691, 28135.3828, 28135.4258, 28135.3965,\n",
            "        28135.4023, 28135.3672, 28135.4121, 28135.3926, 28135.2930, 28135.4023,\n",
            "        28135.3594, 28135.3906, 28135.3770], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.2999334420373998 and immediate abs rewards look like: [0.1100722757364565, 0.14929593634997218, 0.0015701585562055698, 0.011233944242121652, 0.0005462698982228176, 0.001272452237571997, 0.006908467604489488, 0.010719152047158786, 0.0008111922238640545, 0.0004152135979893501, 0.001387698928510872, 0.0004947823736074497, 0.00048267196120832523, 0.0003167186703194602, 0.0008432839326815156, 0.000209001712164536, 0.00028213175346536445, 0.0006033502445461636, 0.000878829300745565, 7.940912769299757e-05, 9.75854870830517e-05, 8.906477205528063e-06, 4.561927562463097e-05, 1.402613042955636e-05, 0.00014369390100910095, 7.187338064795767e-05, 2.6026331852335716e-05, 0.00013366329017117096, 0.0001170351874861808, 0.00023358046610155725, 1.6501606296515092e-05, 3.027447701242636e-05, 0.000142585993216926, 1.8529077351558954e-05, 4.664741254600813e-05, 3.108001646978664e-05, 1.809700756894017e-05, 9.01727389646112e-06, 3.847069001494674e-05, 1.3040776138950605e-06, 5.545853764488129e-05, 5.725870983042114e-05, 6.891334419378836e-05, 5.839875575475162e-05, 5.627464361168677e-06, 3.1788365504326066e-06, 4.549679715637467e-06, 8.171724175554118e-06, 3.759883838938549e-06, 6.670427410426782e-07]\n",
            "DEBUGGING: the total relative reward of the trajectory = 2.166569669177168 and immediate relative rewards look like: [0.3051419852930756, 0.8538086521673165, 0.014070027116109107, 0.1342845837153998, 0.00818976810966732, 0.022895925979205867, 0.14508115205096248, 0.2577998711326462, 0.022019139303885292, 0.012525984931880936, 0.046055622653362806, 0.017921405128153687, 0.01894248184633054, 0.013387714547053379, 0.03819542611162146, 0.010100123924244602, 0.01448722420423041, 0.03280675699920882, 0.05044970073044259, 0.004799723477684191, 0.006193423076886605, 0.0005921989993796734, 0.0031711473159673357, 0.0010174083542811721, 0.010857413287354359, 0.005648177133177165, 0.00212399284367925, 0.011312274030598871, 0.010259158458702396, 0.02118216878070879, 0.0015464334293501822, 0.0029286812614054388, 0.014224606474447475, 0.0019045873144135687, 0.004935898407604161, 0.0033826765641586445, 0.002024367267158217, 0.001035957761371923, 0.004536061743278392, 0.00015770768501938525, 0.006874511888908428, 0.007270892562697325, 0.008959343310470073, 0.007769082205654613, 0.0007656783752464573, 0.00044212786100684005, 0.0006465482693703433, 0.0011859812008490145, 0.0005570503470754547, 0.00010084354446529597]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0049e-03, 0.0000e+00, 6.1335e-11,\n",
            "        2.8026e-45, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.0786e-40,\n",
            "        2.6699e-09, 2.8791e-40, 1.4307e-42, 4.7014e-26, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 3.8893e-01, 8.0141e-25, 8.2364e-38, 0.0000e+00,\n",
            "        1.3864e-16, 0.0000e+00, 0.0000e+00, 2.4804e-18, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 2.8026e-45, 0.0000e+00, 0.0000e+00, 5.9304e-01,\n",
            "        1.9201e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.4078e-45, 8.8098e-32, 3.6308e-30,\n",
            "        0.0000e+00, 4.7027e-11, 0.0000e+00, 1.4013e-45, 1.3939e-32, 1.5536e-25,\n",
            "        9.0649e-37, 0.0000e+00, 0.0000e+00, 1.0235e-34, 0.0000e+00, 0.0000e+00,\n",
            "        8.8018e-25, 7.4766e-06, 7.4766e-06, 9.0049e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [20]\n",
            "DEBUGGING: logits looks like: tensor([27933.1504, 27978.6230, 27956.9355, 28014.0371, 27976.5605, 28009.3359,\n",
            "        27989.5625, 27978.4004, 27965.8770, 27986.8203, 27814.1367, 27992.7402,\n",
            "        28010.2793, 27992.4531, 27991.1270, 28000.6348, 27963.3262, 27988.8047,\n",
            "        27976.2559, 27972.6680, 28014.9785, 28001.3438, 27993.8672, 27968.6172,\n",
            "        28006.0859, 27979.9668, 27969.0430, 28005.0801, 27974.4922, 27956.3594,\n",
            "        27979.6465, 27984.0820, 27989.6016, 27980.4023, 27975.5469, 28015.0840,\n",
            "        28011.9238, 27975.6953, 27983.1875, 27910.9082, 27985.6758, 27981.7832,\n",
            "        27977.4473, 27957.9062, 27986.3633, 27988.5391, 27979.0215, 27986.6699,\n",
            "        27975.7148, 27958.6348, 27980.9629, 27989.8477, 27997.3379, 27998.2676,\n",
            "        27980.1699, 28009.2695, 27986.0156, 27989.2793, 27996.8770, 28000.9336,\n",
            "        27994.4668, 27976.2520, 27888.6406, 27995.6484, 27976.2539, 27971.2227,\n",
            "        28001.3672, 28012.2637, 28012.2637, 28014.0371],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 9.6555e-20, 1.9889e-06, 8.3035e-10, 5.3194e-10, 4.3078e-10,\n",
            "        4.0129e-14, 1.1930e-15, 9.9022e-08, 2.2975e-08, 1.9446e-39, 1.7578e-09,\n",
            "        2.1095e-04, 2.8895e-03, 8.5004e-10, 4.9167e-14, 5.1588e-06, 9.2687e-06,\n",
            "        2.9858e-32, 6.8879e-06, 1.8673e-10, 1.9877e-10, 1.9254e-14, 7.6772e-25,\n",
            "        4.4606e-12, 7.8404e-15, 1.4295e-07, 3.0345e-02, 1.0100e-05, 9.3218e-07,\n",
            "        1.4964e-15, 3.8199e-04, 2.5684e-07, 2.0379e-13, 7.6427e-16, 1.0503e-05,\n",
            "        2.4143e-03, 9.1497e-01, 2.6183e-09, 3.1308e-02, 7.6242e-06, 1.3935e-08,\n",
            "        5.0182e-08, 9.6322e-10, 1.2298e-08, 6.2862e-42, 5.2638e-41, 9.2495e-33,\n",
            "        9.3218e-07, 3.5488e-13, 8.0989e-07, 4.9374e-12, 4.4099e-10, 2.9794e-07,\n",
            "        1.3731e-15, 8.0528e-06, 4.4285e-08, 1.2551e-02, 1.7505e-11, 3.0829e-44,\n",
            "        1.8422e-09, 6.9755e-26, 1.3935e-34, 5.4702e-19, 0.0000e+00, 1.2089e-05,\n",
            "        2.4590e-24, 3.2429e-15, 3.2148e-08, 3.4345e-10, 9.2382e-15, 1.1007e-05,\n",
            "        1.8306e-12, 8.5004e-10, 9.0486e-10, 4.6174e-03, 4.2987e-11, 2.2632e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [37]\n",
            "DEBUGGING: logits looks like: tensor([27932.4043, 28016.1895, 28023.8535, 28021.9082, 28021.7969, 28021.7441,\n",
            "        28019.4238, 28018.5449, 28023.1035, 28022.7383, 28004.8516, 28022.0957,\n",
            "        28025.0195, 28025.6738, 28021.9141, 28019.4746, 28024.0918, 28024.2383,\n",
            "        28008.9883, 28024.1641, 28021.5352, 28021.5508, 28019.2402, 28013.2539,\n",
            "        28020.6016, 28019.0156, 28023.1953, 28026.2617, 28024.2598, 28023.6641,\n",
            "        28018.6016, 28025.1680, 28023.3418, 28019.8301, 28018.4336, 28024.2695,\n",
            "        28025.6289, 28027.1133, 28022.1953, 28026.2695, 28024.1895, 28022.6133,\n",
            "        28022.9336, 28021.9453, 28022.5820, 28003.4180, 28003.9492, 28008.6953,\n",
            "        28023.6641, 28019.9688, 28023.6289, 28020.6270, 28021.7500, 28023.3789,\n",
            "        28018.5801, 28024.2031, 28022.9023, 28026.0410, 28020.9434, 28002.0859,\n",
            "        28022.1074, 28012.6543, 28007.6465, 28016.6230, 27999.8613, 28024.3047,\n",
            "        28013.5449, 28018.7949, 28022.8223, 28021.6875, 28019.0566, 28024.2812,\n",
            "        28020.3789, 28021.9141, 28021.9297, 28025.7910, 28021.1680, 28025.0371],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.1108e-06, 3.4973e-03, 1.5887e-03, 3.8711e-03, 4.0887e-03,\n",
            "        3.1462e-05, 2.2839e-05, 1.3617e-02, 8.9252e-07, 2.3346e-02, 4.5874e-04,\n",
            "        6.3327e-03, 6.3958e-02, 2.0083e-03, 3.7656e-05, 1.1443e-03, 2.2150e-01,\n",
            "        1.0660e-07, 3.2257e-08, 2.1257e-02, 2.4695e-05, 6.8473e-03, 7.6341e-07,\n",
            "        6.4693e-04, 6.3958e-02, 5.6886e-02, 4.6137e-05, 6.5436e-06, 2.2485e-05,\n",
            "        3.4826e-05, 1.2897e-13, 2.4488e-09, 5.2801e-04, 8.4021e-06, 2.8768e-03,\n",
            "        2.2263e-06, 1.2418e-05, 3.3897e-03, 5.4591e-03, 1.5730e-04, 8.7552e-05,\n",
            "        1.9314e-03, 5.8112e-03, 5.7990e-04, 1.4271e-02, 4.1857e-03, 8.7552e-05,\n",
            "        2.5190e-03, 9.8231e-06, 2.3529e-02, 1.0360e-02, 1.6069e-05, 2.5865e-09,\n",
            "        2.1398e-10, 6.5337e-03, 1.7302e-07, 9.6708e-06, 3.7894e-02, 6.0300e-04,\n",
            "        2.5679e-05, 3.0798e-04, 6.4557e-05, 5.2991e-06, 3.7735e-04, 2.7351e-01,\n",
            "        5.6088e-05, 1.1068e-04, 5.6342e-14, 1.0834e-03, 4.3185e-03, 2.8527e-07,\n",
            "        8.1094e-08, 2.9941e-10, 8.8931e-05, 5.2690e-05, 5.9365e-04, 1.9273e-04,\n",
            "        4.8730e-05, 4.8453e-04, 6.0554e-02, 4.9602e-04, 1.3589e-03, 4.0024e-02,\n",
            "        6.6988e-06, 5.6088e-05, 7.3152e-05, 9.6708e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [83]\n",
            "DEBUGGING: logits looks like: tensor([27939.2051, 28032.3125, 28034.3262, 28034.1289, 28034.3516, 28034.3652,\n",
            "        28033.1484, 28033.0684, 28034.6660, 28032.2578, 28034.8008, 28033.8184,\n",
            "        28034.4746, 28035.0527, 28034.1875, 28033.1934, 28034.0469, 28035.3633,\n",
            "        28031.7266, 28031.4277, 28034.7773, 28033.0879, 28034.4941, 28032.2188,\n",
            "        28033.9043, 28035.0527, 28035.0234, 28033.2441, 28032.7559, 28033.0645,\n",
            "        28033.1738, 28028.3203, 28030.7832, 28033.8535, 28032.8184, 28034.2773,\n",
            "        28032.4863, 28032.9160, 28034.3184, 28034.4375, 28033.5508, 28033.4043,\n",
            "        28034.1777, 28034.4531, 28033.8770, 28034.6777, 28034.3711, 28033.4043,\n",
            "        28034.2441, 28032.8574, 28034.8027, 28034.5977, 28032.9805, 28030.7969,\n",
            "        28030.1738, 28034.4824, 28031.8477, 28032.8535, 28034.9219, 28033.8867,\n",
            "        28033.0977, 28033.7188, 28033.3281, 28032.7031, 28033.7695, 28035.4160,\n",
            "        28033.2930, 28033.4629, 28028.1133, 28034.0332, 28034.3789, 28031.9727,\n",
            "        28031.6582, 28030.2578, 28033.4082, 28033.2773, 28033.8828, 28033.6016,\n",
            "        28033.2578, 28033.8320, 28035.0391, 28033.8379, 28034.0898, 28034.9355,\n",
            "        28032.7617, 28033.2930, 28033.3594, 28032.8535],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000, 0.0110, 0.0127, 0.0087, 0.0051, 0.0056, 0.0234, 0.0047, 0.0076,\n",
            "        0.0072, 0.0081, 0.0149, 0.0086, 0.0189, 0.0168, 0.0102, 0.0163, 0.0076,\n",
            "        0.0098, 0.0087, 0.0130, 0.0080, 0.0083, 0.0067, 0.0105, 0.0105, 0.0127,\n",
            "        0.0051, 0.0164, 0.0022, 0.0048, 0.0168, 0.0058, 0.0112, 0.0127, 0.0136,\n",
            "        0.0101, 0.0084, 0.0044, 0.0065, 0.0083, 0.0136, 0.0121, 0.0136, 0.0142,\n",
            "        0.0053, 0.0087, 0.0074, 0.0069, 0.0119, 0.0112, 0.0119, 0.0164, 0.0082,\n",
            "        0.0080, 0.0080, 0.0042, 0.0154, 0.0094, 0.0087, 0.0094, 0.0067, 0.0105,\n",
            "        0.0084, 0.0037, 0.0088, 0.0116, 0.0133, 0.0091, 0.0098, 0.0128, 0.0119,\n",
            "        0.0082, 0.0133, 0.0128, 0.0197, 0.0133, 0.0129, 0.0143, 0.0035, 0.0101,\n",
            "        0.0021, 0.0183, 0.0175, 0.0042, 0.0136, 0.0074, 0.0041, 0.0056, 0.0110,\n",
            "        0.0064, 0.0092, 0.0127, 0.0064, 0.0136, 0.0107, 0.0149, 0.0083, 0.0124],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [91]\n",
            "DEBUGGING: logits looks like: tensor([27944.5332, 28039.4082, 28039.4453, 28039.3516, 28039.2148, 28039.2422,\n",
            "        28039.5977, 28039.1973, 28039.3164, 28039.3027, 28039.3340, 28039.4844,\n",
            "        28039.3477, 28039.5449, 28039.5156, 28039.3906, 28039.5078, 28039.3184,\n",
            "        28039.3809, 28039.3516, 28039.4512, 28039.3281, 28039.3379, 28039.2852,\n",
            "        28039.3984, 28039.3965, 28039.4453, 28039.2148, 28039.5098, 28039.0117,\n",
            "        28039.2012, 28039.5156, 28039.2480, 28039.4141, 28039.4453, 28039.4629,\n",
            "        28039.3887, 28039.3418, 28039.1797, 28039.2773, 28039.3379, 28039.4629,\n",
            "        28039.4336, 28039.4629, 28039.4727, 28039.2266, 28039.3516, 28039.3105,\n",
            "        28039.2930, 28039.4297, 28039.4141, 28039.4297, 28039.5098, 28039.3359,\n",
            "        28039.3281, 28039.3281, 28039.1699, 28039.4941, 28039.3691, 28039.3516,\n",
            "        28039.3691, 28039.2871, 28039.3984, 28039.3418, 28039.1367, 28039.3535,\n",
            "        28039.4219, 28039.4570, 28039.3613, 28039.3809, 28039.4473, 28039.4297,\n",
            "        28039.3359, 28039.4570, 28039.4473, 28039.5547, 28039.4570, 28039.4492,\n",
            "        28039.4746, 28039.1211, 28039.3887, 28038.9980, 28039.5371, 28039.5254,\n",
            "        28039.1699, 28039.4629, 28039.3105, 28039.1621, 28039.2422, 28039.4082,\n",
            "        28039.2734, 28039.3652, 28039.4453, 28039.2734, 28039.4629, 28039.4023,\n",
            "        28039.4844, 28039.3379, 28039.4395], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.2681e-02, 4.5610e-10, 4.8727e-12, 1.7468e-02, 2.8706e-11,\n",
            "        2.1236e-02, 1.6799e-02, 3.2852e-10, 1.4197e-04, 1.2100e-02, 9.1803e-08,\n",
            "        8.8605e-10, 4.3731e-04, 1.1820e-02, 9.6906e-12, 1.4257e-02, 6.3858e-06,\n",
            "        2.1236e-02, 1.0762e-02, 1.1319e-04, 1.1278e-02, 2.9528e-05, 1.3377e-10,\n",
            "        1.5351e-04, 9.4036e-04, 1.4482e-02, 1.5059e-02, 5.8811e-08, 4.5119e-04,\n",
            "        1.3186e-02, 1.2780e-02, 1.5537e-02, 9.5517e-04, 1.4825e-02, 1.5658e-02,\n",
            "        1.5537e-02, 2.2162e-04, 1.1820e-02, 1.7197e-02, 1.9036e-02, 7.5402e-05,\n",
            "        4.2757e-11, 6.0806e-07, 9.7110e-11, 1.0678e-02, 1.5537e-02, 1.6799e-02,\n",
            "        1.3682e-03, 1.4036e-02, 1.6668e-02, 1.0431e-02, 1.4036e-02, 9.6209e-08,\n",
            "        1.4443e-07, 7.7028e-06, 1.3819e-02, 1.2681e-02, 1.2780e-02, 5.6270e-03,\n",
            "        1.5416e-02, 1.9487e-02, 1.7458e-06, 4.9213e-11, 3.0593e-03, 1.5658e-02,\n",
            "        1.6238e-07, 1.7909e-05, 1.3898e-03, 4.6649e-03, 3.0769e-04, 1.4257e-02,\n",
            "        1.4710e-02, 1.9036e-02, 1.7197e-02, 1.5416e-02, 1.0067e-04, 1.4525e-08,\n",
            "        1.3604e-02, 1.1912e-02, 3.0119e-03, 1.9640e-02, 1.2100e-02, 1.6156e-02,\n",
            "        1.5537e-02, 1.6799e-02, 1.2100e-02, 1.3393e-02, 1.3186e-02, 1.6156e-02,\n",
            "        1.4146e-02, 1.2780e-02, 1.4710e-02, 1.3604e-02, 1.5537e-02, 1.6156e-02,\n",
            "        1.4595e-02, 8.5801e-03, 1.2582e-02, 1.9949e-02, 4.2475e-03, 7.5130e-03,\n",
            "        1.2582e-02, 1.7197e-02, 1.4595e-02, 1.6799e-02, 1.5296e-02, 2.0701e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [40]\n",
            "DEBUGGING: logits looks like: tensor([27948.8340, 28043.3691, 28039.0840, 28037.9492, 28043.4492, 28038.3926,\n",
            "        28043.4980, 28043.4395, 28039.0020, 28042.2461, 28043.3574, 28040.4102,\n",
            "        28039.2500, 28042.5273, 28043.3516, 28038.1211, 28043.3984, 28041.4707,\n",
            "        28043.4980, 28043.3281, 28042.1895, 28043.3398, 28041.8535, 28038.7773,\n",
            "        28042.2656, 28042.7188, 28043.4023, 28043.4121, 28040.2988, 28042.5352,\n",
            "        28043.3789, 28043.3711, 28043.4199, 28042.7227, 28043.4082, 28043.4219,\n",
            "        28043.4199, 28042.3574, 28043.3516, 28043.4453, 28043.4707, 28042.0879,\n",
            "        28038.4922, 28040.8828, 28038.6973, 28043.3262, 28043.4199, 28043.4395,\n",
            "        28042.8125, 28043.3945, 28043.4375, 28043.3203, 28043.3945, 28040.4219,\n",
            "        28040.5234, 28041.5176, 28043.3906, 28043.3691, 28043.3711, 28043.1660,\n",
            "        28043.4180, 28043.4766, 28041.1465, 28038.5273, 28043.0137, 28043.4219,\n",
            "        28040.5527, 28041.7285, 28042.8164, 28043.1191, 28042.4395, 28043.3984,\n",
            "        28043.4062, 28043.4707, 28043.4453, 28043.4180, 28042.1602, 28039.9492,\n",
            "        28043.3867, 28043.3535, 28043.0098, 28043.4785, 28043.3574, 28043.4297,\n",
            "        28043.4199, 28043.4395, 28043.3574, 28043.3828, 28043.3789, 28043.4297,\n",
            "        28043.3965, 28043.3711, 28043.4062, 28043.3867, 28043.4199, 28043.4297,\n",
            "        28043.4043, 28043.2715, 28043.3672, 28043.4824, 28043.0957, 28043.2383,\n",
            "        28043.3672, 28043.4453, 28043.4043, 28043.4395, 28043.4160, 28042.9160],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.14549559285751457 and immediate abs rewards look like: [0.010754348344562459, 0.012717792419607576, 0.0065206662161472195, 0.029698524268951587, 0.0019199828384444118, 0.0011962372022935597, 0.0042497824883867, 0.008576207812438952, 0.010111354340097023, 0.007122450360839139, 0.014524171484026738, 0.0005507872824637161, 0.015565254841476417, 0.0009180166266560263, 7.548842586402316e-05, 0.0012599699302882073, 0.004780525523528922, 0.0051716254638449755, 0.0042934635257552145, 0.00044653558506979607, 2.7420311653258977e-05, 0.0002803520856105024, 4.512456735028536e-05, 0.002926465251675836, 6.615909296669997e-05, 0.00021491612415047712, 0.00018959375165650272, 0.00022146255514599034, 5.567588777921628e-05, 0.00033145422139568836, 0.0002028236108344572, 0.0001483937116972811, 8.882616839400725e-05, 1.6566445538046537e-05, 4.923740561935119e-07, 2.4142318579833955e-06, 3.827402088063536e-05, 1.2983962733414955e-05, 1.858827954492881e-05, 4.485954650590429e-05, 1.3393923836702015e-06, 3.642690171545837e-05, 1.0465304058016045e-05, 1.3510025382856838e-06, 4.960900696460158e-06, 1.9887722373823635e-05, 2.0781162675120868e-06, 3.2262105378322303e-06, 2.6958102807839168e-05, 2.8680219656962436e-06]\n",
            "DEBUGGING: the total relative reward of the trajectory = 3.4655457223733177 and immediate relative rewards look like: [0.029001021819185686, 0.06879110038297566, 0.0530884576119323, 0.3229616529705132, 0.026311414330148514, 0.019682216088701875, 0.08160423000137006, 0.188425552086821, 0.2505131117645211, 0.19661587866456123, 0.4419040102996608, 0.018355120876993317, 0.5620282183592734, 0.03585244425048085, 0.0031595341006597625, 0.056252357722344735, 0.2268495092838419, 0.26019129651772394, 0.2283404242549798, 0.025028207108188344, 0.001613948613291227, 0.017287326386770847, 0.002909218724555013, 0.19687727696646143, 0.004640095714545199, 0.015676452704076235, 0.014362148719011064, 0.017398550766211985, 0.0045305076974205835, 0.02790187045373444, 0.017644489865885085, 0.013326591899355214, 0.008226717381582347, 0.0015808504611704527, 4.836684523257939e-05, 0.00024393049254994712, 0.003974575244499284, 0.0013847788819514413, 0.0020346745819789253, 0.005036261749359422, 0.000154131204805871, 0.004294084428177545, 0.0012630594756960847, 0.00016684515975141765, 0.0006265820984229829, 0.002567724473386212, 0.0002741420551712357, 0.00043465247844891503, 0.0037076097545642034, 0.0004024986003730457]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 3\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.6251e-18, 0.0000e+00, 0.0000e+00, 5.2489e-14, 3.7053e-31,\n",
            "        2.2407e-25, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1184e-35,\n",
            "        3.2572e-18, 1.6129e-29, 9.5962e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.2455e-37, 0.0000e+00,\n",
            "        3.2038e-37, 5.8998e-29, 0.0000e+00, 2.8470e-30, 1.7335e-17, 0.0000e+00,\n",
            "        4.1473e-22, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4463e-40,\n",
            "        0.0000e+00, 5.0524e-21, 4.2049e-08, 1.7870e-36, 0.0000e+00, 2.2393e-29,\n",
            "        2.6625e-44, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        4.6391e-17, 0.0000e+00, 5.7613e-18, 9.0338e-01, 0.0000e+00, 0.0000e+00,\n",
            "        7.2545e-05, 0.0000e+00, 5.8415e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
            "        1.7096e-43, 0.0000e+00], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [51]\n",
            "DEBUGGING: logits looks like: tensor([28133.2773, 28203.0742, 28076.7871, 28068.6855, 28205.6699, 28195.7969,\n",
            "        28199.1250, 28154.5000, 28109.8594, 28102.9121, 28045.4355, 28193.4512,\n",
            "        28203.2480, 28196.7402, 28212.7285, 28025.9688, 28126.0566, 28043.8750,\n",
            "        28117.2461, 28149.9102, 28023.4121, 28146.8691, 28192.5430, 27952.7520,\n",
            "        28192.3066, 28197.0645, 28145.5684, 28196.3066, 28203.6660, 28142.8516,\n",
            "        28201.0059, 28171.7559, 28183.8184, 28148.7617, 28169.4160, 28190.3809,\n",
            "        28099.1035, 28201.6309, 28209.0684, 28192.7363, 28172.0684, 28196.8223,\n",
            "        28188.2363, 28129.9785, 28120.5898, 28168.6602, 28057.0840, 28114.7852,\n",
            "        28203.9121, 28111.4238, 28203.3906, 28213.2891, 28179.0801, 28158.1387,\n",
            "        28210.9316, 28172.9082, 28211.4531, 28168.3477, 28160.4062, 28149.9121,\n",
            "        28188.6953, 28176.4238], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.0888e-15, 2.0177e-30, 6.0710e-30, 8.8198e-01, 4.1951e-20,\n",
            "        4.9460e-16, 0.0000e+00, 4.6534e-19, 1.0442e-20, 6.7523e-24, 2.5676e-38,\n",
            "        1.1066e-11, 1.3004e-16, 2.2781e-02, 5.5561e-35, 3.3831e-22, 3.5636e-27,\n",
            "        0.0000e+00, 6.5073e-23, 0.0000e+00, 6.2882e-17, 7.6836e-22, 2.5545e-33,\n",
            "        1.4398e-27, 7.0255e-20, 2.9614e-11, 1.4555e-33, 4.7195e-16, 5.4928e-07,\n",
            "        0.0000e+00, 1.2023e-05, 0.0000e+00, 7.0764e-24, 1.6990e-04, 4.3231e-28,\n",
            "        2.0792e-12, 7.5781e-10, 2.8703e-11, 2.6205e-32, 2.5323e-26, 1.0405e-18,\n",
            "        3.7245e-32, 9.1518e-02, 1.3153e-18, 1.2419e-23, 1.1119e-05, 2.0292e-05,\n",
            "        1.6384e-25, 1.1159e-07, 8.4489e-14, 3.3517e-19, 3.0813e-33, 9.4169e-07,\n",
            "        9.7715e-08, 0.0000e+00, 1.6990e-04, 3.0998e-19, 1.0250e-14, 4.5306e-28,\n",
            "        6.6396e-06, 3.9397e-09, 2.8004e-19, 1.2634e-26, 9.9703e-17, 1.0299e-08,\n",
            "        8.4288e-30, 7.0339e-12, 4.3557e-17, 3.3336e-03, 3.9779e-23, 2.6803e-25,\n",
            "        3.4622e-11, 1.1688e-11, 1.4239e-36, 1.9491e-13, 4.6674e-25, 6.6876e-10],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [4]\n",
            "DEBUGGING: logits looks like: tensor([28162.2812, 28228.9590, 28220.4785, 28220.7539, 28237.5410, 28226.4180,\n",
            "        28228.7617, 28191.2031, 28227.0195, 28226.0703, 28224.2344, 28215.9336,\n",
            "        28231.2656, 28228.4277, 28236.6270, 28217.8535, 28225.2129, 28222.3477,\n",
            "        28199.2559, 28224.8008, 28204.3789, 28228.2461, 28225.4180, 28218.8105,\n",
            "        28222.1211, 28226.5469, 28231.5117, 28218.6699, 28228.7500, 28233.9688,\n",
            "        28192.0059, 28234.7402, 28205.6172, 28224.2461, 28235.4023, 28221.8203,\n",
            "        28230.8477, 28232.3223, 28231.5039, 28219.3926, 28222.8379, 28227.2207,\n",
            "        28219.4805, 28236.9746, 28227.2793, 28224.3867, 28234.7207, 28234.8711,\n",
            "        28223.3047, 28233.5703, 28230.0469, 28226.9375, 28218.8574, 28234.1035,\n",
            "        28233.5371, 28173.9336, 28235.4023, 28226.9180, 28229.5195, 28221.8320,\n",
            "        28234.5918, 28232.7344, 28226.8926, 28222.6641, 28228.3613, 28232.9746,\n",
            "        28220.8359, 28231.1523, 28228.1543, 28236.1465, 28224.6777, 28223.4277,\n",
            "        28231.5508, 28231.2793, 28216.9375, 28230.2559, 28223.5664, 28232.2910],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 9.9704e-32, 7.2376e-06, 9.9971e-01, 9.6114e-16, 1.2941e-11,\n",
            "        3.9695e-13, 2.2884e-26, 2.4662e-35, 5.4469e-26, 3.9150e-27, 4.7181e-20,\n",
            "        8.6207e-12, 1.2973e-21, 4.4270e-28, 3.7866e-28, 1.2887e-13, 2.4492e-16,\n",
            "        1.8616e-09, 7.1191e-25, 9.3411e-37, 5.6587e-19, 8.2214e-42, 7.0129e-21,\n",
            "        6.3833e-10, 8.8199e-16, 1.3133e-30, 4.6814e-20, 3.3719e-20, 1.1203e-09,\n",
            "        0.0000e+00, 0.0000e+00, 1.1390e-16, 4.3335e-27, 3.5263e-21, 4.1103e-15,\n",
            "        2.8241e-04, 1.1490e-23, 4.2129e-33, 6.4026e-16, 1.9668e-20, 2.4692e-27,\n",
            "        1.1257e-29, 1.6077e-23, 1.9586e-22, 7.1727e-14, 1.0027e-32, 6.4489e-20,\n",
            "        9.8393e-16, 5.1726e-32, 1.6291e-13, 8.9240e-29, 1.5085e-31, 4.8329e-16,\n",
            "        3.7673e-23, 5.1741e-17, 2.0219e-18, 3.6800e-23, 1.1393e-27, 0.0000e+00,\n",
            "        9.9554e-29, 5.3191e-15, 1.9621e-36, 2.7853e-18, 4.0637e-39, 1.2588e-13,\n",
            "        4.9090e-16, 2.4721e-19, 5.4649e-17, 4.2407e-15, 0.0000e+00, 2.3796e-26,\n",
            "        9.5912e-17, 7.9826e-30, 1.3228e-08, 3.2398e-13, 1.1496e-19, 0.0000e+00,\n",
            "        1.4329e-22, 1.4329e-22, 3.9504e-19, 6.6457e-28, 1.9709e-19, 3.0627e-10,\n",
            "        0.0000e+00, 4.2407e-15, 3.7312e-09], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [3]\n",
            "DEBUGGING: logits looks like: tensor([28184.2559, 28242.9277, 28257.8145, 28260.7734, 28252.1289, 28254.5059,\n",
            "        28253.6348, 28246.0137, 28240.8516, 28246.2305, 28245.5723, 28249.6484,\n",
            "        28254.4043, 28248.7500, 28245.0273, 28244.9883, 28253.3535, 28251.7871,\n",
            "        28255.7480, 28246.8730, 28240.0332, 28250.2695, 28237.1230, 28249.1719,\n",
            "        28255.4805, 28252.1074, 28243.5723, 28249.6465, 28249.5645, 28255.6211,\n",
            "        28216.2188, 28234.1543, 28251.5957, 28245.5977, 28249.0000, 28252.4922,\n",
            "        28258.7305, 28247.5684, 28242.1367, 28252.0273, 28249.4297, 28245.4570,\n",
            "        28244.1094, 28247.6523, 28248.2773, 28253.2070, 28242.3535, 28249.7266,\n",
            "        28252.1348, 28242.7637, 28253.4121, 28244.6270, 28243.0312, 28251.9570,\n",
            "        28247.8652, 28251.3984, 28250.5879, 28247.8594, 28245.2637, 28225.5195,\n",
            "        28244.6543, 28252.5566, 28240.2188, 28250.6680, 28238.6738, 28253.3477,\n",
            "        28251.9609, 28250.0625, 28251.4121, 28252.5000, 28225.1602, 28246.0234,\n",
            "        28251.5527, 28244.0234, 28256.2383, 28253.5840, 28249.8711, 28215.8867,\n",
            "        28248.1992, 28248.1992, 28250.1797, 28245.1289, 28250.0059, 28255.2969,\n",
            "        28225.1602, 28252.5000, 28255.9219], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000e+00, 1.4445e-02, 6.4465e-04, 1.4000e-02, 2.4764e-02, 4.4054e-03,\n",
            "        2.9514e-04, 1.6852e-03, 1.0464e-03, 2.8163e-04, 3.8575e-03, 1.5831e-03,\n",
            "        2.9639e-02, 2.0973e-03, 1.5312e-04, 8.0397e-03, 1.9928e-05, 7.1916e-04,\n",
            "        4.4399e-03, 2.3397e-03, 6.2350e-05, 3.8114e-05, 1.0464e-03, 6.3104e-03,\n",
            "        3.6522e-03, 1.2774e-01, 1.0084e-02, 1.5106e-03, 1.4051e-04, 1.1250e-02,\n",
            "        3.1550e-02, 1.7117e-03, 9.8297e-04, 1.8080e-03, 8.0228e-04, 5.6447e-04,\n",
            "        9.7737e-03, 4.4120e-06, 1.6105e-06, 2.2152e-03, 6.8622e-04, 7.2067e-03,\n",
            "        1.7502e-11, 2.8666e-03, 4.5098e-03, 1.4841e-04, 1.7350e-04, 3.5398e-03,\n",
            "        4.9145e-03, 6.1034e-04, 9.3993e-03, 3.2163e-04, 5.3556e-03, 4.6168e-03,\n",
            "        9.1816e-03, 4.2943e-04, 4.2277e-04, 8.5402e-04, 1.8469e-04, 8.4559e-05,\n",
            "        1.3200e-04, 6.5618e-03, 1.0880e-03, 3.8194e-04, 2.4764e-02, 7.0652e-05,\n",
            "        6.7945e-05, 1.4756e-03, 3.1731e-03, 4.1063e-03, 2.6046e-04, 3.6731e-04,\n",
            "        1.4191e-03, 1.3971e-03, 1.8839e-02, 1.2329e-03, 9.1623e-04, 4.3371e-03,\n",
            "        3.2738e-03, 1.3569e-02, 2.0853e-02, 4.5809e-03, 1.5464e-03, 6.2971e-04,\n",
            "        8.0397e-03, 6.3829e-05, 2.3034e-03, 9.0910e-04, 5.3556e-03, 1.2721e-03,\n",
            "        2.5154e-02, 1.6138e-05, 2.5952e-02, 4.3803e-02, 3.8436e-01, 3.3777e-03,\n",
            "        1.1226e-03, 2.0169e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [94]\n",
            "DEBUGGING: logits looks like: tensor([28201.7480, 28274.3457, 28273.5684, 28274.3379, 28274.4805, 28274.0488,\n",
            "        28273.3730, 28273.8086, 28273.6895, 28273.3613, 28274.0156, 28273.7930,\n",
            "        28274.5254, 28273.8633, 28273.2090, 28274.1992, 28272.6992, 28273.5957,\n",
            "        28274.0508, 28273.8906, 28272.9844, 28272.8613, 28273.6895, 28274.1387,\n",
            "        28274.0020, 28274.8906, 28274.2559, 28273.7812, 28273.1875, 28274.2832,\n",
            "        28274.5410, 28273.8125, 28273.6738, 28273.8262, 28273.6230, 28273.5352,\n",
            "        28274.2480, 28272.3223, 28272.0703, 28273.8770, 28273.5840, 28274.1719,\n",
            "        28269.2129, 28273.9414, 28274.0547, 28273.2012, 28273.2402, 28273.9941,\n",
            "        28274.0762, 28273.5547, 28274.2383, 28273.3945, 28274.0977, 28274.0605,\n",
            "        28274.2324, 28273.4668, 28273.4629, 28273.6387, 28273.2559, 28273.0605,\n",
            "        28273.1719, 28274.1484, 28273.6992, 28273.4375, 28274.4805, 28273.0156,\n",
            "        28273.0059, 28273.7754, 28273.9668, 28274.0312, 28273.3418, 28273.4277,\n",
            "        28273.7656, 28273.7617, 28274.4121, 28273.7305, 28273.6562, 28274.0449,\n",
            "        28273.9746, 28274.3301, 28274.4375, 28274.0586, 28273.7871, 28273.5625,\n",
            "        28274.1992, 28272.9902, 28273.8867, 28273.6543, 28274.0977, 28273.7383,\n",
            "        28274.4844, 28272.6465, 28274.4922, 28274.6230, 28275.1660, 28273.9824,\n",
            "        28273.7070, 28273.8535], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0000, 0.0079, 0.0197, 0.0066, 0.0105, 0.0077, 0.0015, 0.0044, 0.0082,\n",
            "        0.0094, 0.0105, 0.0091, 0.0044, 0.0197, 0.0443, 0.0062, 0.0046, 0.0057,\n",
            "        0.0062, 0.0091, 0.0077, 0.0182, 0.0143, 0.0162, 0.0041, 0.0112, 0.0099,\n",
            "        0.0081, 0.0137, 0.0006, 0.0113, 0.0067, 0.0129, 0.0153, 0.0052, 0.0090,\n",
            "        0.0057, 0.0113, 0.0043, 0.0055, 0.0120, 0.0009, 0.0468, 0.0102, 0.0090,\n",
            "        0.0038, 0.0050, 0.0171, 0.0126, 0.0107, 0.0042, 0.0051, 0.0100, 0.0127,\n",
            "        0.0114, 0.0036, 0.0151, 0.0132, 0.0090, 0.0241, 0.0072, 0.0105, 0.0163,\n",
            "        0.0112, 0.0087, 0.0053, 0.0082, 0.0067, 0.0110, 0.0046, 0.0126, 0.0042,\n",
            "        0.0010, 0.0097, 0.0071, 0.0100, 0.0005, 0.0223, 0.0051, 0.0024, 0.0105,\n",
            "        0.0015, 0.0046, 0.0090, 0.0099, 0.0082, 0.0094, 0.0035, 0.0167, 0.0144,\n",
            "        0.0208, 0.0119, 0.0108, 0.0129, 0.0132, 0.0095, 0.0044, 0.0091, 0.0159,\n",
            "        0.0037, 0.0020, 0.0036, 0.0071], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [75]\n",
            "DEBUGGING: logits looks like: tensor([28215.8672, 28287.9258, 28288.1543, 28287.8828, 28287.9980, 28287.9199,\n",
            "        28287.5176, 28287.7793, 28287.9355, 28287.9688, 28287.9980, 28287.9629,\n",
            "        28287.7793, 28288.1543, 28288.3574, 28287.8652, 28287.7930, 28287.8457,\n",
            "        28287.8652, 28287.9629, 28287.9199, 28288.1348, 28288.0742, 28288.1055,\n",
            "        28287.7617, 28288.0137, 28287.9824, 28287.9316, 28288.0645, 28287.2891,\n",
            "        28288.0156, 28287.8867, 28288.0488, 28288.0918, 28287.8242, 28287.9590,\n",
            "        28287.8438, 28288.0156, 28287.7754, 28287.8340, 28288.0312, 28287.3789,\n",
            "        28288.3711, 28287.9902, 28287.9590, 28287.7422, 28287.8125, 28288.1191,\n",
            "        28288.0430, 28288.0020, 28287.7715, 28287.8184, 28287.9863, 28288.0449,\n",
            "        28288.0176, 28287.7324, 28288.0879, 28288.0547, 28287.9590, 28288.2051,\n",
            "        28287.9043, 28287.9980, 28288.1074, 28288.0137, 28287.9492, 28287.8281,\n",
            "        28287.9355, 28287.8867, 28288.0098, 28287.7891, 28288.0430, 28287.7656,\n",
            "        28287.4062, 28287.9766, 28287.8984, 28287.9844, 28287.2480, 28288.1855,\n",
            "        28287.8184, 28287.6289, 28287.9980, 28287.5137, 28287.7930, 28287.9590,\n",
            "        28287.9824, 28287.9355, 28287.9688, 28287.7246, 28288.1133, 28288.0762,\n",
            "        28288.1680, 28288.0293, 28288.0039, 28288.0488, 28288.0547, 28287.9727,\n",
            "        28287.7793, 28287.9629, 28288.1016, 28287.7344, 28287.5820, 28287.7285,\n",
            "        28287.8984], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.10198047421681622 and immediate abs rewards look like: [0.017294578184191778, 0.012272575242604944, 0.0024996665515573113, 0.0011182527596247382, 0.0012108692526453524, 0.0051692562142307, 0.0004399879649099603, 0.00039128852858993923, 0.00717427568815765, 0.0020203175113238103, 0.0004812379011127632, 0.00099843107182096, 0.0008665209397804574, 0.0001279271718885866, 0.00016299257094942732, 0.0015755519934828044, 0.009788264185772277, 0.0059321042813280656, 0.005520548954336846, 0.0001549477269691124, 0.0010489891078577784, 0.003387441918675904, 0.002454200821375707, 0.002395997074927436, 0.0048881747256928065, 0.00017512881413495052, 0.0035070246954092, 0.004101730234197021, 1.667765764068463e-05, 0.0010065789456348284, 0.001181191411887994, 0.000249863193857891, 0.0002481685573911818, 9.305024832428899e-06, 0.0005721181323679048, 5.841948222951032e-07, 0.00021996321902406635, 0.0006817698658778681, 2.764870123428409e-05, 2.419058364466764e-05, 2.9981620173202828e-06, 5.689451882062713e-05, 0.00010304510669811862, 6.882918660267023e-05, 0.0001166243832813052, 7.507035979870125e-05, 5.8269480632588966e-05, 2.0666055206675082e-05, 5.5248214721359545e-05, 2.648717327247141e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 4.7390824995982666 and immediate relative rewards look like: [0.05991038410894446, 0.08553966188243509, 0.026246211095055864, 0.015669075491463853, 0.021216845646546138, 0.10873696231507382, 0.010817440203599685, 0.0109961305568608, 0.2268470072994042, 0.07115872242976956, 0.018658218370975307, 0.04223676701079044, 0.03972524964120065, 0.006317827833886248, 0.008624930821197295, 0.0889353146345516, 0.5873778906808809, 0.3782225606383895, 0.3723192836524917, 0.011021653079496128, 0.07835121562111551, 0.26516247849760705, 0.20108479302957152, 0.20503059987905986, 0.4360929449599772, 0.01627726816118859, 0.33851688938390495, 0.41110023399254525, 0.0017337790754066433, 0.10825111996674737, 0.13131127364074477, 0.02868509576235547, 0.02938350959207618, 0.0011352149354203233, 0.07185166715534529, 7.548009928582961e-05, 0.029209501169077643, 0.0929882413779052, 0.0038712593401696543, 0.0034739500725295253, 0.0004413264542322019, 0.0085790893890295, 0.015908387965113433, 0.010873559273952086, 0.018843389235221424, 0.012399428263758247, 0.0098339057832636, 0.0035620084674258014, 0.009721061186466476, 0.0047556904747568084]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 200 number of matrices\n",
            "DEBUGGING: ACT_MAT has 200 number of matrices\n",
            "DEBUGGING: VAL looks like: [[4.523018758475986, 4.5627787205229575, 4.595516040644265, 4.546007232220104, 3.6649014251847705, 3.5617482809403302, 3.3455607256242397, 3.2848561619082473, 3.316315612481827, 3.34669305321867, 3.3782300359432993, 3.406266948899503, 3.4317527579558424, 2.5793878998995226, 2.214664443731162, 2.2351298701396467, 1.884222071936033, 1.8645630972154748, 1.7352608335379285, 1.3131231599999067, 1.2852448341810554, 0.7835739526045176, 0.7847175636627314, 0.7526537172687466, 0.7567568492168749, 0.7507083364352234, 0.7391671238457848, 0.6479841262301723, 0.6433703137306972, 0.5212593779777246, 0.5263403486972142, 0.5138232948110298, 0.516519363575311, 0.5161908649998264, 0.4304270159128562, 0.43388511468482616, 0.07869174013325443, 0.07619783513340112, 0.07371550567145325, 0.047221521844701464, 0.04671364712919205, 0.04520281422959401, 0.045341907651763505, 0.040531443823940735, 0.03985918923771828, 0.018265754985722363, 0.015761859281115075, 0.0007968647553705674, 0.000802205797528641, 1.9250457644164464e-05], [2.0514241462578235, 1.7639213747118667, 0.9193057803480305, 0.9143795487191124, 0.7879747121249623, 0.787661559611409, 0.7724905390224275, 0.6337468555267323, 0.3797444286808951, 0.36133867613839377, 0.3523360517237503, 0.3093741707781692, 0.2943967329798136, 0.2782366173065486, 0.26752414420151027, 0.2316451697877665, 0.22378287460961807, 0.21140974788422998, 0.18040706150002137, 0.1312700613834129, 0.12774781606639263, 0.12278221514091518, 0.12342425872882375, 0.12146778930591556, 0.12166705146629736, 0.11192892745347778, 0.1073542932528289, 0.1062932327365148, 0.09594036232920801, 0.08654667057626829, 0.06602474928844394, 0.06512961197888259, 0.06282922294694662, 0.049095572194443576, 0.04766766149497981, 0.0431633970579552, 0.04018254595332986, 0.03854361483451681, 0.037886522296105944, 0.033687333891745004, 0.03386830929972284, 0.02726646203112567, 0.02019754491760439, 0.011351718795085168, 0.003618824837808642, 0.002881966123800187, 0.0024644830937306534, 0.0018362978023841513, 0.0006568854560960977, 0.00010084354446529597], [3.076128905715515, 3.0779069534306354, 3.0395109626744037, 3.0165883889519916, 2.7208350868499784, 2.7217410833533635, 2.729352391176426, 2.674493092096016, 2.5111793333426218, 2.2835012339172738, 2.1079650053057706, 1.6828898939455654, 1.6813482556248203, 1.130626300268229, 1.1058321777957052, 1.1138107512071165, 1.0682408014997693, 0.8498901941575023, 0.5956554521613924, 0.3710252807135481, 0.34949199354076743, 0.3513919645732083, 0.33747943251155305, 0.3379497108959576, 0.14249740800959207, 0.13924981039903722, 0.12482157342925353, 0.11157517647499239, 0.09512790475634385, 0.09151252228174067, 0.06425318366465277, 0.04707948868562393, 0.03409383513764517, 0.02612840177380083, 0.02479550637639432, 0.024997110637537113, 0.0250032122676638, 0.02124104749814598, 0.020056836986055086, 0.01820420444856178, 0.013300952221416522, 0.013279617188495609, 0.009076295717492994, 0.007892157819996878, 0.00780334612146006, 0.007249256588926341, 0.004728820318727402, 0.004499675013693098, 0.004106083368933518, 0.0004024986003730457], [3.8781038228308486, 3.8567610492140445, 3.8093145326581914, 3.8212811328920564, 3.844052583232922, 3.8614502399862385, 3.790619472395116, 3.8179818506985015, 3.8454401213551925, 3.6551445596523116, 3.6201877143662045, 3.6379085818133627, 3.6319917321238107, 3.628552002507687, 3.6588223986604045, 3.6870681493325326, 3.6344776108060417, 3.0778785051769297, 2.726925196503576, 2.3783898109606914, 2.391280967556763, 2.336292678722876, 2.0920507072982515, 1.910066580069374, 1.722258565848802, 1.2991571928169947, 1.2958383077331375, 0.9669913316658915, 0.5615061592660063, 0.5654266466571715, 0.46179346130345866, 0.3338203915784989, 0.308217470521357, 0.2816504655851321, 0.2833487380300119, 0.2136334049239057, 0.21571507558042413, 0.1883894691023702, 0.09636487648935858, 0.09342789611029184, 0.09086257175531547, 0.09133459121321542, 0.08359141598402618, 0.06836669496859873, 0.058073874439037027, 0.03962675273112687, 0.02750234794683699, 0.01784691127633676, 0.014429194756475715, 0.0047556904747568084]]\n",
            "DEBUGGING: traj_returns = [4.523018758475986, 2.0514241462578235, 3.076128905715515, 3.8781038228308486]\n",
            "DEBUGGING: actions = [[6], [15], [23], [63], [26], [7], [31], [2], [2], [21], [69], [69], [21], [52], [12], [49], [28], [6], [4], [4], [77], [4], [38], [27], [31], [68], [8], [4], [53], [10], [69], [21], [5], [72], [45], [26], [19], [15], [45], [4], [95], [26], [44], [13], [41], [92], [82], [51], [3], [78], [17], [14], [41], [3], [41], [22], [7], [65], [58], [8], [23], [8], [3], [2], [58], [5], [19], [27], [72], [48], [68], [2], [82], [1], [17], [65], [47], [41], [71], [71], [21], [32], [27], [43], [83], [10], [74], [69], [3], [76], [43], [46], [21], [78], [47], [6], [59], [102], [104], [34], [43], [36], [3], [18], [43], [3], [3], [3], [66], [20], [18], [56], [16], [20], [27], [13], [24], [69], [23], [37], [28], [16], [44], [28], [81], [83], [44], [67], [13], [83], [52], [78], [69], [17], [84], [37], [72], [46], [11], [91], [77], [91], [51], [18], [79], [74], [4], [22], [29], [40], [17], [25], [17], [63], [64], [62], [63], [63], [18], [51], [61], [57], [68], [39], [61], [67], [13], [2], [37], [4], [63], [2], [16], [69], [2], [17], [14], [71], [4], [3], [17], [15], [14], [15], [66], [60], [8], [19], [61], [94], [92], [98], [42], [93], [45], [40], [18], [12], [63], [75]]\n",
            "DEBUGGING: actions length = 200\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[-33.8734,  59.4251, -63.2019,  ...,  50.5502,  65.0628, -32.0369],\n",
            "        [-33.1448,  58.1308, -61.8431,  ...,  49.4519,  63.6544, -31.3415],\n",
            "        [-33.6546,  59.0266, -62.7962,  ...,  50.2148,  64.6345, -31.8218],\n",
            "        ...,\n",
            "        [-33.5457,  58.8377, -62.5938,  ...,  50.0544,  64.4278, -31.7201],\n",
            "        [-33.5461,  58.8384, -62.5945,  ...,  50.0550,  64.4286, -31.7205],\n",
            "        [-33.5459,  58.8381, -62.5942,  ...,  50.0547,  64.4282, -31.7203]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[-33.4598,  58.6871, -62.4345,  ...,  49.9269,  64.2639, -31.6388],\n",
            "        [-33.5457,  58.8378, -62.5939,  ...,  50.0544,  64.4279, -31.7201],\n",
            "        [-33.5460,  58.8383, -62.5944,  ...,  50.0548,  64.4284, -31.7204],\n",
            "        ...,\n",
            "        [-33.5453,  58.8371, -62.5931,  ...,  50.0538,  64.4271, -31.7197],\n",
            "        [-33.5455,  58.8374, -62.5934,  ...,  50.0541,  64.4275, -31.7199],\n",
            "        [-33.5457,  58.8377, -62.5938,  ...,  50.0544,  64.4278, -31.7201]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([28215.8672, 28287.9258, 28288.1543, 28287.8828, 28287.9980, 28287.9199,\n",
            "        28287.5176, 28287.7793, 28287.9355, 28287.9688, 28287.9980, 28287.9629,\n",
            "        28287.7793, 28288.1543, 28288.3574, 28287.8652, 28287.7930, 28287.8457,\n",
            "        28287.8652, 28287.9629, 28287.9199, 28288.1348, 28288.0742, 28288.1055,\n",
            "        28287.7617, 28288.0137, 28287.9824, 28287.9316, 28288.0645, 28287.2891,\n",
            "        28288.0156, 28287.8867, 28288.0488, 28288.0918, 28287.8242, 28287.9590,\n",
            "        28287.8438, 28288.0156, 28287.7754, 28287.8340, 28288.0312, 28287.3789,\n",
            "        28288.3711, 28287.9902, 28287.9590, 28287.7422, 28287.8125, 28288.1191,\n",
            "        28288.0430, 28288.0020, 28287.7715, 28287.8184, 28287.9863, 28288.0449,\n",
            "        28288.0176, 28287.7324, 28288.0879, 28288.0547, 28287.9590, 28288.2051,\n",
            "        28287.9043, 28287.9980, 28288.1074, 28288.0137, 28287.9492, 28287.8281,\n",
            "        28287.9355, 28287.8867, 28288.0098, 28287.7891, 28288.0430, 28287.7656,\n",
            "        28287.4062, 28287.9766, 28287.8984, 28287.9844, 28287.2480, 28288.1855,\n",
            "        28287.8184, 28287.6289, 28287.9980, 28287.5137, 28287.7930, 28287.9590,\n",
            "        28287.9824, 28287.9355, 28287.9688, 28287.7246, 28288.1133, 28288.0762,\n",
            "        28288.1680, 28288.0293, 28288.0039, 28288.0488, 28288.0547, 28287.9727,\n",
            "        28287.7793, 28287.9629, 28288.1016, 28287.7344, 28287.5820, 28287.7285,\n",
            "        28287.8984], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[3.38216891e+00 3.31534202e+00 3.09091183e+00 3.07456408e+00\n",
            "  2.75444095e+00 2.73315029e+00 2.65950578e+00 2.60276949e+00\n",
            "  2.51316987e+00 2.41166938e+00 2.36467970e+00 2.25910990e+00\n",
            "  2.25987237e+00 1.90420070e+00 1.81171079e+00 1.81691349e+00\n",
            "  1.70268084e+00 1.50093539e+00 1.30956214e+00 1.04845208e+00\n",
            "  1.03844140e+00 8.98510203e-01 8.34417991e-01 7.80534449e-01\n",
            "  6.85794969e-01 5.75261067e-01 5.66795325e-01 4.58210967e-01\n",
            "  3.48986185e-01 3.16186304e-01 2.79602936e-01 2.39963197e-01\n",
            "  2.30414973e-01 2.18266326e-01 1.96559730e-01 1.78919757e-01\n",
            "  8.98981435e-02 8.10929916e-02 5.70059354e-02 4.81352391e-02\n",
            "  4.61863701e-02 4.42708712e-02 3.95517911e-02 3.20355039e-02\n",
            "  2.73388087e-02 1.70059326e-02 1.26143777e-02 6.24493721e-03\n",
            "  4.99859234e-03 1.31957077e-03]]\n",
            "DEBUGGING: baseline2 looks like: 3.3821689083200432\n",
            "DEBUGGING: ADS looks like: [ -7.69774743  -7.5719136   -7.4955647   -7.23890057  -7.92150941\n",
            "  -7.97383324  -8.15360886  -7.8328515   -7.64744707  -7.27222606\n",
            "  -7.26464247  -6.64955626  -6.33699271  -6.65290478  -6.79098675\n",
            "  -6.6937369   -6.53390382  -6.57960625  -6.48993926  -6.61685001\n",
            "  -6.11479769  -6.32241504  -6.33021106  -6.34379906  -6.37268886\n",
            "  -6.40048159  -5.41771094  -5.51556741  -5.1789478   -5.14149869\n",
            "  -4.98504061  -4.98773065  -5.00870706  -4.47067638  -3.99132246\n",
            "  -3.99959513  -3.74085733  -3.75276179  -3.77665245  -3.61365603\n",
            "  -3.62419318  -2.95152039  -2.95277786  -2.96392078  -1.84049304\n",
            "  -1.85312889  -1.4538798   -1.46971515  -0.85412347  -0.84126361\n",
            " -10.16934204 -10.37077095 -11.17177496 -10.87052825 -10.79843613\n",
            " -10.74791996 -10.72667905 -10.48396081 -10.58401826 -10.25758044\n",
            " -10.29053646  -9.74644904  -9.47434874  -8.95405607  -8.73812705\n",
            "  -8.6972216   -8.19434302  -8.23275959  -8.04479304  -7.79870311\n",
            "  -7.27229471  -6.98320678  -6.99150437  -6.97498499  -7.00777866\n",
            "  -7.039261    -6.04952377  -6.0572583   -5.72637776  -5.5762114\n",
            "  -5.44535621  -5.43642434  -5.4623972   -4.93777167  -4.37408181\n",
            "  -4.39031685  -3.77936653  -3.79041601  -3.81248143  -3.62719022\n",
            "  -3.63703852  -2.96945674  -2.97792223  -2.9931005   -1.8767334\n",
            "  -1.86851268  -1.46717717  -1.46867571  -0.85426879  -0.84118202\n",
            "  -9.14463728  -9.05678537  -9.05156978  -8.76831941  -8.86557575\n",
            "  -8.81384044  -8.76981719  -8.44321457  -8.45258335  -8.33541788\n",
            "  -8.5349075   -8.37293332  -8.08739722  -8.10166638  -7.89981902\n",
            "  -7.81505602  -7.34988509  -7.59427915  -7.62954465  -7.55894789\n",
            "  -7.05055053  -6.75459703  -6.7774492   -6.75850307  -6.9869483\n",
            "  -7.01194012  -6.03205649  -6.05197636  -5.72719021  -5.57124555\n",
            "  -5.44712778  -5.45447446  -5.49113259  -4.96073884  -4.39695396\n",
            "  -4.40848314  -3.79454586  -3.80771858  -3.83031111  -3.64267335\n",
            "  -3.65760588  -2.98344358  -2.98904348  -2.99656007  -1.87254888\n",
            "  -1.86414539  -1.46491283  -1.46601234  -0.85081959  -0.84088036\n",
            "  -8.34266237  -8.27793127  -8.28176621  -7.96362667  -7.74235826\n",
            "  -7.67413128  -7.70855011  -7.29972581  -7.11832256  -6.96377456\n",
            "  -7.02268479  -6.41791463  -6.13675374  -5.60374068  -5.3468288\n",
            "  -5.24179862  -4.78364828  -5.36629084  -5.4982749   -5.55158336\n",
            "  -5.00876156  -4.76969631  -5.02287792  -5.1863862   -5.40718715\n",
            "  -5.85203273  -4.86103976  -5.1965602   -5.26081196  -5.09733142\n",
            "  -5.0495875   -5.16773356  -5.21700895  -4.70521678  -4.13840073\n",
            "  -4.21984684  -3.603834    -3.64057016  -3.75400308  -3.56744966\n",
            "  -3.58004426  -2.90538861  -2.91452836  -2.93608553  -1.82227835\n",
            "  -1.83176789  -1.44213931  -1.4526651   -0.84049648  -0.83652717]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(-6.3627, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.0662, -0.1594,  0.0373,  ...,  0.0384, -0.0553,  0.0109],\n",
            "        [ 0.0756, -0.1821,  0.0426,  ...,  0.0439, -0.0632,  0.0117],\n",
            "        [ 0.0978, -0.2353,  0.0550,  ...,  0.0567, -0.0816,  0.0170],\n",
            "        ...,\n",
            "        [ 0.1381, -0.3323,  0.0777,  ...,  0.0801, -0.1153,  0.0204],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0104,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0028,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0075,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0223,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0095,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0171,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0181,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0025,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0112,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0099,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0036,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0074,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0175,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0047,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0126,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0263,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0078,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0196,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0136,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0023,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0084,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0182,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0067,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0137,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0230,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0089,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0175,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0122,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0052,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0101,  0.0000,  0.0000,  0.0000]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.1865,  0.1673,  0.1188,  ..., -0.2702, -0.0415,  0.0503],\n",
            "        [ 0.2112,  0.1894,  0.1345,  ..., -0.3061, -0.0469,  0.0572],\n",
            "        [ 0.2794,  0.2507,  0.1780,  ..., -0.4050, -0.0621,  0.0748],\n",
            "        ...,\n",
            "        [ 0.3940,  0.3535,  0.2510,  ..., -0.5711, -0.0876,  0.1051],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0326,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0337,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0425,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0555,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0589,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0739,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0583,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0607,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0766,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0275,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0284,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0361,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0548,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0568,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0719,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0726,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0749,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0938,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0430,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0445,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0567,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0469,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0489,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0609,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0611,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000,  0.0631,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0787,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0308,  0.0000,\n",
            "          0.0000,  0.0000,  0.0000, -0.0326,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "         -0.0412,  0.0000,  0.0000,  0.0000]])\n",
            "DEBUGGING: training for one iteration takes 0.005281 min:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571,
          "referenced_widgets": [
            "a4c01a5febb2446db1addbed08d0b626",
            "029807dd33df482a8fbb2f6322d335f1",
            "5a18ceec6ca94b10b6a18562d94040b3",
            "8768a6635cfc44a1b9e74c0a59935b88",
            "33b77f26a8b943abb314e573174ec97f",
            "c5f76eb274744562a487eef20da90f7e",
            "d3550f11c0ae48b7bc2cf034ef581e64",
            "bd230810735740d28b4f42b781a40eb5"
          ]
        },
        "id": "Oe4fCU1V-kAs",
        "outputId": "59bf9d23-2c51-4b2d-a033-80d9399d681a"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4c01a5febb2446db1addbed08d0b626"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>â–ƒâ–‚â–‚â–â–‚â–…â–â–â–ƒâ–â–‚â–ƒâ–†â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–ƒâ–„â–…â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ</td></tr><tr><td>training reward</td><td>â–â–â–‡â–…â–…â–‡â–‚â–â–…â–…â–…â–…â–â–â–â–…â–…â–â–‚â–â–…â–â–‡â–…â–…â–‚â–ˆâ–ˆâ–…â–â–‚â–â–‚â–â–â–â–‚â–ƒâ–‚â–</td></tr><tr><td>training reward moving average</td><td>â–â–â–â–â–â–â–â–â–â–â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–…â–…â–…â–„â–„â–„â–„</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>training loss</td><td>-6.36267</td></tr><tr><td>training reward</td><td>0.10198</td></tr><tr><td>training reward moving average</td><td>0.2256</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">peach-sound-2762</strong>: <a href=\"https://wandb.ai/ieor4575-spring2022/finalproject/runs/1ppyhfj2\" target=\"_blank\">https://wandb.ai/ieor4575-spring2022/finalproject/runs/1ppyhfj2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220509_005505-1ppyhfj2/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [   54246.9141, 27220988.0000,  3948314.5000,  3902082.5000,\n",
        "        27219886.0000,  3816622.7500, 27175632.0000,  3976903.5000,\n",
        "         3977309.0000,  3961905.7500,  3904790.7500, 23420360.0000,\n",
        "        27218672.0000, 27206276.0000, 27190054.0000,  3976984.7500,\n",
        "         3931598.0000,  3963138.5000, 19419398.0000,  3931559.5000,\n",
        "         7862683.0000, 19299310.0000,  3915878.7500, 15562425.0000,\n",
        "        27141808.0000, 27323768.0000, 11622510.0000, 15451909.0000,\n",
        "        23389744.0000,  7781165.5000, 11871555.0000, 11657742.0000,\n",
        "        27473456.0000, 11592561.0000,  4054315.2500,  7718911.0000,\n",
        "        27136936.0000,  3914171.2500, 23255876.0000, 15599427.0000,\n",
        "        19661078.0000,  3915166.7500,  7554840.5000, 27196042.0000,\n",
        "        11791202.0000, 23477022.0000, 15708443.0000, 23297932.0000,\n",
        "        23511102.0000,  7689591.5000, 27405178.0000,  4021836.7500,\n",
        "        15558291.0000,  3948567.5000,  7915618.5000,  3864714.5000,\n",
        "         3995934.2500, 19536616.0000,  3890406.7500, 27284138.0000,\n",
        "        11731948.0000, 23232848.0000, 19200360.0000, 22949674.0000,\n",
        "        26724900.0000,  3268551.2500, 22647966.0000, 25925040.0000,\n",
        "        25380838.0000,  5669201.5000,  7810961.0000, 13092715.0000,\n",
        "        14364957.0000, 15622157.0000, 27473452.0000]"
      ],
      "metadata": {
        "id": "R5xFgG-ZGZkL"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_t = torch.FloatTensor(a)\n",
        "print(a_t)\n",
        "b_t = a_t /1000000\n",
        "print(b_t)\n",
        "print(torch.nn.functional.softmax(b_t, dim=0))\n",
        "b_t = a_t / a_t.max()\n",
        "print(b_t)\n",
        "torch.nn.functional.softmax(b_t, dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5GfEt5DGbcN",
        "outputId": "5222832a-86d3-4f6a-bef8-3baac8c975e7"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   54246.9141, 27220988.0000,  3948314.5000,  3902082.5000,\n",
            "        27219886.0000,  3816622.7500, 27175632.0000,  3976903.5000,\n",
            "         3977309.0000,  3961905.7500,  3904790.7500, 23420360.0000,\n",
            "        27218672.0000, 27206276.0000, 27190054.0000,  3976984.7500,\n",
            "         3931598.0000,  3963138.5000, 19419398.0000,  3931559.5000,\n",
            "         7862683.0000, 19299310.0000,  3915878.7500, 15562425.0000,\n",
            "        27141808.0000, 27323768.0000, 11622510.0000, 15451909.0000,\n",
            "        23389744.0000,  7781165.5000, 11871555.0000, 11657742.0000,\n",
            "        27473456.0000, 11592561.0000,  4054315.2500,  7718911.0000,\n",
            "        27136936.0000,  3914171.2500, 23255876.0000, 15599427.0000,\n",
            "        19661078.0000,  3915166.7500,  7554840.5000, 27196042.0000,\n",
            "        11791202.0000, 23477022.0000, 15708443.0000, 23297932.0000,\n",
            "        23511102.0000,  7689591.5000, 27405178.0000,  4021836.7500,\n",
            "        15558291.0000,  3948567.5000,  7915618.5000,  3864714.5000,\n",
            "         3995934.2500, 19536616.0000,  3890406.7500, 27284138.0000,\n",
            "        11731948.0000, 23232848.0000, 19200360.0000, 22949674.0000,\n",
            "        26724900.0000,  3268551.2500, 22647966.0000, 25925040.0000,\n",
            "        25380838.0000,  5669201.5000,  7810961.0000, 13092715.0000,\n",
            "        14364957.0000, 15622157.0000, 27473452.0000])\n",
            "tensor([ 0.0542, 27.2210,  3.9483,  3.9021, 27.2199,  3.8166, 27.1756,  3.9769,\n",
            "         3.9773,  3.9619,  3.9048, 23.4204, 27.2187, 27.2063, 27.1901,  3.9770,\n",
            "         3.9316,  3.9631, 19.4194,  3.9316,  7.8627, 19.2993,  3.9159, 15.5624,\n",
            "        27.1418, 27.3238, 11.6225, 15.4519, 23.3897,  7.7812, 11.8716, 11.6577,\n",
            "        27.4735, 11.5926,  4.0543,  7.7189, 27.1369,  3.9142, 23.2559, 15.5994,\n",
            "        19.6611,  3.9152,  7.5548, 27.1960, 11.7912, 23.4770, 15.7084, 23.2979,\n",
            "        23.5111,  7.6896, 27.4052,  4.0218, 15.5583,  3.9486,  7.9156,  3.8647,\n",
            "         3.9959, 19.5366,  3.8904, 27.2841, 11.7319, 23.2328, 19.2004, 22.9497,\n",
            "        26.7249,  3.2686, 22.6480, 25.9250, 25.3808,  5.6692,  7.8110, 13.0927,\n",
            "        14.3650, 15.6222, 27.4735])\n",
            "tensor([1.0010e-13, 6.2920e-02, 4.9158e-12, 4.6937e-12, 6.2851e-02, 4.3093e-12,\n",
            "        6.0130e-02, 5.0584e-12, 5.0605e-12, 4.9831e-12, 4.7065e-12, 1.4067e-03,\n",
            "        6.2775e-02, 6.2001e-02, 6.1004e-02, 5.0588e-12, 4.8344e-12, 4.9893e-12,\n",
            "        2.5740e-05, 4.8342e-12, 2.4637e-10, 2.2827e-05, 4.7589e-12, 5.4393e-07,\n",
            "        5.8130e-02, 6.9731e-02, 1.0579e-08, 4.8702e-07, 1.3643e-03, 2.2708e-10,\n",
            "        1.3571e-08, 1.0959e-08, 8.0991e-02, 1.0267e-08, 5.4655e-12, 2.1338e-10,\n",
            "        5.7848e-02, 4.7508e-12, 1.1933e-03, 5.6443e-07, 3.2777e-05, 4.7556e-12,\n",
            "        1.8109e-10, 6.1370e-02, 1.2523e-08, 1.4887e-03, 6.2944e-07, 1.2446e-03,\n",
            "        1.5403e-03, 2.0721e-10, 7.5646e-02, 5.2909e-12, 5.4168e-07, 4.9171e-12,\n",
            "        2.5976e-10, 4.5216e-12, 5.1556e-12, 2.8941e-05, 4.6393e-12, 6.7022e-02,\n",
            "        1.1803e-08, 1.1662e-03, 2.0676e-05, 8.7858e-04, 3.8313e-02, 2.4910e-12,\n",
            "        6.4976e-04, 1.7217e-02, 9.9914e-03, 2.7477e-11, 2.3395e-10, 4.6021e-08,\n",
            "        1.6424e-07, 5.7741e-07, 8.0991e-02])\n",
            "tensor([0.0020, 0.9908, 0.1437, 0.1420, 0.9908, 0.1389, 0.9892, 0.1448, 0.1448,\n",
            "        0.1442, 0.1421, 0.8525, 0.9907, 0.9903, 0.9897, 0.1448, 0.1431, 0.1443,\n",
            "        0.7068, 0.1431, 0.2862, 0.7025, 0.1425, 0.5665, 0.9879, 0.9946, 0.4230,\n",
            "        0.5624, 0.8514, 0.2832, 0.4321, 0.4243, 1.0000, 0.4220, 0.1476, 0.2810,\n",
            "        0.9878, 0.1425, 0.8465, 0.5678, 0.7156, 0.1425, 0.2750, 0.9899, 0.4292,\n",
            "        0.8545, 0.5718, 0.8480, 0.8558, 0.2799, 0.9975, 0.1464, 0.5663, 0.1437,\n",
            "        0.2881, 0.1407, 0.1454, 0.7111, 0.1416, 0.9931, 0.4270, 0.8456, 0.6989,\n",
            "        0.8353, 0.9728, 0.1190, 0.8244, 0.9436, 0.9238, 0.2064, 0.2843, 0.4766,\n",
            "        0.5229, 0.5686, 1.0000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0074, 0.0199, 0.0085, 0.0085, 0.0199, 0.0085, 0.0199, 0.0085, 0.0085,\n",
              "        0.0085, 0.0085, 0.0173, 0.0199, 0.0199, 0.0199, 0.0085, 0.0085, 0.0085,\n",
              "        0.0150, 0.0085, 0.0098, 0.0149, 0.0085, 0.0130, 0.0198, 0.0200, 0.0113,\n",
              "        0.0130, 0.0173, 0.0098, 0.0114, 0.0113, 0.0201, 0.0113, 0.0086, 0.0098,\n",
              "        0.0198, 0.0085, 0.0172, 0.0130, 0.0151, 0.0085, 0.0097, 0.0199, 0.0113,\n",
              "        0.0174, 0.0131, 0.0172, 0.0174, 0.0098, 0.0200, 0.0085, 0.0130, 0.0085,\n",
              "        0.0099, 0.0085, 0.0085, 0.0150, 0.0085, 0.0199, 0.0113, 0.0172, 0.0149,\n",
              "        0.0170, 0.0195, 0.0083, 0.0168, 0.0190, 0.0186, 0.0091, 0.0098, 0.0119,\n",
              "        0.0125, 0.0130, 0.0201])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYdGyAom2SMj",
        "outputId": "4d0b586a-ba6d-4614-983b-01f0334b2e19"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 0., 1., 3., 0., 0., 0., 3., 2., 3., 1., 1., 2., 0., 4., 4., 0.,\n",
              "       2., 1., 2., 2., 2., 4., 1., 3., 2., 0., 1., 2., 0., 3., 0., 3., 1.,\n",
              "       3., 0., 4., 1., 4., 4., 0., 0., 1., 2., 4., 0., 0., 1., 1., 1., 2.,\n",
              "       3., 4., 4., 3., 3., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s[1][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WUaedhX198a",
        "outputId": "6460c586-c962-4776-dbaa-0377819be691"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5902996.0"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s[-2] / np.max(s[-2], axis=1, keepdims=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmmYGIMyEQNl",
        "outputId": "be6308f4-ef3e-4f01-a7ad-b5f4d6cf9947"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.54545455, 0.63636364, 0.81818182, ..., 0.63636364, 0.81818182,\n",
              "        0.63636364],\n",
              "       [0.68758003, 0.67587342, 0.86656301, ..., 0.62154747, 0.6715749 ,\n",
              "        0.50594476],\n",
              "       [0.68755929, 0.67568452, 0.86672773, ..., 0.62108672, 0.67149727,\n",
              "        0.50616638],\n",
              "       ...,\n",
              "       [0.68755279, 0.67562289, 0.86671242, ..., 0.62114654, 0.67124155,\n",
              "        0.50601774],\n",
              "       [0.6876384 , 0.67548087, 0.86687508, ..., 0.62124962, 0.67148626,\n",
              "        0.50601363],\n",
              "       [0.68765826, 0.67576792, 0.86667401, ..., 0.62121546, 0.67130904,\n",
              "        0.50605527]])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(s[-2]), len(s[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GEP-MOCEZKu",
        "outputId": "dbdb5bbc-0923-46da-cd7a-379bcda9a05a"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109, 110)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([0.0057, 0.0235, 0.0144, 0.0181, 0.0181, 0.0123, 0.0293, 0.0095, 0.0122,\n",
        "        0.0146, 0.0152, 0.0095, 0.0184, 0.0151, 0.0143, 0.0095, 0.0220, 0.0120,\n",
        "        0.0209, 0.0226, 0.0142, 0.0124, 0.0145, 0.0133, 0.0218, 0.0146, 0.0098,\n",
        "        0.0186, 0.0146, 0.0126, 0.0182, 0.0204, 0.0155, 0.0180, 0.0098, 0.0184,\n",
        "        0.0248, 0.0150, 0.0215, 0.0114, 0.0186, 0.0175, 0.0141, 0.0199, 0.0250,\n",
        "        0.0178, 0.0310, 0.0170, 0.0153, 0.0204, 0.0121, 0.0247, 0.0187, 0.0197,\n",
        "        0.0130, 0.0127, 0.0240, 0.0189, 0.0104, 0.0125])\n",
        "a.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlcbwh-Ts6Jt",
        "outputId": "93ac33f3-68f8-47f0-bee4-790955906266"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.env_now.env.oldobj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg-stUzCuAdm",
        "outputId": "f11a2427-2006-4d6e-bcb0-0a8b3af18562"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-2102.784760854756"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.env_now.env.newobj\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyF1UWObuLoZ",
        "outputId": "d2e11cce-7a14-4958-e05a-146435c36759"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-2102.784760854756"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.env_now.env.ip_obj"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPL2qJZ0nNrJ",
        "outputId": "c26858ec-1867-4467-a705-d0d54760e489"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-2100.0"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OH notes:\n",
        "\n",
        "baseline is what you use to interprete the reward\n",
        "\n",
        "don't use nn, use \"mean\" of rewards in this episode (I think so)\n",
        "\n",
        "Maybe look in to the instances, and look at how your agent is solving them\n",
        "\n",
        "Cutting off early, but only after solved some LP's\n",
        "- counterfactual exploration\n",
        "  - more than to do it more random\n",
        "- all prob entirely the same\n",
        "- activation function ?\n",
        "\n",
        "not learning? \n",
        "\n",
        "reward shaping?\n",
        "- someone: amplify the reward (shouldn't, since every step wil GIVE a reward), compare it to other POSSIBLE states\n",
        "- pre-trained on the instances and pre-trained the baseline?\n",
        "- get the max reward from the LP solver (isn't this cheating lol)\n",
        "- recalcluate the max-gap-to-go (lol remaining max gap) every step\n",
        "- go in the environment to make if return the shaped new-gap reward\n",
        "- the original reward doesn't help you across LPs?\n",
        "- moving average of *returns* from all *previous* episodes\n",
        "  - return is the discounted sum of the reward\n",
        "- advantage? Q - running averaged RETURN (but different states are mixed in, how do you deal with that)\n",
        "- Think about what's wrong with this base line, and write it down\n",
        "  - something about the states\n",
        "\n",
        "\n",
        "differences between LPs\n",
        "\n",
        "mode: \n",
        "- standardize the constraints, and the b vector by itself\n",
        "  - do you normalize by row or columns?\n",
        "  - He thinks it's more sense to normalize by rows\n",
        "  - Normalize it twice? LOL\n",
        "- or a normalization layer\\\n",
        "\n",
        "\n",
        "When doing softmax you can use a lamda (parameter) to mitigate large score difference\n",
        "- softmax comes with a scalar parameter\n",
        "\n",
        "Professor didn't think normalizing the input is necessary & and it shouldn't make a difference anyways (but come numerical value can be lost after normalization)\n",
        "\n",
        "iteration: \n",
        "\n",
        "plot random policy together, (as a bseline to see if your model is really learning)\n",
        "\n",
        "For baseline, Prof is suggesting Q network can work too.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ha4GPGL8Dduc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sKnhC54KYNNL"
      },
      "execution_count": 124,
      "outputs": []
    }
  ]
}