{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_policy_gradient.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "591549f95fdc4d90afb7c4772bde1f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c116081950dc471abc1a6f55dfb2d265",
              "IPY_MODEL_3618d19faefb447b80d30184c47c2d9f"
            ],
            "layout": "IPY_MODEL_593bb22f5b6e493b8bd86db7f50155ad"
          }
        },
        "c116081950dc471abc1a6f55dfb2d265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f752cec13d74e34a1dec1920105ec6b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6877226f417e42d59c4834127bdf2fbe",
            "value": "1.048 MB of 1.048 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "3618d19faefb447b80d30184c47c2d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_880332d08e6745cbb0c87304acbac072",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8a09347cb234bb0904a023c8fae1e9b",
            "value": 1
          }
        },
        "593bb22f5b6e493b8bd86db7f50155ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f752cec13d74e34a1dec1920105ec6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6877226f417e42d59c4834127bdf2fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "880332d08e6745cbb0c87304acbac072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8a09347cb234bb0904a023c8fae1e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ClaireZixiWang/learn2cut/blob/main/Project_policy_gradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## See README.md file for further details about the project and the environment.\n",
        "\n",
        "### State-Action Description\n",
        "\n",
        "### State\n",
        "State s is an array with give components\n",
        "\n",
        "* s[0]:  constraint matrix $A$of the current LP ($\\max  -c^Tx \\text{ s.t. }Ax \\le  b$) . Dimension is $m \\times n$. See by printing s[0].shape. Here $n$ is the (fixed) number of variables. For instances of size 60 by 60 used in the above command, $n$ will remain fixed as 60. And $m$ is the current number of constraints. Initially, $m$ is to the number of constraints in the IP instance. (For instances generated with --num-c=60, $m$ is 60 at the first step).  But $m$ will increase by one in every step of the episode as one new constraint (cut) is added on taking an action.\n",
        "* s[1]: rhs $b$ for the current LP ($Ax\\le b$). Dimension same as the number $m$ in matrix A.\n",
        "* s[2]: coefficient vector $c$ from the LP objective ($-c^Tx$). Dimension same as the number of variables, i.e., $n$.\n",
        "* s[3],  s[4]: Gomory cuts available in the current round of Gomory's cutting plane algorithm. Each cut $i$ is of the form $D_i x\\le d_i$.   s[3] gives the matrix $D$ (of dimension $k \\times n$) of cuts and s[4] gives the rhs $d$ (of dimension $k$). The number of cuts $k$ available in each round changes, you can find it out by printing the size of last component of state, i.e., s[4].size or s[-1].size.\n",
        "\n",
        "### Actions\n",
        "There are k=s[4].size actions available in each state $s$, with $i^{th}$ action corresponding to the $i^{th}$ cut with inequality $D_i x\\le d_i$ in $s[3], s[4]$."
      ],
      "metadata": {
        "id": "5TN-sMTvcG_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***QUESTIONS***:\n",
        "1. By \"current\" LP, you mean the LP that the agent was running in the last state? As in, the LP with all the added constraints? \n",
        "  * ==> I think so.\n",
        "1. What do you mean Gomory cuts *available*? As in, after doing Simplex methods, the *variables* that you can choose to cut?\n",
        "  * Yes I think so.\n",
        "2. Isn't the number of variables (n) changing? in the C-G cutting plane method?\n",
        "  * No, as the spec says, **$n$ is the fixed number of variables**.\n",
        "  * If you look that cuttng plane lecture notes, you can see that after each step, the dummy variable is not added in the constraint. They are merely there for the sake of the LP solver (simplex method), but not really relevant for us.\n",
        "    * This is not correct, I think they are still very much relevant, it's just that I think among the 60 variables a lot of them are space holders for dummy variables so that our $n$ is fixed, so that we don't have to worry about using LSTM. Since each time the sequence [a, b] will be of size n+1. And we can just use a fixed-input-size network to do that.\n",
        "    * But still need to verify with the TA about the place holder understanding.\n",
        "3. dimension of s[3] and s[4]? Where is the \"available all\" stored? In which dimension?\n",
        "  * Each row of D is an \"available cut\". Therefore each $D_i x\\le d_i$ is an \"available\" cut in CG method solved from the simplex method.\n",
        "4. pointing towards the slides: why does the number of constraints m increase 1 in each step, if you can choose *multiple* cuts in one step? (OR in the algorithm we just choose one cut each time? or is that a more vanilla version to start, but to expand on multiple cuts a time later?)\n",
        "5. What do you mean by each \"instance\"?"
      ],
      "metadata": {
        "id": "XJE0bz30UL1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYROdPaaZOVa",
        "outputId": "46d14047-6df4-4cd5-be97-a79a49841b3f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -i https://pypi.gurobi.com gurobipy"
      ],
      "metadata": {
        "id": "xSXTKB2zurrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59cd0243-622b-4c42-fe5a-184580e52931"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.gurobi.com\n",
            "Requirement already satisfied: gurobipy in /usr/local/lib/python3.7/dist-packages (9.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qqq"
      ],
      "metadata": {
        "id": "YULy9ymNvDxN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/IEOR_RL/Project_learn2cut\n",
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lTnvB0_iZUrX",
        "outputId": "05cb7689-32f9-4d8f-f7cf-4fd81d71b80e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IEOR_RL/Project_learn2cut\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/IEOR_RL/Project_learn2cut'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "id": "Q8PiSPj5us0O"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.nn.Sequential(\n",
        "            torch.nn.Linear(4, 40),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(40, 20), \n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(20, 10)\n",
        "        )\n",
        "\n",
        "datapoint = torch.FloatTensor([\n",
        "                               [[1,2,3,4],\n",
        "                                [2,3,4,5]],\n",
        "                               [[3,4,5,6],\n",
        "                                [4,5,6,7]]\n",
        "                              ])\n"
      ],
      "metadata": {
        "id": "ojB8UvBAPAWk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model(datapoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_r_nraniPaKl",
        "outputId": "a83e1b8e-2bd1-4a3e-b770-bfb66f866559"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1766, -0.0725,  0.1977, -0.0474, -0.5084,  0.1780, -0.1971,\n",
              "          -0.1208,  0.0194, -0.2716],\n",
              "         [ 0.2041, -0.1546,  0.2746, -0.1296, -0.6199,  0.3296, -0.2750,\n",
              "          -0.0710,  0.1022, -0.4243]],\n",
              "\n",
              "        [[ 0.2707, -0.2199,  0.3738, -0.2215, -0.7469,  0.5083, -0.3469,\n",
              "          -0.0447,  0.1822, -0.5494],\n",
              "         [ 0.3359, -0.2808,  0.4771, -0.2963, -0.8794,  0.6826, -0.4273,\n",
              "          -0.0122,  0.2559, -0.6690]]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Code for Policy Model\n",
        "\n",
        "class Policy(object):\n",
        "\n",
        "    # inputsize = n+1 = 61\n",
        "    def __init__(self, lr, input_size, attention_size=10, temperature=1) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Linear(input_size, 40),\n",
        "            # torch.nn.Sigmoid(),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(40, 30), \n",
        "            # torch.nn.Sigmoid(),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(30, 20), \n",
        "            # torch.nn.Sigmoid(),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(20, attention_size)\n",
        "        )\n",
        "\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
        "\n",
        "        # RECORD HYPER-PARAMS\n",
        "        self.input_size = input_size\n",
        "        self.attention_size = attention_size\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def compute_logits_big_batch(self, obs_matrix, act_matrix, batchsize):\n",
        "        '''\n",
        "        Function that takes in a batch of observations and computes the action logits for each of observations in this batch\n",
        "        Args: obs_matrix: np.array(m * batchsize, n+1) # TODO maybe change this to tensor\n",
        "              act_matrix: np.array(k * batchsize, n+1)\n",
        "        Return: batch_logit: tensor(batchsize, k)\n",
        "        '''\n",
        "\n",
        "        # Get the batch result\n",
        "\n",
        "        # transform to tensor\n",
        "        obs_attention = self.model(torch.FloatTensor(obs_matrix)) # tensor(m * batchsize, u)\n",
        "        act_attention = self.model(torch.FloatTensor(act_matrix)) # tensor(k * batchsize, u)\n",
        "\n",
        "        assert obs_attention.shape == (obs_matrix.shape[0], self.attention_size)\n",
        "        assert act_attention.shape == (act_matrix.shape[0], self.attention_size)\n",
        "\n",
        "        # split a batch of output of size tensor(m * batchsize, u) into (batchsize, m, u)\n",
        "        batch_obs_output = torch.reshape(obs_attention, (batchsize, obs_attention.shape[0]/batchsize, obs_attention.shape[1]))\n",
        "        \n",
        "        # split a batch of output of size tensor(k * batchsize, u) into (batchsize, k, u)\n",
        "        batch_act_output = torch.reshape(act_attention, (batchsize, act_attention.shape[0]/batchsize, act_attention.shape[1]))\n",
        "\n",
        "        # To do batch matrix multiplication, transpose (batchsize, k, u) into (batchsize, u, k)\n",
        "        # (batchsize, m, u) @ (batchsize, u, k) =  (batchsize, m, k)\n",
        "        # (batchsize, m, k) == mean across all observation ==> (batchsize, k)\n",
        "        batch_logit = torch.bmm(batch_obs_output, batch_act_output.transpose(0, 2, 1)).mean(dim=1)\n",
        "\n",
        "        assert batch_logit.shape == (batchsize, act_matrix.shape[0]/batchsize)\n",
        "\n",
        "        return batch_logit\n",
        "\n",
        "    def compute_batch_selected_prob(self, batch_probs):\n",
        "        '''\n",
        "        Function that takes in a batch of probabilities and return the max probability for each \"datapoint\" in the batch\n",
        "        Args:    batch_logit: tensor(batchsize, k)\n",
        "        Return:  batch_selected_prob: tensor(batchsize,)\n",
        "        '''\n",
        "        # TODO\n",
        "\n",
        "        return\n",
        "\n",
        "\n",
        "    def compute_one_step_logits(self, obs, act):\n",
        "        '''\n",
        "        Function that takes in ONE observation and action space, computes the action logits\n",
        "        Args:   obs_matrix: np.array(m, n+1)\n",
        "                act_matrix: np.array(k, n+1)\n",
        "        Return: logit: tensor(k)\n",
        "        '''\n",
        "\n",
        "        obs_attention = self.model(torch.FloatTensor(obs)) #-> (m, 10)\n",
        "        act_attention = self.model(torch.FloatTensor(act)) #-> (k, 10)\n",
        "        # print(\"DEBUGGING: obs_attention looks like:\", obs_attention)\n",
        "        # print(\"DEBUGGING: act_attention looks like:\", act_attention)\n",
        "\n",
        "        # attention matrix multiplication & mean to get the score\n",
        "        logits = torch.mm(obs_attention, act_attention.transpose(1, 0)).mean(dim=0)\n",
        "        # print(\"DEBUGGING: logits looks like:\", logits)\n",
        "\n",
        "        # print(\"DEBUGGING: act.shape =\", act_attention.shape)\n",
        "        # print(\"DEBUGGING: logits.shape =\", logits.shape)\n",
        "        assert logits.shape[0] == act_attention.shape[0]\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def predict_prob(self, obs, act):\n",
        "        # Function that uses softmax to transform logits to probabilities\n",
        "        # TODO: What shape should obs and act take?\n",
        "        # Args:   obs_matrix: np.array(m, n+1)\n",
        "        #         act_matrix: np.array(k, n+1)\n",
        "        # Return: probs: tensor(k)\n",
        "\n",
        "        logits = self.compute_one_step_logits(obs, act)\n",
        "\n",
        "        # TODO: make temperature a argument in the function, so that it's depended on the steps\n",
        "        probs = torch.nn.functional.softmax(logits/self.temperature, dim=0)\n",
        "        return probs\n",
        "\n",
        "    def selected_prob(self, probs, action):\n",
        "\n",
        "\n",
        "        # TODO: do I need this function?\n",
        "        one_hot = torch.zeros()\n",
        "        return probs.max()\n",
        "\n",
        "    def choose_action(self, obs, act):\n",
        "\n",
        "        # TODO: is this returning a number?\n",
        "        return torch.argmax(self.predict_prob(obs, act)).item()\n",
        "\n",
        "\n",
        "    def train(self, obs_matrix, act_matrix, actions, Qs):\n",
        "        \"\"\"\n",
        "        Args: obs_matrix: np.array(batchsize * m, n+1) => changed to [np.array(m, n+1)] * batchsize, note that m are varied!\n",
        "              act_matrix: np.array(batchsize * k, n+1)  \n",
        "              actions: => [[action number]] * batchsize      \n",
        "              Qs: np.array(batchsize, )\n",
        "        \"\"\"\n",
        "        # Convert numpy array to tensor\n",
        "\n",
        "        # use compute_batch_prob to compute the batch logits for every datapoint in batch.\n",
        "        # use compute_batch_selected_prob the compute the max probabilty for every datapoint in batch.\n",
        "        start = time.time()\n",
        "        print(\"DEBUGGING: I'm inside the training now!\")\n",
        "        \n",
        "        Qs = torch.FloatTensor(Qs)\n",
        "\n",
        "\n",
        "        # Try using a for loop first, see whether it really cost too much time & whether it works at all\n",
        "        prob_selected = torch.zeros(len(actions))\n",
        "        for i in range(len(obs_matrix)):\n",
        "            #TODO: adjust the temperatures based on trajectory steps\n",
        "            probs = self.predict_prob(obs_matrix[i], act_matrix[i])\n",
        "            one_hot = torch.zeros_like(probs)\n",
        "            one_hot[actions[i][0]] = 1\n",
        "            prob_selected[i] = torch.sum(probs * one_hot)\n",
        "\n",
        "\n",
        "        # For robustness add in noise for prob_selected # TODO: why do this?\n",
        "\n",
        "        # define loss function as in lab 4\n",
        "        # TODO define loss function as described in the text above\n",
        "        loss = - (torch.sum(Qs * torch.log(prob_selected)) / (len(obs_matrix) + 1))\n",
        "        print(\"DEBUGGING: the loss =\", loss)\n",
        "\n",
        "        print(\"DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\")\n",
        "        print(\"   First layer:\")\n",
        "        print(policy.model[0].weight.grad)\n",
        "        print(\"   Last layer:\")\n",
        "        print(policy.model[6].weight.grad)\n",
        "\n",
        "        # backward pass\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        print(\"DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\")\n",
        "        print(\"   First layer:\")\n",
        "        print(policy.model[0].weight.grad)\n",
        "        print(\"   Last layer:\")\n",
        "        print(policy.model[6].weight.grad)\n",
        "\n",
        "        # step\n",
        "        self.optimizer.step()\n",
        "\n",
        "\n",
        "        print(\"DEBUGGING: training for one iteration takes %f min:\" % ((time.time() - start)/60))\n",
        "\n",
        "\n",
        "        # return detached loss (why?)\n",
        "        return loss.detach().cpu().data.numpy()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HViRnY1ssGfc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchsummary import summary\n",
        "# summary(policy.model, (61,))\n",
        "# print(policy.model)"
      ],
      "metadata": {
        "id": "OGm4an0pWPHr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(policy.model[6].weight.grad)"
      ],
      "metadata": {
        "id": "dfkXKSJWW6OR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP model for policy model:\n",
        "#   model.forward\n",
        "#   model.train --> What is in this function? what are the function arguments?\n",
        "# Baseline function b(s) ==> Okay maybe we stil need the V model as a proper baseline\n",
        "\n",
        "\n",
        "# Q value model ==> Discard this right now, just do vanilla policy gradient\n",
        "#   Can I just use the one in Lab4? What does it mean? what does the states and actions mean? --> Print out the s, r to check\n",
        "#   What is a Q-value in our set-up?\n",
        "#   How do I used this? \n",
        "#   (What's the baseline function??)"
      ],
      "metadata": {
        "id": "ACiQz-gESgOO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2xI0riE6md5V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "0b1db623-cca4-4076-8c46-daf5e32691ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mclaire-zixi-wang\u001b[0m (\u001b[33mieor4575-spring2022\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/IEOR_RL/Project_learn2cut/wandb/run-20220508_222731-1am91bic</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ieor4575-spring2022/finalproject/runs/1am91bic\" target=\"_blank\">silver-monkey-2705</a></strong> to <a href=\"https://wandb.ai/ieor4575-spring2022/finalproject\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# import gymenv_v2\n",
        "from gymenv_v2 import make_multiple_env\n",
        "\n",
        "\n",
        "import wandb\n",
        "wandb.login()\n",
        "run=wandb.init(project=\"finalproject\", entity=\"ieor4575-spring2022\", tags=[\"training-easy\"])\n",
        "#run=wandb.init(project=\"finalproject\", entity=\"ieor-4575\", tags=[\"training-hard\"])\n",
        "#run=wandb.init(project=\"finalproject\", entity=\"ieor-4575\", tags=[\"test\"])\n",
        "\n",
        "### TRAINING\n",
        "\n",
        "# Setup: You may generate your own instances on which you train the cutting agent.\n",
        "custom_config = {\n",
        "    \"load_dir\"        : 'instances/randomip_n60_m60',   # this is the location of the randomly generated instances (you may specify a different directory)\n",
        "    \"idx_list\"        : list(range(20)),                # take the first 20 instances from the directory\n",
        "    \"timelimit\"       : 50,                             # the maximum horizon length is 50\n",
        "    \"reward_type\"     : 'obj'                           # DO NOT CHANGE reward_type\n",
        "}\n",
        "\n",
        "# Easy Setup: Use the following environment settings. We will evaluate your agent with the same easy config below:\n",
        "easy_config = {\n",
        "    \"load_dir\"        : 'instances/train_10_n60_m60',\n",
        "    \"idx_list\"        : list(range(5)),\n",
        "    \"timelimit\"       : 50,\n",
        "    \"reward_type\"     : 'obj'\n",
        "}\n",
        "\n",
        "# Hard Setup: Use the following environment settings. We will evaluate your agent with the same hard config below:\n",
        "hard_config = {\n",
        "    \"load_dir\"        : 'instances/train_100_n60_m60',\n",
        "    \"idx_list\"        : list(range(99)),\n",
        "    \"timelimit\"       : 50,\n",
        "    \"reward_type\"     : 'obj'\n",
        "}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch._C import dtype\n",
        "def discounted_rewards(r, gamma):\n",
        "    \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n",
        "    discounted_r = np.zeros_like(r, dtype=float)\n",
        "    running_sum = 0\n",
        "    for i in reversed(range(0,len(r))):\n",
        "        discounted_r[i] = running_sum * gamma + r[i]\n",
        "        running_sum = discounted_r[i]\n",
        "    return list(discounted_r)"
      ],
      "metadata": {
        "id": "COyIO0TEDRjt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = make_multiple_env(**easy_config) \n",
        "s = env.reset()   # samples a RANDOM INSTANCE every time env.reset() is called\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFhvgi_q53V4",
        "outputId": "2e6c5179-027f-4862-e5aa-4a57ad508bcb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading training instances, dir instances/train_10_n60_m60 idx 0\n",
            "Restricted license - for non-production use only - expires 2023-10-25\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 1\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 2\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 3\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import normalize\n",
        "A, b, c0, cuts_a, cuts_b = s\n",
        "concat = np.hstack((s[0], np.expand_dims(s[1], axis=1)))\n",
        "concat\n",
        "# np.linalg.norm(concat, axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJXouQZx9DQ7",
        "outputId": "39d03498-444d-4411-b694-874d9375e6e1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  2,   0,   1, ...,   0,   0, 586],\n",
              "       [  2,   3,   0, ...,   1,   1, 580],\n",
              "       [  0,   4,   4, ...,   4,   4, 564],\n",
              "       ...,\n",
              "       [  4,   2,   3, ...,   1,   1, 598],\n",
              "       [  4,   4,   4, ...,   2,   0, 592],\n",
              "       [  1,   2,   2, ...,   2,   3, 580]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.expand_dims(s[1], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSUhT5go6czx",
        "outputId": "741307a7-2d97-45dc-fce0-84e7ceade803"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[586],\n",
              "       [580],\n",
              "       [564],\n",
              "       [575],\n",
              "       [562],\n",
              "       [563],\n",
              "       [568],\n",
              "       [594],\n",
              "       [585],\n",
              "       [585],\n",
              "       [543],\n",
              "       [552],\n",
              "       [569],\n",
              "       [598],\n",
              "       [548],\n",
              "       [547],\n",
              "       [544],\n",
              "       [557],\n",
              "       [542],\n",
              "       [547],\n",
              "       [582],\n",
              "       [542],\n",
              "       [562],\n",
              "       [578],\n",
              "       [548],\n",
              "       [557],\n",
              "       [588],\n",
              "       [540],\n",
              "       [573],\n",
              "       [580],\n",
              "       [589],\n",
              "       [557],\n",
              "       [568],\n",
              "       [571],\n",
              "       [597],\n",
              "       [566],\n",
              "       [568],\n",
              "       [581],\n",
              "       [562],\n",
              "       [556],\n",
              "       [543],\n",
              "       [554],\n",
              "       [592],\n",
              "       [589],\n",
              "       [597],\n",
              "       [561],\n",
              "       [587],\n",
              "       [576],\n",
              "       [587],\n",
              "       [587],\n",
              "       [590],\n",
              "       [544],\n",
              "       [589],\n",
              "       [586],\n",
              "       [588],\n",
              "       [573],\n",
              "       [581],\n",
              "       [598],\n",
              "       [592],\n",
              "       [580]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.hstack((s[0], np.expand_dims(s[1], axis=1)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjIckPCE7n2z",
        "outputId": "c47ec589-3040-47bc-c633-fc00dd22d793"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  2,   0,   1, ...,   0,   0, 586],\n",
              "       [  2,   3,   0, ...,   1,   1, 580],\n",
              "       [  0,   4,   4, ...,   4,   4, 564],\n",
              "       ...,\n",
              "       [  4,   2,   3, ...,   1,   1, 598],\n",
              "       [  4,   4,   4, ...,   2,   0, 592],\n",
              "       [  1,   2,   2, ...,   2,   3, 580]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([\n",
        "              [1,2,3,4],\n",
        "              [3,3,3,3],\n",
        "              [2,2,2,2],\n",
        "              [1,1,1,1]\n",
        "])\n",
        "print(a.mean(axis=0, keepdims=True))\n",
        "a = a - a.mean(axis=0, keepdims=True)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMUMT8x_A8I0",
        "outputId": "43e6e70b-67ce-47fb-e344-7c7de2f90a32"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.75 2.   2.25 2.5 ]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.75,  0.  ,  0.75,  1.5 ],\n",
              "       [ 1.25,  1.  ,  0.75,  0.5 ],\n",
              "       [ 0.25,  0.  , -0.25, -0.5 ],\n",
              "       [-0.75, -1.  , -1.25, -1.5 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "empty = [np.array([1,2]), np.array([3,4])]\n",
        "a = []\n",
        "b = a + empty + empty\n",
        "\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBFhGXfSJz3l",
        "outputId": "b33c692a-743b-4306-86e0-a230fe0da739"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 2]), array([3, 4]), array([1, 2]), array([3, 4])]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "empty = [np.array([10,20])]\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJY9NttjZiM7",
        "outputId": "0314411e-2889-4518-c342-c09bb10fc771"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([1, 2]), array([3, 4]), array([1, 2]), array([3, 4])]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%wandb\n",
        "# create env\n",
        "env = make_multiple_env(**easy_config) \n",
        "# Parameter initialization\n",
        "numtrajs = 4  # num of trajecories from the current policy to collect in each iteration\n",
        "lr_pg = 1e-2  # learning rate for PG\n",
        "attention_size = 10\n",
        "iterations = 20\n",
        "discount_gamma = .99\n",
        "\n",
        "# Network initialize\n",
        "policy = Policy(lr_pg, 61, attention_size, 0.1)\n",
        "\n",
        "#To record training reward for logging and plotting purposes\n",
        "rrecord = []\n",
        "\n",
        "# For every training iteration, we roll out 5 random instances using the policy network\n",
        "# collect observation and action matrices from these 5 roll-outs, consider this a BATCH\n",
        "# train the network using this BATCH\n",
        "for ite in range(iterations):\n",
        "\n",
        "    print(\"==========================================================================================================\")\n",
        "    print(\"Outer iteration no\", ite)\n",
        "\n",
        "    # To record traectories generated from current policy\n",
        "    OBS_MAT = []  # observations: [obs_matrices_batch_traj1, obs_matrices_batch_traj2, ....]\n",
        "    ACT_MAT = []  # actions\n",
        "    ADS = []  # advantages (to compute policy gradient)\n",
        "    VAL = []  # Monte carlo value predictions (to compute baseline, and policy gradient) => 2 d list (numtrajs, #steps per traj)\n",
        "    traj_returns = []  # a list of 5 numbers, each number represents the RETURN of that roll-out\n",
        "    actions = []\n",
        "    \n",
        "    # collect some trajectories\n",
        "    for num in range(numtrajs):\n",
        "        print(\"-------------------------------------------------------------------------------------------\")\n",
        "        print(\"Running trajectories:\", num)\n",
        "        # Initialize a list of obs_matrices and act_matrices, to store all the obs_matrix and act_matrix in the trajectory\n",
        "        obs_matrices = []  # states: [obs_matrix_state1, obs_matrix_state2, ...]\n",
        "        act_matrices = []  # actions matrices\n",
        "        \n",
        "        # this is used to collect all the immedaite rewards in this trajectory\n",
        "        rews = []  # instant rewards\n",
        "        rel_rews = []\n",
        "\n",
        "        # gym loop\n",
        "        s = env.reset()   # samples a RANDOM INSTANCE every time env.reset() is called\n",
        "        done = False\n",
        "\n",
        "        # TODO: wandb logging -> what reward average should we log??\n",
        "        t = 0 # TODO: how is this used?\n",
        "        repisode = 0  # TODO: how is this used?\n",
        "\n",
        "        inner_step = 1\n",
        "        \n",
        "\n",
        "        # roll out ONE policy\n",
        "        while not done:\n",
        "\n",
        "            # TODO compute the running average RETURN as basline\n",
        "            A, b, c0, cuts_a, cuts_b = s\n",
        "\n",
        "            # choose the action according to the model output probabilities\n",
        "\n",
        "            # Concat [A,b] and [cuts_a, cuts_b]\n",
        "            assert A.shape[0] == b.shape[0]\n",
        "            assert cuts_a.shape[0] == cuts_b.shape[0]\n",
        "\n",
        "            obs_matrix = np.hstack((A, np.expand_dims(b, axis=1)))\n",
        "            act_matrix = np.hstack((cuts_a, np.expand_dims(cuts_b, axis=1)))\n",
        "\n",
        "            assert obs_matrix.shape == (A.shape[0], A.shape[1]+1)\n",
        "            assert act_matrix.shape == (cuts_a.shape[0], cuts_a.shape[1]+1)\n",
        "\n",
        "            # Normalize on a row (MIGHT NOT NEED THIS)\n",
        "            \n",
        "            # The reason we want to normalize a row: we want the numeric space of the model input to be just between 0, 1\n",
        "            # Right now I'm normalizing such that the largest number has value 1 --> each row divided by the largest num in that row\n",
        "            #   => This would result in b vector always be 1 (does it make sense?)\n",
        "            # another option is to normalize such that the SUM of the row is 1\n",
        "            #   => I think this makes more sense, consider this differentiates the max among datapoints\n",
        "            #   => According to prof in OH this might cause some information loss\n",
        "            \n",
        "            obs_matrix = obs_matrix / obs_matrix.max(axis=1, keepdims=True) * 100\n",
        "            act_matrix = act_matrix / act_matrix.max(axis=1, keepdims=True) * 100\n",
        "            \n",
        "            # print(\"DEBUGGING: obs_matrix.shape = \", obs_matrix.shape)\n",
        "            # print(\"DEBUGGING: act_matrix.shape = \", act_matrix.shape)\n",
        "\n",
        "            action_prob = policy.predict_prob(obs_matrix, act_matrix)\n",
        "            action = random.choices(range(0, len(cuts_b)), action_prob) # this returns a list\n",
        "            actions.append(action)\n",
        "\n",
        "            if  inner_step %10 == 0:\n",
        "                # TODO: print the logits as well as well.\n",
        "                print(\"DEBUGGING: the action_prob is:\", action_prob)\n",
        "                print(\"DEBUGGING: the actual action to take is:\", action)\n",
        "                logits_dbg = policy.compute_one_step_logits(obs_matrix, act_matrix)\n",
        "                print(\"DEBUGGING: logits looks like:\", logits_dbg)\n",
        "\n",
        "\n",
        "\n",
        "            # take the action in the environment\n",
        "            # TODO: why does the environment.step function takes in a list?\n",
        "            # TODO: remember to go in the environment to change the returned r to the NORMALIZED r!!\n",
        "            s, r, done, _ = env.step(action)\n",
        "            \n",
        "            # Record the observed immediate reward & observed matrices along the trajectory\n",
        "            abs_reward, rel_reward = r\n",
        "            # print(\"DEBUGGING: rel_reward looks like:\", rel_reward)\n",
        "            rews.append(abs_reward) # rews = list(len of trajectory)\n",
        "            rel_rews.append(rel_reward * 10 * inner_step)\n",
        "            obs_matrices.append(obs_matrix)\n",
        "            act_matrices.append(act_matrix)\n",
        "\n",
        "            inner_step += 1\n",
        "\n",
        "            # TODO: do we need to also record the one step of observation and action where the environment terminates?\n",
        "            #   ==> RN I'm thinking maybe don't need to\n",
        "        print(\"-------------------------------------------------------------------------------------------\")\n",
        "        #Below is for logging training performance\n",
        "        print(\"DEBUGGING: the total abs reward of the trajectory =\", np.sum(rews), \"and immediate abs rewards look like:\", rews)\n",
        "        print(\"DEBUGGING: the total relative reward of the trajectory =\", np.sum(rel_rews), \"and immediate relative rewards look like:\", rel_rews)\n",
        "\n",
        "        rrecord.append(np.sum(rews))\n",
        "\n",
        "        # After the policy roll out for this trajectory,\n",
        "        # compute the monte-carlo RETURN of this trajectory (i.e. discounted sum of rewards), add to big list\n",
        "        # TODO: one of the next steps could be: to make the basline state-dependent\n",
        "        v_hat = discounted_rewards(rel_rews, discount_gamma) # This is a list\n",
        "        traj_returns.append(v_hat[0])\n",
        "        # OBS_MAT.append(np.concatenate(obs_matrices, axis=1))\n",
        "        # ACT_MAT.append(np.concatenate(act_matrices, aixs=1))\n",
        "        VAL.append(v_hat) # VAL -> 2d list\n",
        "        OBS_MAT += obs_matrices\n",
        "        ACT_MAT += act_matrices\n",
        "\n",
        "        # TODO: do I need to specify batchsize somewhere?\n",
        "\n",
        "    print(\"+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\")\n",
        "    \n",
        "    # After collecting 5 (or however many) trajectories,\n",
        "    print(\"DEBUGGING: OBS_MAT has %d number of matrices\" % len(OBS_MAT))\n",
        "    print(\"DEBUGGING: ACT_MAT has %d number of matrices\" % len(ACT_MAT))\n",
        "    print(\"DEBUGGING: VAL looks like:\", VAL)\n",
        "    # print(\"DEBUGGING: OBS_MAT looks like:\", OBS_MAT)\n",
        "    # print(\"DEBUGGING: ACT_MAT looks like:\", ACT_MAT)\n",
        "    print(\"DEBUGGING: traj_returns =\", traj_returns)\n",
        "    print(\"DEBUGGING: actions =\", actions)\n",
        "    print(\"DEBUGGING: actions length =\", len(actions))\n",
        "\n",
        "    ## For debugging purposes, let's look at what does the model output\n",
        "    print(\"DEBUGGING: what does the model output in this round of roll-out?\")\n",
        "    obs_attention_dbg = policy.model(torch.FloatTensor(obs_matrix))\n",
        "    act_attention_dbg = policy.model(torch.FloatTensor(act_matrix))\n",
        "    logits_dbg = policy.compute_one_step_logits(obs_matrix, act_matrix)\n",
        "    print(\"DEBUGGING: obs_attention looks like:\", obs_attention_dbg)\n",
        "    print(\"DEBUGGING: act_attention looks like:\", act_attention_dbg)\n",
        "    print(\"DEBUGGING: logits looks like:\", logits_dbg)\n",
        "\n",
        "\n",
        "    assert len(traj_returns) == numtrajs\n",
        "    VAL = np.array(VAL)\n",
        "    # 1. calculate the baseline: average return of the trajectories\n",
        "    # TODO: potentially can make this into *running average*, take into account of all the previous trajectories as well\n",
        "    # TODO: potentially make the baseline the average *VALUE* of every *state*, \n",
        "    #       but I'm not sure whether that \"state\" is useful in this concept, since the first *step*\n",
        "    #       doesn't really mean the same thing among instances\n",
        "    #       I think prof says it makes sense in the OH, also it would make more sense if you engineered the reward\n",
        "    baseline = np.mean(traj_returns)\n",
        "    baseline_2 = VAL.mean(axis=0, keepdims=True)\n",
        "\n",
        "    # assert baseline_2.shape == VAL.shape\n",
        "\n",
        "    # 2. Update the policy\n",
        "    ADS = (VAL - baseline_2).flatten()\n",
        "    print(\"DEBUGGING: baseline2 looks like:\", baseline_2)\n",
        "    print(\"DEBUGGING: baseline2 looks like:\", baseline)\n",
        "    print(\"DEBUGGING: ADS looks like:\", ADS)\n",
        "\n",
        "\n",
        "    # Train the agent using the batch\n",
        "    # obs_batch = np.concatenate(OBS_MAT)\n",
        "    # act_batch = np.concatenate(ACT_MAT)\n",
        "\n",
        "    assert ADS.shape[0] == len(actions)\n",
        "\n",
        "    # scaling up the rewards to artificially make bigger loss, improve learning\n",
        "\n",
        "    policy.train(OBS_MAT, ACT_MAT, actions, ADS)\n",
        "\n",
        "    fixedWindow=100\n",
        "    movingAverage=0\n",
        "    if len(rrecord) >= fixedWindow:\n",
        "        movingAverage=np.mean(rrecord[len(rrecord)-fixedWindow:len(rrecord)-1])\n",
        "\n",
        "    # TODO: wandb logging\n",
        "    wandb.log({ \"training reward\" : rrecord[-1], \"training reward moving average\" : movingAverage})\n",
        "    #make sure to use the correct tag in wandb.init in the initialization on top\n"
      ],
      "metadata": {
        "id": "aeQHQnp1-8fR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6fa2f828-e5e0-450c-c3b4-da940ec8b3c9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<wandb.jupyter.IFrame at 0x7f787a645d90>"
            ],
            "text/html": [
              "<iframe src=\"https://wandb.ai/ieor4575-spring2022/finalproject/runs/1am91bic?jupyter=true\" style=\"border:none;width:100%;height:420px;\"></iframe>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        853.5057, 853.4646, 853.5204, 853.5165, 853.5284, 853.5727, 853.4672,\n",
            "        853.5013, 853.4910, 853.4882, 853.4868, 853.5197, 853.5336, 853.4965,\n",
            "        853.5005], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.03559521144188693 and immediate abs rewards look like: [0.001628004127269378, 0.0018067069577227812, 0.0020133333973717527, 0.00225755638712144, 0.001049780846642534, 0.007458931105702504, 5.412538985183346e-05, 0.0002217229030065937, 0.0002475739424880885, 0.00038802514336566674, 0.004884292971837567, 0.003356088056534645, 0.0003074913674936397, 0.0027328418254910503, 0.0005082444577055867, 0.002084520901007636, 0.00013295152621140005, 0.00011854276817757636, 0.0001357644055133278, 0.0014271019404077379, 3.11984445033886e-05, 7.886646471888525e-06, 0.00010426312564959517, 5.789756869489793e-06, 6.797551714043948e-05, 0.000598388296111807, 8.020710447453894e-05, 0.00017711419695842778, 8.200725460483227e-06, 2.882795251935022e-05, 2.2963043193158228e-05, 3.490662493277341e-06, 5.4312372412823606e-05, 3.0327441891131457e-06, 0.00015145473207667237, 5.472264547279337e-06, 0.00037031385454611154, 6.488621875178069e-05, 0.00021446246364575927, 6.475686041085282e-05, 0.0005903732330807543, 5.864099694008473e-05, 1.2966361282451544e-06, 1.1798623745562509e-05, 5.437509571493138e-07, 6.551234491780633e-06, 4.262112861397327e-05, 1.666700882196892e-06, 1.2614946172107011e-06, 1.8602390809974167e-06]\n",
            "DEBUGGING: the total relative reward of the trajectory = 14.365050841060482 and immediate relative rewards look like: [0.060166174884518614, 0.1336213914446697, 0.2235040935321425, 0.3344034913575682, 0.19453783581109957, 1.6593281600011691, 0.014086601875985448, 0.06595024994707037, 0.08285126591042892, 0.14429509092178613, 1.998245071359353, 1.5005780983493602, 0.1491295500418945, 1.4275120461568578, 0.2847372036986864, 1.2459166498218168, 0.08449739445574009, 0.07977562683016236, 0.09644537968268647, 1.0672076799552974, 0.024510263986440985, 0.006491063771744588, 0.08971409473959631, 0.005198650387342136, 0.06357882728990294, 0.5820864203146159, 0.08104101505732726, 0.18558920477475974, 0.008900622113205883, 0.032367300339946344, 0.026642025958502145, 0.004180590996465004, 0.06708001079600232, 0.0038592590815182334, 0.19839952262309263, 0.007373674044749192, 0.5128459433835475, 0.09230208329321347, 0.3131135680619137, 0.09697652875142888, 0.9062372369304577, 0.09223123570958383, 0.002087966386564787, 0.0194411149549105, 0.0009163293707257715, 0.011285482290454065, 0.07501757418136029, 0.002996029238291178, 0.0023148822106927236, 0.003483263983832293]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([1.9458e-08, 3.6475e-05, 2.1078e-02, 6.4348e-03, 1.6489e-05, 4.2049e-01,\n",
            "        2.3485e-04, 7.3804e-07, 2.2160e-07, 1.6083e-02, 2.0344e-04, 6.4203e-05,\n",
            "        3.3683e-02, 2.1499e-07, 8.4008e-03, 7.0149e-07, 9.2085e-03, 1.4686e-02,\n",
            "        1.2607e-04, 4.1102e-03, 1.0073e-09, 8.2463e-03, 4.0590e-02, 8.2463e-03,\n",
            "        6.2664e-04, 1.1925e-04, 2.6152e-03, 1.1064e-02, 1.1121e-07, 3.3476e-04,\n",
            "        7.6617e-05, 1.6835e-03, 9.6381e-05, 8.3285e-02, 1.0104e-02, 3.9683e-03,\n",
            "        2.3030e-04, 6.8766e-03, 4.6491e-02, 5.7448e-04, 1.4330e-03, 1.0806e-03,\n",
            "        2.0487e-03, 2.7327e-03, 5.7439e-05, 6.2796e-03, 7.1157e-03, 1.3447e-04,\n",
            "        3.9988e-04, 3.3378e-04, 8.8630e-04, 1.3436e-03, 7.8445e-04, 1.0829e-02,\n",
            "        1.6002e-03, 2.8053e-04, 3.1903e-06, 8.7670e-05, 6.7436e-03, 2.1407e-03,\n",
            "        4.6439e-03, 8.3285e-02, 8.2463e-03, 5.7448e-04, 8.3285e-02, 1.1032e-02,\n",
            "        2.5347e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [37]\n",
            "DEBUGGING: logits looks like: tensor([849.4233, 850.1769, 850.8129, 850.6943, 850.0976, 851.1122, 850.3632,\n",
            "        849.7869, 849.6666, 850.7859, 850.3489, 850.2335, 850.8597, 849.6636,\n",
            "        850.7209, 849.7819, 850.7301, 850.7767, 850.3010, 850.6495, 849.1273,\n",
            "        850.7191, 850.8784, 850.7191, 850.4613, 850.2954, 850.6042, 850.7484,\n",
            "        849.5977, 850.3986, 850.2512, 850.5602, 850.2741, 850.9503, 850.7394,\n",
            "        850.6459, 850.3612, 850.7009, 850.8920, 850.4527, 850.5441, 850.5159,\n",
            "        850.5798, 850.6086, 850.2224, 850.6918, 850.7043, 850.3074, 850.4164,\n",
            "        850.3983, 850.4960, 850.5377, 850.4838, 850.7463, 850.5551, 850.3810,\n",
            "        849.9333, 850.2646, 850.6990, 850.5842, 850.6617, 850.9503, 850.7191,\n",
            "        850.4526, 850.9503, 850.7482, 850.6011], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.5170e-06, 1.8017e-02, 8.1526e-03, 1.7394e-02, 3.8136e-03, 1.4031e-02,\n",
            "        1.5486e-02, 1.1275e-02, 1.6040e-02, 1.7686e-02, 1.4322e-02, 1.4505e-02,\n",
            "        2.9097e-03, 1.3882e-02, 1.0478e-02, 1.3311e-02, 1.2977e-02, 1.5010e-02,\n",
            "        1.6793e-02, 1.5127e-02, 1.8070e-02, 1.5112e-02, 1.2072e-02, 1.1330e-02,\n",
            "        1.4280e-02, 2.4674e-02, 1.7428e-02, 3.9810e-03, 1.4676e-02, 1.4995e-02,\n",
            "        1.2863e-02, 1.5562e-02, 9.0771e-03, 1.3053e-02, 1.2334e-02, 1.0028e-02,\n",
            "        9.2924e-03, 1.5730e-02, 1.9067e-02, 1.9730e-02, 1.1297e-02, 2.2820e-02,\n",
            "        1.1897e-02, 1.4820e-02, 1.1363e-02, 1.4392e-02, 1.6293e-02, 1.7259e-02,\n",
            "        1.7807e-02, 1.1574e-03, 9.2561e-03, 7.7641e-03, 1.7225e-02, 1.0008e-02,\n",
            "        1.7225e-02, 1.5776e-02, 1.2901e-02, 1.2002e-02, 1.0156e-02, 2.9729e-03,\n",
            "        1.8017e-02, 8.9889e-03, 1.2529e-02, 1.0841e-03, 5.7304e-03, 1.0376e-02,\n",
            "        1.8680e-02, 1.0695e-02, 1.6614e-02, 1.7377e-02, 9.9498e-03, 1.2407e-02,\n",
            "        7.8786e-03, 6.0349e-03, 1.2627e-02, 1.7225e-02, 1.1850e-02, 1.2977e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [50]\n",
            "DEBUGGING: logits looks like: tensor([849.8050, 850.6926, 850.6133, 850.6891, 850.5374, 850.6676, 850.6775,\n",
            "        850.6458, 850.6810, 850.6907, 850.6696, 850.6709, 850.5103, 850.6666,\n",
            "        850.6384, 850.6624, 850.6598, 850.6744, 850.6856, 850.6751, 850.6929,\n",
            "        850.6750, 850.6526, 850.6462, 850.6694, 850.7240, 850.6893, 850.5416,\n",
            "        850.6721, 850.6743, 850.6589, 850.6779, 850.6240, 850.6604, 850.6547,\n",
            "        850.6340, 850.6264, 850.6790, 850.6983, 850.7017, 850.6459, 850.7162,\n",
            "        850.6511, 850.6730, 850.6465, 850.6701, 850.6826, 850.6883, 850.6915,\n",
            "        850.4181, 850.6260, 850.6084, 850.6881, 850.6338, 850.6881, 850.6793,\n",
            "        850.6592, 850.6520, 850.6353, 850.5124, 850.6926, 850.6231, 850.6562,\n",
            "        850.4115, 850.5780, 850.6375, 850.6962, 850.6404, 850.6844, 850.6890,\n",
            "        850.6332, 850.6553, 850.6099, 850.5832, 850.6570, 850.6881, 850.6507,\n",
            "        850.6598], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([3.8567e-06, 1.1056e-02, 1.1931e-02, 1.2286e-02, 1.2286e-02, 1.1132e-02,\n",
            "        1.3546e-02, 1.1758e-02, 1.0895e-02, 1.0529e-02, 1.2072e-02, 1.2977e-02,\n",
            "        1.1850e-02, 9.9592e-03, 1.1632e-02, 1.2431e-02, 1.2553e-02, 1.0146e-02,\n",
            "        1.1385e-02, 1.1197e-02, 1.0685e-02, 1.2190e-02, 1.0265e-02, 1.3881e-02,\n",
            "        1.0057e-02, 1.2167e-02, 1.1002e-02, 1.1689e-02, 1.1274e-02, 1.1078e-02,\n",
            "        1.1815e-02, 1.0376e-02, 1.3599e-02, 1.1990e-02, 1.1896e-02, 1.1700e-02,\n",
            "        1.3002e-02, 1.1418e-02, 1.2516e-02, 1.1056e-02, 1.2262e-02, 1.1689e-02,\n",
            "        1.1781e-02, 8.2887e-03, 1.1474e-02, 1.1575e-02, 9.7665e-03, 1.1758e-02,\n",
            "        1.0726e-02, 1.1296e-02, 9.9981e-03, 1.0863e-02, 8.3131e-03, 1.1274e-02,\n",
            "        1.0529e-02, 1.2025e-02, 1.1781e-02, 9.9786e-03, 1.0509e-02, 1.1474e-02,\n",
            "        1.2565e-02, 1.2310e-02, 1.0789e-02, 1.1723e-02, 1.3454e-02, 1.1035e-02,\n",
            "        1.0166e-02, 1.4004e-02, 1.2394e-02, 1.1700e-02, 1.1407e-02, 1.0633e-02,\n",
            "        1.1530e-02, 1.1542e-02, 1.1943e-02, 1.0863e-02, 9.9010e-03, 1.2788e-02,\n",
            "        1.2346e-02, 1.2590e-02, 1.0581e-02, 7.4082e-03, 1.2262e-02, 1.2590e-02,\n",
            "        1.0811e-02, 1.3881e-02, 1.2590e-02, 1.1553e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [69]\n",
            "DEBUGGING: logits looks like: tensor([849.9453, 850.7415, 850.7490, 850.7520, 850.7520, 850.7421, 850.7618,\n",
            "        850.7476, 850.7400, 850.7366, 850.7502, 850.7574, 850.7484, 850.7310,\n",
            "        850.7465, 850.7532, 850.7542, 850.7328, 850.7444, 850.7427, 850.7380,\n",
            "        850.7512, 850.7340, 850.7642, 850.7319, 850.7510, 850.7410, 850.7469,\n",
            "        850.7434, 850.7416, 850.7480, 850.7351, 850.7621, 850.7496, 850.7488,\n",
            "        850.7471, 850.7576, 850.7446, 850.7538, 850.7415, 850.7518, 850.7470,\n",
            "        850.7478, 850.7126, 850.7452, 850.7460, 850.7290, 850.7476, 850.7384,\n",
            "        850.7435, 850.7314, 850.7396, 850.7130, 850.7434, 850.7366, 850.7498,\n",
            "        850.7478, 850.7312, 850.7363, 850.7452, 850.7542, 850.7522, 850.7390,\n",
            "        850.7473, 850.7610, 850.7412, 850.7330, 850.7651, 850.7528, 850.7471,\n",
            "        850.7446, 850.7375, 850.7456, 850.7457, 850.7491, 850.7396, 850.7304,\n",
            "        850.7560, 850.7524, 850.7544, 850.7370, 850.7014, 850.7518, 850.7544,\n",
            "        850.7392, 850.7642, 850.7544, 850.7458], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([4.9263e-06, 9.0385e-03, 9.9657e-03, 1.1437e-02, 1.0754e-02, 1.0024e-02,\n",
            "        1.0424e-02, 1.0034e-02, 1.0014e-02, 9.3527e-03, 1.0988e-02, 1.0353e-02,\n",
            "        1.1260e-02, 1.0775e-02, 9.5465e-03, 1.0775e-02, 1.0403e-02, 9.8785e-03,\n",
            "        1.0577e-02, 1.0754e-02, 1.0363e-02, 1.0242e-02, 1.0475e-02, 9.2709e-03,\n",
            "        8.1975e-03, 1.0681e-02, 1.0702e-02, 1.1858e-02, 9.6590e-03, 1.0892e-02,\n",
            "        9.3436e-03, 1.1315e-02, 1.0272e-02, 1.0839e-02, 1.0999e-02, 8.6499e-03,\n",
            "        1.0786e-02, 9.9365e-03, 8.4826e-03, 8.6499e-03, 1.0546e-02, 9.0385e-03,\n",
            "        1.0640e-02, 9.9462e-03, 8.0468e-03, 9.8592e-03, 1.0650e-02, 1.0413e-02,\n",
            "        9.3802e-03, 1.0403e-02, 1.1020e-02, 1.1020e-02, 9.0385e-03, 1.0444e-02,\n",
            "        1.1074e-02, 1.0849e-02, 9.0827e-03, 8.2457e-03, 9.2528e-03, 9.3619e-03,\n",
            "        9.7158e-03, 1.0222e-02, 1.0754e-02, 9.8881e-03, 1.0828e-02, 1.0242e-02,\n",
            "        1.0526e-02, 9.5839e-03, 1.1042e-02, 1.0860e-02, 1.1053e-02, 1.0629e-02,\n",
            "        9.2528e-03, 8.2377e-03, 1.0495e-02, 9.9754e-03, 1.1053e-02, 1.1139e-02,\n",
            "        1.0005e-02, 1.1370e-02, 1.0567e-02, 1.0292e-02, 1.1315e-02, 1.0892e-02,\n",
            "        1.0353e-02, 1.1074e-02, 1.0924e-02, 1.0871e-02, 9.8112e-03, 1.0692e-02,\n",
            "        1.0292e-02, 8.6161e-03, 1.0444e-02, 1.0786e-02, 1.0577e-02, 9.8785e-03,\n",
            "        7.8527e-03, 1.1594e-02, 1.0014e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [24]\n",
            "DEBUGGING: logits looks like: tensor([850.0536, 850.8051, 850.8149, 850.8286, 850.8224, 850.8154, 850.8193,\n",
            "        850.8156, 850.8154, 850.8085, 850.8246, 850.8187, 850.8271, 850.8227,\n",
            "        850.8105, 850.8227, 850.8192, 850.8140, 850.8209, 850.8225, 850.8188,\n",
            "        850.8176, 850.8198, 850.8076, 850.7953, 850.8218, 850.8220, 850.8322,\n",
            "        850.8117, 850.8237, 850.8084, 850.8276, 850.8179, 850.8233, 850.8247,\n",
            "        850.8007, 850.8228, 850.8146, 850.7988, 850.8007, 850.8206, 850.8051,\n",
            "        850.8214, 850.8147, 850.7935, 850.8138, 850.8215, 850.8192, 850.8088,\n",
            "        850.8192, 850.8250, 850.8250, 850.8051, 850.8196, 850.8254, 850.8234,\n",
            "        850.8055, 850.7959, 850.8074, 850.8087, 850.8123, 850.8174, 850.8224,\n",
            "        850.8141, 850.8232, 850.8176, 850.8203, 850.8110, 850.8251, 850.8235,\n",
            "        850.8252, 850.8214, 850.8074, 850.7958, 850.8201, 850.8149, 850.8252,\n",
            "        850.8260, 850.8152, 850.8281, 850.8207, 850.8181, 850.8276, 850.8237,\n",
            "        850.8187, 850.8254, 850.8240, 850.8235, 850.8133, 850.8219, 850.8181,\n",
            "        850.8004, 850.8196, 850.8228, 850.8208, 850.8140, 850.7910, 850.8300,\n",
            "        850.8154], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([4.0222e-06, 9.3105e-03, 9.1393e-03, 9.4941e-03, 9.1304e-03, 9.2380e-03,\n",
            "        9.3287e-03, 9.0505e-03, 9.1930e-03, 9.4202e-03, 9.0771e-03, 9.1304e-03,\n",
            "        9.2380e-03, 9.6154e-03, 9.0771e-03, 9.6908e-03, 9.3835e-03, 8.8668e-03,\n",
            "        9.4571e-03, 9.3196e-03, 9.0682e-03, 9.0417e-03, 9.2380e-03, 9.2020e-03,\n",
            "        9.3105e-03, 8.2971e-03, 9.1572e-03, 9.4202e-03, 9.4202e-03, 9.5406e-03,\n",
            "        8.8236e-03, 9.2380e-03, 9.3835e-03, 9.3105e-03, 9.2833e-03, 9.3287e-03,\n",
            "        9.0682e-03, 9.2742e-03, 9.3744e-03, 9.5127e-03, 9.3744e-03, 8.7549e-03,\n",
            "        9.1930e-03, 9.6060e-03, 9.4294e-03, 9.7478e-03, 9.2923e-03, 9.1393e-03,\n",
            "        8.9015e-03, 9.4019e-03, 9.6625e-03, 9.1126e-03, 9.3378e-03, 9.0152e-03,\n",
            "        9.4202e-03, 9.7003e-03, 9.5220e-03, 8.8236e-03, 9.3469e-03, 9.4294e-03,\n",
            "        9.0240e-03, 9.3469e-03, 9.3287e-03, 9.0064e-03, 9.3652e-03, 9.4663e-03,\n",
            "        9.3196e-03, 9.2742e-03, 9.1930e-03, 8.7892e-03, 9.2651e-03, 8.8928e-03,\n",
            "        9.1930e-03, 9.4387e-03, 9.2833e-03, 9.1572e-03, 9.1126e-03, 9.2200e-03,\n",
            "        9.3744e-03, 9.1304e-03, 9.2290e-03, 9.4202e-03, 9.2651e-03, 9.3652e-03,\n",
            "        9.2290e-03, 9.2020e-03, 9.4941e-03, 9.1126e-03, 9.3652e-03, 9.5499e-03,\n",
            "        9.2651e-03, 9.5127e-03, 9.2200e-03, 8.9363e-03, 9.1572e-03, 9.1751e-03,\n",
            "        9.1572e-03, 9.4019e-03, 9.4202e-03, 9.2471e-03, 9.1751e-03, 9.3105e-03,\n",
            "        9.9400e-03, 9.1751e-03, 9.1572e-03, 9.1215e-03, 9.5686e-03, 9.4663e-03,\n",
            "        8.5105e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [11]\n",
            "DEBUGGING: logits looks like: tensor([850.1405, 850.9153, 850.9134, 850.9172, 850.9133, 850.9145, 850.9155,\n",
            "        850.9124, 850.9140, 850.9164, 850.9127, 850.9133, 850.9144, 850.9185,\n",
            "        850.9127, 850.9193, 850.9161, 850.9103, 850.9168, 850.9153, 850.9127,\n",
            "        850.9123, 850.9144, 850.9141, 850.9152, 850.9037, 850.9136, 850.9164,\n",
            "        850.9164, 850.9177, 850.9099, 850.9144, 850.9161, 850.9153, 850.9149,\n",
            "        850.9155, 850.9127, 850.9149, 850.9160, 850.9174, 850.9160, 850.9091,\n",
            "        850.9140, 850.9183, 850.9166, 850.9199, 850.9150, 850.9134, 850.9108,\n",
            "        850.9162, 850.9189, 850.9131, 850.9156, 850.9120, 850.9164, 850.9194,\n",
            "        850.9175, 850.9099, 850.9156, 850.9166, 850.9122, 850.9156, 850.9155,\n",
            "        850.9119, 850.9158, 850.9169, 850.9153, 850.9149, 850.9139, 850.9095,\n",
            "        850.9147, 850.9107, 850.9139, 850.9166, 850.9149, 850.9136, 850.9131,\n",
            "        850.9143, 850.9160, 850.9133, 850.9144, 850.9164, 850.9147, 850.9158,\n",
            "        850.9144, 850.9141, 850.9172, 850.9131, 850.9158, 850.9178, 850.9147,\n",
            "        850.9174, 850.9143, 850.9112, 850.9136, 850.9138, 850.9136, 850.9163,\n",
            "        850.9164, 850.9146, 850.9138, 850.9153, 850.9218, 850.9138, 850.9136,\n",
            "        850.9132, 850.9180, 850.9169, 850.9063], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.11826756379696235 and immediate abs rewards look like: [0.023139232434004953, 0.025094216445268103, 0.0128031645158444, 0.02215979134234658, 0.0014151756599858345, 0.0024309266154887155, 0.0015942590330269013, 0.0006894680436744238, 0.005400986704898969, 0.0011935172915400472, 0.0061265662570804125, 0.0002842517424141988, 0.0020957382603228325, 0.0018571448126749601, 0.0012777302736139973, 0.0022187665376804944, 0.0007879744521233079, 0.0004602171234182606, 9.146090178546729e-06, 0.0006387885559888673, 0.00024300994073200854, 0.0005351179693207087, 0.0008206630946006044, 0.0013244278934507747, 4.642150906875031e-05, 0.0006332529192150105, 0.00024312159530381905, 0.001155749179815757, 2.9807673854520544e-05, 2.284258425788721e-05, 1.3778347238257993e-05, 5.212743644733564e-05, 5.5351136325043626e-05, 7.287736480066087e-06, 7.418993391183903e-05, 0.00010517173677726532, 0.00015371966310340213, 1.3643354577652644e-05, 2.5622562134230975e-06, 1.2033528946631122e-06, 8.846856417221716e-06, 0.000108369936242525, 0.00016096592707981472, 0.00017512454996904125, 0.0002897815888900368, 3.885988462570822e-06, 1.5736730802018428e-05, 3.0827823138679378e-06, 2.7364671041141264e-05, 0.00026389326058051665]\n",
            "DEBUGGING: the total relative reward of the trajectory = 19.423171532238353 and immediate relative rewards look like: [0.623990746066064, 1.3619190145231326, 1.04943057612669, 2.430315521977163, 0.19519293194344045, 0.40250975238219766, 0.30817803291022594, 0.15238426451104678, 1.3431803961123918, 0.3302904961561188, 1.8656090886897212, 0.0945872072770032, 0.7555490247689325, 0.7214538277000688, 0.5320948317125872, 0.9859258906427143, 0.37225576820508505, 0.2302558993124071, 0.004830811882057038, 0.35515609541631543, 0.14189026905796606, 0.32734886433053445, 0.5249234663661987, 0.8841825473953442, 0.03229398717676334, 0.45816147049122524, 0.18269718376222657, 0.9007319437495657, 0.02406798620573974, 0.019080237003471955, 0.011892655980684128, 0.04644490177570906, 0.050859078533422294, 0.006899319818555432, 0.0723017167698228, 0.10542560431265477, 0.15837565318952343, 0.014437121912647049, 0.0027826890113875095, 0.001340388889307614, 0.010100684408560191, 0.12674684120699042, 0.19275007399624125, 0.21459090894550742, 0.3631751253093093, 0.004978828671603377, 0.020600638776472724, 0.004121490594272146, 0.03734710146952, 0.3675125748117616]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 150 number of matrices\n",
            "DEBUGGING: ACT_MAT has 150 number of matrices\n",
            "DEBUGGING: VAL looks like: [[41.33087471486136, 41.26889356417879, 41.43590792930031, 40.521738081717864, 34.228368286600535, 34.39573753912189, 34.690179644605756, 34.95311146091246, 35.2026905993388, 35.52889274422435, 35.85843794143988, 36.214853709770786, 36.56661748207721, 36.733954899605685, 36.85878674726014, 37.071333180207965, 36.95668961720386, 37.3250441784475, 37.501171615841116, 37.6684169721969, 36.99354088222464, 36.8225472106864, 36.84283990174379, 31.717255142906417, 32.03041368255296, 32.30575570005291, 30.185214251412017, 24.366126954741254, 21.11396936917625, 18.700322488350245, 18.047283749682265, 14.98194384635568, 13.83494941571773, 12.540769300184461, 10.73075785711839, 7.184709896033914, 5.307960560104311, 5.303021842424864, 3.3607290584612617, 3.3187363274341184, 2.693835661755706, 2.719325724970142, 2.716877900790344, 2.7342248828053877, 2.7260537327167764, 2.7323983051899416, 2.582405963382416, 1.6811443103869026, 0.017514882749467366, 0.006817626209769273], [12.240686420571956, 12.303555803724684, 12.292863042707085, 12.191271665833275, 11.976634519672432, 11.901107761476094, 10.345231920681744, 10.435500322026018, 10.474293002099946, 10.496405794130824, 10.45667747798893, 8.543871117807653, 7.1144373933922145, 7.035664488232647, 5.664800446541201, 5.43440731600254, 4.230798652707801, 4.188183089143496, 4.149906527589225, 4.094405199905595, 3.0577752726770684, 3.063904049182452, 3.0882959448593, 3.0288705556764683, 3.0542140457465923, 3.020843655006757, 2.4633911461536777, 2.4064142738346974, 2.2432576455150888, 2.256926286264528, 2.2470292787116986, 2.2428154068214106, 2.2612472887120663, 2.2163305837536003, 2.23481951987079, 2.0569898962097954, 2.0703194163283296, 1.5732055282270525, 1.4958620655897363, 1.1946954520483057, 1.1088069932291686, 0.20461591545324348, 0.11351987852894914, 0.11255748701250945, 0.09405694147232217, 0.09408142636524888, 0.08363226674221699, 0.008701709657431004, 0.005763313554686693, 0.003483263983832293], [17.03044397156479, 16.57217497525124, 15.363894909826373, 14.459054882524931, 12.150241778331079, 12.075806915543069, 11.791209255718051, 11.599021437179623, 11.562259770372298, 10.32230239824233, 10.092941315238598, 8.310436592473613, 8.298837762824858, 7.619483573793864, 6.9677068142361565, 6.500618164165221, 5.57039623588132, 5.250646937046702, 5.07110205831747, 5.117445703470114, 4.8103935434886855, 4.715659873162343, 4.432637382658393, 3.947185774032519, 3.0939426531688636, 3.092574410093031, 2.6610231713149557, 2.503359583386595, 1.6188157976131612, 1.6108563751590115, 1.6078546850055955, 1.6120828576009205, 1.5814524806315267, 1.5460539415132368, 1.5547016380754357, 1.4973736578844574, 1.406008134921013, 1.2602348300318076, 1.2583815233526874, 1.2682816508497978, 1.2797386484449398, 1.282462589935737, 1.167389645180552, 0.9844844153376877, 0.7776702084769498, 0.41868190218953594, 0.41788189244235613, 0.40129419562210444, 0.40118455053316393, 0.3675125748117616]]\n",
            "DEBUGGING: traj_returns = [41.33087471486136, 12.240686420571956, 17.03044397156479]\n",
            "DEBUGGING: actions = [[12], [7], [39], [8], [12], [13], [3], [3], [67], [21], [32], [15], [19], [18], [1], [55], [22], [9], [26], [59], [42], [60], [58], [37], [73], [76], [33], [18], [67], [52], [78], [61], [48], [72], [19], [5], [45], [53], [21], [40], [59], [19], [89], [32], [64], [87], [100], [101], [81], [69], [55], [1], [61], [1], [1], [10], [9], [6], [14], [64], [47], [13], [47], [44], [5], [71], [46], [63], [7], [76], [61], [78], [30], [13], [10], [3], [80], [14], [19], [11], [8], [27], [52], [59], [49], [90], [11], [52], [24], [26], [72], [70], [25], [74], [75], [78], [22], [58], [67], [54], [34], [22], [35], [24], [35], [22], [30], [17], [21], [37], [62], [16], [4], [29], [34], [32], [23], [40], [16], [50], [33], [29], [71], [50], [48], [23], [49], [49], [67], [69], [6], [11], [58], [2], [19], [53], [74], [3], [33], [24], [70], [87], [54], [81], [10], [94], [5], [22], [52], [11]]\n",
            "DEBUGGING: actions length = 150\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[  5.1469,   5.1368,   9.6177,  ...,   3.8074, -10.4593, -16.0905],\n",
            "        [  5.1744,   5.1929,   9.6932,  ...,   3.8264, -10.5359, -16.2263],\n",
            "        [  5.1293,   5.1368,   9.6017,  ...,   3.7861, -10.4142, -16.0322],\n",
            "        ...,\n",
            "        [  5.1877,   5.1882,   9.7041,  ...,   3.8361, -10.5403, -16.2354],\n",
            "        [  5.1877,   5.1883,   9.7041,  ...,   3.8361, -10.5403, -16.2354],\n",
            "        [  5.1877,   5.1882,   9.7041,  ...,   3.8361, -10.5403, -16.2353]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[  5.1842,   5.1829,   9.6943,  ...,   3.8334, -10.5308, -16.2208],\n",
            "        [  5.1877,   5.1882,   9.7041,  ...,   3.8361, -10.5403, -16.2353],\n",
            "        [  5.1877,   5.1882,   9.7041,  ...,   3.8361, -10.5403, -16.2353],\n",
            "        ...,\n",
            "        [  5.1877,   5.1883,   9.7041,  ...,   3.8361, -10.5403, -16.2354],\n",
            "        [  5.1877,   5.1882,   9.7041,  ...,   3.8361, -10.5403, -16.2354],\n",
            "        [  5.1876,   5.1882,   9.7040,  ...,   3.8361, -10.5402, -16.2352]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([850.1405, 850.9153, 850.9134, 850.9172, 850.9133, 850.9145, 850.9155,\n",
            "        850.9124, 850.9140, 850.9164, 850.9127, 850.9133, 850.9144, 850.9185,\n",
            "        850.9127, 850.9193, 850.9161, 850.9103, 850.9168, 850.9153, 850.9127,\n",
            "        850.9123, 850.9144, 850.9141, 850.9152, 850.9037, 850.9136, 850.9164,\n",
            "        850.9164, 850.9177, 850.9099, 850.9144, 850.9161, 850.9153, 850.9149,\n",
            "        850.9155, 850.9127, 850.9149, 850.9160, 850.9174, 850.9160, 850.9091,\n",
            "        850.9140, 850.9183, 850.9166, 850.9199, 850.9150, 850.9134, 850.9108,\n",
            "        850.9162, 850.9189, 850.9131, 850.9156, 850.9120, 850.9164, 850.9194,\n",
            "        850.9175, 850.9099, 850.9156, 850.9166, 850.9122, 850.9156, 850.9155,\n",
            "        850.9119, 850.9158, 850.9169, 850.9153, 850.9149, 850.9139, 850.9095,\n",
            "        850.9147, 850.9107, 850.9139, 850.9166, 850.9149, 850.9136, 850.9131,\n",
            "        850.9143, 850.9160, 850.9133, 850.9144, 850.9164, 850.9147, 850.9158,\n",
            "        850.9144, 850.9141, 850.9172, 850.9131, 850.9158, 850.9178, 850.9147,\n",
            "        850.9174, 850.9143, 850.9112, 850.9136, 850.9138, 850.9136, 850.9163,\n",
            "        850.9164, 850.9146, 850.9138, 850.9153, 850.9218, 850.9138, 850.9136,\n",
            "        850.9132, 850.9180, 850.9169, 850.9063], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[23.5340017  23.38154145 23.03088863 22.39068821 19.45174819 19.45755074\n",
            "  18.94220694 18.99587774 19.07974779 18.78253365 18.80268558 17.68972047\n",
            "  17.32663088 17.12970099 16.497098   16.33545289 15.5859615  15.58795807\n",
            "  15.57406007 15.62675596 14.95390323 14.86737038 14.78792441 12.89777049\n",
            "  12.72619013 12.80639126 11.76987619  9.7586336   8.3253476   7.52270172\n",
            "   7.30072257  6.27894737  5.89254973  5.43438461  4.84009301  3.57969115\n",
            "   2.92809604  2.71215407  2.03832422  1.92723781  1.6941271   1.40213474\n",
            "   1.33259581  1.27708893  1.19926029  1.08172054  1.02797337  0.69704674\n",
            "   0.14148758  0.12593782]]\n",
            "DEBUGGING: baseline2 looks like: 23.534001702332702\n",
            "DEBUGGING: ADS looks like: [ 17.79687301  17.88735212  18.4050193   18.13104987  14.77662009\n",
            "  14.9381868   15.7479727   15.95723372  16.12294281  16.7463591\n",
            "  17.05575236  18.52513324  19.2399866   19.60425391  20.36168874\n",
            "  20.73588029  21.37072812  21.73708611  21.92711155  22.04166101\n",
            "  22.03963765  21.95517683  22.05491549  18.81948465  19.30422356\n",
            "  19.49936445  18.41533806  14.60749335  12.78862177  11.17762077\n",
            "  10.74656118   8.70299648   7.94239969   7.10638469   5.89066485\n",
            "   3.60501875   2.37986452   2.59086778   1.32240484   1.39149852\n",
            "   0.99970856   1.31719098   1.38428209   1.45713595   1.52679344\n",
            "   1.65067776   1.55443259   0.98409757  -0.1239727   -0.1191202\n",
            " -11.29331528 -11.07798564 -10.73802558 -10.19941654  -7.47511368\n",
            "  -7.55644298  -8.59697502  -8.56037742  -8.60545479  -8.28612785\n",
            "  -8.3460081   -9.14584936 -10.21219349 -10.0940365  -10.83229756\n",
            " -10.90104557 -11.35516285 -11.39977498 -11.42415354 -11.53235076\n",
            " -11.89612796 -11.80346633 -11.69962846  -9.86889994  -9.67197608\n",
            "  -9.7855476   -9.30648504  -7.35221933  -6.08208996  -5.26577543\n",
            "  -5.05369329  -4.03613196  -3.63130244  -3.21805402  -2.60527349\n",
            "  -1.52270125  -0.85777662  -1.13894854  -0.54246215  -0.73254236\n",
            "  -0.58532011  -1.19751883  -1.21907593  -1.16453144  -1.10520335\n",
            "  -0.98763912  -0.94434111  -0.68834503  -0.13572427  -0.12245456\n",
            "  -6.50355773  -6.80936647  -7.66699372  -7.93163333  -7.30150642\n",
            "  -7.38174382  -7.15099768  -7.3968563   -7.51748802  -8.46023125\n",
            "  -8.70974426  -9.37928388  -9.02779312  -9.51021741  -9.52939119\n",
            "  -9.83483472 -10.01556527 -10.33731113 -10.50295801 -10.50931026\n",
            " -10.14350969 -10.1517105  -10.35528703  -8.95058472  -9.63224747\n",
            "  -9.71381684  -9.10885302  -7.25527402  -6.70653181  -5.91184534\n",
            "  -5.69286789  -4.66686451  -4.31109725  -3.88833067  -3.28539137\n",
            "  -2.08231749  -1.5220879   -1.45191924  -0.77994269  -0.65895616\n",
            "  -0.41438845  -0.11967215  -0.16520616  -0.29260451  -0.42159009\n",
            "  -0.66303864  -0.61009148  -0.29575254   0.25969697   0.24157475]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(-2.7716, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-0.0516,  0.1392, -0.1308,  ..., -0.0476, -0.1168,  0.1646],\n",
            "        [ 0.0111, -0.0302,  0.0282,  ...,  0.0102,  0.0252, -0.0568],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [-0.0127,  0.0340, -0.0320,  ..., -0.0117, -0.0286,  0.0338],\n",
            "        [-0.0304,  0.0821, -0.0771,  ..., -0.0280, -0.0689,  0.0990],\n",
            "        [-0.0316,  0.0853, -0.0800,  ..., -0.0291, -0.0715,  0.1171]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0340,  0.0537,  0.0396,  0.0000,  0.0000,  0.0000,  0.0000,  0.0395,\n",
            "          0.0000,  0.0000,  0.0179,  0.0518,  0.0313,  0.0000,  0.0524,  0.0000,\n",
            "          0.0273,  0.0000,  0.0120,  0.0000],\n",
            "        [ 0.0281,  0.0433,  0.0338,  0.0000,  0.0000,  0.0000,  0.0000,  0.0312,\n",
            "          0.0000,  0.0000,  0.0128,  0.0436,  0.0281,  0.0000,  0.0456,  0.0000,\n",
            "          0.0221,  0.0000,  0.0073,  0.0000],\n",
            "        [ 0.0510,  0.0779,  0.0625,  0.0000,  0.0000,  0.0000,  0.0000,  0.0554,\n",
            "          0.0000,  0.0000,  0.0214,  0.0804,  0.0534,  0.0000,  0.0852,  0.0000,\n",
            "          0.0398,  0.0000,  0.0107,  0.0000],\n",
            "        [-0.0422, -0.0667, -0.0488,  0.0000,  0.0000,  0.0000,  0.0000, -0.0493,\n",
            "          0.0000,  0.0000, -0.0226, -0.0639, -0.0383,  0.0000, -0.0644,  0.0000,\n",
            "         -0.0339,  0.0000, -0.0154,  0.0000],\n",
            "        [-0.0344, -0.0483, -0.0471,  0.0000,  0.0000,  0.0000,  0.0000, -0.0310,\n",
            "          0.0000,  0.0000, -0.0056, -0.0586, -0.0464,  0.0000, -0.0682,  0.0000,\n",
            "         -0.0249,  0.0000,  0.0045,  0.0000],\n",
            "        [-0.0549, -0.0823, -0.0690,  0.0000,  0.0000,  0.0000,  0.0000, -0.0573,\n",
            "          0.0000,  0.0000, -0.0198, -0.0880, -0.0612,  0.0000, -0.0955,  0.0000,\n",
            "         -0.0421,  0.0000, -0.0073,  0.0000],\n",
            "        [ 0.0275,  0.0415,  0.0343,  0.0000,  0.0000,  0.0000,  0.0000,  0.0291,\n",
            "          0.0000,  0.0000,  0.0104,  0.0439,  0.0301,  0.0000,  0.0473,  0.0000,\n",
            "          0.0212,  0.0000,  0.0043,  0.0000],\n",
            "        [ 0.0187,  0.0282,  0.0233,  0.0000,  0.0000,  0.0000,  0.0000,  0.0198,\n",
            "          0.0000,  0.0000,  0.0071,  0.0298,  0.0205,  0.0000,  0.0321,  0.0000,\n",
            "          0.0144,  0.0000,  0.0029,  0.0000],\n",
            "        [-0.0355, -0.0499, -0.0486,  0.0000,  0.0000,  0.0000,  0.0000, -0.0320,\n",
            "          0.0000,  0.0000, -0.0057, -0.0605, -0.0480,  0.0000, -0.0704,  0.0000,\n",
            "         -0.0257,  0.0000,  0.0047,  0.0000],\n",
            "        [-0.0552, -0.0777, -0.0754,  0.0000,  0.0000,  0.0000,  0.0000, -0.0499,\n",
            "          0.0000,  0.0000, -0.0093, -0.0938, -0.0741,  0.0000, -0.1089,  0.0000,\n",
            "         -0.0400,  0.0000,  0.0068,  0.0000]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.7005,  0.2460, -0.1159,  ..., -0.1914, -0.1510, -0.3780],\n",
            "        [-0.1942, -0.0682,  0.0320,  ...,  0.0529,  0.0418,  0.0841],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.2010,  0.0706, -0.0333,  ..., -0.0549, -0.0433, -0.1132],\n",
            "        [ 0.4495,  0.1578, -0.0744,  ..., -0.1228, -0.0968, -0.2377],\n",
            "        [ 0.3860,  0.1356, -0.0639,  ..., -0.1054, -0.0832, -0.2014]])\n",
            "   Last layer:\n",
            "tensor([[-0.0409, -0.0367, -0.0390,  0.0000,  0.0000,  0.0000,  0.0000, -0.0472,\n",
            "          0.0000,  0.0000, -0.0564, -0.0285,  0.0163,  0.0000, -0.0439,  0.0000,\n",
            "         -0.0343,  0.0000, -0.0551,  0.0000],\n",
            "        [-0.0489, -0.0502, -0.0468,  0.0000,  0.0000,  0.0000,  0.0000, -0.0581,\n",
            "          0.0000,  0.0000, -0.0633, -0.0392,  0.0121,  0.0000, -0.0528,  0.0000,\n",
            "         -0.0414,  0.0000, -0.0615,  0.0000],\n",
            "        [-0.1035, -0.1147, -0.0994,  0.0000,  0.0000,  0.0000,  0.0000, -0.1252,\n",
            "          0.0000,  0.0000, -0.1289, -0.0895,  0.0164,  0.0000, -0.1124,  0.0000,\n",
            "         -0.0882,  0.0000, -0.1246,  0.0000],\n",
            "        [ 0.0493,  0.0453,  0.0471,  0.0000,  0.0000,  0.0000,  0.0000,  0.0571,\n",
            "          0.0000,  0.0000,  0.0673,  0.0351, -0.0184,  0.0000,  0.0529,  0.0000,\n",
            "          0.0415,  0.0000,  0.0657,  0.0000],\n",
            "        [ 0.1006,  0.1065,  0.0967,  0.0000,  0.0000,  0.0000,  0.0000,  0.1206,\n",
            "          0.0000,  0.0000,  0.1288,  0.0830, -0.0217,  0.0000,  0.1089,  0.0000,\n",
            "          0.0854,  0.0000,  0.1248,  0.0000],\n",
            "        [ 0.1299,  0.1463,  0.1247,  0.0000,  0.0000,  0.0000,  0.0000,  0.1576,\n",
            "          0.0000,  0.0000,  0.1600,  0.1141, -0.0178,  0.0000,  0.1410,  0.0000,\n",
            "          0.1106,  0.0000,  0.1545,  0.0000],\n",
            "        [-0.0454, -0.0404, -0.0433,  0.0000,  0.0000,  0.0000,  0.0000, -0.0523,\n",
            "          0.0000,  0.0000, -0.0629, -0.0314,  0.0186,  0.0000, -0.0487,  0.0000,\n",
            "         -0.0381,  0.0000, -0.0615,  0.0000],\n",
            "        [-0.0317, -0.0296, -0.0303,  0.0000,  0.0000,  0.0000,  0.0000, -0.0368,\n",
            "          0.0000,  0.0000, -0.0430, -0.0230,  0.0113,  0.0000, -0.0340,  0.0000,\n",
            "         -0.0266,  0.0000, -0.0419,  0.0000],\n",
            "        [ 0.1141,  0.1272,  0.1094,  0.0000,  0.0000,  0.0000,  0.0000,  0.1382,\n",
            "          0.0000,  0.0000,  0.1415,  0.0992, -0.0170,  0.0000,  0.1236,  0.0000,\n",
            "          0.0970,  0.0000,  0.1366,  0.0000],\n",
            "        [ 0.2007,  0.2390,  0.1933,  0.0000,  0.0000,  0.0000,  0.0000,  0.2474,\n",
            "          0.0000,  0.0000,  0.2399,  0.1864, -0.0132,  0.0000,  0.2191,  0.0000,\n",
            "          0.1715,  0.0000,  0.2305,  0.0000]])\n",
            "DEBUGGING: training for one iteration takes 0.005121 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 13\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([1.8233e-06, 4.4621e-03, 7.3834e-05, 6.2549e-04, 3.5264e-03, 5.3457e-03,\n",
            "        2.9953e-04, 2.5325e-03, 4.1470e-03, 1.4981e-07, 3.9726e-03, 2.5800e-03,\n",
            "        1.5848e-03, 2.5699e-03, 8.7792e-03, 3.3644e-04, 8.2300e-04, 3.1060e-03,\n",
            "        3.7308e-05, 3.0075e-03, 3.2773e-03, 6.2497e-03, 4.2041e-03, 1.3179e-02,\n",
            "        1.0196e-01, 3.6884e-03, 6.8352e-05, 5.6644e-01, 3.9110e-03, 8.5578e-04,\n",
            "        2.2136e-02, 4.7918e-03, 4.0053e-07, 1.3452e-02, 1.2116e-03, 4.5800e-05,\n",
            "        4.4752e-03, 6.1349e-03, 1.1514e-04, 1.8547e-03, 1.0125e-02, 3.3452e-03,\n",
            "        1.4486e-03, 6.2193e-03, 3.3290e-03, 1.7358e-02, 1.8456e-03, 5.4663e-04,\n",
            "        2.3376e-03, 1.8241e-03, 4.4578e-03, 3.1827e-03, 1.9005e-03, 5.5607e-07,\n",
            "        9.6392e-05, 2.0168e-04, 3.8129e-03, 7.5353e-06, 4.9343e-03, 6.0693e-03,\n",
            "        1.6167e-07, 1.6493e-04, 2.9551e-03, 1.0488e-01, 8.1592e-03, 4.9343e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [64]\n",
            "DEBUGGING: logits looks like: tensor([1084.7618, 1085.5421, 1085.1320, 1085.3456, 1085.5186, 1085.5602,\n",
            "        1085.2720, 1085.4855, 1085.5348, 1084.5120, 1085.5305, 1085.4873,\n",
            "        1085.4386, 1085.4869, 1085.6097, 1085.2836, 1085.3730, 1085.5059,\n",
            "        1085.0637, 1085.5027, 1085.5112, 1085.5758, 1085.5361, 1085.6504,\n",
            "        1085.8550, 1085.5231, 1085.1243, 1086.0265, 1085.5289, 1085.3770,\n",
            "        1085.7023, 1085.5492, 1084.6102, 1085.6525, 1085.4117, 1085.0842,\n",
            "        1085.5424, 1085.5740, 1085.1764, 1085.4543, 1085.6240, 1085.5133,\n",
            "        1085.4296, 1085.5753, 1085.5128, 1085.6780, 1085.4539, 1085.3322,\n",
            "        1085.4774, 1085.4526, 1085.5420, 1085.5083, 1085.4568, 1084.6431,\n",
            "        1085.1586, 1085.2324, 1085.5264, 1084.9037, 1085.5521, 1085.5729,\n",
            "        1084.5195, 1085.2123, 1085.5009, 1085.8578, 1085.6024, 1085.5521],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.8359e-05, 1.1778e-02, 8.0478e-03, 7.8844e-03, 1.8822e-02, 1.2188e-02,\n",
            "        1.2247e-02, 1.4544e-02, 9.6508e-03, 1.1305e-02, 1.1790e-02, 5.7459e-03,\n",
            "        2.5204e-02, 1.6545e-02, 1.0303e-02, 1.1964e-02, 1.0893e-02, 1.5911e-02,\n",
            "        1.3905e-02, 6.1105e-03, 7.9153e-03, 1.0745e-02, 1.2499e-03, 2.0451e-02,\n",
            "        1.3919e-02, 1.8083e-02, 9.8315e-03, 1.4502e-02, 1.5601e-03, 8.2145e-03,\n",
            "        1.7135e-03, 1.0589e-02, 6.4351e-03, 1.2961e-02, 7.0952e-03, 1.6513e-02,\n",
            "        4.1548e-03, 1.2936e-02, 9.7932e-03, 2.8337e-02, 6.2310e-03, 1.2069e-02,\n",
            "        8.3684e-03, 2.8949e-03, 4.2873e-02, 1.4249e-02, 1.4759e-02, 1.3517e-02,\n",
            "        7.7850e-03, 2.0035e-02, 1.9957e-02, 1.2188e-02, 1.4744e-02, 1.6225e-02,\n",
            "        2.1265e-02, 3.1179e-03, 9.0307e-03, 5.8307e-03, 1.5332e-02, 1.4601e-02,\n",
            "        4.5631e-03, 1.3811e-02, 1.7733e-02, 1.1974e-03, 1.6352e-02, 2.2527e-02,\n",
            "        9.6587e-04, 1.9821e-02, 2.8337e-02, 1.6352e-02, 2.1664e-02, 2.4097e-02,\n",
            "        6.1284e-03, 1.6021e-02, 1.3230e-02, 2.5451e-02, 1.9022e-03, 6.4037e-03,\n",
            "        1.6513e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [78]\n",
            "DEBUGGING: logits looks like: tensor([1085.3044, 1085.9508, 1085.9127, 1085.9106, 1085.9977, 1085.9542,\n",
            "        1085.9547, 1085.9719, 1085.9309, 1085.9467, 1085.9509, 1085.8790,\n",
            "        1086.0269, 1085.9847, 1085.9374, 1085.9524, 1085.9430, 1085.9808,\n",
            "        1085.9674, 1085.8851, 1085.9110, 1085.9417, 1085.7264, 1086.0060,\n",
            "        1085.9675, 1085.9937, 1085.9327, 1085.9716, 1085.7487, 1085.9148,\n",
            "        1085.7581, 1085.9402, 1085.8904, 1085.9603, 1085.9001, 1085.9846,\n",
            "        1085.8466, 1085.9602, 1085.9324, 1086.0386, 1085.8871, 1085.9532,\n",
            "        1085.9166, 1085.8104, 1086.0800, 1085.9698, 1085.9734, 1085.9646,\n",
            "        1085.9094, 1086.0039, 1086.0035, 1085.9542, 1085.9733, 1085.9828,\n",
            "        1086.0099, 1085.8179, 1085.9242, 1085.8805, 1085.9772, 1085.9723,\n",
            "        1085.8560, 1085.9667, 1085.9917, 1085.7222, 1085.9836, 1086.0156,\n",
            "        1085.7007, 1086.0028, 1086.0386, 1085.9836, 1086.0117, 1086.0223,\n",
            "        1085.8855, 1085.9816, 1085.9624, 1086.0278, 1085.7684, 1085.8899,\n",
            "        1085.9846], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.3452e-05, 1.9883e-04, 7.2224e-05, 1.9266e-06, 3.1552e-05, 1.3284e-04,\n",
            "        2.6952e-01, 4.3557e-04, 5.0766e-05, 3.1189e-04, 8.7657e-03, 1.6425e-02,\n",
            "        1.0676e-03, 3.0284e-05, 6.5770e-04, 2.9161e-03, 7.6946e-06, 1.5953e-01,\n",
            "        2.0438e-03, 6.2322e-05, 3.0008e-14, 8.9547e-04, 2.3984e-04, 1.3960e-05,\n",
            "        7.4685e-03, 1.3234e-03, 2.0615e-04, 3.4750e-06, 5.8108e-03, 4.1112e-05,\n",
            "        7.3483e-07, 8.1589e-06, 1.2202e-04, 3.8332e-03, 3.2554e-05, 3.3734e-02,\n",
            "        8.0414e-05, 1.6576e-06, 1.5624e-03, 1.3988e-05, 1.6388e-04, 1.2586e-06,\n",
            "        7.2659e-04, 2.5009e-05, 1.6664e-03, 2.4597e-05, 4.2417e-05, 1.2095e-04,\n",
            "        1.4887e-06, 2.0389e-06, 3.5818e-06, 2.8177e-04, 5.9642e-05, 5.8515e-02,\n",
            "        6.8725e-04, 1.4612e-07, 1.4466e-02, 2.4680e-02, 4.2660e-06, 7.6381e-03,\n",
            "        1.0274e-05, 1.5953e-01, 7.1083e-07, 5.8515e-02, 2.7155e-03, 1.7143e-03,\n",
            "        1.4458e-06, 1.1232e-03, 1.1232e-03, 1.5760e-04, 1.2569e-02, 3.0428e-06,\n",
            "        8.7132e-04, 2.7041e-05, 4.2512e-03, 1.9087e-03, 5.3696e-02, 2.9381e-05,\n",
            "        7.3086e-04, 3.2023e-04, 1.1327e-05, 3.4669e-02, 3.2158e-02, 2.4118e-06,\n",
            "        7.6807e-05, 4.5819e-05, 5.9499e-08, 5.8528e-07, 4.4976e-05, 6.9275e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [61]\n",
            "DEBUGGING: logits looks like: tensor([1085.5040, 1085.7733, 1085.6721, 1085.3097, 1085.5892, 1085.7330,\n",
            "        1086.4945, 1085.8518, 1085.6368, 1085.8184, 1086.1520, 1086.2147,\n",
            "        1085.9414, 1085.5852, 1085.8929, 1086.0419, 1085.4481, 1086.4421,\n",
            "        1086.0063, 1085.6573, 1083.5120, 1085.9238, 1085.7921, 1085.5077,\n",
            "        1086.1360, 1085.9629, 1085.7770, 1085.3687, 1086.1108, 1085.6157,\n",
            "        1085.2133, 1085.4540, 1085.7245, 1086.0692, 1085.5924, 1086.2867,\n",
            "        1085.6829, 1085.2947, 1085.9795, 1085.5079, 1085.7540, 1085.2671,\n",
            "        1085.9030, 1085.5660, 1085.9860, 1085.5643, 1085.6189, 1085.7236,\n",
            "        1085.2839, 1085.3153, 1085.3717, 1085.8082, 1085.6530, 1086.3418,\n",
            "        1085.8973, 1085.0518, 1086.2020, 1086.2555, 1085.3892, 1086.1382,\n",
            "        1085.4771, 1086.4421, 1085.2100, 1086.3418, 1086.0348, 1085.9888,\n",
            "        1085.2810, 1085.9465, 1085.9465, 1085.7501, 1086.1880, 1085.3553,\n",
            "        1085.9211, 1085.5739, 1086.0796, 1085.9995, 1086.3333, 1085.5822,\n",
            "        1085.9036, 1085.8210, 1085.4868, 1086.2894, 1086.2820, 1085.3322,\n",
            "        1085.6782, 1085.6266, 1084.9619, 1085.1906, 1085.6248, 1086.1284],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.5090e-03, 9.1004e-03, 2.3463e-03, 2.5099e-03, 2.1053e-03, 3.2639e-03,\n",
            "        2.2564e-03, 1.7318e-03, 4.0180e-04, 3.0692e-03, 2.4637e-03, 1.1937e-03,\n",
            "        2.6077e-02, 1.7536e-04, 1.8273e-03, 5.8234e-04, 9.4261e-03, 5.5894e-04,\n",
            "        1.5980e-05, 2.2455e-03, 3.2071e-03, 2.6252e-03, 6.0859e-03, 8.8463e-03,\n",
            "        1.8670e-03, 1.7303e-02, 6.1157e-03, 3.2512e-03, 8.9580e-04, 2.5444e-03,\n",
            "        4.9956e-04, 3.5228e-02, 4.5760e-03, 8.0311e-03, 1.0483e-03, 1.3555e-02,\n",
            "        7.4337e-04, 7.0460e-03, 3.2863e-03, 1.6897e-04, 1.4827e-03, 7.6186e-03,\n",
            "        4.3325e-03, 1.2282e-02, 3.7312e-03, 9.9739e-04, 2.0599e-05, 1.1335e-03,\n",
            "        1.1902e-03, 3.9563e-03, 1.2670e-03, 4.9964e-03, 2.5623e-02, 6.9175e-02,\n",
            "        4.0785e-02, 3.4783e-02, 5.7060e-03, 8.4813e-04, 6.1038e-03, 5.1643e-04,\n",
            "        1.0321e-03, 4.6299e-03, 2.2476e-03, 7.7776e-02, 1.5063e-02, 5.1291e-04,\n",
            "        2.8889e-03, 8.0783e-03, 8.9244e-03, 4.7536e-03, 2.4613e-03, 1.6113e-02,\n",
            "        1.6066e-02, 1.4800e-02, 7.1850e-03, 3.9096e-04, 1.6719e-03, 4.9769e-03,\n",
            "        8.3022e-03, 5.6269e-05, 1.1986e-02, 6.0445e-03, 6.4532e-03, 1.2524e-02,\n",
            "        2.6197e-04, 5.8024e-02, 8.9493e-04, 3.3316e-03, 9.1973e-04, 2.1266e-01,\n",
            "        3.0756e-02, 1.1457e-03, 7.7537e-03, 1.5894e-02, 7.4181e-05, 1.5478e-03,\n",
            "        5.4661e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [89]\n",
            "DEBUGGING: logits looks like: tensor([1086.0936, 1086.2733, 1086.1378, 1086.1445, 1086.1270, 1086.1708,\n",
            "        1086.1339, 1086.1074, 1085.9613, 1086.1647, 1086.1427, 1086.0702,\n",
            "        1086.3787, 1085.8784, 1086.1128, 1085.9984, 1086.2769, 1085.9944,\n",
            "        1085.6389, 1086.1334, 1086.1691, 1086.1490, 1086.2332, 1086.2705,\n",
            "        1086.1150, 1086.3376, 1086.2336, 1086.1704, 1086.0415, 1086.1459,\n",
            "        1085.9832, 1086.4087, 1086.2046, 1086.2609, 1086.0573, 1086.3132,\n",
            "        1086.0228, 1086.2478, 1086.1715, 1085.8748, 1086.0919, 1086.2556,\n",
            "        1086.1991, 1086.3033, 1086.1842, 1086.0522, 1085.6643, 1086.0651,\n",
            "        1086.0699, 1086.1901, 1086.0762, 1086.2134, 1086.3768, 1086.4762,\n",
            "        1086.4233, 1086.4075, 1086.2267, 1086.0360, 1086.2334, 1085.9865,\n",
            "        1086.0557, 1086.2058, 1086.1335, 1086.4879, 1086.3237, 1085.9857,\n",
            "        1086.1586, 1086.2615, 1086.2714, 1086.2084, 1086.1426, 1086.3304,\n",
            "        1086.3302, 1086.3220, 1086.2498, 1085.9586, 1086.1039, 1086.2130,\n",
            "        1086.2642, 1085.7648, 1086.3009, 1086.2324, 1086.2390, 1086.3053,\n",
            "        1085.9186, 1086.4586, 1086.0414, 1086.1729, 1086.0442, 1086.5885,\n",
            "        1086.3951, 1086.0662, 1086.2573, 1086.3291, 1085.7924, 1086.0962,\n",
            "        1086.2224], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0006, 0.0126, 0.0091, 0.0103, 0.0110, 0.0085, 0.0089, 0.0101, 0.0103,\n",
            "        0.0075, 0.0165, 0.0101, 0.0103, 0.0117, 0.0096, 0.0094, 0.0102, 0.0083,\n",
            "        0.0155, 0.0098, 0.0096, 0.0091, 0.0092, 0.0078, 0.0104, 0.0108, 0.0109,\n",
            "        0.0114, 0.0082, 0.0082, 0.0076, 0.0087, 0.0127, 0.0097, 0.0108, 0.0093,\n",
            "        0.0104, 0.0099, 0.0096, 0.0124, 0.0099, 0.0077, 0.0095, 0.0078, 0.0095,\n",
            "        0.0081, 0.0104, 0.0102, 0.0071, 0.0083, 0.0080, 0.0097, 0.0075, 0.0087,\n",
            "        0.0096, 0.0103, 0.0116, 0.0104, 0.0102, 0.0068, 0.0090, 0.0117, 0.0059,\n",
            "        0.0096, 0.0096, 0.0075, 0.0109, 0.0087, 0.0084, 0.0093, 0.0068, 0.0038,\n",
            "        0.0133, 0.0094, 0.0114, 0.0061, 0.0086, 0.0157, 0.0105, 0.0106, 0.0117,\n",
            "        0.0107, 0.0080, 0.0097, 0.0097, 0.0129, 0.0094, 0.0092, 0.0087, 0.0091,\n",
            "        0.0092, 0.0104, 0.0098, 0.0096, 0.0091, 0.0115, 0.0108, 0.0096, 0.0103,\n",
            "        0.0109, 0.0112, 0.0117, 0.0118], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [64]\n",
            "DEBUGGING: logits looks like: tensor([1086.3376, 1086.6444, 1086.6121, 1086.6245, 1086.6311, 1086.6058,\n",
            "        1086.6101, 1086.6228, 1086.6244, 1086.5924, 1086.6716, 1086.6230,\n",
            "        1086.6243, 1086.6376, 1086.6176, 1086.6160, 1086.6239, 1086.6034,\n",
            "        1086.6652, 1086.6191, 1086.6171, 1086.6119, 1086.6132, 1086.5970,\n",
            "        1086.6257, 1086.6290, 1086.6305, 1086.6349, 1086.6021, 1086.6023,\n",
            "        1086.5936, 1086.6075, 1086.6453, 1086.6190, 1086.6294, 1086.6141,\n",
            "        1086.6257, 1086.6210, 1086.6171, 1086.6429, 1086.6205, 1086.5961,\n",
            "        1086.6169, 1086.5972, 1086.6163, 1086.6008, 1086.6252, 1086.6238,\n",
            "        1086.5870, 1086.6030, 1086.5999, 1086.6183, 1086.5928, 1086.6073,\n",
            "        1086.6178, 1086.6248, 1086.6361, 1086.6252, 1086.6239, 1086.5825,\n",
            "        1086.6116, 1086.6375, 1086.5681, 1086.6176, 1086.6174, 1086.5928,\n",
            "        1086.6306, 1086.6079, 1086.6046, 1086.6144, 1086.5833, 1086.5237,\n",
            "        1086.6501, 1086.6157, 1086.6350, 1086.5715, 1086.6067, 1086.6669,\n",
            "        1086.6261, 1086.6276, 1086.6376, 1086.6283, 1086.5995, 1086.6188,\n",
            "        1086.6188, 1086.6473, 1086.6154, 1086.6138, 1086.6073, 1086.6124,\n",
            "        1086.6132, 1086.6252, 1086.6199, 1086.6173, 1086.6124, 1086.6354,\n",
            "        1086.6292, 1086.6179, 1086.6245, 1086.6300, 1086.6329, 1086.6375,\n",
            "        1086.6378], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.14332629204091063 and immediate abs rewards look like: [0.017294578184191778, 0.011014779996003199, 0.008970019261596462, 0.016124257560477417, 0.0035209734628551814, 0.0056436211930304125, 0.0035638231152006483, 0.00022056286206861841, 0.0004781732072842715, 0.00011102198368462268, 0.007355451378316502, 0.0006286887119131279, 8.903269190341234e-05, 0.00237605859820178, 0.0009692844441815396, 0.002057708167740202, 0.0007253508711073664, 0.0006581820221072121, 0.0008834857871988788, 3.7972578411427094e-05, 0.0005458020250443951, 0.0019797197992375004, 0.0011914367305507767, 0.0019779468666456523, 1.5523365618719254e-05, 0.00026076472886416013, 0.00021939720727459644, 0.012437668104666955, 0.0029591662828352128, 0.0034456193488949793, 0.00022955022723181173, 0.0008104446374090912, 0.00040984884435602, 0.0005624129048555915, 0.009042274419698515, 0.00043820013570439187, 0.00334863414764186, 0.004653335866350972, 0.001272188517759787, 0.000445775768639578, 0.008899402841507253, 0.0002999461939907633, 0.001947476689110772, 0.00020572858511513914, 8.19892397885269e-05, 0.00027678706692313426, 0.0018796147737702995, 0.0003805990631917666, 0.0003694086349241843, 1.660294583416544e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 89.29912456948391 and immediate relative rewards look like: [0.5991038410894446, 0.76772848236173, 0.9414272601117304, 2.263481012871865, 0.6213473018673566, 1.1966049572323216, 0.8833297722600494, 0.06255750881336382, 0.15258743751198095, 0.039370746732804426, 2.8693516911681427, 0.2682458517878128, 0.0411629086239846, 1.1830746057371653, 0.5175312858354992, 1.1723242201334008, 0.43939929638585823, 0.4222727788311302, 0.598452422708477, 0.027084034470751424, 0.4087648969372893, 1.5535674264579564, 0.9781586798232823, 1.69520058601685, 0.013868452117376312, 0.24228509711888274, 0.21170925166189608, 12.447324951982948, 3.0809265792057863, 3.715045764197297, 0.25606674316049277, 0.9333036481214313, 0.4868710712594404, 0.6884534635887815, 11.396567574903859, 0.5699277344330337, 4.476957471142112, 6.397162005984806, 1.7979895623210498, 0.6464691464499164, 13.2308050864115, 0.4582874245662051, 3.04672607203343, 0.32957011665109126, 0.1343390937494384, 0.463606622686881, 3.2170401869192164, 0.6657268861681921, 0.6597061081049592, 0.030259448773628263]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([2.3867e-05, 2.0321e-03, 1.1386e-04, 2.7452e-03, 3.8320e-06, 3.4634e-03,\n",
            "        2.9658e-02, 4.8938e-03, 5.5113e-05, 6.3631e-04, 2.4259e-07, 2.2610e-01,\n",
            "        7.7170e-07, 2.4898e-03, 4.1934e-04, 2.4659e-02, 6.7623e-02, 1.3937e-04,\n",
            "        8.5457e-04, 1.5384e-03, 8.7313e-04, 8.5876e-04, 2.5694e-08, 2.4556e-04,\n",
            "        3.0560e-04, 6.7142e-04, 3.6296e-03, 2.3415e-02, 7.3874e-05, 8.3559e-04,\n",
            "        8.7925e-03, 3.8798e-08, 4.9115e-05, 1.1158e-02, 9.7500e-04, 5.0582e-04,\n",
            "        4.9667e-02, 1.9931e-02, 3.1381e-03, 1.5491e-09, 3.9930e-05, 2.5748e-07,\n",
            "        9.1875e-03, 1.6814e-03, 1.6183e-04, 2.0025e-03, 3.8127e-07, 3.2215e-04,\n",
            "        3.7737e-04, 2.6842e-03, 1.3525e-02, 6.7623e-02, 3.0032e-03, 8.2953e-07,\n",
            "        1.4090e-03, 3.3860e-04, 7.2740e-04, 4.6683e-05, 5.2546e-04, 3.2419e-01,\n",
            "        4.6873e-04, 1.7988e-02, 2.9624e-03, 4.9089e-02, 1.6328e-03, 7.4403e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [16]\n",
            "DEBUGGING: logits looks like: tensor([1085.0742, 1085.5187, 1085.2305, 1085.5487, 1084.8914, 1085.5720,\n",
            "        1085.7867, 1085.6066, 1085.1580, 1085.4026, 1084.6154, 1085.9899,\n",
            "        1084.7311, 1085.5389, 1085.3608, 1085.7683, 1085.8691, 1085.2507,\n",
            "        1085.4320, 1085.4908, 1085.4342, 1085.4325, 1084.3909, 1085.3074,\n",
            "        1085.3292, 1085.4080, 1085.5767, 1085.7631, 1085.1873, 1085.4298,\n",
            "        1085.6652, 1084.4320, 1085.1464, 1085.6890, 1085.4452, 1085.3796,\n",
            "        1085.8383, 1085.7469, 1085.5621, 1084.1100, 1085.1257, 1084.6213,\n",
            "        1085.6696, 1085.4998, 1085.2656, 1085.5172, 1084.6605, 1085.3345,\n",
            "        1085.3503, 1085.5465, 1085.7083, 1085.8691, 1085.5577, 1084.7383,\n",
            "        1085.4821, 1085.3395, 1085.4159, 1085.1414, 1085.3834, 1086.0259,\n",
            "        1085.3719, 1085.7367, 1085.5564, 1085.8372, 1085.4968, 1085.6484],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([9.7039e-04, 7.6637e-02, 1.2971e-02, 8.1012e-03, 8.5232e-03, 5.8067e-03,\n",
            "        1.0955e-02, 1.8965e-02, 1.5464e-02, 8.1568e-03, 4.1337e-03, 1.7799e-02,\n",
            "        2.5742e-03, 2.2676e-02, 2.9031e-02, 1.8167e-02, 4.9522e-03, 1.7251e-02,\n",
            "        1.1730e-02, 3.4336e-03, 1.6064e-02, 2.1013e-02, 1.3821e-02, 1.9624e-02,\n",
            "        1.2535e-02, 3.0395e-02, 1.6046e-03, 2.6279e-02, 4.8469e-03, 1.8580e-02,\n",
            "        1.8400e-02, 9.5829e-03, 2.2628e-03, 1.8346e-02, 4.9329e-03, 1.8744e-02,\n",
            "        5.6832e-03, 1.9701e-02, 6.9632e-03, 1.3727e-02, 1.9992e-02, 5.1984e-05,\n",
            "        1.2329e-02, 1.2114e-02, 5.1194e-03, 1.8061e-02, 8.5649e-03, 6.5414e-03,\n",
            "        1.1116e-02, 3.3026e-02, 6.1091e-03, 2.2281e-02, 1.0331e-02, 9.7624e-03,\n",
            "        6.8286e-03, 1.2149e-02, 1.7816e-02, 5.0746e-03, 2.0486e-02, 6.3774e-03,\n",
            "        6.2479e-03, 2.8272e-03, 9.1888e-03, 2.4759e-02, 4.4434e-03, 1.9545e-03,\n",
            "        8.8368e-03, 3.1849e-03, 6.0498e-03, 2.1386e-02, 1.7083e-02, 2.5492e-03,\n",
            "        2.9865e-02, 1.3660e-02, 1.0330e-03, 9.4713e-03, 5.9096e-03, 6.0144e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [13]\n",
            "DEBUGGING: logits looks like: tensor([1085.5027, 1085.9396, 1085.7620, 1085.7148, 1085.7200, 1085.6815,\n",
            "        1085.7450, 1085.7999, 1085.7795, 1085.7156, 1085.6476, 1085.7936,\n",
            "        1085.6002, 1085.8177, 1085.8425, 1085.7957, 1085.6656, 1085.7904,\n",
            "        1085.7518, 1085.6290, 1085.7833, 1085.8102, 1085.7683, 1085.8033,\n",
            "        1085.7585, 1085.8470, 1085.5530, 1085.8325, 1085.6635, 1085.7979,\n",
            "        1085.7969, 1085.7317, 1085.5873, 1085.7966, 1085.6653, 1085.7987,\n",
            "        1085.6794, 1085.8037, 1085.6997, 1085.7676, 1085.8052, 1085.2100,\n",
            "        1085.7568, 1085.7551, 1085.6689, 1085.7950, 1085.7205, 1085.6935,\n",
            "        1085.7465, 1085.8553, 1085.6866, 1085.8160, 1085.7391, 1085.7335,\n",
            "        1085.6978, 1085.7554, 1085.7937, 1085.6681, 1085.8076, 1085.6909,\n",
            "        1085.6888, 1085.6096, 1085.7274, 1085.8265, 1085.6548, 1085.5726,\n",
            "        1085.7235, 1085.6215, 1085.6857, 1085.8119, 1085.7894, 1085.5992,\n",
            "        1085.8453, 1085.7671, 1085.5089, 1085.7305, 1085.6833, 1085.6851],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0004, 0.0109, 0.0080, 0.0054, 0.0130, 0.0103, 0.0121, 0.0106, 0.0061,\n",
            "        0.0084, 0.0108, 0.0110, 0.0106, 0.0130, 0.0123, 0.0099, 0.0113, 0.0194,\n",
            "        0.0094, 0.0094, 0.0112, 0.0099, 0.0114, 0.0085, 0.0125, 0.0100, 0.0127,\n",
            "        0.0135, 0.0111, 0.0120, 0.0119, 0.0103, 0.0133, 0.0018, 0.0095, 0.0077,\n",
            "        0.0184, 0.0166, 0.0119, 0.0131, 0.0070, 0.0103, 0.0088, 0.0098, 0.0125,\n",
            "        0.0111, 0.0056, 0.0093, 0.0144, 0.0095, 0.0076, 0.0111, 0.0105, 0.0181,\n",
            "        0.0164, 0.0100, 0.0137, 0.0133, 0.0201, 0.0078, 0.0113, 0.0131, 0.0140,\n",
            "        0.0071, 0.0173, 0.0092, 0.0057, 0.0113, 0.0208, 0.0063, 0.0103, 0.0059,\n",
            "        0.0107, 0.0121, 0.0121, 0.0122, 0.0158, 0.0093, 0.0123, 0.0094, 0.0120,\n",
            "        0.0128, 0.0211, 0.0064, 0.0102, 0.0077, 0.0123, 0.0124, 0.0157, 0.0070],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [72]\n",
            "DEBUGGING: logits looks like: tensor([1085.7811, 1086.1058, 1086.0752, 1086.0354, 1086.1235, 1086.1006,\n",
            "        1086.1162, 1086.1027, 1086.0474, 1086.0803, 1086.1049, 1086.1064,\n",
            "        1086.1025, 1086.1233, 1086.1183, 1086.0959, 1086.1093, 1086.1633,\n",
            "        1086.0911, 1086.0914, 1086.1086, 1086.0966, 1086.1105, 1086.0813,\n",
            "        1086.1193, 1086.0973, 1086.1207, 1086.1273, 1086.1074, 1086.1155,\n",
            "        1086.1146, 1086.1000, 1086.1257, 1085.9240, 1086.0920, 1086.0712,\n",
            "        1086.1583, 1086.1479, 1086.1149, 1086.1243, 1086.0614, 1086.1001,\n",
            "        1086.0840, 1086.0951, 1086.1199, 1086.1077, 1086.0389, 1086.0901,\n",
            "        1086.1335, 1086.0917, 1086.0692, 1086.1074, 1086.1022, 1086.1567,\n",
            "        1086.1466, 1086.0975, 1086.1283, 1086.1259, 1086.1669, 1086.0728,\n",
            "        1086.1096, 1086.1239, 1086.1307, 1086.0625, 1086.1520, 1086.0891,\n",
            "        1086.0405, 1086.1091, 1086.1707, 1086.0502, 1086.1005, 1086.0443,\n",
            "        1086.1035, 1086.1158, 1086.1158, 1086.1168, 1086.1427, 1086.0895,\n",
            "        1086.1177, 1086.0907, 1086.1151, 1086.1219, 1086.1718, 1086.0526,\n",
            "        1086.0992, 1086.0707, 1086.1179, 1086.1187, 1086.1423, 1086.0615],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0007, 0.0093, 0.0106, 0.0099, 0.0102, 0.0101, 0.0098, 0.0104, 0.0102,\n",
            "        0.0109, 0.0105, 0.0097, 0.0102, 0.0101, 0.0105, 0.0109, 0.0106, 0.0101,\n",
            "        0.0112, 0.0105, 0.0100, 0.0103, 0.0102, 0.0103, 0.0099, 0.0107, 0.0102,\n",
            "        0.0107, 0.0105, 0.0119, 0.0106, 0.0103, 0.0104, 0.0095, 0.0108, 0.0103,\n",
            "        0.0100, 0.0114, 0.0100, 0.0099, 0.0106, 0.0096, 0.0100, 0.0099, 0.0103,\n",
            "        0.0106, 0.0106, 0.0105, 0.0102, 0.0099, 0.0097, 0.0103, 0.0110, 0.0103,\n",
            "        0.0093, 0.0103, 0.0102, 0.0092, 0.0094, 0.0102, 0.0104, 0.0100, 0.0107,\n",
            "        0.0106, 0.0108, 0.0097, 0.0102, 0.0098, 0.0104, 0.0102, 0.0105, 0.0101,\n",
            "        0.0102, 0.0100, 0.0103, 0.0109, 0.0096, 0.0098, 0.0099, 0.0108, 0.0103,\n",
            "        0.0113, 0.0096, 0.0105, 0.0102, 0.0098, 0.0109, 0.0105, 0.0105, 0.0105,\n",
            "        0.0113, 0.0107, 0.0108, 0.0103, 0.0109, 0.0101, 0.0100, 0.0103],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [84]\n",
            "DEBUGGING: logits looks like: tensor([1086.0770, 1086.3373, 1086.3507, 1086.3440, 1086.3464, 1086.3451,\n",
            "        1086.3429, 1086.3488, 1086.3468, 1086.3536, 1086.3499, 1086.3417,\n",
            "        1086.3466, 1086.3459, 1086.3492, 1086.3536, 1086.3501, 1086.3457,\n",
            "        1086.3555, 1086.3495, 1086.3446, 1086.3479, 1086.3464, 1086.3477,\n",
            "        1086.3434, 1086.3511, 1086.3461, 1086.3514, 1086.3492, 1086.3617,\n",
            "        1086.3506, 1086.3475, 1086.3484, 1086.3391, 1086.3521, 1086.3479,\n",
            "        1086.3445, 1086.3574, 1086.3446, 1086.3436, 1086.3503, 1086.3408,\n",
            "        1086.3445, 1086.3438, 1086.3477, 1086.3506, 1086.3507, 1086.3495,\n",
            "        1086.3461, 1086.3433, 1086.3420, 1086.3477, 1086.3540, 1086.3470,\n",
            "        1086.3378, 1086.3470, 1086.3469, 1086.3358, 1086.3383, 1086.3462,\n",
            "        1086.3481, 1086.3441, 1086.3513, 1086.3500, 1086.3524, 1086.3418,\n",
            "        1086.3468, 1086.3423, 1086.3489, 1086.3462, 1086.3496, 1086.3457,\n",
            "        1086.3468, 1086.3450, 1086.3472, 1086.3529, 1086.3409, 1086.3429,\n",
            "        1086.3431, 1086.3524, 1086.3477, 1086.3563, 1086.3405, 1086.3495,\n",
            "        1086.3466, 1086.3430, 1086.3531, 1086.3491, 1086.3490, 1086.3490,\n",
            "        1086.3572, 1086.3517, 1086.3525, 1086.3475, 1086.3535, 1086.3453,\n",
            "        1086.3444, 1086.3474], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0007, 0.0093, 0.0091, 0.0092, 0.0092, 0.0091, 0.0092, 0.0091, 0.0092,\n",
            "        0.0091, 0.0092, 0.0092, 0.0091, 0.0092, 0.0092, 0.0092, 0.0091, 0.0092,\n",
            "        0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0091, 0.0092, 0.0092, 0.0091,\n",
            "        0.0092, 0.0091, 0.0088, 0.0093, 0.0092, 0.0091, 0.0093, 0.0092, 0.0091,\n",
            "        0.0091, 0.0092, 0.0091, 0.0093, 0.0090, 0.0092, 0.0092, 0.0092, 0.0093,\n",
            "        0.0092, 0.0092, 0.0092, 0.0090, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092,\n",
            "        0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0092, 0.0091, 0.0091, 0.0091,\n",
            "        0.0090, 0.0091, 0.0092, 0.0092, 0.0091, 0.0092, 0.0090, 0.0092, 0.0092,\n",
            "        0.0092, 0.0092, 0.0093, 0.0091, 0.0092, 0.0090, 0.0091, 0.0092, 0.0091,\n",
            "        0.0092, 0.0092, 0.0091, 0.0091, 0.0090, 0.0091, 0.0092, 0.0092, 0.0092,\n",
            "        0.0091, 0.0091, 0.0091, 0.0092, 0.0092, 0.0093, 0.0092, 0.0092, 0.0092,\n",
            "        0.0092, 0.0091, 0.0092, 0.0090, 0.0093, 0.0093, 0.0092, 0.0093, 0.0091,\n",
            "        0.0092, 0.0090], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [20]\n",
            "DEBUGGING: logits looks like: tensor([1086.3162, 1086.5813, 1086.5800, 1086.5802, 1086.5806, 1086.5800,\n",
            "        1086.5806, 1086.5798, 1086.5812, 1086.5797, 1086.5812, 1086.5804,\n",
            "        1086.5792, 1086.5809, 1086.5802, 1086.5802, 1086.5796, 1086.5808,\n",
            "        1086.5811, 1086.5807, 1086.5808, 1086.5802, 1086.5812, 1086.5800,\n",
            "        1086.5804, 1086.5804, 1086.5798, 1086.5804, 1086.5798, 1086.5767,\n",
            "        1086.5814, 1086.5804, 1086.5800, 1086.5813, 1086.5806, 1086.5801,\n",
            "        1086.5792, 1086.5809, 1086.5792, 1086.5815, 1086.5789, 1086.5807,\n",
            "        1086.5808, 1086.5808, 1086.5814, 1086.5809, 1086.5808, 1086.5804,\n",
            "        1086.5789, 1086.5804, 1086.5804, 1086.5812, 1086.5803, 1086.5811,\n",
            "        1086.5802, 1086.5811, 1086.5807, 1086.5808, 1086.5804, 1086.5808,\n",
            "        1086.5801, 1086.5801, 1086.5795, 1086.5781, 1086.5795, 1086.5812,\n",
            "        1086.5808, 1086.5800, 1086.5809, 1086.5789, 1086.5804, 1086.5802,\n",
            "        1086.5808, 1086.5812, 1086.5817, 1086.5800, 1086.5808, 1086.5780,\n",
            "        1086.5791, 1086.5808, 1086.5792, 1086.5804, 1086.5802, 1086.5792,\n",
            "        1086.5793, 1086.5789, 1086.5796, 1086.5804, 1086.5808, 1086.5806,\n",
            "        1086.5796, 1086.5790, 1086.5801, 1086.5804, 1086.5804, 1086.5815,\n",
            "        1086.5806, 1086.5808, 1086.5804, 1086.5812, 1086.5801, 1086.5809,\n",
            "        1086.5782, 1086.5813, 1086.5814, 1086.5808, 1086.5822, 1086.5800,\n",
            "        1086.5803, 1086.5786], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.1239060166726631 and immediate abs rewards look like: [0.017294578184191778, 0.011014779996003199, 0.008970019261596462, 0.016124257560477417, 0.004231098425407254, 0.004791104357082077, 0.003802886301855324, 0.003862809267047851, 0.0002448850245855283, 0.005235760578216286, 0.013689364882793598, 0.019296430145459453, 5.827127279189881e-05, 0.00019603684086177964, 0.00022236945824261056, 0.00016818921312733437, 0.0034290668672838365, 0.0019977169754383794, 0.00030047855489101494, 0.002161266037091991, 8.021085250220494e-06, 0.0002205371738455142, 0.0001895933510240866, 0.0013660084855473542, 0.0007458258778569871, 0.00023490799640057958, 0.0009589645874257258, 0.00015971189895935822, 0.0005087828189971333, 0.000550154710708739, 0.00016357636195607483, 5.9392420553194825e-05, 0.0004246526955284935, 5.784826817034627e-05, 0.00026158678065257845, 0.00015893028285063338, 0.00020657598997786408, 2.491379746061284e-06, 1.6644916286168154e-05, 8.547262950742152e-07, 3.745322101167403e-05, 0.00011649941507130279, 0.00013576815217675176, 2.821258567564655e-05, 3.728557021531742e-05, 6.341224843708915e-05, 2.589834230093402e-05, 3.5184893022233155e-05, 2.2831762635178166e-05, 1.703946963971248e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 36.59694106660442 and immediate relative rewards look like: [0.5991038410894446, 0.76772848236173, 0.9414272601117304, 2.263481012871865, 0.7466632788621359, 1.0161026165560476, 0.9425364905600796, 1.0956332576869001, 0.0782477546444637, 1.859022670540377, 5.356597403961307, 8.277348882950728, 0.027266974475770974, 0.09879021604004572, 0.12007296865239493, 0.09687946650078454, 2.0987697197147197, 1.2962324153954128, 0.20594742029873964, 1.559461204984518, 0.0060817356958973254, 0.1751785224233154, 0.15745697174065867, 1.1838735766559805, 0.6736470730853513, 0.22072074807943237, 0.9357831368042093, 0.16167941612410708, 0.5334760668122662, 0.5968572794993379, 0.1834142421603951, 0.0687475961079951, 0.5069132794420456, 0.07115768972248795, 0.3312420679270329, 0.2070198124413262, 0.2765726911277074, 0.003425971290677363, 0.023491286795934412, 0.0012372294725255884, 0.055569484130038545, 0.1770688866134429, 0.2112778136341996, 0.044926691559227086, 0.0607248719866665, 0.1055723404624094, 0.04405538060304012, 0.061126661377355763, 0.040492468707667775, 0.030836735862483602]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([5.0433e-16, 5.2569e-26, 1.0490e-22, 2.1983e-18, 3.0523e-11, 1.8657e-05,\n",
            "        2.6385e-12, 6.8475e-15, 1.8275e-06, 1.6122e-15, 6.1183e-17, 1.3498e-21,\n",
            "        5.6717e-21, 7.7412e-11, 9.9644e-01, 5.3416e-04, 9.6449e-10, 9.4925e-12,\n",
            "        2.7211e-15, 3.7168e-13, 8.3947e-11, 5.3703e-27, 1.6421e-16, 1.7782e-19,\n",
            "        6.2553e-06, 1.3160e-27, 2.0305e-33, 2.5430e-17, 4.7976e-17, 1.0418e-09,\n",
            "        9.4513e-15, 2.8083e-13, 1.0317e-09, 4.1246e-09, 2.5918e-14, 2.4724e-16,\n",
            "        8.1273e-12, 5.1789e-15, 8.6672e-26, 6.0671e-34, 3.9381e-18, 1.4822e-09,\n",
            "        2.8151e-10, 6.4408e-13, 9.5944e-19, 2.8665e-13, 1.4934e-11, 6.0144e-14,\n",
            "        9.4670e-30, 1.7756e-16, 5.3489e-21, 4.4772e-09, 6.0184e-16, 2.0771e-12,\n",
            "        1.5434e-06, 2.7500e-03, 1.3899e-21, 1.0584e-08, 7.1433e-13, 7.7615e-13,\n",
            "        1.5485e-17, 1.2777e-16, 5.7533e-30, 2.3336e-04, 2.9838e-19, 3.7070e-11,\n",
            "        1.1573e-05, 1.3277e-07, 1.4542e-06], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [14]\n",
            "DEBUGGING: logits looks like: tensor([1081.4274, 1079.1289, 1079.8888, 1080.8838, 1082.5284, 1083.8607,\n",
            "        1082.2836, 1081.6882, 1083.6284, 1081.5436, 1081.2164, 1080.1443,\n",
            "        1080.2878, 1082.6215, 1084.9493, 1084.1962, 1082.8738, 1082.4116,\n",
            "        1081.5959, 1082.0876, 1082.6296, 1078.9008, 1081.3152, 1080.6323,\n",
            "        1083.7515, 1078.7601, 1077.4220, 1081.1287, 1081.1921, 1082.8815,\n",
            "        1081.7205, 1082.0596, 1082.8805, 1083.0190, 1081.8213, 1081.3561,\n",
            "        1082.3961, 1081.6603, 1079.1790, 1077.3011, 1080.9421, 1082.9167,\n",
            "        1082.7506, 1082.1426, 1080.8009, 1082.0616, 1082.4569, 1081.9055,\n",
            "        1078.2667, 1081.3230, 1080.2820, 1083.0272, 1081.4451, 1082.2596,\n",
            "        1083.6116, 1084.3601, 1080.1472, 1083.1133, 1082.1530, 1082.1613,\n",
            "        1081.0790, 1081.2900, 1078.2169, 1084.1134, 1080.6841, 1082.5479,\n",
            "        1083.8130, 1083.3662, 1083.6056], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([5.5438e-13, 1.4163e-09, 1.7267e-03, 2.7382e-02, 1.4595e-04, 2.3849e-05,\n",
            "        1.9994e-02, 3.7166e-03, 3.3807e-03, 1.3515e-02, 1.8655e-02, 6.2834e-05,\n",
            "        9.1780e-05, 2.3701e-01, 4.3071e-03, 6.1199e-05, 2.1450e-02, 1.3369e-03,\n",
            "        6.7731e-06, 4.0828e-08, 8.0233e-03, 8.0233e-03, 5.1434e-05, 1.9001e-03,\n",
            "        1.1718e-03, 1.1161e-02, 1.9411e-04, 1.9209e-02, 2.6021e-10, 4.0383e-03,\n",
            "        9.1987e-03, 6.3345e-03, 2.1846e-04, 6.7234e-03, 5.9965e-04, 1.6818e-03,\n",
            "        2.4402e-02, 1.0282e-02, 1.4856e-03, 9.9821e-05, 1.9593e-07, 1.4474e-01,\n",
            "        4.0819e-03, 4.0350e-02, 1.8111e-04, 1.7657e-04, 1.6969e-02, 7.1710e-03,\n",
            "        9.8577e-04, 5.3499e-03, 1.2034e-01, 1.8930e-02, 1.2304e-03, 2.9545e-03,\n",
            "        6.1217e-03, 3.8303e-04, 1.0554e-04, 1.9041e-02, 5.3282e-04, 5.8987e-03,\n",
            "        5.6949e-03, 3.5494e-04, 1.6559e-02, 1.1706e-03, 1.3927e-04, 2.6796e-03,\n",
            "        4.0108e-03, 2.5824e-02, 3.9300e-02, 2.9119e-02, 3.5149e-04, 5.6868e-06,\n",
            "        1.1549e-02, 3.6153e-05], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [68]\n",
            "DEBUGGING: logits looks like: tensor([1082.2153, 1082.9999, 1084.4012, 1084.6776, 1084.1542, 1083.9730,\n",
            "        1084.6462, 1084.4779, 1084.4685, 1084.6071, 1084.6393, 1084.0699,\n",
            "        1084.1078, 1084.8934, 1084.4927, 1084.0673, 1084.6532, 1084.3757,\n",
            "        1083.8472, 1083.3361, 1084.5549, 1084.5549, 1084.0499, 1084.4109,\n",
            "        1084.3625, 1084.5879, 1084.1827, 1084.6422, 1082.8304, 1084.4862,\n",
            "        1084.5686, 1084.5312, 1084.1946, 1084.5372, 1084.2955, 1084.3987,\n",
            "        1084.6661, 1084.5797, 1084.3862, 1084.1162, 1083.4929, 1084.8441,\n",
            "        1084.4873, 1084.7164, 1084.1758, 1084.1732, 1084.6298, 1084.5437,\n",
            "        1084.3452, 1084.5144, 1084.8257, 1084.6407, 1084.3674, 1084.4550,\n",
            "        1084.5278, 1084.2507, 1084.1218, 1084.6414, 1084.2837, 1084.5242,\n",
            "        1084.5206, 1084.2430, 1084.6273, 1084.3624, 1084.1495, 1084.4452,\n",
            "        1084.4856, 1084.6718, 1084.7137, 1084.6838, 1084.2421, 1083.8297,\n",
            "        1084.5913, 1084.0146], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([8.5579e-12, 2.0120e-02, 9.9699e-03, 1.2168e-02, 4.3028e-06, 8.0502e-03,\n",
            "        1.4677e-02, 1.4720e-02, 1.2061e-02, 2.1840e-02, 7.8945e-03, 1.1090e-02,\n",
            "        8.0345e-03, 8.8070e-03, 1.9368e-02, 5.4047e-03, 4.3428e-03, 2.1776e-02,\n",
            "        1.2764e-02, 1.4952e-02, 2.7879e-02, 5.5113e-03, 1.6405e-02, 1.0246e-02,\n",
            "        1.7739e-02, 1.1645e-02, 1.2227e-02, 1.3282e-04, 4.7649e-03, 1.6550e-02,\n",
            "        1.0448e-02, 8.2815e-03, 1.4450e-02, 4.0916e-03, 1.5247e-02, 3.8021e-04,\n",
            "        1.6422e-02, 6.2329e-03, 5.6310e-03, 1.1003e-02, 3.8368e-02, 6.7657e-03,\n",
            "        1.4634e-02, 9.5040e-03, 1.8445e-02, 8.7726e-03, 2.3382e-03, 7.0904e-03,\n",
            "        7.5036e-03, 1.6389e-02, 1.6228e-03, 3.6214e-03, 9.7580e-03, 9.7770e-03,\n",
            "        1.5321e-02, 1.0791e-02, 2.0317e-02, 1.1319e-02, 1.2420e-02, 7.2444e-03,\n",
            "        1.6713e-02, 2.0022e-02, 2.1904e-02, 3.4489e-03, 5.3001e-03, 7.3155e-03,\n",
            "        1.7294e-02, 5.8897e-03, 1.0327e-02, 5.2027e-03, 2.0658e-02, 7.6966e-03,\n",
            "        4.5601e-03, 9.5692e-03, 6.9127e-03, 4.7883e-03, 8.3139e-03, 1.9520e-02,\n",
            "        1.2965e-02, 2.4151e-02, 5.7645e-03, 1.5715e-02, 2.2446e-02, 1.7026e-02,\n",
            "        4.3174e-03, 1.3118e-02, 3.6785e-03, 1.0048e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [74]\n",
            "DEBUGGING: logits looks like: tensor([1082.6063, 1084.7642, 1084.6940, 1084.7139, 1083.9192, 1084.6726,\n",
            "        1084.7327, 1084.7329, 1084.7130, 1084.7723, 1084.6707, 1084.7046,\n",
            "        1084.6724, 1084.6815, 1084.7604, 1084.6327, 1084.6108, 1084.7721,\n",
            "        1084.7186, 1084.7345, 1084.7968, 1084.6346, 1084.7438, 1084.6967,\n",
            "        1084.7516, 1084.7095, 1084.7144, 1084.2621, 1084.6201, 1084.7446,\n",
            "        1084.6986, 1084.6754, 1084.7311, 1084.6049, 1084.7365, 1084.3673,\n",
            "        1084.7439, 1084.6470, 1084.6368, 1084.7039, 1084.8287, 1084.6552,\n",
            "        1084.7323, 1084.6892, 1084.7555, 1084.6812, 1084.5490, 1084.6599,\n",
            "        1084.6655, 1084.7437, 1084.5125, 1084.5927, 1084.6918, 1084.6920,\n",
            "        1084.7369, 1084.7019, 1084.7651, 1084.7067, 1084.7159, 1084.6620,\n",
            "        1084.7456, 1084.7637, 1084.7727, 1084.5878, 1084.6307, 1084.6630,\n",
            "        1084.7490, 1084.6414, 1084.6975, 1084.6289, 1084.7668, 1084.6681,\n",
            "        1084.6157, 1084.6898, 1084.6573, 1084.6206, 1084.6758, 1084.7611,\n",
            "        1084.7202, 1084.7825, 1084.6392, 1084.7395, 1084.7751, 1084.7474,\n",
            "        1084.6102, 1084.7214, 1084.5942, 1084.6947], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.1874e-10, 4.2166e-03, 4.5282e-03, 1.0590e-02, 3.8694e-03, 1.0916e-02,\n",
            "        3.0884e-02, 7.2149e-03, 4.1196e-02, 1.2024e-02, 1.9901e-02, 6.0332e-04,\n",
            "        6.2500e-03, 1.3611e-02, 2.2463e-02, 1.0926e-02, 5.6907e-03, 3.0017e-03,\n",
            "        6.5436e-03, 4.0829e-03, 7.2502e-03, 1.5713e-02, 1.2393e-02, 9.9098e-03,\n",
            "        1.0969e-02, 2.7304e-03, 1.8460e-02, 9.7181e-03, 2.2617e-02, 7.7859e-03,\n",
            "        1.6593e-03, 1.2273e-02, 8.8398e-03, 4.2043e-03, 3.0223e-03, 6.3175e-03,\n",
            "        8.1835e-03, 1.3519e-02, 4.7040e-03, 1.5790e-02, 8.7283e-03, 8.7283e-03,\n",
            "        8.4763e-03, 6.2745e-03, 8.6773e-03, 6.9724e-03, 9.6519e-03, 1.9046e-02,\n",
            "        8.2236e-03, 1.5155e-02, 2.1185e-02, 9.1383e-03, 7.5169e-03, 1.7341e-02,\n",
            "        1.9804e-02, 5.2888e-03, 9.2912e-03, 1.0036e-02, 1.2273e-02, 1.9686e-03,\n",
            "        1.1055e-02, 1.0549e-02, 1.6132e-02, 9.5955e-03, 6.8376e-03, 7.3715e-03,\n",
            "        4.8675e-03, 2.4865e-02, 1.7089e-02, 8.0174e-03, 2.0393e-02, 1.6499e-02,\n",
            "        1.6352e-03, 7.2562e-04, 3.9844e-03, 1.4818e-02, 1.1860e-02, 2.8503e-03,\n",
            "        1.2071e-02, 1.3322e-02, 8.3043e-03, 1.3718e-02, 1.1930e-02, 9.0495e-03,\n",
            "        1.1395e-02, 5.3147e-03, 1.2261e-02, 1.1699e-02, 1.1055e-02, 7.3428e-03,\n",
            "        5.7466e-03, 1.1895e-02, 7.6428e-03, 5.7186e-03, 1.6499e-02, 7.5390e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [7]\n",
            "DEBUGGING: logits looks like: tensor([1082.8809, 1084.5583, 1084.5654, 1084.6504, 1084.5497, 1084.6534,\n",
            "        1084.7574, 1084.6121, 1084.7863, 1084.6631, 1084.7135, 1084.3639,\n",
            "        1084.5977, 1084.6755, 1084.7256, 1084.6536, 1084.5883, 1084.5243,\n",
            "        1084.6023, 1084.5551, 1084.6125, 1084.6898, 1084.6661, 1084.6438,\n",
            "        1084.6539, 1084.5149, 1084.7059, 1084.6418, 1084.7263, 1084.6196,\n",
            "        1084.4651, 1084.6652, 1084.6323, 1084.5580, 1084.5250, 1084.5988,\n",
            "        1084.6246, 1084.6748, 1084.5692, 1084.6903, 1084.6311, 1084.6311,\n",
            "        1084.6282, 1084.5980, 1084.6305, 1084.6086, 1084.6411, 1084.7091,\n",
            "        1084.6251, 1084.6863, 1084.7197, 1084.6356, 1084.6161, 1084.6997,\n",
            "        1084.7130, 1084.5809, 1084.6373, 1084.6450, 1084.6652, 1084.4822,\n",
            "        1084.6547, 1084.6500, 1084.6925, 1084.6405, 1084.6067, 1084.6141,\n",
            "        1084.5726, 1084.7357, 1084.6982, 1084.6226, 1084.7159, 1084.6947,\n",
            "        1084.4636, 1084.3823, 1084.5526, 1084.6840, 1084.6617, 1084.5192,\n",
            "        1084.6635, 1084.6733, 1084.6261, 1084.6763, 1084.6624, 1084.6346,\n",
            "        1084.6577, 1084.5814, 1084.6650, 1084.6604, 1084.6547, 1084.6138,\n",
            "        1084.5892, 1084.6620, 1084.6178, 1084.5887, 1084.6947, 1084.6165],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.6574e-09, 5.6615e-03, 1.8871e-03, 4.7073e-03, 7.7762e-03, 1.0966e-02,\n",
            "        2.7542e-02, 1.0608e-02, 2.3463e-03, 1.4275e-02, 1.5327e-03, 5.5250e-03,\n",
            "        4.6798e-03, 2.6561e-03, 4.8331e-03, 1.6236e-03, 6.4593e-03, 5.8250e-02,\n",
            "        7.3552e-03, 1.2162e-02, 3.3413e-03, 1.3999e-02, 5.9216e-03, 8.2940e-03,\n",
            "        1.5739e-02, 1.7590e-03, 2.9058e-03, 2.7700e-03, 4.8331e-03, 6.0443e-03,\n",
            "        6.9570e-03, 4.0898e-03, 6.5675e-03, 3.6057e-03, 2.8695e-02, 1.5164e-03,\n",
            "        1.2709e-02, 3.1292e-04, 1.0546e-02, 1.0754e-02, 1.6883e-03, 1.6900e-03,\n",
            "        2.8246e-03, 3.8121e-03, 3.3153e-03, 2.7431e-03, 2.6047e-03, 4.8520e-03,\n",
            "        2.2608e-03, 3.3713e-02, 4.8473e-03, 1.3112e-02, 1.2402e-02, 1.8485e-04,\n",
            "        2.8747e-03, 2.6822e-03, 3.0068e-03, 7.8219e-03, 2.3763e-03, 8.6581e-03,\n",
            "        1.2934e-02, 5.8986e-03, 5.5420e-02, 1.1117e-02, 2.7142e-02, 1.3215e-02,\n",
            "        5.7732e-03, 6.5932e-03, 7.1919e-03, 2.8027e-03, 7.2969e-04, 2.2990e-02,\n",
            "        6.2851e-03, 1.6016e-03, 2.4090e-03, 1.0754e-02, 7.2695e-03, 6.2423e-03,\n",
            "        1.5046e-03, 1.9758e-03, 9.6966e-03, 8.8289e-03, 1.1925e-03, 9.8013e-03,\n",
            "        2.1283e-02, 3.9912e-03, 2.1342e-03, 2.3926e-03, 9.6966e-03, 5.3654e-03,\n",
            "        1.2610e-02, 5.0849e-03, 9.4351e-03, 1.4960e-02, 1.0373e-02, 1.2438e-09,\n",
            "        2.7542e-02, 1.5046e-03, 3.4778e-03, 4.6163e-03, 1.9378e-02, 3.1976e-03,\n",
            "        3.8721e-03, 7.5370e-03, 6.3664e-02, 5.8307e-02, 3.7457e-03, 5.0898e-03,\n",
            "        1.6966e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [49]\n",
            "DEBUGGING: logits looks like: tensor([1083.0809, 1084.5853, 1084.4755, 1084.5669, 1084.6171, 1084.6515,\n",
            "        1084.7435, 1084.6482, 1084.4973, 1084.6779, 1084.4547, 1084.5829,\n",
            "        1084.5663, 1084.5096, 1084.5696, 1084.4604, 1084.5985, 1084.8185,\n",
            "        1084.6116, 1084.6619, 1084.5326, 1084.6759, 1084.5898, 1084.6235,\n",
            "        1084.6876, 1084.4685, 1084.5187, 1084.5139, 1084.5696, 1084.5919,\n",
            "        1084.6060, 1084.5529, 1084.6002, 1084.5403, 1084.7477, 1084.4536,\n",
            "        1084.6663, 1084.2958, 1084.6476, 1084.6495, 1084.4644, 1084.4645,\n",
            "        1084.5159, 1084.5458, 1084.5319, 1084.5129, 1084.5077, 1084.5699,\n",
            "        1084.4935, 1084.7638, 1084.5698, 1084.6693, 1084.6638, 1084.2432,\n",
            "        1084.5176, 1084.5106, 1084.5221, 1084.6177, 1084.4985, 1084.6278,\n",
            "        1084.6680, 1084.5895, 1084.8135, 1084.6528, 1084.7421, 1084.6702,\n",
            "        1084.5873, 1084.6006, 1084.6093, 1084.5150, 1084.3805, 1084.7255,\n",
            "        1084.5958, 1084.4591, 1084.4999, 1084.6495, 1084.6104, 1084.5951,\n",
            "        1084.4529, 1084.4801, 1084.6392, 1084.6298, 1084.4296, 1084.6403,\n",
            "        1084.7178, 1084.5504, 1084.4878, 1084.4993, 1084.6392, 1084.5800,\n",
            "        1084.6654, 1084.5746, 1084.6365, 1084.6825, 1084.6459, 1083.0522,\n",
            "        1084.7435, 1084.4529, 1084.5366, 1084.5649, 1084.7084, 1084.5282,\n",
            "        1084.5474, 1084.6140, 1084.8274, 1084.8186, 1084.5441, 1084.5747,\n",
            "        1084.4648], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.0406888768020508 and immediate abs rewards look like: [0.001628004127269378, 0.0018067069577227812, 0.0020133333973717527, 0.00225755638712144, 0.001049780846642534, 0.007458931105702504, 5.412538985183346e-05, 8.25832817099581e-05, 0.005409354246239673, 0.0038234696748986607, 0.001938702199367981, 0.0010795137354762119, 0.0022476452722912654, 5.1742295909207314e-05, 0.0025795594838200486, 5.602560577244731e-06, 0.001934421039550216, 5.4782225106464466e-05, 3.7565332604572177e-06, 0.00023676452747167787, 8.359547564396053e-05, 0.0005985645207147172, 9.276413402403705e-05, 7.092369241945562e-05, 0.0003111133919446729, 9.610620054445462e-06, 1.245064504473703e-05, 0.0005014181388105499, 0.00035208848930778913, 5.2550331929523963e-05, 0.00013362237177716452, 2.1749969164375216e-05, 0.0007585047023894731, 3.159997095281142e-05, 1.9960601093771402e-05, 3.911629391950555e-06, 3.4420486372255255e-05, 4.488949480219162e-05, 1.3837900496582733e-05, 1.6765513919381192e-05, 8.026230261748424e-06, 8.522846928826766e-05, 1.1824497960333247e-05, 0.0005446731338452082, 6.066960304451641e-05, 5.040997075411724e-05, 0.00018866307345888345, 0.0008509525032422971, 7.014374205027707e-06, 7.375783752650023e-07]\n",
            "DEBUGGING: the total relative reward of the trajectory = 17.63873698999255 and immediate relative rewards look like: [0.060166174884518614, 0.1336213914446697, 0.2235040935321425, 0.3344034913575682, 0.19453783581109957, 1.6593281600011691, 0.014086601875985448, 0.024563939928475026, 1.8101608619202534, 1.4244960836394096, 0.7956581021653004, 0.4836669030477613, 1.091398003401979, 0.027080116097819275, 1.4465118560512797, 0.003354368301308774, 1.2305663658136767, 0.03692595777840833, 0.0026728177349749247, 0.1773268607361829, 0.0657458689354194, 0.4931893052136781, 0.07992548845045916, 0.06376686114829083, 0.29138199609655324, 0.009362231527051927, 0.012595395260256482, 0.5260369880628034, 0.3826393536852425, 0.059087257671679536, 0.1552553375309638, 0.026087715204103797, 0.9382167427607765, 0.040282837350594125, 0.026193965894120753, 0.0052798678129022565, 0.04775097151145393, 0.06395837254462648, 0.020235372812516642, 0.025145224357858702, 0.012338911656870746, 0.13421982527973447, 0.019065479639313564, 0.8986428545067735, 0.10239314205771141, 0.08697037888924387, 0.33257535177334363, 1.5320840301552754, 0.012896138279942872, 0.0013837383990066622]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 150 number of matrices\n",
            "DEBUGGING: ACT_MAT has 150 number of matrices\n",
            "DEBUGGING: VAL looks like: [[66.59896307492583, 66.66652447862262, 66.56444040026352, 66.28587185873918, 64.66908166249225, 64.69468117234837, 64.13947092435964, 63.895092072827865, 64.47730764041869, 64.97446485142092, 65.59100414614961, 63.35520449998128, 63.724200654740876, 64.32630075365343, 63.78103651304673, 63.9025305325366, 63.36384476000324, 63.56004592284584, 63.77552842829768, 63.815228288473946, 64.43246894343757, 64.67040812777806, 63.75438454678799, 63.41032915855021, 62.33851370962966, 62.954187128800285, 63.34535558755697, 63.77135993524755, 51.84245957905515, 49.25407373722158, 45.99901815456998, 46.20500142566615, 45.72898765408557, 45.699107659420335, 45.465307268516725, 34.41286837738674, 34.18478852823606, 30.007910158680758, 23.849240558278737, 22.273990905007764, 21.845981574300858, 8.70219847261551, 8.327182876817481, 5.3337947523071225, 5.054772359248517, 4.970134611615231, 4.552048473665, 1.3484932189351349, 0.6896629623908512, 0.030259448773628263], [32.07592531131446, 31.79476916184345, 31.340445130789618, 30.70607865725039, 28.72989661048336, 28.265892254162853, 27.525040037986674, 26.851013684269287, 26.015535784426653, 26.199280838163826, 24.58611936123581, 19.42375955280253, 11.259000676617982, 11.345185557719406, 11.359995294625616, 11.353456894922447, 11.370280230728952, 9.365162132337607, 8.15043405751737, 8.024733976988514, 6.530578557579794, 6.590400830185755, 6.480022533093373, 6.386429859952237, 5.255107356864905, 4.627737660383389, 4.451532234650461, 3.5512617149962136, 3.4238205039112186, 2.919539835453487, 2.346143995913282, 2.1845755088413, 2.1371999118518232, 1.6467541741512906, 1.591511600433134, 1.2729995277839405, 1.0767471872147618, 0.8082570667546004, 0.8129607024888111, 0.797443854235229, 0.8042491159219227, 0.7562420523150345, 0.5850233996985774, 0.377520794004422, 0.33595363883353024, 0.2780088554008725, 0.17417829791763947, 0.13143729021676703, 0.07102083721152655, 0.030836735862483602], [14.6484327195133, 14.735622772352306, 14.749496344351147, 14.672719445271722, 14.483147428196116, 14.432938982207087, 12.902637194147392, 13.01873797199132, 13.125428315214995, 11.429563084136102, 10.106128283329992, 9.40451533450979, 9.010958011577808, 7.999555563813968, 8.053005502743584, 6.673225905749804, 6.737243977220702, 5.562300617582854, 5.581186525054995, 5.634862330626282, 5.51266209079808, 5.501935577639051, 5.059339669116538, 5.0297112936021, 5.01610548732708, 4.7724479709399255, 4.81119771657866, 4.847073051836771, 4.364682892700977, 4.022266201025995, 4.0032110538932475, 3.8868239559214985, 3.899733576482217, 2.991431145173172, 2.9809578866894726, 2.984610021005406, 3.0094243971641452, 2.9915893188411022, 2.957202976057046, 2.9666339426712414, 2.9712007255690733, 2.988749306982023, 2.8833631128305943, 2.8932299325164452, 2.014734422231992, 1.9316578587618993, 1.863320686740056, 1.5462074090572853, 0.014266039294959468, 0.0013837383990066622]]\n",
            "DEBUGGING: traj_returns = [66.59896307492583, 32.07592531131446, 14.6484327195133]\n",
            "DEBUGGING: actions = [[17], [16], [16], [55], [16], [16], [62], [45], [60], [64], [64], [16], [59], [42], [22], [31], [46], [33], [48], [78], [27], [19], [54], [24], [2], [28], [62], [24], [17], [61], [49], [38], [35], [66], [64], [78], [33], [40], [76], [89], [25], [55], [89], [41], [83], [63], [12], [77], [30], [64], [17], [27], [16], [55], [42], [16], [62], [12], [17], [16], [45], [13], [38], [16], [16], [11], [42], [35], [19], [13], [23], [61], [43], [74], [70], [54], [58], [25], [38], [72], [82], [16], [21], [63], [4], [58], [52], [56], [37], [84], [11], [39], [31], [29], [101], [56], [51], [74], [71], [20], [55], [1], [61], [61], [1], [10], [9], [9], [23], [14], [60], [53], [67], [14], [23], [64], [66], [13], [21], [68], [26], [45], [23], [20], [37], [33], [46], [10], [32], [74], [18], [48], [26], [7], [6], [74], [69], [91], [93], [7], [74], [57], [27], [94], [7], [77], [48], [17], [14], [49]]\n",
            "DEBUGGING: actions length = 150\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[  6.0712,   6.1162,  10.8457,  ...,   4.2682, -11.5832, -17.8876],\n",
            "        [  6.1351,   6.1995,  10.9741,  ...,   4.3134, -11.7165, -18.0834],\n",
            "        [  6.1774,   6.2318,  11.0558,  ...,   4.3483, -11.8069, -18.2156],\n",
            "        ...,\n",
            "        [  6.1569,   6.2126,  10.9995,  ...,   4.3261, -11.7460, -18.1271],\n",
            "        [  6.1569,   6.2126,  10.9994,  ...,   4.3260, -11.7459, -18.1268],\n",
            "        [  6.1570,   6.2127,  10.9995,  ...,   4.3261, -11.7461, -18.1270]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[  6.1469,   6.2024,  10.9819,  ...,   4.3203, -11.7315, -18.1037],\n",
            "        [  6.1570,   6.2126,  10.9994,  ...,   4.3261, -11.7459, -18.1269],\n",
            "        [  6.1562,   6.2119,  10.9982,  ...,   4.3256, -11.7449, -18.1252],\n",
            "        ...,\n",
            "        [  6.1566,   6.2123,  10.9990,  ...,   4.3259, -11.7456, -18.1263],\n",
            "        [  6.1569,   6.2126,  10.9993,  ...,   4.3260, -11.7458, -18.1267],\n",
            "        [  6.1562,   6.2118,  10.9981,  ...,   4.3256, -11.7447, -18.1250]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([1083.0809, 1084.5853, 1084.4755, 1084.5669, 1084.6171, 1084.6515,\n",
            "        1084.7435, 1084.6482, 1084.4973, 1084.6779, 1084.4547, 1084.5829,\n",
            "        1084.5663, 1084.5096, 1084.5696, 1084.4604, 1084.5985, 1084.8185,\n",
            "        1084.6116, 1084.6619, 1084.5326, 1084.6759, 1084.5898, 1084.6235,\n",
            "        1084.6876, 1084.4685, 1084.5187, 1084.5139, 1084.5696, 1084.5919,\n",
            "        1084.6060, 1084.5529, 1084.6002, 1084.5403, 1084.7477, 1084.4536,\n",
            "        1084.6663, 1084.2958, 1084.6476, 1084.6495, 1084.4644, 1084.4645,\n",
            "        1084.5159, 1084.5458, 1084.5319, 1084.5129, 1084.5077, 1084.5699,\n",
            "        1084.4935, 1084.7638, 1084.5698, 1084.6693, 1084.6638, 1084.2432,\n",
            "        1084.5176, 1084.5106, 1084.5221, 1084.6177, 1084.4985, 1084.6278,\n",
            "        1084.6680, 1084.5895, 1084.8135, 1084.6528, 1084.7421, 1084.6702,\n",
            "        1084.5873, 1084.6006, 1084.6093, 1084.5150, 1084.3805, 1084.7255,\n",
            "        1084.5958, 1084.4591, 1084.4999, 1084.6495, 1084.6104, 1084.5951,\n",
            "        1084.4529, 1084.4801, 1084.6392, 1084.6298, 1084.4296, 1084.6403,\n",
            "        1084.7178, 1084.5504, 1084.4878, 1084.4993, 1084.6392, 1084.5800,\n",
            "        1084.6654, 1084.5746, 1084.6365, 1084.6825, 1084.6459, 1083.0522,\n",
            "        1084.7435, 1084.4529, 1084.5366, 1084.5649, 1084.7084, 1084.5282,\n",
            "        1084.5474, 1084.6140, 1084.8274, 1084.8186, 1084.5441, 1084.5747,\n",
            "        1084.4648], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[3.77744404e+01 3.77323055e+01 3.75514606e+01 3.72215567e+01\n",
            "  3.59607086e+01 3.57978375e+01 3.48557161e+01 3.45882812e+01\n",
            "  3.45394239e+01 3.42011029e+01 3.34277506e+01 3.07278265e+01\n",
            "  2.79980531e+01 2.78903473e+01 2.77313458e+01 2.73097378e+01\n",
            "  2.71571230e+01 2.61625029e+01 2.58357163e+01 2.58249415e+01\n",
            "  2.54919032e+01 2.55875815e+01 2.50979156e+01 2.49421568e+01\n",
            "  2.42032422e+01 2.41181243e+01 2.42026952e+01 2.40565649e+01\n",
            "  1.98769877e+01 1.87319599e+01 1.74494577e+01 1.74254670e+01\n",
            "  1.72553070e+01 1.67790977e+01 1.66792589e+01 1.28901593e+01\n",
            "  1.27569867e+01 1.12692522e+01 9.20646808e+00 8.67935623e+00\n",
            "  8.54047714e+00 4.14906328e+00 3.93185646e+00 2.86818183e+00\n",
            "  2.46848681e+00 2.39326711e+00 2.19651582e+00 1.00871264e+00\n",
            "  2.58316613e-01 2.08266410e-02]]\n",
            "DEBUGGING: baseline2 looks like: 37.77444036858453\n",
            "DEBUGGING: ADS looks like: [ 2.88245227e+01  2.89342190e+01  2.90129798e+01  2.90643152e+01\n",
            "  2.87083731e+01  2.88968437e+01  2.92837549e+01  2.93068108e+01\n",
            "  2.99378837e+01  3.07733619e+01  3.21632535e+01  3.26273780e+01\n",
            "  3.57261475e+01  3.64359535e+01  3.60496907e+01  3.65927928e+01\n",
            "  3.62067218e+01  3.73975430e+01  3.79398121e+01  3.79902868e+01\n",
            "  3.89405657e+01  3.90828266e+01  3.86564690e+01  3.84681724e+01\n",
            "  3.81352715e+01  3.88360629e+01  3.91426604e+01  3.97147950e+01\n",
            "  3.19654719e+01  3.05221138e+01  2.85495604e+01  2.87795345e+01\n",
            "  2.84736806e+01  2.89200100e+01  2.87860483e+01  2.15227091e+01\n",
            "  2.14278018e+01  1.87386580e+01  1.46427725e+01  1.35946347e+01\n",
            "  1.33055044e+01  4.55313520e+00  4.39532641e+00  2.46561293e+00\n",
            "  2.58628555e+00  2.57686750e+00  2.35553265e+00  3.39780580e-01\n",
            "  4.31346349e-01  9.43280776e-03 -5.69851506e+00 -5.93753631e+00\n",
            " -6.21101549e+00 -6.51547800e+00 -7.23081196e+00 -7.53194522e+00\n",
            " -7.33067601e+00 -7.73726756e+00 -8.52388813e+00 -8.00182209e+00\n",
            " -8.84163124e+00 -1.13040669e+01 -1.67390524e+01 -1.65451617e+01\n",
            " -1.63713505e+01 -1.59562809e+01 -1.57868428e+01 -1.67973408e+01\n",
            " -1.76852823e+01 -1.78002076e+01 -1.89613246e+01 -1.89971807e+01\n",
            " -1.86178930e+01 -1.85557269e+01 -1.89481348e+01 -1.94903866e+01\n",
            " -1.97511629e+01 -2.05053032e+01 -1.64531672e+01 -1.58124201e+01\n",
            " -1.51033137e+01 -1.52408915e+01 -1.51181071e+01 -1.51323435e+01\n",
            " -1.50877473e+01 -1.16171598e+01 -1.16802395e+01 -1.04609951e+01\n",
            " -8.39350738e+00 -7.88191238e+00 -7.73622802e+00 -3.39282122e+00\n",
            " -3.34683306e+00 -2.49066103e+00 -2.13253317e+00 -2.11525825e+00\n",
            " -2.02233752e+00 -8.77275349e-01 -1.87295776e-01  1.00100949e-02\n",
            " -2.31260076e+01 -2.29966827e+01 -2.28019643e+01 -2.25488372e+01\n",
            " -2.14775611e+01 -2.13648985e+01 -2.19530789e+01 -2.15695433e+01\n",
            " -2.14139956e+01 -2.27715398e+01 -2.33216223e+01 -2.13233111e+01\n",
            " -1.89870951e+01 -1.98907917e+01 -1.96783403e+01 -2.06365119e+01\n",
            " -2.04198790e+01 -2.06002023e+01 -2.02545298e+01 -2.01900792e+01\n",
            " -1.99792411e+01 -2.00856459e+01 -2.00385759e+01 -1.99124455e+01\n",
            " -1.91871367e+01 -1.93456763e+01 -1.93914975e+01 -1.92094918e+01\n",
            " -1.55123048e+01 -1.47096937e+01 -1.34462467e+01 -1.35386430e+01\n",
            " -1.33555735e+01 -1.37876665e+01 -1.36983010e+01 -9.90554929e+00\n",
            " -9.74756231e+00 -8.27766286e+00 -6.24926510e+00 -5.71272229e+00\n",
            " -5.56927641e+00 -1.16031397e+00 -1.04849335e+00  2.50481062e-02\n",
            " -4.53752385e-01 -4.61609250e-01 -3.33195133e-01  5.37494770e-01\n",
            " -2.44050574e-01 -1.94429026e-02]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(3.1879, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.7005,  0.2460, -0.1159,  ..., -0.1914, -0.1510, -0.3780],\n",
            "        [-0.1942, -0.0682,  0.0320,  ...,  0.0529,  0.0418,  0.0841],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.2010,  0.0706, -0.0333,  ..., -0.0549, -0.0433, -0.1132],\n",
            "        [ 0.4495,  0.1578, -0.0744,  ..., -0.1228, -0.0968, -0.2377],\n",
            "        [ 0.3860,  0.1356, -0.0639,  ..., -0.1054, -0.0832, -0.2014]])\n",
            "   Last layer:\n",
            "tensor([[-0.0409, -0.0367, -0.0390,  0.0000,  0.0000,  0.0000,  0.0000, -0.0472,\n",
            "          0.0000,  0.0000, -0.0564, -0.0285,  0.0163,  0.0000, -0.0439,  0.0000,\n",
            "         -0.0343,  0.0000, -0.0551,  0.0000],\n",
            "        [-0.0489, -0.0502, -0.0468,  0.0000,  0.0000,  0.0000,  0.0000, -0.0581,\n",
            "          0.0000,  0.0000, -0.0633, -0.0392,  0.0121,  0.0000, -0.0528,  0.0000,\n",
            "         -0.0414,  0.0000, -0.0615,  0.0000],\n",
            "        [-0.1035, -0.1147, -0.0994,  0.0000,  0.0000,  0.0000,  0.0000, -0.1252,\n",
            "          0.0000,  0.0000, -0.1289, -0.0895,  0.0164,  0.0000, -0.1124,  0.0000,\n",
            "         -0.0882,  0.0000, -0.1246,  0.0000],\n",
            "        [ 0.0493,  0.0453,  0.0471,  0.0000,  0.0000,  0.0000,  0.0000,  0.0571,\n",
            "          0.0000,  0.0000,  0.0673,  0.0351, -0.0184,  0.0000,  0.0529,  0.0000,\n",
            "          0.0415,  0.0000,  0.0657,  0.0000],\n",
            "        [ 0.1006,  0.1065,  0.0967,  0.0000,  0.0000,  0.0000,  0.0000,  0.1206,\n",
            "          0.0000,  0.0000,  0.1288,  0.0830, -0.0217,  0.0000,  0.1089,  0.0000,\n",
            "          0.0854,  0.0000,  0.1248,  0.0000],\n",
            "        [ 0.1299,  0.1463,  0.1247,  0.0000,  0.0000,  0.0000,  0.0000,  0.1576,\n",
            "          0.0000,  0.0000,  0.1600,  0.1141, -0.0178,  0.0000,  0.1410,  0.0000,\n",
            "          0.1106,  0.0000,  0.1545,  0.0000],\n",
            "        [-0.0454, -0.0404, -0.0433,  0.0000,  0.0000,  0.0000,  0.0000, -0.0523,\n",
            "          0.0000,  0.0000, -0.0629, -0.0314,  0.0186,  0.0000, -0.0487,  0.0000,\n",
            "         -0.0381,  0.0000, -0.0615,  0.0000],\n",
            "        [-0.0317, -0.0296, -0.0303,  0.0000,  0.0000,  0.0000,  0.0000, -0.0368,\n",
            "          0.0000,  0.0000, -0.0430, -0.0230,  0.0113,  0.0000, -0.0340,  0.0000,\n",
            "         -0.0266,  0.0000, -0.0419,  0.0000],\n",
            "        [ 0.1141,  0.1272,  0.1094,  0.0000,  0.0000,  0.0000,  0.0000,  0.1382,\n",
            "          0.0000,  0.0000,  0.1415,  0.0992, -0.0170,  0.0000,  0.1236,  0.0000,\n",
            "          0.0970,  0.0000,  0.1366,  0.0000],\n",
            "        [ 0.2007,  0.2390,  0.1933,  0.0000,  0.0000,  0.0000,  0.0000,  0.2474,\n",
            "          0.0000,  0.0000,  0.2399,  0.1864, -0.0132,  0.0000,  0.2191,  0.0000,\n",
            "          0.1715,  0.0000,  0.2305,  0.0000]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-0.2719, -1.1219, -0.3111,  ...,  0.1758,  0.4456,  1.3405],\n",
            "        [ 0.0884,  0.3648,  0.1012,  ..., -0.0572, -0.1449, -0.4297],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [-0.0876, -0.3614, -0.1002,  ...,  0.0567,  0.1436,  0.4450],\n",
            "        [-0.1874, -0.7732, -0.2144,  ...,  0.1212,  0.3072,  0.9337],\n",
            "        [-0.1395, -0.5755, -0.1596,  ...,  0.0902,  0.2286,  0.6898]])\n",
            "   Last layer:\n",
            "tensor([[ 0.1979,  0.2989,  0.2280,  0.0000,  0.0000,  0.0000,  0.0000,  0.3122,\n",
            "          0.0000,  0.0000,  0.1575,  0.2247,  0.1648,  0.0000,  0.1865,  0.0000,\n",
            "          0.1463,  0.0000,  0.1661,  0.0000],\n",
            "        [ 0.1668,  0.2467,  0.1981,  0.0000,  0.0000,  0.0000,  0.0000,  0.2712,\n",
            "          0.0000,  0.0000,  0.1303,  0.1834,  0.1493,  0.0000,  0.1512,  0.0000,\n",
            "          0.1182,  0.0000,  0.1415,  0.0000],\n",
            "        [ 0.3150,  0.4698,  0.3701,  0.0000,  0.0000,  0.0000,  0.0000,  0.5060,\n",
            "          0.0000,  0.0000,  0.2479,  0.3503,  0.2744,  0.0000,  0.2901,  0.0000,\n",
            "          0.2269,  0.0000,  0.2657,  0.0000],\n",
            "        [-0.2229, -0.3362, -0.2580,  0.0000,  0.0000,  0.0000,  0.0000, -0.3533,\n",
            "          0.0000,  0.0000, -0.1769, -0.2522, -0.1877,  0.0000, -0.2090,  0.0000,\n",
            "         -0.1638,  0.0000, -0.1872,  0.0000],\n",
            "        [-0.3741, -0.5667, -0.4299,  0.0000,  0.0000,  0.0000,  0.0000, -0.5884,\n",
            "          0.0000,  0.0000, -0.2981, -0.4264, -0.3097,  0.0000, -0.3539,  0.0000,\n",
            "         -0.2774,  0.0000, -0.3135,  0.0000],\n",
            "        [-0.3810, -0.5680, -0.4471,  0.0000,  0.0000,  0.0000,  0.0000, -0.6120,\n",
            "          0.0000,  0.0000, -0.2996, -0.4236, -0.3318,  0.0000, -0.3505,  0.0000,\n",
            "         -0.2744,  0.0000, -0.3215,  0.0000],\n",
            "        [ 0.2015,  0.3024,  0.2348,  0.0000,  0.0000,  0.0000,  0.0000,  0.3212,\n",
            "          0.0000,  0.0000,  0.1593,  0.2263,  0.1722,  0.0000,  0.1875,  0.0000,\n",
            "          0.1466,  0.0000,  0.1696,  0.0000],\n",
            "        [ 0.1462,  0.2223,  0.1674,  0.0000,  0.0000,  0.0000,  0.0000,  0.2291,\n",
            "          0.0000,  0.0000,  0.1169,  0.1676,  0.1196,  0.0000,  0.1393,  0.0000,\n",
            "          0.1092,  0.0000,  0.1224,  0.0000],\n",
            "        [-0.3617, -0.5444, -0.4194,  0.0000,  0.0000,  0.0000,  0.0000, -0.5746,\n",
            "          0.0000,  0.0000, -0.2867, -0.4080, -0.3064,  0.0000, -0.3383,  0.0000,\n",
            "         -0.2649,  0.0000, -0.3040,  0.0000],\n",
            "        [-0.5832, -0.8819, -0.6726,  0.0000,  0.0000,  0.0000,  0.0000, -0.9203,\n",
            "          0.0000,  0.0000, -0.4643, -0.6631, -0.4857,  0.0000, -0.5505,  0.0000,\n",
            "         -0.4315,  0.0000, -0.4891,  0.0000]])\n",
            "DEBUGGING: training for one iteration takes 0.004759 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 14\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([2.9468e-18, 5.3271e-03, 1.8410e-03, 3.0201e-17, 1.5308e-09, 5.0330e-04,\n",
            "        4.4327e-11, 1.0820e-11, 9.3488e-10, 5.4269e-03, 8.9039e-03, 1.0217e-03,\n",
            "        1.1839e-10, 1.6670e-01, 3.9448e-07, 3.5840e-02, 3.0146e-03, 2.1180e-06,\n",
            "        5.5585e-06, 3.1934e-03, 1.4611e-01, 7.4032e-03, 1.0378e-03, 7.0071e-05,\n",
            "        1.3974e-05, 9.0000e-03, 2.1994e-02, 3.0956e-02, 6.3791e-06, 4.4671e-05,\n",
            "        5.4269e-03, 1.7396e-03, 1.0197e-03, 1.2727e-03, 1.4017e-04, 3.0917e-04,\n",
            "        4.1453e-02, 1.8619e-06, 4.1177e-01, 3.7397e-05, 7.9545e-06, 5.1513e-12,\n",
            "        4.2577e-06, 2.7701e-07, 1.0482e-08, 7.8872e-04, 2.3619e-02, 4.9357e-04,\n",
            "        4.2005e-05, 1.8054e-03, 4.6412e-04, 1.2868e-08, 3.9570e-06, 4.6009e-10,\n",
            "        2.0978e-05, 2.8861e-07, 1.4585e-06, 1.1402e-07, 9.7489e-04, 2.6397e-03,\n",
            "        6.3700e-09, 1.2312e-03, 2.0104e-02, 7.8400e-05, 1.2419e-04, 1.7309e-04,\n",
            "        3.5840e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [38]\n",
            "DEBUGGING: logits looks like: tensor([1191.0060, 1194.5190, 1194.4128, 1191.2386, 1193.0128, 1194.2831,\n",
            "        1192.6586, 1192.5176, 1192.9635, 1194.5209, 1194.5704, 1194.3539,\n",
            "        1192.7568, 1194.8634, 1193.5680, 1194.7097, 1194.4622, 1193.7361,\n",
            "        1193.8325, 1194.4679, 1194.8502, 1194.5520, 1194.3555, 1194.0859,\n",
            "        1193.9247, 1194.5715, 1194.6609, 1194.6951, 1193.8463, 1194.0409,\n",
            "        1194.5209, 1194.4071, 1194.3538, 1194.3759, 1194.1553, 1194.2344,\n",
            "        1194.7242, 1193.7231, 1194.9539, 1194.0232, 1193.8684, 1192.4434,\n",
            "        1193.8059, 1193.5326, 1193.2052, 1194.3280, 1194.6680, 1194.2811,\n",
            "        1194.0348, 1194.4109, 1194.2750, 1193.2257, 1193.7986, 1192.8926,\n",
            "        1193.9653, 1193.5367, 1193.6987, 1193.4438, 1194.3492, 1194.4489,\n",
            "        1193.1554, 1194.3726, 1194.6519, 1194.0972, 1194.1432, 1194.1764,\n",
            "        1194.7097], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([4.1074e-17, 4.9749e-09, 3.3974e-06, 1.1700e-10, 2.8553e-06, 2.5157e-04,\n",
            "        2.9700e-04, 2.1260e-06, 8.5771e-04, 1.0262e-05, 6.9626e-01, 6.4167e-05,\n",
            "        6.3234e-05, 1.5561e-03, 4.6770e-04, 1.1645e-09, 2.7361e-04, 4.2996e-05,\n",
            "        1.5466e-05, 1.5934e-08, 1.2863e-03, 4.8882e-09, 8.5078e-06, 4.8728e-04,\n",
            "        3.5994e-05, 2.0377e-09, 5.9385e-07, 4.5738e-03, 5.8009e-07, 2.7152e-03,\n",
            "        3.4217e-04, 2.0401e-01, 1.9900e-04, 3.1725e-07, 6.4554e-04, 7.2275e-06,\n",
            "        6.0940e-04, 1.1450e-04, 4.3758e-05, 4.1234e-04, 2.3648e-06, 1.3653e-03,\n",
            "        7.9624e-05, 5.3823e-05, 1.4517e-04, 1.6436e-03, 1.1448e-12, 2.6910e-04,\n",
            "        8.6081e-06, 2.9402e-06, 6.9925e-05, 1.7614e-04, 8.1054e-10, 9.7667e-04,\n",
            "        1.2635e-05, 3.7449e-21, 3.9660e-03, 9.6059e-04, 3.7790e-06, 7.0474e-05,\n",
            "        7.8531e-06, 1.5288e-04, 5.2909e-02, 5.8385e-03, 6.1288e-05, 1.2697e-05,\n",
            "        4.0391e-05, 1.4764e-02, 2.6775e-05, 3.0518e-05, 2.7068e-04, 8.9349e-05,\n",
            "        1.5835e-04, 7.1304e-05, 6.1635e-13, 9.1646e-05],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [10]\n",
            "DEBUGGING: logits looks like: tensor([1191.5269, 1193.3881, 1194.0408, 1193.0131, 1194.0233, 1194.4712,\n",
            "        1194.4878, 1193.9939, 1194.5939, 1194.1512, 1195.2638, 1194.3346,\n",
            "        1194.3331, 1194.6534, 1194.5332, 1193.2429, 1194.4796, 1194.2946,\n",
            "        1194.1923, 1193.5045, 1194.6344, 1193.3864, 1194.1326, 1194.5374,\n",
            "        1194.2767, 1193.2988, 1193.8663, 1194.7612, 1193.8640, 1194.7091,\n",
            "        1194.5020, 1195.1410, 1194.4478, 1193.8036, 1194.5654, 1194.1162,\n",
            "        1194.5597, 1194.3925, 1194.2963, 1194.5206, 1194.0045, 1194.6404,\n",
            "        1194.3562, 1194.3170, 1194.4163, 1194.6589, 1192.5504, 1194.4779,\n",
            "        1194.1337, 1194.0262, 1194.3431, 1194.4355, 1193.2067, 1194.6068,\n",
            "        1194.1721, 1190.5966, 1194.7469, 1194.6052, 1194.0514, 1194.3440,\n",
            "        1194.1245, 1194.4214, 1195.0061, 1194.7856, 1194.3300, 1194.1726,\n",
            "        1194.2883, 1194.8784, 1194.2472, 1194.2603, 1194.4785, 1194.3677,\n",
            "        1194.4249, 1194.3451, 1192.4885, 1194.3702], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.0072e-15, 1.0301e-02, 1.6671e-02, 1.3073e-02, 5.4388e-03, 7.6775e-03,\n",
            "        1.4569e-02, 2.3976e-08, 1.2832e-02, 1.4799e-02, 1.0433e-02, 7.5216e-03,\n",
            "        7.3906e-03, 7.8366e-03, 1.7798e-02, 1.3073e-02, 1.2658e-02, 1.3821e-02,\n",
            "        1.0753e-02, 1.2807e-02, 1.0753e-02, 1.8928e-02, 9.3334e-03, 9.2067e-03,\n",
            "        1.2149e-02, 1.1203e-02, 6.8019e-03, 1.5539e-02, 7.3978e-03, 1.1730e-02,\n",
            "        8.3583e-03, 1.3098e-02, 1.1845e-02, 1.0082e-02, 1.1961e-02, 1.5313e-02,\n",
            "        1.9396e-02, 1.2946e-02, 1.4442e-02, 1.0965e-02, 1.4093e-02, 1.4050e-03,\n",
            "        1.7268e-02, 1.5091e-02, 4.9764e-03, 1.4343e-02, 1.4066e-02, 8.6827e-03,\n",
            "        1.2807e-02, 3.2193e-03, 1.1525e-02, 1.0514e-02, 9.6485e-03, 1.2462e-02,\n",
            "        1.2413e-02, 1.1503e-02, 7.8201e-04, 1.5722e-02, 1.1559e-02, 7.8442e-03,\n",
            "        1.4944e-02, 1.1336e-02, 1.2197e-02, 6.7555e-03, 1.1856e-02, 1.2820e-02,\n",
            "        1.1458e-02, 1.1525e-02, 1.3149e-02, 9.1708e-03, 9.7623e-03, 1.0463e-02,\n",
            "        1.8616e-02, 1.1525e-02, 1.0053e-02, 9.6580e-03, 1.4784e-02, 7.1492e-03,\n",
            "        1.3409e-02, 1.4162e-02, 1.4973e-02, 1.5135e-02, 1.5418e-02, 1.5418e-02,\n",
            "        1.5923e-02, 9.9548e-03, 1.7557e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [66]\n",
            "DEBUGGING: logits looks like: tensor([1191.9308, 1194.9264, 1194.9745, 1194.9502, 1194.8625, 1194.8970,\n",
            "        1194.9611, 1193.6293, 1194.9484, 1194.9626, 1194.9276, 1194.8949,\n",
            "        1194.8932, 1194.8990, 1194.9811, 1194.9502, 1194.9470, 1194.9558,\n",
            "        1194.9307, 1194.9481, 1194.9307, 1194.9872, 1194.9165, 1194.9152,\n",
            "        1194.9429, 1194.9348, 1194.8849, 1194.9675, 1194.8933, 1194.9393,\n",
            "        1194.9055, 1194.9504, 1194.9403, 1194.9242, 1194.9413, 1194.9661,\n",
            "        1194.9896, 1194.9492, 1194.9602, 1194.9326, 1194.9578, 1194.7272,\n",
            "        1194.9780, 1194.9646, 1194.8536, 1194.9595, 1194.9575, 1194.9093,\n",
            "        1194.9481, 1194.8101, 1194.9376, 1194.9285, 1194.9198, 1194.9454,\n",
            "        1194.9451, 1194.9374, 1194.6686, 1194.9686, 1194.9379, 1194.8992,\n",
            "        1194.9636, 1194.9359, 1194.9432, 1194.8842, 1194.9404, 1194.9482,\n",
            "        1194.9370, 1194.9376, 1194.9508, 1194.9148, 1194.9210, 1194.9280,\n",
            "        1194.9856, 1194.9376, 1194.9240, 1194.9199, 1194.9625, 1194.8899,\n",
            "        1194.9528, 1194.9583, 1194.9637, 1194.9648, 1194.9667, 1194.9667,\n",
            "        1194.9700, 1194.9230, 1194.9797], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.0609e-15, 1.0005e-02, 9.7924e-03, 9.9466e-03, 9.5937e-03, 1.0383e-02,\n",
            "        1.0034e-02, 1.0455e-02, 1.1437e-02, 1.1282e-02, 1.0588e-02, 1.0630e-02,\n",
            "        1.1674e-02, 1.0946e-02, 1.0956e-02, 1.0292e-02, 1.0434e-02, 1.1064e-02,\n",
            "        1.0404e-02, 1.0903e-02, 9.3440e-03, 9.6500e-03, 1.1282e-02, 1.0924e-02,\n",
            "        1.1161e-02, 9.8404e-03, 1.0383e-02, 1.0839e-02, 1.0242e-02, 1.0093e-02,\n",
            "        1.0323e-02, 1.0537e-02, 1.0343e-02, 1.0924e-02, 1.0444e-02, 1.0133e-02,\n",
            "        1.1975e-02, 1.0084e-02, 1.0650e-02, 1.0202e-02, 1.0383e-02, 1.0588e-02,\n",
            "        1.0183e-02, 1.0818e-02, 1.0537e-02, 1.1282e-02, 1.1337e-02, 1.0640e-02,\n",
            "        1.0485e-02, 1.0485e-02, 1.0871e-02, 1.0455e-02, 1.0475e-02, 1.0282e-02,\n",
            "        1.0183e-02, 1.0485e-02, 1.1304e-02, 1.0537e-02, 1.0630e-02, 1.1161e-02,\n",
            "        1.0956e-02, 1.0383e-02, 1.0946e-02, 1.0343e-02, 1.0640e-02, 1.0871e-02,\n",
            "        1.0786e-02, 9.7543e-03, 1.0797e-02, 1.0924e-02, 1.0526e-02, 1.0373e-02,\n",
            "        1.0537e-02, 1.0839e-02, 1.0222e-02, 9.7067e-03, 1.0495e-02, 1.0630e-02,\n",
            "        9.3258e-03, 1.0383e-02, 1.1249e-02, 1.0292e-02, 1.1075e-02, 1.0661e-02,\n",
            "        9.9953e-03, 1.0765e-02, 9.6500e-03, 9.7924e-03, 1.0850e-02, 9.9272e-03,\n",
            "        1.0547e-02, 9.2442e-03, 1.0537e-02, 1.1493e-02, 1.0588e-02, 1.0578e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [34]\n",
            "DEBUGGING: logits looks like: tensor([1192.2100, 1195.1975, 1195.1953, 1195.1969, 1195.1932, 1195.2012,\n",
            "        1195.1978, 1195.2019, 1195.2108, 1195.2095, 1195.2031, 1195.2035,\n",
            "        1195.2129, 1195.2064, 1195.2065, 1195.2003, 1195.2017, 1195.2075,\n",
            "        1195.2014, 1195.2061, 1195.1907, 1195.1938, 1195.2095, 1195.2063,\n",
            "        1195.2084, 1195.1958, 1195.2012, 1195.2054, 1195.1998, 1195.1984,\n",
            "        1195.2006, 1195.2026, 1195.2008, 1195.2063, 1195.2018, 1195.1987,\n",
            "        1195.2155, 1195.1982, 1195.2037, 1195.1995, 1195.2012, 1195.2031,\n",
            "        1195.1992, 1195.2053, 1195.2026, 1195.2095, 1195.2100, 1195.2036,\n",
            "        1195.2021, 1195.2021, 1195.2058, 1195.2019, 1195.2020, 1195.2002,\n",
            "        1195.1992, 1195.2021, 1195.2097, 1195.2026, 1195.2035, 1195.2084,\n",
            "        1195.2065, 1195.2012, 1195.2064, 1195.2008, 1195.2036, 1195.2058,\n",
            "        1195.2050, 1195.1949, 1195.2051, 1195.2063, 1195.2025, 1195.2010,\n",
            "        1195.2026, 1195.2054, 1195.1996, 1195.1945, 1195.2023, 1195.2035,\n",
            "        1195.1904, 1195.2012, 1195.2092, 1195.2003, 1195.2076, 1195.2039,\n",
            "        1195.1974, 1195.2048, 1195.1938, 1195.1953, 1195.2056, 1195.1967,\n",
            "        1195.2028, 1195.1896, 1195.2026, 1195.2113, 1195.2031, 1195.2030],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.0781e-15, 9.6541e-03, 9.1940e-03, 9.2662e-03, 9.8253e-03, 9.8927e-03,\n",
            "        9.7775e-03, 9.9217e-03, 9.7870e-03, 1.0019e-02, 8.7047e-03, 9.0958e-03,\n",
            "        8.9986e-03, 9.5137e-03, 9.8445e-03, 9.3297e-03, 9.3754e-03, 9.0515e-03,\n",
            "        9.8831e-03, 9.6447e-03, 9.4952e-03, 9.7108e-03, 9.7870e-03, 9.4766e-03,\n",
            "        9.5603e-03, 7.4456e-03, 8.7133e-03, 9.3754e-03, 9.4121e-03, 9.2662e-03,\n",
            "        9.8061e-03, 9.5230e-03, 9.4489e-03, 9.6071e-03, 9.7775e-03, 9.1403e-03,\n",
            "        9.0427e-03, 9.8253e-03, 9.4489e-03, 9.3297e-03, 9.8253e-03, 9.6919e-03,\n",
            "        7.0013e-03, 9.5137e-03, 9.0515e-03, 7.8487e-03, 8.2094e-03, 8.7133e-03,\n",
            "        9.2843e-03, 8.8678e-03, 8.7388e-03, 9.6541e-03, 9.2843e-03, 8.9986e-03,\n",
            "        1.0167e-02, 9.9217e-03, 9.5883e-03, 9.4952e-03, 9.3115e-03, 7.9490e-03,\n",
            "        1.0237e-02, 8.7388e-03, 9.5416e-03, 8.6708e-03, 9.5977e-03, 9.7775e-03,\n",
            "        9.9703e-03, 9.5044e-03, 9.9217e-03, 8.9986e-03, 9.9800e-03, 9.1136e-03,\n",
            "        8.6202e-03, 1.0019e-02, 9.5416e-03, 9.1493e-03, 9.4213e-03, 9.0692e-03,\n",
            "        9.6824e-03, 9.6824e-03, 9.6165e-03, 9.5416e-03, 9.1493e-03, 1.0019e-02,\n",
            "        1.0019e-02, 9.5044e-03, 9.2662e-03, 9.5883e-03, 9.6919e-03, 9.7966e-03,\n",
            "        9.0515e-03, 9.9217e-03, 9.2662e-03, 9.0074e-03, 8.4287e-03, 9.6541e-03,\n",
            "        9.4121e-03, 8.8074e-03, 1.0098e-02, 9.9996e-03, 8.4287e-03, 9.2662e-03,\n",
            "        8.2254e-03, 8.2899e-03, 8.5364e-03, 9.4766e-03, 9.9024e-03, 9.7108e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [53]\n",
            "DEBUGGING: logits looks like: tensor([1192.4329, 1195.4152, 1195.4103, 1195.4110, 1195.4169, 1195.4176,\n",
            "        1195.4164, 1195.4178, 1195.4165, 1195.4188, 1195.4048, 1195.4092,\n",
            "        1195.4081, 1195.4137, 1195.4171, 1195.4117, 1195.4122, 1195.4087,\n",
            "        1195.4175, 1195.4150, 1195.4135, 1195.4158, 1195.4165, 1195.4133,\n",
            "        1195.4142, 1195.3892, 1195.4049, 1195.4122, 1195.4126, 1195.4110,\n",
            "        1195.4167, 1195.4138, 1195.4130, 1195.4147, 1195.4164, 1195.4097,\n",
            "        1195.4086, 1195.4169, 1195.4130, 1195.4117, 1195.4169, 1195.4155,\n",
            "        1195.3831, 1195.4137, 1195.4087, 1195.3944, 1195.3989, 1195.4049,\n",
            "        1195.4113, 1195.4066, 1195.4052, 1195.4152, 1195.4113, 1195.4081,\n",
            "        1195.4203, 1195.4178, 1195.4144, 1195.4135, 1195.4115, 1195.3958,\n",
            "        1195.4210, 1195.4052, 1195.4139, 1195.4044, 1195.4146, 1195.4164,\n",
            "        1195.4183, 1195.4136, 1195.4178, 1195.4081, 1195.4185, 1195.4094,\n",
            "        1195.4038, 1195.4188, 1195.4139, 1195.4098, 1195.4127, 1195.4089,\n",
            "        1195.4154, 1195.4154, 1195.4148, 1195.4139, 1195.4098, 1195.4188,\n",
            "        1195.4188, 1195.4136, 1195.4110, 1195.4144, 1195.4155, 1195.4166,\n",
            "        1195.4087, 1195.4178, 1195.4110, 1195.4082, 1195.4016, 1195.4152,\n",
            "        1195.4126, 1195.4060, 1195.4197, 1195.4187, 1195.4016, 1195.4110,\n",
            "        1195.3992, 1195.3999, 1195.4028, 1195.4133, 1195.4177, 1195.4158],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.2646999406242685 and immediate abs rewards look like: [0.01569241746415173, 0.0026544313013801, 0.10759943206858225, 0.06422925513811606, 0.008921904336830266, 0.01090458385169768, 0.010837916582886464, 0.0005811617738800123, 0.001546643277606563, 0.004742078745493927, 0.0056254372352668724, 0.0032330324331724114, 0.0006589275376427395, 0.0024684133707069122, 0.0005511153622137499, 0.0022499399801745312, 1.1798764262493933e-05, 0.001070131681899511, 0.003045542114705313, 0.0035659270731684956, 0.004494305870593962, 0.00042144724579884496, 0.002112523050072923, 0.0013110090560530807, 0.0003566557475096488, 0.0011621257644947036, 0.0003220343594421138, 0.0002752701143435843, 0.001051214441531556, 2.06232427899522e-05, 0.0005992905539642379, 0.000670766464281769, 0.00012989605693292106, 0.00017603447849978693, 0.00018785578981805884, 0.00029534653799601074, 0.00021939486487099202, 6.736469049428706e-05, 4.917452065456018e-05, 6.762511202396126e-05, 9.889501257021038e-05, 1.571102075104136e-07, 0.00014632461716246326, 2.549136706875288e-05, 1.2995200904697413e-05, 6.0978370584052755e-06, 0.00014013819395586324, 5.245938245934667e-05, 1.4259021327234223e-05, 2.307482554897433e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 45.59926379682546 and immediate relative rewards look like: [0.4350246587545607, 0.14781513930648982, 8.994349521901603, 7.379912903236773, 1.3054895577838286, 1.9197363984821008, 2.2331447567515106, 0.13729280034314661, 0.41111937237616436, 1.4012075417248226, 1.8310138812925578, 1.1498931485198436, 0.2541344543757165, 1.025447361894709, 0.2454818815127891, 1.069172212163038, 0.0059611836209322085, 0.5724773438076691, 1.7203029481439864, 2.1221817439958475, 2.811403056868852, 0.2765597028296728, 1.449462184839943, 0.9392221142832602, 0.2662628664916218, 0.9023896429375373, 0.2597672267235039, 0.23029115748087806, 0.9109304199479679, 0.018493134893747033, 0.555308257590489, 0.6417030862408457, 0.1281769150821417, 0.17897543681755557, 0.1966220713471876, 0.3179789869680329, 0.2427898799510565, 0.07656791343588672, 0.057364655517865126, 0.08091220276671486, 0.12128666863431409, 0.0001973882792039796, 0.1882147004420618, 0.03355308845885779, 0.01749385498895617, 0.008391224602565372, 0.19703658196081902, 0.07533123880731395, 0.020902744526140646, 0.03451658312237502]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([1.1431e-12, 1.8601e-02, 1.5069e-06, 3.9263e-02, 1.4772e-02, 1.8381e-03,\n",
            "        6.0633e-02, 1.4246e-03, 8.5706e-06, 5.0554e-03, 4.5532e-04, 1.2662e-01,\n",
            "        1.8414e-04, 1.9436e-02, 2.9459e-03, 2.5026e-03, 1.8492e-02, 1.7050e-03,\n",
            "        4.1267e-02, 3.3349e-03, 4.6527e-03, 1.0944e-03, 2.8390e-02, 1.5251e-04,\n",
            "        1.3970e-03, 1.1504e-02, 3.5362e-03, 2.4494e-03, 1.3321e-01, 1.1064e-02,\n",
            "        4.0860e-03, 9.6594e-03, 4.5235e-02, 2.7616e-04, 1.2021e-02, 9.5082e-04,\n",
            "        1.1616e-03, 6.1699e-03, 8.6391e-05, 3.7318e-02, 1.1627e-03, 4.1660e-04,\n",
            "        1.4246e-03, 2.6182e-08, 7.5817e-03, 2.4787e-02, 4.6113e-04, 1.7976e-02,\n",
            "        2.4233e-03, 3.7722e-02, 1.4295e-06, 1.4557e-02, 3.9986e-04, 6.6954e-05,\n",
            "        6.9381e-02, 3.1574e-03, 5.0661e-02, 3.6271e-03, 1.5859e-04, 2.8110e-03,\n",
            "        2.5624e-02, 4.5045e-04, 4.4217e-04, 6.4723e-03, 1.0547e-02, 3.9224e-02,\n",
            "        5.5091e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [34]\n",
            "DEBUGGING: logits looks like: tensor([1191.2963, 1193.6476, 1192.7054, 1193.7223, 1193.6245, 1193.4161,\n",
            "        1193.7657, 1193.3906, 1192.8793, 1193.5173, 1193.2766, 1193.8394,\n",
            "        1193.1860, 1193.6520, 1193.4633, 1193.4470, 1193.6470, 1193.4086,\n",
            "        1193.7273, 1193.4757, 1193.5090, 1193.3643, 1193.6898, 1193.1672,\n",
            "        1193.3887, 1193.5995, 1193.4816, 1193.4448, 1193.8445, 1193.5956,\n",
            "        1193.4960, 1193.5820, 1193.7365, 1193.2266, 1193.6039, 1193.3502,\n",
            "        1193.3702, 1193.5372, 1193.1104, 1193.7172, 1193.3704, 1193.2677,\n",
            "        1193.3906, 1192.3002, 1193.5579, 1193.6763, 1193.2778, 1193.6442,\n",
            "        1193.4437, 1193.7183, 1192.7002, 1193.6230, 1193.2635, 1193.0848,\n",
            "        1193.7792, 1193.4702, 1193.7478, 1193.4841, 1193.1711, 1193.4586,\n",
            "        1193.6796, 1193.2755, 1193.2737, 1193.5420, 1193.5908, 1193.7222,\n",
            "        1193.5259], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.1993e-12, 2.6487e-03, 5.7636e-02, 3.0402e-02, 7.2000e-03, 5.5591e-02,\n",
            "        1.4540e-04, 1.2270e-03, 1.7713e-03, 1.7475e-02, 2.0608e-03, 1.1394e-02,\n",
            "        5.1063e-02, 1.2304e-04, 3.3685e-02, 2.9053e-05, 3.5543e-02, 5.0068e-03,\n",
            "        8.0165e-03, 7.4068e-03, 1.4714e-03, 1.6273e-02, 1.9552e-02, 4.2244e-03,\n",
            "        1.0568e-02, 3.8127e-03, 5.0856e-03, 4.1070e-02, 9.3083e-03, 1.1744e-02,\n",
            "        6.4603e-03, 1.7887e-03, 1.1099e-01, 1.0114e-02, 4.7962e-03, 8.5991e-04,\n",
            "        1.3672e-04, 3.4429e-06, 8.6256e-03, 1.3278e-04, 3.5852e-03, 2.5672e-03,\n",
            "        5.9582e-02, 5.8281e-06, 1.2009e-03, 4.4265e-04, 7.1300e-03, 3.0820e-02,\n",
            "        5.4067e-05, 6.5675e-04, 5.5312e-03, 3.0097e-04, 5.4454e-03, 6.8837e-03,\n",
            "        2.3673e-03, 6.6006e-03, 1.9435e-03, 3.6708e-02, 3.7646e-03, 2.5953e-02,\n",
            "        2.7623e-03, 9.8220e-03, 2.6277e-04, 5.8062e-05, 9.3539e-03, 3.0402e-02,\n",
            "        4.5855e-03, 7.7926e-03, 9.6981e-03, 1.1573e-02, 3.7505e-02, 2.3038e-02,\n",
            "        7.7395e-03, 1.5257e-02, 1.0517e-02, 9.9281e-03, 7.0814e-03, 3.8689e-03,\n",
            "        1.7696e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [32]\n",
            "DEBUGGING: logits looks like: tensor([1191.7301, 1193.8210, 1194.1290, 1194.0651, 1193.9210, 1194.1254,\n",
            "        1193.5308, 1193.7440, 1193.7808, 1194.0096, 1193.7959, 1193.9669,\n",
            "        1194.1169, 1193.5140, 1194.0753, 1193.3698, 1194.0807, 1193.8846,\n",
            "        1193.9318, 1193.9238, 1193.7622, 1194.0026, 1194.0209, 1193.8677,\n",
            "        1193.9594, 1193.8574, 1193.8862, 1194.0951, 1193.9467, 1193.9700,\n",
            "        1193.9102, 1193.7817, 1194.1946, 1193.9550, 1193.8804, 1193.7085,\n",
            "        1193.5247, 1193.1565, 1193.9391, 1193.5217, 1193.8513, 1193.8179,\n",
            "        1194.1323, 1193.2091, 1193.7419, 1193.6421, 1193.9200, 1194.0664,\n",
            "        1193.4319, 1193.6815, 1193.8947, 1193.6035, 1193.8931, 1193.9165,\n",
            "        1193.8098, 1193.9124, 1193.7900, 1194.0839, 1193.8562, 1194.0492,\n",
            "        1193.8252, 1193.9520, 1193.5900, 1193.4390, 1193.9471, 1194.0651,\n",
            "        1193.8759, 1193.9290, 1193.9508, 1193.9685, 1194.0861, 1194.0374,\n",
            "        1193.9282, 1193.9961, 1193.9589, 1193.9531, 1193.9193, 1193.8589,\n",
            "        1193.7806], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([3.6926e-11, 6.8198e-03, 1.2716e-02, 1.5626e-02, 1.1455e-02, 1.8430e-02,\n",
            "        1.0288e-02, 7.9654e-03, 5.9717e-03, 9.7024e-03, 1.9143e-03, 1.1499e-02,\n",
            "        1.3817e-02, 1.0379e-02, 9.6457e-03, 2.2015e-02, 1.3844e-02, 1.2434e-02,\n",
            "        9.0525e-03, 8.9733e-03, 1.2325e-02, 1.4255e-02, 6.5843e-03, 6.0126e-03,\n",
            "        1.2016e-02, 3.3563e-03, 1.5429e-02, 9.7881e-03, 7.5932e-03, 1.0268e-02,\n",
            "        9.2130e-03, 1.2729e-02, 1.7212e-02, 1.2904e-02, 2.9910e-03, 1.2967e-02,\n",
            "        1.1911e-02, 7.3812e-03, 1.0328e-02, 1.0687e-02, 7.7506e-03, 9.0791e-03,\n",
            "        4.7703e-03, 6.5843e-03, 9.1682e-03, 1.4794e-02, 1.8996e-02, 1.4409e-02,\n",
            "        1.2654e-02, 1.9409e-02, 7.3812e-03, 3.9316e-03, 1.3208e-03, 1.8647e-02,\n",
            "        8.0436e-03, 1.6472e-02, 7.4101e-03, 7.2385e-03, 1.2446e-02, 2.1296e-02,\n",
            "        1.9542e-02, 1.4594e-02, 9.9131e-03, 7.4828e-03, 1.0238e-02, 1.0238e-02,\n",
            "        1.6748e-02, 1.6683e-02, 1.0941e-02, 1.3418e-02, 1.1200e-02, 1.2446e-02,\n",
            "        1.5502e-03, 8.2343e-03, 1.6521e-02, 1.2181e-02, 1.6748e-02, 1.5764e-02,\n",
            "        1.1477e-02, 7.2243e-03, 9.8938e-03, 1.7759e-02, 1.7179e-02, 1.3120e-02,\n",
            "        1.0328e-02, 6.4822e-03, 1.0218e-02, 1.2028e-02, 1.5339e-02, 4.2098e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [67]\n",
            "DEBUGGING: logits looks like: tensor([1192.2769, 1194.1803, 1194.2426, 1194.2632, 1194.2322, 1194.2797,\n",
            "        1194.2214, 1194.1958, 1194.1670, 1194.2156, 1194.0532, 1194.2325,\n",
            "        1194.2509, 1194.2223, 1194.2150, 1194.2975, 1194.2511, 1194.2404,\n",
            "        1194.2086, 1194.2078, 1194.2395, 1194.2540, 1194.1768, 1194.1677,\n",
            "        1194.2369, 1194.1094, 1194.2620, 1194.2164, 1194.1910, 1194.2212,\n",
            "        1194.2103, 1194.2427, 1194.2728, 1194.2440, 1194.0979, 1194.2445,\n",
            "        1194.2361, 1194.1882, 1194.2218, 1194.2252, 1194.1931, 1194.2089,\n",
            "        1194.1445, 1194.1768, 1194.2098, 1194.2577, 1194.2827, 1194.2551,\n",
            "        1194.2421, 1194.2849, 1194.1882, 1194.1252, 1194.0161, 1194.2809,\n",
            "        1194.1968, 1194.2684, 1194.1886, 1194.1863, 1194.2405, 1194.2942,\n",
            "        1194.2855, 1194.2563, 1194.2177, 1194.1896, 1194.2209, 1194.2209,\n",
            "        1194.2701, 1194.2698, 1194.2275, 1194.2479, 1194.2299, 1194.2405,\n",
            "        1194.0321, 1194.1991, 1194.2688, 1194.2383, 1194.2701, 1194.2640,\n",
            "        1194.2323, 1194.1860, 1194.2175, 1194.2760, 1194.2727, 1194.2457,\n",
            "        1194.2218, 1194.1752, 1194.2207, 1194.2371, 1194.2614, 1194.1321],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.4066e-10, 1.1217e-02, 7.9697e-03, 1.5272e-02, 9.1194e-03, 1.4431e-02,\n",
            "        1.5272e-02, 9.4365e-03, 7.6718e-03, 9.9670e-03, 1.2188e-02, 1.0303e-02,\n",
            "        6.7770e-03, 1.5422e-02, 1.4573e-02, 7.8922e-03, 1.3347e-02, 9.1641e-03,\n",
            "        3.6954e-03, 9.1820e-03, 9.8316e-03, 1.4263e-02, 7.8614e-03, 1.1562e-02,\n",
            "        1.0273e-02, 1.2081e-02, 4.2993e-03, 1.2404e-02, 5.9399e-03, 5.9632e-03,\n",
            "        2.8417e-03, 7.2211e-03, 1.0134e-02, 1.5803e-02, 1.1721e-02, 1.4111e-02,\n",
            "        9.2359e-03, 9.5384e-03, 1.2117e-02, 7.4068e-03, 1.3191e-02, 4.4315e-03,\n",
            "        4.4401e-03, 1.3178e-02, 1.3987e-02, 1.2624e-02, 9.5758e-03, 1.0415e-02,\n",
            "        9.1194e-03, 1.4616e-02, 1.2961e-02, 1.2711e-02, 7.7019e-03, 9.1194e-03,\n",
            "        1.1506e-02, 1.0735e-02, 1.5109e-02, 1.3757e-02, 7.2282e-03, 1.4235e-02,\n",
            "        8.5335e-03, 4.6623e-03, 1.8296e-02, 1.5392e-02, 1.5153e-02, 1.6954e-02,\n",
            "        4.4185e-03, 1.1206e-02, 1.1653e-02, 1.1755e-02, 6.6850e-03, 1.3127e-02,\n",
            "        5.5529e-03, 1.1065e-02, 1.2081e-02, 1.4431e-02, 1.2224e-02, 1.3101e-02,\n",
            "        1.1607e-02, 1.0314e-02, 1.6194e-02, 9.1373e-03, 5.3446e-04, 8.9868e-03,\n",
            "        1.0055e-02, 1.2798e-02, 1.4759e-02, 8.6594e-03, 1.5850e-02, 3.6774e-03,\n",
            "        9.6320e-03, 5.0019e-03, 5.7124e-03, 5.2625e-03, 9.4181e-03, 9.1820e-03,\n",
            "        8.7786e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [49]\n",
            "DEBUGGING: logits looks like: tensor([1192.5142, 1194.3336, 1194.2994, 1194.3645, 1194.3129, 1194.3588,\n",
            "        1194.3645, 1194.3163, 1194.2957, 1194.3218, 1194.3419, 1194.3251,\n",
            "        1194.2832, 1194.3655, 1194.3597, 1194.2985, 1194.3510, 1194.3134,\n",
            "        1194.2225, 1194.3136, 1194.3204, 1194.3577, 1194.2981, 1194.3367,\n",
            "        1194.3248, 1194.3411, 1194.2377, 1194.3436, 1194.2700, 1194.2704,\n",
            "        1194.1963, 1194.2896, 1194.3235, 1194.3679, 1194.3380, 1194.3566,\n",
            "        1194.3142, 1194.3174, 1194.3413, 1194.2921, 1194.3499, 1194.2407,\n",
            "        1194.2410, 1194.3497, 1194.3557, 1194.3455, 1194.3177, 1194.3262,\n",
            "        1194.3129, 1194.3601, 1194.3480, 1194.3461, 1194.2960, 1194.3129,\n",
            "        1194.3362, 1194.3292, 1194.3634, 1194.3540, 1194.2897, 1194.3574,\n",
            "        1194.3063, 1194.2458, 1194.3826, 1194.3652, 1194.3636, 1194.3749,\n",
            "        1194.2405, 1194.3335, 1194.3374, 1194.3383, 1194.2819, 1194.3494,\n",
            "        1194.2633, 1194.3323, 1194.3411, 1194.3588, 1194.3422, 1194.3491,\n",
            "        1194.3370, 1194.3252, 1194.3704, 1194.3131, 1194.0292, 1194.3114,\n",
            "        1194.3226, 1194.3468, 1194.3611, 1194.3077, 1194.3682, 1194.2220,\n",
            "        1194.3184, 1194.2528, 1194.2661, 1194.2579, 1194.3162, 1194.3136,\n",
            "        1194.3091], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.1440e-10, 8.9307e-03, 9.5345e-03, 9.8180e-03, 9.3410e-03, 9.4881e-03,\n",
            "        8.6728e-03, 8.6306e-03, 9.5719e-03, 8.3487e-03, 8.8872e-03, 9.5252e-03,\n",
            "        9.1962e-03, 9.7226e-03, 8.3978e-03, 9.4235e-03, 9.5345e-03, 9.3776e-03,\n",
            "        9.4235e-03, 9.2322e-03, 9.6564e-03, 7.9820e-03, 8.5551e-03, 9.6564e-03,\n",
            "        8.7068e-03, 9.6752e-03, 9.5252e-03, 8.4802e-03, 9.7702e-03, 8.8872e-03,\n",
            "        8.4636e-03, 9.2142e-03, 1.0249e-02, 9.7893e-03, 8.5885e-03, 8.4389e-03,\n",
            "        8.3569e-03, 8.2676e-03, 8.6728e-03, 9.1693e-03, 8.8958e-03, 8.1952e-03,\n",
            "        9.7606e-03, 9.8180e-03, 9.3776e-03, 9.5066e-03, 1.0041e-02, 9.7702e-03,\n",
            "        8.4554e-03, 9.5066e-03, 8.4802e-03, 9.2593e-03, 8.9656e-03, 9.7226e-03,\n",
            "        8.8180e-03, 9.8084e-03, 9.5625e-03, 8.1872e-03, 9.2322e-03, 9.1068e-03,\n",
            "        9.0183e-03, 9.7226e-03, 9.2593e-03, 9.4881e-03, 8.8612e-03, 8.7153e-03,\n",
            "        1.0080e-02, 1.3315e-02, 9.4419e-03, 9.8468e-03, 9.1514e-03, 9.0359e-03,\n",
            "        8.6474e-03, 9.0183e-03, 9.2955e-03, 9.5625e-03, 9.0624e-03, 9.7226e-03,\n",
            "        9.3046e-03, 7.8352e-03, 9.2593e-03, 9.1693e-03, 9.3410e-03, 9.1514e-03,\n",
            "        9.7416e-03, 8.7238e-03, 9.4235e-03, 8.0603e-03, 9.7893e-03, 8.7153e-03,\n",
            "        9.4788e-03, 9.1872e-03, 1.0431e-02, 8.7068e-03, 9.1693e-03, 8.8180e-03,\n",
            "        1.0031e-02, 9.6564e-03, 9.7511e-03, 8.0289e-03, 9.5812e-03, 9.1246e-03,\n",
            "        9.6752e-03, 5.7943e-03, 8.8008e-03, 8.0132e-03, 1.0647e-02, 6.9961e-03,\n",
            "        9.4235e-03, 9.2955e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [98]\n",
            "DEBUGGING: logits looks like: tensor([1192.6976, 1194.4521, 1194.4587, 1194.4617, 1194.4567, 1194.4583,\n",
            "        1194.4492, 1194.4487, 1194.4591, 1194.4454, 1194.4517, 1194.4586,\n",
            "        1194.4551, 1194.4607, 1194.4460, 1194.4575, 1194.4587, 1194.4570,\n",
            "        1194.4575, 1194.4554, 1194.4600, 1194.4409, 1194.4479, 1194.4600,\n",
            "        1194.4496, 1194.4602, 1194.4586, 1194.4470, 1194.4612, 1194.4517,\n",
            "        1194.4468, 1194.4553, 1194.4659, 1194.4613, 1194.4482, 1194.4465,\n",
            "        1194.4456, 1194.4445, 1194.4492, 1194.4548, 1194.4518, 1194.4436,\n",
            "        1194.4611, 1194.4617, 1194.4570, 1194.4584, 1194.4639, 1194.4612,\n",
            "        1194.4467, 1194.4584, 1194.4470, 1194.4558, 1194.4525, 1194.4607,\n",
            "        1194.4509, 1194.4615, 1194.4590, 1194.4435, 1194.4554, 1194.4541,\n",
            "        1194.4531, 1194.4607, 1194.4558, 1194.4583, 1194.4514, 1194.4497,\n",
            "        1194.4642, 1194.4921, 1194.4578, 1194.4619, 1194.4546, 1194.4534,\n",
            "        1194.4490, 1194.4531, 1194.4562, 1194.4590, 1194.4536, 1194.4607,\n",
            "        1194.4563, 1194.4391, 1194.4558, 1194.4548, 1194.4567, 1194.4546,\n",
            "        1194.4608, 1194.4498, 1194.4575, 1194.4419, 1194.4613, 1194.4497,\n",
            "        1194.4581, 1194.4550, 1194.4677, 1194.4496, 1194.4548, 1194.4509,\n",
            "        1194.4637, 1194.4600, 1194.4609, 1194.4415, 1194.4592, 1194.4543,\n",
            "        1194.4602, 1194.4089, 1194.4507, 1194.4413, 1194.4697, 1194.4277,\n",
            "        1194.4575, 1194.4562], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.13816392865328453 and immediate abs rewards look like: [0.023139232434004953, 0.025094216445268103, 0.032070419584215415, 0.02996658244228456, 0.0018364752472734835, 0.00214366861837334, 0.0013431441120701493, 6.872772883070866e-05, 0.00012940877604705747, 0.000782693540713808, 0.0017417306162315072, 0.0005959957607046817, 5.750979426011327e-05, 7.86981745477533e-05, 0.00027138387031300226, 0.00013325721738510765, 0.0001312297758886416, 5.587953455687966e-05, 0.0008612548981545842, 0.000925992809698073, 0.0008310556054311746, 9.837911238719244e-05, 0.0012475638363866892, 0.0008615849196758063, 0.0012027594357277849, 0.00013083842713967897, 0.002126078310993762, 0.0014061526348996267, 7.538568979725824e-05, 1.6107991086755646e-05, 0.001360685550935159, 0.0009795694363674556, 0.0001750676838128129, 0.0010934234474007098, 0.0007448876990565623, 1.696718982202583e-05, 8.41926844259433e-05, 0.0011483139114716323, 0.00037753989272459876, 0.0004140593450756569, 0.0015806223773324746, 0.00012019799214613158, 6.880204227854847e-05, 0.0002508773059162195, 9.682266863819677e-07, 7.285017318281461e-05, 7.357888989645289e-06, 0.0001422903537786624, 2.966378815472126e-06, 9.888172871796996e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 25.684346511953073 and immediate relative rewards look like: [0.623990746066064, 1.3619190145231326, 2.628700026406572, 3.3039581975418413, 0.25520815263556007, 0.3576597664220433, 0.2616018437400136, 0.015303982518017364, 0.032418806978581426, 0.21787037618067828, 0.5334266814274554, 0.19922146772735244, 0.020829027412938753, 0.030696119592594252, 0.11341633183476454, 0.0594078544318116, 0.06216280153883928, 0.028027892066869144, 0.45599199593784934, 0.5161949662608374, 0.486561383548223, 0.06035516985273969, 0.8001868750678363, 0.5768478277963687, 0.8390254007955101, 0.09495345426305281, 1.6023632943055515, 1.0996798804379604, 0.06108481930627842, 0.013502623738246932, 1.1786285371898508, 0.8762092650436717, 0.16153308790029458, 1.0395134862595612, 0.7292131241611721, 0.017088287497656722, 0.08714937266218434, 1.220794703770432, 0.412064701553304, 0.46356050726891407, 1.8140370940135777, 0.1413750850869257, 0.08285348492830005, 0.30914584707391257, 0.001220307948554913, 0.09385737760128443, 0.00968589922138523, 0.1912962464019627, 0.004071268558812648, 0.13848204745573076]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([1.9582e-05, 3.2751e-07, 8.0720e-09, 6.6030e-07, 3.2751e-07, 3.1470e-06,\n",
            "        3.7864e-10, 2.4291e-07, 2.0013e-16, 7.7943e-08, 1.0860e-09, 5.1012e-02,\n",
            "        4.4604e-05, 2.6108e-08, 1.1134e-06, 4.6777e-07, 9.3482e-07, 3.0206e-06,\n",
            "        2.6379e-04, 8.5212e-06, 7.3562e-03, 1.8148e-04, 6.7080e-06, 5.7471e-08,\n",
            "        3.4099e-05, 6.3049e-09, 1.1306e-08, 2.1887e-05, 1.0404e-09, 2.9742e-05,\n",
            "        1.9691e-07, 7.2896e-05, 7.5210e-05, 8.1616e-07, 6.7738e-06, 1.2836e-08,\n",
            "        1.5478e-17, 4.4257e-05, 4.8127e-06, 1.6429e-10, 1.2410e-05, 7.1616e-06,\n",
            "        4.8940e-05, 9.1454e-10, 3.6328e-06, 3.9833e-04, 9.1419e-06, 1.3931e-09,\n",
            "        5.0437e-06, 4.9517e-05, 2.2185e-06, 1.0540e-07, 1.9491e-10, 9.4399e-07,\n",
            "        8.6905e-05, 1.6510e-03, 5.8394e-06, 5.4103e-07, 4.6277e-07, 7.1599e-01,\n",
            "        1.4690e-07, 3.6471e-06, 1.3346e-02, 2.5337e-06, 8.0720e-09, 2.0918e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [59]\n",
            "DEBUGGING: logits looks like: tensor([1191.2799, 1190.8708, 1190.5005, 1190.9409, 1190.8708, 1191.0970,\n",
            "        1190.1946, 1190.8409, 1188.7493, 1190.7273, 1190.2999, 1192.0664,\n",
            "        1191.3622, 1190.6179, 1190.9932, 1190.9065, 1190.9757, 1191.0930,\n",
            "        1191.5399, 1191.1967, 1191.8728, 1191.5026, 1191.1727, 1190.6968,\n",
            "        1191.3353, 1190.4758, 1190.5342, 1191.2910, 1190.2957, 1191.3217,\n",
            "        1190.8199, 1191.4114, 1191.4144, 1190.9622, 1191.1737, 1190.5469,\n",
            "        1188.4933, 1191.3615, 1191.1395, 1190.1111, 1191.2343, 1191.1793,\n",
            "        1191.3715, 1190.2827, 1191.1115, 1191.5812, 1191.2037, 1190.3248,\n",
            "        1191.1443, 1191.3727, 1191.0621, 1190.7574, 1190.1282, 1190.9767,\n",
            "        1191.4290, 1191.7234, 1191.1589, 1190.9210, 1190.9054, 1192.3306,\n",
            "        1190.7906, 1191.1118, 1191.9324, 1191.0754, 1190.5005, 1192.2075],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.9589e-07, 6.6459e-03, 2.3310e-02, 4.1677e-02, 1.8822e-02, 7.2211e-03,\n",
            "        1.7977e-02, 3.0309e-03, 1.0075e-02, 1.3690e-02, 1.5943e-02, 1.8657e-02,\n",
            "        2.3793e-02, 1.7087e-02, 1.0851e-02, 1.6905e-02, 6.0041e-03, 5.6837e-04,\n",
            "        3.0876e-03, 2.9095e-02, 1.3851e-02, 2.1141e-02, 1.3321e-02, 1.3919e-02,\n",
            "        1.4613e-03, 8.1666e-03, 1.4445e-02, 2.3793e-02, 1.2117e-02, 1.2673e-02,\n",
            "        8.5753e-03, 1.4745e-02, 1.0303e-02, 7.0884e-03, 7.5161e-03, 1.7340e-02,\n",
            "        9.3175e-03, 1.0893e-02, 6.1465e-03, 1.0517e-02, 1.1725e-06, 1.3851e-02,\n",
            "        3.1214e-02, 1.1941e-02, 1.8261e-02, 1.9025e-02, 6.4289e-03, 6.3602e-03,\n",
            "        1.1011e-02, 1.1206e-02, 1.9007e-02, 1.6353e-02, 1.2686e-02, 1.2550e-02,\n",
            "        1.8083e-02, 6.8904e-03, 1.7424e-02, 1.1119e-02, 1.0273e-02, 7.5015e-03,\n",
            "        8.4000e-04, 3.6882e-03, 1.8261e-02, 1.8332e-02, 1.5452e-02, 2.9520e-03,\n",
            "        1.4015e-02, 1.9629e-02, 1.1664e-02, 1.5711e-02, 1.0154e-02, 6.3354e-03,\n",
            "        6.4540e-03, 1.3784e-02, 1.6225e-02, 6.1165e-03, 5.4989e-03, 1.4361e-02,\n",
            "        1.0579e-02, 6.9921e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [20]\n",
            "DEBUGGING: logits looks like: tensor([1190.7520, 1191.7539, 1191.8794, 1191.9375, 1191.8580, 1191.7622,\n",
            "        1191.8534, 1191.6754, 1191.7955, 1191.8262, 1191.8414, 1191.8572,\n",
            "        1191.8815, 1191.8484, 1191.8030, 1191.8473, 1191.7438, 1191.5081,\n",
            "        1191.6772, 1191.9016, 1191.8274, 1191.8696, 1191.8235, 1191.8279,\n",
            "        1191.6024, 1191.7745, 1191.8315, 1191.8815, 1191.8140, 1191.8185,\n",
            "        1191.7794, 1191.8336, 1191.7977, 1191.7604, 1191.7662, 1191.8499,\n",
            "        1191.7877, 1191.8033, 1191.7461, 1191.7998, 1190.8896, 1191.8274,\n",
            "        1191.9086, 1191.8125, 1191.8550, 1191.8591, 1191.7506, 1191.7495,\n",
            "        1191.8044, 1191.8062, 1191.8590, 1191.8440, 1191.8186, 1191.8175,\n",
            "        1191.8540, 1191.7576, 1191.8503, 1191.8054, 1191.7975, 1191.7660,\n",
            "        1191.5471, 1191.6951, 1191.8550, 1191.8553, 1191.8383, 1191.6727,\n",
            "        1191.8285, 1191.8622, 1191.8102, 1191.8400, 1191.7963, 1191.7491,\n",
            "        1191.7510, 1191.8269, 1191.8431, 1191.7456, 1191.7350, 1191.8309,\n",
            "        1191.8004, 1191.7590], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([8.5060e-07, 2.0081e-02, 1.6326e-02, 1.3131e-02, 1.2690e-02, 8.7470e-03,\n",
            "        1.0167e-02, 1.7395e-02, 1.4549e-02, 9.9894e-03, 2.1293e-02, 4.1601e-03,\n",
            "        1.2420e-02, 7.0559e-03, 1.0696e-02, 1.2180e-02, 1.0377e-02, 1.1003e-02,\n",
            "        1.3325e-02, 7.8254e-03, 1.0489e-02, 1.0572e-02, 1.2978e-02, 5.4791e-03,\n",
            "        6.6869e-03, 9.2387e-03, 3.9349e-03, 1.2665e-02, 1.2764e-02, 1.1667e-02,\n",
            "        1.1220e-02, 5.2078e-03, 1.2251e-02, 1.0707e-02, 1.2432e-02, 1.2978e-02,\n",
            "        9.2387e-03, 2.2978e-02, 3.9491e-05, 9.5879e-03, 6.4559e-03, 5.9012e-03,\n",
            "        9.0423e-03, 1.8141e-02, 8.9807e-03, 7.3084e-03, 1.4691e-02, 2.0577e-02,\n",
            "        1.3131e-02, 9.6161e-03, 7.1600e-03, 1.2603e-02, 1.6025e-02, 1.2251e-02,\n",
            "        1.0038e-02, 9.8441e-03, 1.1220e-02, 8.8070e-03, 1.2505e-02, 1.8920e-02,\n",
            "        1.3429e-02, 8.0189e-03, 1.4735e-02, 1.6278e-02, 1.2864e-02, 1.0038e-02,\n",
            "        9.3841e-03, 1.4337e-02, 1.0337e-02, 1.5025e-02, 1.0654e-02, 1.0087e-02,\n",
            "        6.4939e-03, 1.3067e-02, 1.1724e-02, 1.0276e-02, 9.1847e-03, 9.9020e-03,\n",
            "        1.2263e-02, 1.2097e-02, 8.8501e-03, 1.0236e-02, 1.0603e-02, 9.8441e-03,\n",
            "        1.3828e-02, 1.0603e-02, 9.3202e-03, 1.6827e-02, 9.9504e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [32]\n",
            "DEBUGGING: logits looks like: tensor([1191.0864, 1192.0934, 1192.0726, 1192.0509, 1192.0475, 1192.0103,\n",
            "        1192.0253, 1192.0790, 1192.0612, 1192.0236, 1192.0992, 1191.9359,\n",
            "        1192.0453, 1191.9888, 1192.0304, 1192.0433, 1192.0273, 1192.0332,\n",
            "        1192.0524, 1191.9991, 1192.0284, 1192.0292, 1192.0497, 1191.9635,\n",
            "        1191.9834, 1192.0157, 1191.9304, 1192.0472, 1192.0481, 1192.0391,\n",
            "        1192.0352, 1191.9584, 1192.0439, 1192.0305, 1192.0454, 1192.0497,\n",
            "        1192.0157, 1192.1068, 1191.4702, 1192.0194, 1191.9799, 1191.9709,\n",
            "        1192.0135, 1192.0833, 1192.0129, 1191.9923, 1192.0621, 1192.0958,\n",
            "        1192.0509, 1192.0198, 1191.9902, 1192.0468, 1192.0708, 1192.0439,\n",
            "        1192.0240, 1192.0221, 1192.0352, 1192.0110, 1192.0460, 1192.0874,\n",
            "        1192.0531, 1192.0016, 1192.0624, 1192.0724, 1192.0488, 1192.0240,\n",
            "        1192.0173, 1192.0597, 1192.0270, 1192.0643, 1192.0300, 1192.0245,\n",
            "        1191.9805, 1192.0504, 1192.0396, 1192.0264, 1192.0151, 1192.0227,\n",
            "        1192.0441, 1192.0427, 1192.0115, 1192.0260, 1192.0295, 1192.0221,\n",
            "        1192.0560, 1192.0295, 1192.0166, 1192.0757, 1192.0232],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([4.1489e-07, 9.2462e-03, 1.0106e-02, 5.9756e-03, 1.0245e-02, 1.0355e-02,\n",
            "        1.0245e-02, 1.2333e-02, 1.3090e-02, 8.3451e-03, 1.2491e-02, 7.5687e-03,\n",
            "        1.0096e-02, 1.2357e-02, 1.1688e-02, 1.0498e-02, 1.1654e-02, 9.8811e-03,\n",
            "        1.3907e-02, 8.3045e-03, 1.0295e-02, 1.0017e-02, 1.0705e-02, 8.8660e-03,\n",
            "        8.3941e-03, 8.0883e-03, 1.4113e-02, 1.1351e-02, 9.4010e-03, 1.0549e-02,\n",
            "        1.0046e-02, 1.2454e-02, 2.2504e-03, 8.7627e-03, 1.0757e-02, 1.0467e-02,\n",
            "        9.5211e-03, 7.7406e-03, 1.5898e-02, 9.9975e-03, 8.4106e-03, 1.3232e-02,\n",
            "        1.2712e-02, 9.3187e-03, 1.1023e-02, 9.6805e-03, 1.1329e-02, 8.6353e-03,\n",
            "        8.9442e-03, 1.0757e-02, 1.0125e-02, 1.2601e-02, 1.3772e-02, 1.5289e-02,\n",
            "        1.2130e-02, 8.5932e-03, 9.9294e-03, 9.3187e-03, 9.7564e-03, 1.3052e-02,\n",
            "        1.5790e-02, 1.2491e-02, 1.2601e-02, 9.5211e-03, 1.0096e-02, 1.0406e-02,\n",
            "        5.9756e-03, 9.5771e-03, 1.3880e-02, 1.0245e-02, 7.5098e-03, 9.8329e-03,\n",
            "        8.1200e-03, 2.1352e-02, 9.9975e-03, 1.1023e-02, 1.3705e-02, 1.7073e-02,\n",
            "        7.1032e-03, 9.0056e-03, 1.0736e-02, 1.3219e-02, 8.1837e-03, 7.5909e-03,\n",
            "        7.1729e-03, 1.0315e-02, 7.7180e-03, 8.3533e-03, 8.0411e-03, 1.3440e-02,\n",
            "        1.1406e-02, 9.8042e-03, 1.1896e-02, 9.6899e-03, 1.0549e-02, 9.9101e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [69]\n",
            "DEBUGGING: logits looks like: tensor([1191.3167, 1192.3177, 1192.3267, 1192.2742, 1192.3280, 1192.3291,\n",
            "        1192.3280, 1192.3466, 1192.3525, 1192.3075, 1192.3479, 1192.2977,\n",
            "        1192.3265, 1192.3468, 1192.3412, 1192.3304, 1192.3409, 1192.3245,\n",
            "        1192.3586, 1192.3070, 1192.3285, 1192.3258, 1192.3324, 1192.3136,\n",
            "        1192.3081, 1192.3044, 1192.3601, 1192.3383, 1192.3195, 1192.3309,\n",
            "        1192.3260, 1192.3475, 1192.1765, 1192.3124, 1192.3329, 1192.3302,\n",
            "        1192.3207, 1192.3000, 1192.3719, 1192.3256, 1192.3083, 1192.3536,\n",
            "        1192.3496, 1192.3186, 1192.3353, 1192.3224, 1192.3381, 1192.3109,\n",
            "        1192.3145, 1192.3329, 1192.3269, 1192.3488, 1192.3577, 1192.3680,\n",
            "        1192.3450, 1192.3104, 1192.3250, 1192.3186, 1192.3231, 1192.3523,\n",
            "        1192.3713, 1192.3479, 1192.3488, 1192.3207, 1192.3265, 1192.3296,\n",
            "        1192.2742, 1192.3213, 1192.3584, 1192.3280, 1192.2970, 1192.3240,\n",
            "        1192.3048, 1192.4015, 1192.3256, 1192.3353, 1192.3572, 1192.3792,\n",
            "        1192.2914, 1192.3152, 1192.3328, 1192.3535, 1192.3055, 1192.2981,\n",
            "        1192.2924, 1192.3287, 1192.2997, 1192.3076, 1192.3038, 1192.3552,\n",
            "        1192.3387, 1192.3236, 1192.3430, 1192.3225, 1192.3309, 1192.3247],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([3.7511e-07, 9.3991e-03, 9.3899e-03, 9.3442e-03, 9.3533e-03, 9.4820e-03,\n",
            "        9.2624e-03, 9.1634e-03, 9.2986e-03, 8.9862e-03, 9.5844e-03, 8.9337e-03,\n",
            "        9.1188e-03, 9.3807e-03, 9.3442e-03, 9.0744e-03, 9.3350e-03, 9.1903e-03,\n",
            "        9.6032e-03, 8.2785e-03, 9.2805e-03, 9.2805e-03, 9.1277e-03, 9.1634e-03,\n",
            "        9.4451e-03, 9.2533e-03, 9.3442e-03, 9.2443e-03, 9.0832e-03, 9.5191e-03,\n",
            "        9.2083e-03, 9.1277e-03, 9.2624e-03, 9.1277e-03, 9.3259e-03, 9.5564e-03,\n",
            "        9.4358e-03, 9.2805e-03, 9.3077e-03, 9.2353e-03, 9.0655e-03, 9.1277e-03,\n",
            "        9.2173e-03, 9.4266e-03, 9.4266e-03, 9.3442e-03, 9.1903e-03, 9.3991e-03,\n",
            "        9.3533e-03, 9.3077e-03, 9.1277e-03, 9.3442e-03, 9.2896e-03, 9.2533e-03,\n",
            "        9.2624e-03, 9.5099e-03, 9.4358e-03, 9.5099e-03, 9.3807e-03, 9.2624e-03,\n",
            "        9.4635e-03, 9.2805e-03, 7.9148e-03, 9.1634e-03, 9.3259e-03, 9.2173e-03,\n",
            "        9.7735e-03, 8.9337e-03, 9.3442e-03, 9.3991e-03, 9.2896e-03, 9.0214e-03,\n",
            "        9.2533e-03, 9.7069e-03, 9.0390e-03, 9.2443e-03, 9.2533e-03, 9.0302e-03,\n",
            "        9.4913e-03, 9.1188e-03, 9.2805e-03, 9.3350e-03, 9.4635e-03, 9.2533e-03,\n",
            "        9.3077e-03, 9.5378e-03, 9.3807e-03, 8.6927e-03, 8.9424e-03, 9.6314e-03,\n",
            "        9.0832e-03, 9.3991e-03, 9.3807e-03, 9.3716e-03, 9.3533e-03, 9.2173e-03,\n",
            "        9.3259e-03, 9.1545e-03, 9.1993e-03, 8.8469e-03, 9.3259e-03, 9.2083e-03,\n",
            "        9.3442e-03, 8.9424e-03, 9.0214e-03, 9.1277e-03, 9.3442e-03, 9.5099e-03,\n",
            "        9.3899e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [105]\n",
            "DEBUGGING: logits looks like: tensor([1191.5088, 1192.5217, 1192.5216, 1192.5211, 1192.5212, 1192.5226,\n",
            "        1192.5203, 1192.5192, 1192.5206, 1192.5172, 1192.5237, 1192.5166,\n",
            "        1192.5187, 1192.5215, 1192.5211, 1192.5182, 1192.5210, 1192.5194,\n",
            "        1192.5238, 1192.5090, 1192.5204, 1192.5204, 1192.5188, 1192.5192,\n",
            "        1192.5222, 1192.5201, 1192.5211, 1192.5200, 1192.5183, 1192.5229,\n",
            "        1192.5197, 1192.5188, 1192.5203, 1192.5188, 1192.5209, 1192.5233,\n",
            "        1192.5221, 1192.5204, 1192.5208, 1192.5199, 1192.5181, 1192.5188,\n",
            "        1192.5198, 1192.5220, 1192.5220, 1192.5211, 1192.5194, 1192.5217,\n",
            "        1192.5212, 1192.5208, 1192.5188, 1192.5211, 1192.5205, 1192.5201,\n",
            "        1192.5203, 1192.5228, 1192.5221, 1192.5228, 1192.5215, 1192.5203,\n",
            "        1192.5223, 1192.5204, 1192.5045, 1192.5192, 1192.5209, 1192.5198,\n",
            "        1192.5256, 1192.5166, 1192.5211, 1192.5217, 1192.5205, 1192.5176,\n",
            "        1192.5201, 1192.5249, 1192.5178, 1192.5200, 1192.5201, 1192.5177,\n",
            "        1192.5227, 1192.5187, 1192.5204, 1192.5210, 1192.5223, 1192.5201,\n",
            "        1192.5208, 1192.5232, 1192.5215, 1192.5139, 1192.5167, 1192.5242,\n",
            "        1192.5183, 1192.5217, 1192.5215, 1192.5214, 1192.5212, 1192.5198,\n",
            "        1192.5209, 1192.5190, 1192.5195, 1192.5156, 1192.5209, 1192.5197,\n",
            "        1192.5211, 1192.5167, 1192.5176, 1192.5188, 1192.5211, 1192.5228,\n",
            "        1192.5216], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.13198742322310864 and immediate abs rewards look like: [0.01472099603006427, 0.021325042837361252, 0.005864587830274104, 0.02603912185622903, 0.004401140057325392, 0.0045453279326466145, 0.016714532082005462, 0.005479842456225015, 0.010706608370128379, 0.0005560424260693253, 0.004521372913131927, 0.0001805688416425255, 0.002280316647102154, 0.0010755418525150162, 0.001040989153807459, 0.0007803122134646401, 0.0013567305295509868, 0.0007019122390374832, 0.0002603438306323369, 0.00025822183351920103, 0.0015671142414248607, 0.001127511631239031, 0.00059029320755144, 0.0015016668380667397, 5.222803338256199e-05, 3.872929028148064e-06, 0.00019400667315494502, 1.6913219496927923e-05, 4.1407859043829376e-05, 0.0006386826826201286, 3.208146608812967e-05, 9.713085819385014e-05, 0.00013012798626732547, 9.718917863210663e-05, 0.00010107327807418187, 0.0011000993995367025, 0.0002902655874095217, 0.0013718580212298548, 6.314956635833369e-05, 2.7237265385338105e-06, 8.932365972214029e-05, 1.4680217645945959e-06, 2.929141373897437e-07, 5.6393218983430415e-08, 1.417770363332238e-07, 9.628774932934903e-08, 1.779456579242833e-05, 3.846234312732122e-05, 5.325011443346739e-06, 5.513933047041064e-06]\n",
            "DEBUGGING: the total relative reward of the trajectory = 30.70674418851986 and immediate relative rewards look like: [0.47467008632435814, 1.3817865142604329, 0.5739720120429465, 3.404473806555201, 0.7254559482557009, 0.9003739164228932, 3.868573904487027, 1.4575501103181498, 3.209606867734641, 0.18587325559441123, 1.6628486445828177, 0.07255557308504967, 0.9926850657706769, 0.5046149165893563, 0.5234783953320468, 0.4186983746669552, 0.7736937182967019, 0.4240133889401143, 0.16604563276118478, 0.17337540070149468, 1.1048978368727314, 0.8332483136096104, 0.4562373894673431, 1.2113405080680633, 0.04390806971723491, 0.003386266838574056, 0.17615269392319935, 0.015926542623214742, 0.04038503245558836, 0.6443949162319497, 0.03345452796412121, 0.10455646628056371, 0.1444583107127215, 0.11116644653962131, 0.1190132980148734, 1.3324173860339459, 0.3614630481088026, 1.7546957517514294, 0.0829362945205404, 0.0036689549354221606, 0.12333026007080033, 0.0020764148727672165, 0.00042417136784561203, 8.356264254922522e-05, 0.0002148577480233464, 0.00014916313408951101, 0.028165528183503184, 0.0621744890153084, 0.008787341412181151, 0.009284812681075555]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 150 number of matrices\n",
            "DEBUGGING: ACT_MAT has 150 number of matrices\n",
            "DEBUGGING: VAL looks like: [[40.794874335095685, 40.767524925597094, 41.03000988514203, 32.35925289216205, 25.231656554469975, 24.167845451198126, 22.472837426985883, 20.444134010337752, 20.51196081817637, 20.303880248283036, 19.093608794503247, 17.436964558798675, 16.45158728310993, 16.36106346336789, 15.490521314619375, 15.399029730410692, 14.47460355378551, 14.614790272893513, 14.184154473824085, 12.589749015838484, 10.573300274588522, 7.840300219918858, 7.640141936453723, 6.25321187031695, 5.367666420236051, 5.152932882570131, 4.293478019830903, 4.07445534657313, 3.8829941303962134, 3.0020845560083287, 3.013728708196547, 2.4832529804101595, 1.860151408251832, 1.7494691850198891, 1.5863573214164985, 1.403772979867991, 1.0967616089898566, 0.8625977060997981, 0.7939694875393044, 0.7440452848701407, 0.6698313960640665, 0.5540855832623761, 0.5594830252355274, 0.3750185098923895, 0.34491456710457746, 0.33072799203598113, 0.32559269437718763, 0.12985465900643295, 0.05507416181729192, 0.03451658312237502], [21.21509992445493, 20.799100180190774, 19.633516328957214, 17.176582123788528, 14.012751440653219, 13.896508371735008, 13.675604651831277, 13.549497785950772, 13.670902831750258, 13.77624648966836, 13.695329407563314, 13.294851238521069, 13.227908859387593, 13.340484678762278, 13.444230867848166, 13.465469228296366, 13.541476135216723, 13.615468013816043, 13.724686991665832, 13.402722217907055, 13.016694193582039, 12.656699808114967, 12.72358044268912, 12.043831886486144, 11.582812180494722, 10.852309878484052, 10.866016590122221, 9.35722555132997, 8.340955223123242, 8.363505458400972, 8.434346297639117, 7.329007838837643, 6.517978357367648, 6.420651787340761, 5.435493233415354, 4.753818292175942, 4.784575762301298, 4.74487514104961, 3.5596772093729068, 3.1794065735551547, 2.7432788548345863, 0.9386280412333419, 0.8053060163095114, 0.7297500316981933, 0.42485271174169764, 0.4279115189829724, 0.3374284256380687, 0.3310530569865489, 0.1411684955399861, 0.13848204745573076], [26.980887078192083, 26.773956557442144, 25.648656609274454, 25.327964239627786, 22.14493983138645, 21.635842306192675, 20.94491756542402, 17.24883198074444, 15.950789768107365, 12.869881717548207, 12.81212975954929, 11.26190011612775, 11.302368225295657, 10.413821373257555, 10.009299451179999, 9.581637430149446, 9.25549399543686, 8.5674750274143, 8.225718826741602, 8.141084034323654, 8.048190539012282, 7.013426971858131, 6.242604705301535, 5.844815470539588, 4.6802777398702275, 4.683201687023225, 4.727086283014799, 4.596902615244041, 4.627248558202854, 4.633195480552795, 4.0290914791119645, 4.035996920351357, 3.9711519738088823, 3.8653471344405665, 3.7921017049504497, 3.7101903100359355, 2.4017908323252417, 2.060937155774181, 0.3093347515381329, 0.2286853101187803, 0.22728924765995773, 0.10500907837288627, 0.10397238737385762, 0.10459415758183031, 0.10556625751442533, 0.10641555531959797, 0.10733979008637218, 0.0799740019220899, 0.017979305966445952, 0.009284812681075555]]\n",
            "DEBUGGING: traj_returns = [40.794874335095685, 21.21509992445493, 26.980887078192083]\n",
            "DEBUGGING: actions = [[8], [22], [50], [21], [13], [17], [58], [45], [15], [38], [11], [28], [54], [32], [10], [40], [40], [15], [28], [10], [10], [37], [14], [22], [54], [2], [53], [37], [10], [66], [36], [65], [56], [85], [50], [8], [70], [13], [15], [34], [4], [20], [68], [91], [88], [3], [61], [12], [34], [53], [34], [22], [3], [2], [3], [26], [7], [17], [17], [34], [33], [54], [64], [2], [1], [70], [14], [22], [8], [32], [48], [80], [56], [17], [13], [77], [62], [42], [63], [67], [30], [15], [2], [46], [59], [67], [59], [20], [53], [49], [62], [76], [78], [59], [73], [92], [101], [96], [70], [98], [12], [39], [15], [31], [58], [3], [65], [37], [58], [59], [7], [4], [21], [21], [70], [29], [57], [19], [49], [20], [45], [2], [48], [31], [60], [69], [38], [52], [20], [32], [28], [61], [33], [73], [59], [75], [40], [10], [42], [69], [73], [47], [76], [79], [16], [27], [42], [89], [53], [105]]\n",
            "DEBUGGING: actions length = 150\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[  6.5375,   6.7235,  11.5888,  ...,   4.4055, -12.4038, -19.0749],\n",
            "        [  6.4283,   6.6033,  11.3917,  ...,   4.3451, -12.2402, -18.8259],\n",
            "        [  6.3994,   6.5724,  11.3515,  ...,   4.3214, -12.1811, -18.7368],\n",
            "        ...,\n",
            "        [  6.4952,   6.6710,  11.5120,  ...,   4.3844, -12.3368, -18.9742],\n",
            "        [  6.4952,   6.6710,  11.5120,  ...,   4.3844, -12.3368, -18.9742],\n",
            "        [  6.4952,   6.6710,  11.5120,  ...,   4.3844, -12.3368, -18.9742]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[  6.4876,   6.6635,  11.5010,  ...,   4.3799, -12.3275, -18.9609],\n",
            "        [  6.4952,   6.6710,  11.5120,  ...,   4.3844, -12.3368, -18.9742],\n",
            "        [  6.4952,   6.6710,  11.5120,  ...,   4.3844, -12.3368, -18.9742],\n",
            "        ...,\n",
            "        [  6.4952,   6.6710,  11.5120,  ...,   4.3844, -12.3368, -18.9742],\n",
            "        [  6.4952,   6.6710,  11.5120,  ...,   4.3844, -12.3368, -18.9742],\n",
            "        [  6.4952,   6.6710,  11.5120,  ...,   4.3844, -12.3368, -18.9742]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([1191.5088, 1192.5217, 1192.5216, 1192.5211, 1192.5212, 1192.5226,\n",
            "        1192.5203, 1192.5192, 1192.5206, 1192.5172, 1192.5237, 1192.5166,\n",
            "        1192.5187, 1192.5215, 1192.5211, 1192.5182, 1192.5210, 1192.5194,\n",
            "        1192.5238, 1192.5090, 1192.5204, 1192.5204, 1192.5188, 1192.5192,\n",
            "        1192.5222, 1192.5201, 1192.5211, 1192.5200, 1192.5183, 1192.5229,\n",
            "        1192.5197, 1192.5188, 1192.5203, 1192.5188, 1192.5209, 1192.5233,\n",
            "        1192.5221, 1192.5204, 1192.5208, 1192.5199, 1192.5181, 1192.5188,\n",
            "        1192.5198, 1192.5220, 1192.5220, 1192.5211, 1192.5194, 1192.5217,\n",
            "        1192.5212, 1192.5208, 1192.5188, 1192.5211, 1192.5205, 1192.5201,\n",
            "        1192.5203, 1192.5228, 1192.5221, 1192.5228, 1192.5215, 1192.5203,\n",
            "        1192.5223, 1192.5204, 1192.5045, 1192.5192, 1192.5209, 1192.5198,\n",
            "        1192.5256, 1192.5166, 1192.5211, 1192.5217, 1192.5205, 1192.5176,\n",
            "        1192.5201, 1192.5249, 1192.5178, 1192.5200, 1192.5201, 1192.5177,\n",
            "        1192.5227, 1192.5187, 1192.5204, 1192.5210, 1192.5223, 1192.5201,\n",
            "        1192.5208, 1192.5232, 1192.5215, 1192.5139, 1192.5167, 1192.5242,\n",
            "        1192.5183, 1192.5217, 1192.5215, 1192.5214, 1192.5212, 1192.5198,\n",
            "        1192.5209, 1192.5190, 1192.5195, 1192.5156, 1192.5209, 1192.5197,\n",
            "        1192.5211, 1192.5167, 1192.5176, 1192.5188, 1192.5211, 1192.5228,\n",
            "        1192.5216], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[29.66362045 29.44686055 28.77072761 24.95459975 20.46311594 19.90006538\n",
            "  19.03111988 17.08082126 16.71121781 15.65000282 15.20035599 13.9979053\n",
            "  13.66062146 13.37178984 12.98135054 12.8153788  12.42385789 12.2659111\n",
            "  12.04485343 11.37785176 10.54606167  9.17014233  8.86877569  8.04728641\n",
            "   7.21025211  6.89614815  6.6288603   6.00952784  5.61706597  5.3329285\n",
            "   5.15905549  4.61608591  4.11642725  4.0118227   3.60465075  3.28926053\n",
            "   2.76104273  2.55613667  1.55432715  1.38404572  1.2134665   0.53257423\n",
            "   0.48958714  0.4031209   0.29177785  0.28835169  0.25678697  0.18029391\n",
            "   0.07140732  0.06076115]]\n",
            "DEBUGGING: baseline2 looks like: 29.663620445914233\n",
            "DEBUGGING: ADS looks like: [11.13125389 11.32066437 12.25928228  7.40465314  4.76854061  4.26778007\n",
            "  3.44171755  3.36331275  3.80074301  4.65387743  3.89325281  3.43905925\n",
            "  2.79096583  2.98927362  2.50917077  2.58365093  2.05074566  2.34887917\n",
            "  2.13930104  1.21189726  0.02723861 -1.32984211 -1.22863376 -1.79407454\n",
            " -1.84258569 -1.74321527 -2.33538228 -1.93507249 -1.73407184 -2.33084394\n",
            " -2.14532679 -2.13283293 -2.25627584 -2.26235352 -2.01829343 -1.88548755\n",
            " -1.66428113 -1.69353896 -0.76035766 -0.64000044 -0.5436351   0.02151135\n",
            "  0.06989588 -0.02810239  0.05313672  0.0423763   0.06880572 -0.05043925\n",
            " -0.01633316 -0.02624456 -8.44852052 -8.64776037 -9.13721128 -7.77801763\n",
            " -6.4503645  -6.003557   -5.35551523 -3.53132347 -3.04031497 -1.87375633\n",
            " -1.50502658 -0.70305407 -0.4327126  -0.03130516  0.46288032  0.65009043\n",
            "  1.11761824  1.34955691  1.67983356  2.02487046  2.47063252  3.48655747\n",
            "  3.85480475  3.99654548  4.37256007  3.95616173  4.23715629  3.34769771\n",
            "  2.72388925  3.03057696  3.2752908   2.71292193  2.40155111  2.40882909\n",
            "  1.83084248  1.46455776  2.02353303  2.18873847  2.00535006  1.79536085\n",
            "  1.52981236  0.40605381  0.31571887  0.32662913  0.13307487  0.13955983\n",
            "  0.08064146  0.15075915  0.06976117  0.0777209  -2.68273337 -2.672904\n",
            " -3.122071    0.37336449  1.68182389  1.73577693  1.91379768  0.16801072\n",
            " -0.76042804 -2.7801211  -2.38822623 -2.73600519 -2.35825323 -2.95796847\n",
            " -2.97205109 -3.23374137 -3.1683639  -3.69843608 -3.8191346  -3.23676772\n",
            " -2.49787113 -2.15671536 -2.62617099 -2.20247094 -2.52997437 -2.21294646\n",
            " -1.90177401 -1.41262522 -0.98981741 -0.69973302 -1.12996402 -0.58008899\n",
            " -0.14527527 -0.14647557  0.18745095  0.42092978 -0.3592519  -0.49519951\n",
            " -1.2449924  -1.15536041 -0.98617725 -0.42756516 -0.38561476 -0.29852674\n",
            " -0.18621159 -0.18193613 -0.14944718 -0.1003199  -0.05342802 -0.05147634]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(-0.2741, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-0.2719, -1.1219, -0.3111,  ...,  0.1758,  0.4456,  1.3405],\n",
            "        [ 0.0884,  0.3648,  0.1012,  ..., -0.0572, -0.1449, -0.4297],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [-0.0876, -0.3614, -0.1002,  ...,  0.0567,  0.1436,  0.4450],\n",
            "        [-0.1874, -0.7732, -0.2144,  ...,  0.1212,  0.3072,  0.9337],\n",
            "        [-0.1395, -0.5755, -0.1596,  ...,  0.0902,  0.2286,  0.6898]])\n",
            "   Last layer:\n",
            "tensor([[ 0.1979,  0.2989,  0.2280,  0.0000,  0.0000,  0.0000,  0.0000,  0.3122,\n",
            "          0.0000,  0.0000,  0.1575,  0.2247,  0.1648,  0.0000,  0.1865,  0.0000,\n",
            "          0.1463,  0.0000,  0.1661,  0.0000],\n",
            "        [ 0.1668,  0.2467,  0.1981,  0.0000,  0.0000,  0.0000,  0.0000,  0.2712,\n",
            "          0.0000,  0.0000,  0.1303,  0.1834,  0.1493,  0.0000,  0.1512,  0.0000,\n",
            "          0.1182,  0.0000,  0.1415,  0.0000],\n",
            "        [ 0.3150,  0.4698,  0.3701,  0.0000,  0.0000,  0.0000,  0.0000,  0.5060,\n",
            "          0.0000,  0.0000,  0.2479,  0.3503,  0.2744,  0.0000,  0.2901,  0.0000,\n",
            "          0.2269,  0.0000,  0.2657,  0.0000],\n",
            "        [-0.2229, -0.3362, -0.2580,  0.0000,  0.0000,  0.0000,  0.0000, -0.3533,\n",
            "          0.0000,  0.0000, -0.1769, -0.2522, -0.1877,  0.0000, -0.2090,  0.0000,\n",
            "         -0.1638,  0.0000, -0.1872,  0.0000],\n",
            "        [-0.3741, -0.5667, -0.4299,  0.0000,  0.0000,  0.0000,  0.0000, -0.5884,\n",
            "          0.0000,  0.0000, -0.2981, -0.4264, -0.3097,  0.0000, -0.3539,  0.0000,\n",
            "         -0.2774,  0.0000, -0.3135,  0.0000],\n",
            "        [-0.3810, -0.5680, -0.4471,  0.0000,  0.0000,  0.0000,  0.0000, -0.6120,\n",
            "          0.0000,  0.0000, -0.2996, -0.4236, -0.3318,  0.0000, -0.3505,  0.0000,\n",
            "         -0.2744,  0.0000, -0.3215,  0.0000],\n",
            "        [ 0.2015,  0.3024,  0.2348,  0.0000,  0.0000,  0.0000,  0.0000,  0.3212,\n",
            "          0.0000,  0.0000,  0.1593,  0.2263,  0.1722,  0.0000,  0.1875,  0.0000,\n",
            "          0.1466,  0.0000,  0.1696,  0.0000],\n",
            "        [ 0.1462,  0.2223,  0.1674,  0.0000,  0.0000,  0.0000,  0.0000,  0.2291,\n",
            "          0.0000,  0.0000,  0.1169,  0.1676,  0.1196,  0.0000,  0.1393,  0.0000,\n",
            "          0.1092,  0.0000,  0.1224,  0.0000],\n",
            "        [-0.3617, -0.5444, -0.4194,  0.0000,  0.0000,  0.0000,  0.0000, -0.5746,\n",
            "          0.0000,  0.0000, -0.2867, -0.4080, -0.3064,  0.0000, -0.3383,  0.0000,\n",
            "         -0.2649,  0.0000, -0.3040,  0.0000],\n",
            "        [-0.5832, -0.8819, -0.6726,  0.0000,  0.0000,  0.0000,  0.0000, -0.9203,\n",
            "          0.0000,  0.0000, -0.4643, -0.6631, -0.4857,  0.0000, -0.5505,  0.0000,\n",
            "         -0.4315,  0.0000, -0.4891,  0.0000]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.2868, -0.2953,  0.1331,  ..., -0.0941, -0.4046, -0.1150],\n",
            "        [-0.1070,  0.1102, -0.0497,  ...,  0.0351,  0.1509,  0.0434],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0942, -0.0970,  0.0437,  ..., -0.0309, -0.1328, -0.0362],\n",
            "        [ 0.2089, -0.2151,  0.0970,  ..., -0.0685, -0.2947, -0.0806],\n",
            "        [ 0.1355, -0.1395,  0.0629,  ..., -0.0445, -0.1912, -0.0557]])\n",
            "   Last layer:\n",
            "tensor([[-0.0105, -0.0121, -0.0164,  0.0000,  0.0000,  0.0000,  0.0000, -0.0132,\n",
            "          0.0000,  0.0000, -0.0147, -0.0211, -0.0009,  0.0000, -0.0290,  0.0000,\n",
            "         -0.0141,  0.0000, -0.0204,  0.0000],\n",
            "        [-0.0125, -0.0153, -0.0185,  0.0000,  0.0000,  0.0000,  0.0000, -0.0158,\n",
            "          0.0000,  0.0000, -0.0166, -0.0239, -0.0017,  0.0000, -0.0317,  0.0000,\n",
            "         -0.0160,  0.0000, -0.0223,  0.0000],\n",
            "        [-0.0258, -0.0336, -0.0361,  0.0000,  0.0000,  0.0000,  0.0000, -0.0330,\n",
            "          0.0000,  0.0000, -0.0324, -0.0470, -0.0052,  0.0000, -0.0595,  0.0000,\n",
            "         -0.0314,  0.0000, -0.0419,  0.0000],\n",
            "        [ 0.0153,  0.0193,  0.0221,  0.0000,  0.0000,  0.0000,  0.0000,  0.0195,\n",
            "          0.0000,  0.0000,  0.0198,  0.0286,  0.0026,  0.0000,  0.0370,  0.0000,\n",
            "          0.0191,  0.0000,  0.0261,  0.0000],\n",
            "        [ 0.0126,  0.0110,  0.0239,  0.0000,  0.0000,  0.0000,  0.0000,  0.0152,\n",
            "          0.0000,  0.0000,  0.0213,  0.0299, -0.0018,  0.0000,  0.0460,  0.0000,\n",
            "          0.0199,  0.0000,  0.0323,  0.0000],\n",
            "        [ 0.0313,  0.0406,  0.0438,  0.0000,  0.0000,  0.0000,  0.0000,  0.0400,\n",
            "          0.0000,  0.0000,  0.0393,  0.0569,  0.0063,  0.0000,  0.0721,  0.0000,\n",
            "          0.0380,  0.0000,  0.0508,  0.0000],\n",
            "        [-0.0061, -0.0043, -0.0128,  0.0000,  0.0000,  0.0000,  0.0000, -0.0072,\n",
            "          0.0000,  0.0000, -0.0114, -0.0159,  0.0017,  0.0000, -0.0256,  0.0000,\n",
            "         -0.0106,  0.0000, -0.0180,  0.0000],\n",
            "        [-0.0047, -0.0042, -0.0088,  0.0000,  0.0000,  0.0000,  0.0000, -0.0057,\n",
            "          0.0000,  0.0000, -0.0079, -0.0111,  0.0006,  0.0000, -0.0170,  0.0000,\n",
            "         -0.0074,  0.0000, -0.0119,  0.0000],\n",
            "        [ 0.0197,  0.0226,  0.0311,  0.0000,  0.0000,  0.0000,  0.0000,  0.0247,\n",
            "          0.0000,  0.0000,  0.0278,  0.0397,  0.0015,  0.0000,  0.0549,  0.0000,\n",
            "          0.0265,  0.0000,  0.0386,  0.0000],\n",
            "        [ 0.0335,  0.0401,  0.0508,  0.0000,  0.0000,  0.0000,  0.0000,  0.0421,\n",
            "          0.0000,  0.0000,  0.0455,  0.0654,  0.0039,  0.0000,  0.0880,  0.0000,\n",
            "          0.0435,  0.0000,  0.0619,  0.0000]])\n",
            "DEBUGGING: training for one iteration takes 0.004644 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 15\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([8.9174e-26, 3.7447e-03, 1.5179e-01, 2.9168e-02, 3.0609e-06, 5.3596e-02,\n",
            "        1.6947e-02, 1.5456e-04, 1.0345e-05, 1.2287e-04, 5.2441e-04, 9.8452e-04,\n",
            "        3.0355e-03, 7.6090e-03, 5.6860e-05, 8.0343e-05, 5.6886e-02, 7.4400e-03,\n",
            "        8.7835e-03, 4.9024e-04, 2.5416e-02, 1.2219e-02, 1.0492e-02, 1.6185e-03,\n",
            "        7.1689e-03, 1.0552e-03, 1.9966e-03, 6.2285e-03, 1.7330e-03, 9.9016e-05,\n",
            "        2.7051e-03, 1.0479e-04, 2.0379e-03, 1.9714e-03, 5.4735e-05, 3.5743e-01,\n",
            "        1.3886e-02, 1.1714e-03, 4.1127e-03, 3.7156e-03, 1.8631e-02, 8.2999e-03,\n",
            "        3.5070e-04, 7.8570e-04, 8.2100e-04, 1.9129e-02, 2.5612e-03, 4.7881e-05,\n",
            "        9.5876e-05, 4.0682e-04, 1.7571e-02, 6.7752e-02, 3.6467e-04, 1.8922e-03,\n",
            "        1.2191e-04, 2.1109e-03, 1.9525e-02, 8.6137e-03, 3.3848e-06, 1.1080e-03,\n",
            "        9.9046e-03, 3.4836e-03, 4.8642e-04, 3.8933e-04, 3.3394e-05, 1.1602e-02,\n",
            "        6.4703e-03, 2.4579e-04, 5.5281e-04], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [16]\n",
            "DEBUGGING: logits looks like: tensor([1308.7932, 1314.0023, 1314.3726, 1314.2076, 1313.2914, 1314.2684,\n",
            "        1314.1533, 1313.6836, 1313.4132, 1313.6606, 1313.8058, 1313.8688,\n",
            "        1313.9813, 1314.0732, 1313.5836, 1313.6182, 1314.2744, 1314.0710,\n",
            "        1314.0876, 1313.7991, 1314.1938, 1314.1206, 1314.1053, 1313.9185,\n",
            "        1314.0673, 1313.8757, 1313.9395, 1314.0532, 1313.9253, 1313.6390,\n",
            "        1313.9698, 1313.6448, 1313.9415, 1313.9382, 1313.5798, 1314.4583,\n",
            "        1314.1334, 1313.8861, 1314.0117, 1314.0016, 1314.1628, 1314.0819,\n",
            "        1313.7655, 1313.8462, 1313.8506, 1314.1654, 1313.9644, 1313.5664,\n",
            "        1313.6359, 1313.7804, 1314.1570, 1314.2919, 1313.7694, 1313.9341,\n",
            "        1313.6599, 1313.9451, 1314.1675, 1314.0857, 1313.3015, 1313.8806,\n",
            "        1314.0996, 1313.9951, 1313.7982, 1313.7760, 1313.5304, 1314.1155,\n",
            "        1314.0570, 1313.7300, 1313.8110], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([4.0040e-25, 1.9909e-02, 1.0657e-02, 1.1935e-02, 1.1344e-02, 1.0339e-02,\n",
            "        1.2692e-02, 8.0126e-03, 6.0719e-03, 6.8268e-03, 1.0909e-02, 1.2842e-02,\n",
            "        1.4868e-02, 1.1761e-02, 9.5711e-03, 1.6473e-02, 1.1059e-02, 1.3603e-02,\n",
            "        1.6700e-02, 1.4694e-02, 8.0126e-03, 1.0909e-02, 9.3403e-03, 1.4049e-02,\n",
            "        1.6586e-02, 1.7604e-02, 2.3735e-02, 1.3082e-02, 1.3314e-02, 7.4177e-03,\n",
            "        2.1866e-02, 1.2398e-02, 1.4709e-02, 1.9202e-02, 1.6377e-02, 1.4709e-02,\n",
            "        4.4466e-03, 1.1256e-02, 1.3994e-02, 1.5997e-02, 1.3953e-02, 7.4905e-03,\n",
            "        1.1511e-02, 9.4412e-03, 1.4608e-02, 1.1636e-02, 6.9615e-03, 2.1297e-02,\n",
            "        1.1366e-02, 1.7450e-02, 1.6765e-02, 1.0984e-02, 1.0709e-02, 1.3940e-02,\n",
            "        1.4410e-02, 1.8216e-02, 1.4256e-02, 8.3155e-03, 1.7365e-02, 1.2842e-02,\n",
            "        8.6891e-03, 1.2968e-02, 1.1865e-02, 5.0142e-03, 9.1417e-03, 1.5190e-02,\n",
            "        8.5544e-03, 1.1670e-02, 1.5505e-02, 1.0657e-02, 1.1038e-02, 1.8395e-02,\n",
            "        1.1911e-02, 1.4580e-02, 1.1478e-02, 1.3288e-02, 1.3643e-02, 1.0339e-02,\n",
            "        1.3288e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [76]\n",
            "DEBUGGING: logits looks like: tensor([1309.5133, 1314.7394, 1314.6769, 1314.6882, 1314.6831, 1314.6738,\n",
            "        1314.6943, 1314.6483, 1314.6206, 1314.6323, 1314.6792, 1314.6956,\n",
            "        1314.7102, 1314.6868, 1314.6661, 1314.7205, 1314.6805, 1314.7013,\n",
            "        1314.7218, 1314.7090, 1314.6483, 1314.6792, 1314.6637, 1314.7045,\n",
            "        1314.7211, 1314.7271, 1314.7570, 1314.6974, 1314.6991, 1314.6406,\n",
            "        1314.7488, 1314.6920, 1314.7091, 1314.7357, 1314.7198, 1314.7091,\n",
            "        1314.5895, 1314.6824, 1314.7041, 1314.7175, 1314.7039, 1314.6416,\n",
            "        1314.6846, 1314.6648, 1314.7084, 1314.6857, 1314.6343, 1314.7461,\n",
            "        1314.6833, 1314.7262, 1314.7222, 1314.6799, 1314.6774, 1314.7037,\n",
            "        1314.7070, 1314.7305, 1314.7059, 1314.6521, 1314.7257, 1314.6956,\n",
            "        1314.6565, 1314.6965, 1314.6876, 1314.6014, 1314.6615, 1314.7123,\n",
            "        1314.6549, 1314.6859, 1314.7144, 1314.6769, 1314.6804, 1314.7314,\n",
            "        1314.6880, 1314.7083, 1314.6843, 1314.6990, 1314.7015, 1314.6738,\n",
            "        1314.6990], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.6678e-25, 1.1547e-02, 1.2364e-02, 1.2066e-02, 1.1638e-02, 1.2522e-02,\n",
            "        9.8384e-03, 1.0648e-02, 1.1833e-02, 1.1335e-02, 1.1116e-02, 1.1729e-02,\n",
            "        1.1236e-02, 1.1972e-02, 1.2137e-02, 1.1159e-02, 1.1752e-02, 1.0220e-02,\n",
            "        1.2043e-02, 1.3646e-02, 1.0270e-02, 9.3239e-03, 1.3136e-02, 1.1683e-02,\n",
            "        1.1324e-02, 1.1116e-02, 8.5478e-03, 1.2401e-02, 1.0301e-02, 1.1469e-02,\n",
            "        1.1891e-02, 1.1435e-02, 1.1914e-02, 1.2757e-02, 1.0784e-02, 1.1159e-02,\n",
            "        1.1547e-02, 1.1925e-02, 1.0321e-02, 1.0091e-02, 1.2066e-02, 1.1949e-02,\n",
            "        9.9059e-03, 1.4176e-02, 1.2571e-02, 1.0181e-02, 1.2280e-02, 1.0711e-02,\n",
            "        1.1604e-02, 1.0795e-02, 1.4134e-02, 1.2149e-02, 1.2090e-02, 1.1752e-02,\n",
            "        1.0250e-02, 1.2066e-02, 1.3807e-02, 1.2401e-02, 1.1718e-02, 1.1181e-02,\n",
            "        1.1925e-02, 1.0422e-02, 1.0943e-02, 1.1062e-02, 1.0680e-02, 1.2832e-02,\n",
            "        1.2707e-02, 1.2161e-02, 1.2461e-02, 1.2437e-02, 1.2510e-02, 1.2744e-02,\n",
            "        1.1752e-02, 1.1225e-02, 1.0596e-02, 1.1683e-02, 1.3448e-02, 1.2364e-02,\n",
            "        1.1787e-02, 1.0700e-02, 1.2757e-02, 1.2184e-02, 1.1019e-02, 9.8480e-03,\n",
            "        1.1269e-02, 1.2920e-02, 1.1581e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [9]\n",
            "DEBUGGING: logits looks like: tensor([1310.0602, 1315.2723, 1315.2792, 1315.2767, 1315.2732, 1315.2805,\n",
            "        1315.2563, 1315.2643, 1315.2748, 1315.2705, 1315.2686, 1315.2739,\n",
            "        1315.2697, 1315.2760, 1315.2773, 1315.2689, 1315.2742, 1315.2601,\n",
            "        1315.2766, 1315.2891, 1315.2606, 1315.2510, 1315.2853, 1315.2736,\n",
            "        1315.2704, 1315.2686, 1315.2423, 1315.2795, 1315.2610, 1315.2717,\n",
            "        1315.2753, 1315.2714, 1315.2755, 1315.2823, 1315.2655, 1315.2689,\n",
            "        1315.2723, 1315.2756, 1315.2611, 1315.2589, 1315.2767, 1315.2758,\n",
            "        1315.2571, 1315.2928, 1315.2809, 1315.2598, 1315.2786, 1315.2649,\n",
            "        1315.2728, 1315.2656, 1315.2926, 1315.2775, 1315.2770, 1315.2742,\n",
            "        1315.2605, 1315.2767, 1315.2903, 1315.2795, 1315.2738, 1315.2692,\n",
            "        1315.2756, 1315.2621, 1315.2670, 1315.2681, 1315.2645, 1315.2830,\n",
            "        1315.2820, 1315.2776, 1315.2800, 1315.2798, 1315.2804, 1315.2822,\n",
            "        1315.2742, 1315.2695, 1315.2638, 1315.2736, 1315.2876, 1315.2792,\n",
            "        1315.2744, 1315.2648, 1315.2823, 1315.2777, 1315.2677, 1315.2565,\n",
            "        1315.2699, 1315.2836, 1315.2727], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.5671e-25, 1.0398e-02, 1.0196e-02, 1.0675e-02, 1.0541e-02, 1.0196e-02,\n",
            "        1.1275e-02, 9.7867e-03, 1.0438e-02, 1.0367e-02, 9.5599e-03, 1.0337e-02,\n",
            "        1.0418e-02, 1.0696e-02, 1.0387e-02, 9.7485e-03, 1.0623e-02, 1.0592e-02,\n",
            "        1.0448e-02, 1.0438e-02, 1.0286e-02, 1.0418e-02, 1.0236e-02, 1.0317e-02,\n",
            "        1.0019e-02, 1.0286e-02, 1.0592e-02, 1.0327e-02, 9.8923e-03, 1.0418e-02,\n",
            "        1.1166e-02, 1.0418e-02, 9.8346e-03, 1.1386e-02, 1.0500e-02, 1.0500e-02,\n",
            "        1.0428e-02, 1.0654e-02, 1.0644e-02, 1.0500e-02, 1.0939e-02, 1.1155e-02,\n",
            "        1.0950e-02, 1.0812e-02, 1.0428e-02, 9.9797e-03, 1.1166e-02, 1.1057e-02,\n",
            "        9.8250e-03, 1.0812e-02, 1.0317e-02, 1.0854e-02, 1.0572e-02, 9.6067e-03,\n",
            "        1.0367e-02, 9.5974e-03, 1.0500e-02, 1.0117e-02, 1.0367e-02, 1.0337e-02,\n",
            "        1.0418e-02, 1.0337e-02, 1.0327e-02, 1.0418e-02, 1.0117e-02, 1.0418e-02,\n",
            "        1.0019e-02, 9.9894e-03, 1.0489e-02, 1.0500e-02, 1.0907e-02, 1.0572e-02,\n",
            "        1.0489e-02, 1.0236e-02, 9.6349e-03, 1.0489e-02, 1.0843e-02, 1.0186e-02,\n",
            "        1.0286e-02, 9.6538e-03, 1.0479e-02, 1.0854e-02, 1.0500e-02, 1.0438e-02,\n",
            "        1.0707e-02, 1.0196e-02, 1.0780e-02, 1.0317e-02, 1.0327e-02, 1.0541e-02,\n",
            "        1.0236e-02, 1.0448e-02, 1.0696e-02, 1.0367e-02, 1.0572e-02, 1.0337e-02,\n",
            "        1.0177e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [72]\n",
            "DEBUGGING: logits looks like: tensor([1310.4954, 1315.7009, 1315.6990, 1315.7035, 1315.7023, 1315.6990,\n",
            "        1315.7090, 1315.6948, 1315.7013, 1315.7006, 1315.6925, 1315.7003,\n",
            "        1315.7010, 1315.7037, 1315.7008, 1315.6945, 1315.7030, 1315.7028,\n",
            "        1315.7014, 1315.7013, 1315.6998, 1315.7010, 1315.6993, 1315.7001,\n",
            "        1315.6971, 1315.6998, 1315.7028, 1315.7002, 1315.6959, 1315.7010,\n",
            "        1315.7080, 1315.7010, 1315.6953, 1315.7100, 1315.7019, 1315.7019,\n",
            "        1315.7012, 1315.7034, 1315.7032, 1315.7019, 1315.7059, 1315.7079,\n",
            "        1315.7061, 1315.7048, 1315.7012, 1315.6968, 1315.7080, 1315.7070,\n",
            "        1315.6952, 1315.7048, 1315.7001, 1315.7052, 1315.7025, 1315.6930,\n",
            "        1315.7006, 1315.6929, 1315.7019, 1315.6981, 1315.7006, 1315.7003,\n",
            "        1315.7010, 1315.7003, 1315.7002, 1315.7010, 1315.6981, 1315.7010,\n",
            "        1315.6971, 1315.6969, 1315.7018, 1315.7019, 1315.7057, 1315.7025,\n",
            "        1315.7018, 1315.6993, 1315.6932, 1315.7018, 1315.7051, 1315.6989,\n",
            "        1315.6998, 1315.6935, 1315.7017, 1315.7052, 1315.7019, 1315.7013,\n",
            "        1315.7039, 1315.6990, 1315.7045, 1315.7001, 1315.7002, 1315.7023,\n",
            "        1315.6993, 1315.7014, 1315.7037, 1315.7006, 1315.7025, 1315.7003,\n",
            "        1315.6987], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.4282e-25, 8.8420e-03, 9.0164e-03, 9.0871e-03, 9.7110e-03, 8.7560e-03,\n",
            "        9.5979e-03, 8.0822e-03, 9.2482e-03, 9.7110e-03, 9.9025e-03, 9.2392e-03,\n",
            "        1.5337e-02, 9.0960e-03, 1.0634e-02, 9.4491e-03, 9.9997e-03, 8.5282e-03,\n",
            "        9.4122e-03, 5.9189e-03, 9.8447e-03, 9.3755e-03, 9.7300e-03, 9.1048e-03,\n",
            "        9.9025e-03, 9.5698e-03, 9.7776e-03, 9.8736e-03, 9.2302e-03, 9.8351e-03,\n",
            "        9.1763e-03, 9.3299e-03, 1.0098e-02, 8.5783e-03, 9.6448e-03, 9.5418e-03,\n",
            "        9.6921e-03, 9.3208e-03, 9.5232e-03, 9.7490e-03, 9.8832e-03, 9.6921e-03,\n",
            "        1.0187e-02, 9.7776e-03, 9.0605e-03, 9.6448e-03, 8.8333e-03, 9.1583e-03,\n",
            "        8.9812e-03, 9.5604e-03, 8.8679e-03, 1.2252e-02, 1.0347e-02, 9.1405e-03,\n",
            "        9.7967e-03, 1.0908e-02, 8.8506e-03, 9.6166e-03, 9.3664e-03, 8.8333e-03,\n",
            "        9.1316e-03, 9.6637e-03, 9.3572e-03, 9.4306e-03, 9.6072e-03, 9.7015e-03,\n",
            "        9.5604e-03, 8.6625e-03, 9.3117e-03, 9.6921e-03, 9.2212e-03, 8.7390e-03,\n",
            "        9.6354e-03, 9.7110e-03, 9.0693e-03, 9.4030e-03, 9.2302e-03, 9.5604e-03,\n",
            "        9.2844e-03, 8.1695e-03, 8.9812e-03, 9.5418e-03, 9.0252e-03, 9.9705e-03,\n",
            "        9.1852e-03, 9.2663e-03, 9.2663e-03, 1.0593e-02, 9.5511e-03, 8.8420e-03,\n",
            "        9.2032e-03, 8.8679e-03, 9.8351e-03, 9.5979e-03, 9.6921e-03, 9.7300e-03,\n",
            "        9.6354e-03, 9.7110e-03, 8.7049e-03, 1.3364e-02, 9.5511e-03, 9.5698e-03,\n",
            "        9.5418e-03, 9.3299e-03, 9.6072e-03, 1.0469e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [56]\n",
            "DEBUGGING: logits looks like: tensor([1310.8501, 1316.0450, 1316.0470, 1316.0477, 1316.0544, 1316.0441,\n",
            "        1316.0532, 1316.0360, 1316.0496, 1316.0544, 1316.0564, 1316.0494,\n",
            "        1316.1001, 1316.0479, 1316.0635, 1316.0516, 1316.0574, 1316.0414,\n",
            "        1316.0513, 1316.0049, 1316.0558, 1316.0509, 1316.0546, 1316.0480,\n",
            "        1316.0564, 1316.0530, 1316.0551, 1316.0560, 1316.0493, 1316.0557,\n",
            "        1316.0487, 1316.0504, 1316.0583, 1316.0420, 1316.0537, 1316.0526,\n",
            "        1316.0542, 1316.0503, 1316.0525, 1316.0548, 1316.0562, 1316.0542,\n",
            "        1316.0592, 1316.0551, 1316.0475, 1316.0537, 1316.0449, 1316.0486,\n",
            "        1316.0466, 1316.0529, 1316.0453, 1316.0776, 1316.0608, 1316.0483,\n",
            "        1316.0553, 1316.0660, 1316.0452, 1316.0535, 1316.0508, 1316.0449,\n",
            "        1316.0482, 1316.0540, 1316.0507, 1316.0515, 1316.0533, 1316.0543,\n",
            "        1316.0529, 1316.0430, 1316.0502, 1316.0542, 1316.0492, 1316.0438,\n",
            "        1316.0536, 1316.0544, 1316.0476, 1316.0511, 1316.0493, 1316.0529,\n",
            "        1316.0499, 1316.0371, 1316.0466, 1316.0526, 1316.0471, 1316.0570,\n",
            "        1316.0488, 1316.0497, 1316.0497, 1316.0631, 1316.0527, 1316.0450,\n",
            "        1316.0491, 1316.0453, 1316.0557, 1316.0532, 1316.0542, 1316.0546,\n",
            "        1316.0536, 1316.0544, 1316.0435, 1316.0863, 1316.0527, 1316.0530,\n",
            "        1316.0526, 1316.0504, 1316.0533, 1316.0619], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.19288149017438627 and immediate abs rewards look like: [0.01569241746415173, 0.0026544313013801, 0.10759943206858225, 0.012856183425810741, 0.009804705031456251, 0.0024292352097745606, 0.006410862813254425, 0.00802650599507615, 0.00102888738956608, 0.013412732141887318, 0.004419945313202334, 0.0008417814251515665, 0.00020579183501467924, 0.0002730423868797516, 0.0018013391036220128, 0.001042015103621452, 0.0007034478585410397, 0.0002832728773682902, 3.664629275590414e-07, 0.00022804531863584998, 1.0546435760261375e-05, 0.00020448287841645651, 0.0006096999845794926, 0.0002335708418286231, 2.5690621896501398e-06, 2.532364328544645e-05, 0.0002225757784799498, 2.9165774776629405e-05, 2.7549561536943656e-05, 0.00037297094513633056, 0.00021145352457097033, 0.0003519308211252792, 2.4339618676094688e-05, 3.236612383261672e-05, 0.00010506196076676133, 1.0737228421930922e-06, 1.3507036328519462e-05, 6.527795903821243e-07, 3.7738407399956486e-05, 1.8425431562718586e-05, 0.0001330611332832632, 5.70025395063567e-06, 6.0531858707690844e-06, 1.31904514546477e-05, 2.0186751726214425e-05, 3.243079572712304e-05, 4.377256777843286e-05, 0.0003685076840156398, 8.819514505375992e-06, 3.2297748475684784e-07]\n",
            "DEBUGGING: the total relative reward of the trajectory = 26.93327014135557 and immediate relative rewards look like: [0.4350246587545607, 0.14781513930648982, 8.994349521901603, 1.477169768612427, 1.4134149542131291, 0.4214202278912197, 1.2984170949844072, 1.8613263931142963, 0.26904690472517734, 3.898205641625448, 1.4185784326045654, 0.2951105876315406, 0.07817763276451475, 0.11171082239129822, 0.7896934441983703, 0.48752230839135624, 0.3497950667522005, 0.14917626057874356, 0.000203723842524739, 0.13344718436387742, 0.006480555628761681, 0.1316340390877795, 0.4103539167421812, 0.1640672588349234, 0.0018799070237173392, 0.019271770104663733, 0.1759004519318746, 0.023904801053982946, 0.023386755833674736, 0.3275344988275397, 0.19190435698931158, 0.32971778945961805, 0.023518388426599073, 0.03222200439860942, 0.10767146101518903, 0.0011318662585962304, 0.014633976358643393, 0.000726360867800859, 0.04309734668277823, 0.021581658547778906, 0.1597513640009079, 0.007010837757927651, 0.007622187230259253, 0.016995746841508546, 0.026601648469622218, 0.04368653483605641, 0.06024710296233974, 0.5179998559807752, 0.012656962184569754, 0.00047296836983330107]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([7.6552e-09, 1.1510e-04, 1.7789e-05, 6.0840e-04, 1.2720e-08, 3.1533e-04,\n",
            "        8.2282e-03, 7.9817e-04, 2.4815e-06, 1.1232e-04, 1.0503e-09, 5.1910e-01,\n",
            "        8.1888e-09, 2.9913e-04, 1.2801e-05, 1.2583e-02, 1.9913e-02, 6.6669e-06,\n",
            "        8.8595e-05, 3.0473e-04, 6.8061e-05, 1.6682e-04, 4.8883e-11, 3.1806e-05,\n",
            "        2.5087e-05, 6.0005e-05, 1.0169e-03, 1.0062e-02, 2.1964e-06, 8.7221e-05,\n",
            "        1.7485e-03, 4.6743e-10, 9.9483e-07, 2.6479e-03, 7.5263e-05, 4.3009e-05,\n",
            "        2.6561e-02, 4.8277e-03, 2.7638e-04, 8.9096e-13, 6.9112e-07, 2.3347e-09,\n",
            "        4.1086e-04, 3.4463e-04, 4.5687e-06, 4.1006e-04, 7.3035e-10, 3.2848e-05,\n",
            "        2.9676e-05, 5.6433e-04, 6.7091e-03, 1.9913e-02, 5.9721e-04, 1.4316e-08,\n",
            "        2.8073e-04, 1.9672e-05, 3.5137e-05, 1.6243e-06, 7.8414e-05, 3.0997e-01,\n",
            "        2.1291e-05, 8.5143e-03, 3.0892e-04, 3.9990e-02, 2.8183e-04, 1.2742e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [11]\n",
            "DEBUGGING: logits looks like: tensor([1317.6865, 1318.6483, 1318.4617, 1318.8148, 1317.7373, 1318.7491,\n",
            "        1319.0753, 1318.8420, 1318.2646, 1318.6459, 1317.4879, 1319.4897,\n",
            "        1317.6932, 1318.7439, 1318.4287, 1319.1178, 1319.1637, 1318.3635,\n",
            "        1318.6222, 1318.7457, 1318.5958, 1318.6854, 1317.1812, 1318.5198,\n",
            "        1318.4960, 1318.5833, 1318.8662, 1319.0955, 1318.2524, 1318.6206,\n",
            "        1318.9204, 1317.4070, 1318.1732, 1318.9619, 1318.6058, 1318.5499,\n",
            "        1319.1925, 1319.0220, 1318.7360, 1316.7806, 1318.1368, 1317.5677,\n",
            "        1318.7756, 1318.7581, 1318.3257, 1318.7754, 1317.4515, 1318.5229,\n",
            "        1318.5128, 1318.8074, 1319.0549, 1319.1637, 1318.8130, 1317.7491,\n",
            "        1318.7375, 1318.4717, 1318.5297, 1318.2223, 1318.6100, 1319.4382,\n",
            "        1318.4796, 1319.0787, 1318.7471, 1319.2334, 1318.7379, 1318.8888],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.5665e-06, 1.7401e-02, 3.7527e-02, 9.8648e-04, 1.4313e-02, 1.4954e-03,\n",
            "        3.3113e-03, 1.7606e-02, 1.0238e-03, 1.5103e-02, 2.1865e-03, 4.1987e-02,\n",
            "        2.7806e-02, 4.4298e-03, 2.7242e-02, 2.3645e-02, 9.1695e-03, 3.0960e-02,\n",
            "        1.6898e-02, 1.5266e-02, 1.8632e-02, 1.4398e-02, 2.0185e-02, 6.1441e-03,\n",
            "        1.1180e-02, 1.9583e-02, 3.0208e-03, 1.2327e-02, 1.3171e-03, 1.6523e-02,\n",
            "        2.0563e-02, 1.1971e-02, 3.8902e-03, 4.8890e-03, 1.2387e-02, 7.4839e-03,\n",
            "        1.0942e-02, 1.5934e-03, 5.0639e-03, 1.1268e-02, 2.0948e-02, 1.0720e-02,\n",
            "        1.1832e-02, 9.4145e-03, 1.7953e-02, 8.5804e-03, 1.7612e-06, 1.2472e-02,\n",
            "        1.0783e-02, 4.4951e-03, 7.3320e-03, 2.4559e-03, 7.8431e-03, 1.1268e-02,\n",
            "        1.8523e-02, 1.6346e-02, 6.8811e-03, 1.8907e-02, 1.2667e-03, 1.0910e-02,\n",
            "        3.5391e-02, 8.8355e-03, 1.2779e-03, 4.1695e-03, 1.9698e-02, 1.1971e-02,\n",
            "        1.7097e-02, 1.7503e-02, 5.4754e-03, 1.7418e-02, 4.3745e-02, 2.6122e-02,\n",
            "        3.5048e-02, 4.8414e-03, 4.5883e-03, 4.8414e-03, 6.0371e-03, 5.2862e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [32]\n",
            "DEBUGGING: logits looks like: tensor([1318.6349, 1319.5664, 1319.6433, 1319.2794, 1319.5469, 1319.3210,\n",
            "        1319.4005, 1319.5676, 1319.2831, 1319.5522, 1319.3590, 1319.6545,\n",
            "        1319.6133, 1319.4296, 1319.6112, 1319.5970, 1319.5023, 1319.6240,\n",
            "        1319.5635, 1319.5533, 1319.5732, 1319.5475, 1319.5813, 1319.4623,\n",
            "        1319.5222, 1319.5782, 1319.3914, 1319.5320, 1319.3083, 1319.5613,\n",
            "        1319.5831, 1319.5291, 1319.4166, 1319.4395, 1319.5325, 1319.4821,\n",
            "        1319.5200, 1319.3274, 1319.4430, 1319.5229, 1319.5850, 1319.5179,\n",
            "        1319.5278, 1319.5050, 1319.5696, 1319.4957, 1318.6466, 1319.5331,\n",
            "        1319.5186, 1319.4310, 1319.4800, 1319.3706, 1319.4867, 1319.5229,\n",
            "        1319.5726, 1319.5602, 1319.4736, 1319.5747, 1319.3044, 1319.5198,\n",
            "        1319.6375, 1319.4987, 1319.3053, 1319.4236, 1319.5789, 1319.5291,\n",
            "        1319.5647, 1319.5670, 1319.4508, 1319.5665, 1319.6586, 1319.6071,\n",
            "        1319.6365, 1319.4385, 1319.4331, 1319.4385, 1319.4606, 1319.4473],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([7.8043e-06, 1.1305e-02, 9.3174e-03, 1.1698e-02, 9.5477e-03, 1.1076e-02,\n",
            "        1.2898e-02, 1.0925e-02, 1.1427e-02, 1.1952e-02, 9.4734e-03, 1.2128e-02,\n",
            "        1.2128e-02, 1.1130e-02, 1.2848e-02, 1.2248e-02, 1.2093e-02, 1.3025e-02,\n",
            "        1.0914e-02, 1.1698e-02, 1.2128e-02, 1.0830e-02, 1.1801e-02, 1.0006e-02,\n",
            "        1.2034e-02, 1.1250e-02, 1.1778e-02, 1.1952e-02, 1.1360e-02, 1.1261e-02,\n",
            "        1.2886e-02, 1.2058e-02, 1.0075e-02, 1.2176e-02, 1.1630e-02, 9.4089e-03,\n",
            "        1.1584e-02, 1.2105e-02, 9.8220e-03, 1.1438e-02, 1.0223e-02, 1.1607e-02,\n",
            "        1.1664e-02, 1.0104e-02, 1.0415e-02, 9.9572e-03, 1.1584e-02, 1.2898e-02,\n",
            "        1.1472e-02, 1.0568e-02, 1.1316e-02, 1.1086e-02, 9.2449e-03, 1.0154e-02,\n",
            "        8.1109e-03, 1.0883e-02, 1.1272e-02, 1.2128e-02, 8.8043e-03, 9.5291e-03,\n",
            "        1.2673e-02, 1.1952e-02, 1.3050e-02, 1.2477e-02, 1.2835e-02, 1.0173e-02,\n",
            "        1.1294e-02, 7.1369e-03, 1.0936e-02, 1.0293e-02, 9.5944e-03, 1.1054e-02,\n",
            "        1.1687e-02, 1.1584e-02, 1.1517e-02, 1.1710e-02, 1.3690e-02, 1.2428e-02,\n",
            "        1.0893e-02, 1.2823e-02, 7.7774e-03, 1.1349e-02, 1.1917e-02, 9.8124e-03,\n",
            "        9.9766e-03, 1.1427e-02, 1.1652e-02, 1.5589e-02, 1.0568e-02, 1.1687e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [12]\n",
            "DEBUGGING: logits looks like: tensor([1319.1721, 1319.8999, 1319.8806, 1319.9033, 1319.8831, 1319.8978,\n",
            "        1319.9131, 1319.8965, 1319.9010, 1319.9055, 1319.8822, 1319.9070,\n",
            "        1319.9070, 1319.8983, 1319.9127, 1319.9080, 1319.9066, 1319.9141,\n",
            "        1319.8964, 1319.9033, 1319.9070, 1319.8956, 1319.9042, 1319.8877,\n",
            "        1319.9061, 1319.8994, 1319.9041, 1319.9055, 1319.9004, 1319.8995,\n",
            "        1319.9130, 1319.9064, 1319.8884, 1319.9073, 1319.9027, 1319.8816,\n",
            "        1319.9023, 1319.9067, 1319.8859, 1319.9011, 1319.8899, 1319.9026,\n",
            "        1319.9031, 1319.8887, 1319.8917, 1319.8872, 1319.9023, 1319.9131,\n",
            "        1319.9014, 1319.8932, 1319.9000, 1319.8979, 1319.8798, 1319.8892,\n",
            "        1319.8667, 1319.8961, 1319.8997, 1319.9070, 1319.8749, 1319.8828,\n",
            "        1319.9114, 1319.9055, 1319.9143, 1319.9098, 1319.9126, 1319.8894,\n",
            "        1319.8998, 1319.8539, 1319.8966, 1319.8905, 1319.8835, 1319.8977,\n",
            "        1319.9032, 1319.9023, 1319.9017, 1319.9034, 1319.9191, 1319.9094,\n",
            "        1319.8962, 1319.9125, 1319.8625, 1319.9003, 1319.9052, 1319.8857,\n",
            "        1319.8875, 1319.9010, 1319.9030, 1319.9320, 1319.8932, 1319.9032],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([4.1456e-06, 1.1056e-02, 9.2557e-03, 9.6338e-03, 1.0457e-02, 1.1002e-02,\n",
            "        1.0981e-02, 1.1034e-02, 9.4383e-03, 1.0674e-02, 1.0927e-02, 1.0225e-02,\n",
            "        1.0027e-02, 1.0821e-02, 1.0601e-02, 9.6150e-03, 9.5869e-03, 1.0509e-02,\n",
            "        1.1485e-02, 1.0366e-02, 1.1078e-02, 1.0027e-02, 1.0664e-02, 1.0768e-02,\n",
            "        1.1088e-02, 1.0821e-02, 1.1034e-02, 1.1045e-02, 1.1263e-02, 9.7379e-03,\n",
            "        1.1110e-02, 1.1598e-02, 1.0981e-02, 9.3010e-03, 1.0215e-02, 1.1519e-02,\n",
            "        9.8623e-03, 9.6150e-03, 1.0468e-02, 9.1211e-03, 8.1284e-03, 1.0457e-02,\n",
            "        1.0821e-02, 1.0863e-02, 1.0205e-02, 9.6338e-03, 1.0175e-02, 1.0447e-02,\n",
            "        1.0155e-02, 1.0685e-02, 1.0560e-02, 9.2106e-03, 1.0821e-02, 9.6715e-03,\n",
            "        1.0874e-02, 1.1769e-02, 1.0356e-02, 9.9299e-03, 1.0821e-02, 8.5184e-03,\n",
            "        1.0155e-02, 8.8491e-03, 1.0991e-02, 1.0215e-02, 1.0601e-02, 1.1208e-02,\n",
            "        1.1219e-02, 1.1088e-02, 1.0366e-02, 1.1485e-02, 1.0356e-02, 1.0927e-02,\n",
            "        1.0674e-02, 9.4383e-03, 1.0519e-02, 1.0895e-02, 8.6020e-03, 1.0674e-02,\n",
            "        1.0917e-02, 1.1296e-02, 1.1363e-02, 1.0726e-02, 9.1658e-03, 1.0096e-02,\n",
            "        1.0622e-02, 1.0716e-02, 1.0664e-02, 8.4935e-03, 9.1837e-03, 1.0789e-02,\n",
            "        1.1241e-02, 1.0821e-02, 1.0315e-02, 1.1418e-02, 1.0215e-02, 1.0376e-02,\n",
            "        1.0195e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [18]\n",
            "DEBUGGING: logits looks like: tensor([1319.5194, 1320.3083, 1320.2905, 1320.2946, 1320.3027, 1320.3079,\n",
            "        1320.3076, 1320.3081, 1320.2925, 1320.3048, 1320.3071, 1320.3005,\n",
            "        1320.2986, 1320.3062, 1320.3041, 1320.2943, 1320.2941, 1320.3032,\n",
            "        1320.3121, 1320.3019, 1320.3085, 1320.2986, 1320.3047, 1320.3057,\n",
            "        1320.3086, 1320.3062, 1320.3081, 1320.3082, 1320.3102, 1320.2957,\n",
            "        1320.3088, 1320.3131, 1320.3076, 1320.2910, 1320.3004, 1320.3124,\n",
            "        1320.2969, 1320.2943, 1320.3029, 1320.2891, 1320.2776, 1320.3027,\n",
            "        1320.3062, 1320.3065, 1320.3003, 1320.2946, 1320.3000, 1320.3026,\n",
            "        1320.2998, 1320.3049, 1320.3037, 1320.2900, 1320.3062, 1320.2949,\n",
            "        1320.3066, 1320.3146, 1320.3018, 1320.2976, 1320.3062, 1320.2822,\n",
            "        1320.2998, 1320.2860, 1320.3077, 1320.3004, 1320.3041, 1320.3097,\n",
            "        1320.3098, 1320.3086, 1320.3019, 1320.3121, 1320.3018, 1320.3071,\n",
            "        1320.3048, 1320.2925, 1320.3033, 1320.3069, 1320.2832, 1320.3048,\n",
            "        1320.3070, 1320.3104, 1320.3110, 1320.3053, 1320.2896, 1320.2992,\n",
            "        1320.3043, 1320.3052, 1320.3047, 1320.2820, 1320.2898, 1320.3059,\n",
            "        1320.3099, 1320.3062, 1320.3014, 1320.3115, 1320.3004, 1320.3020,\n",
            "        1320.3002], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([4.2030e-06, 9.1396e-03, 9.6157e-03, 9.4573e-03, 9.4944e-03, 9.3289e-03,\n",
            "        9.4113e-03, 9.5129e-03, 9.6063e-03, 9.3198e-03, 9.5129e-03, 9.5129e-03,\n",
            "        9.3289e-03, 9.6063e-03, 9.5408e-03, 9.4666e-03, 9.4113e-03, 9.3746e-03,\n",
            "        9.5502e-03, 9.6439e-03, 9.4297e-03, 9.6063e-03, 9.5502e-03, 9.4666e-03,\n",
            "        9.5408e-03, 9.4573e-03, 9.4666e-03, 9.6439e-03, 9.3289e-03, 9.2473e-03,\n",
            "        9.5129e-03, 9.4573e-03, 9.3380e-03, 9.1574e-03, 9.5502e-03, 9.4573e-03,\n",
            "        9.4573e-03, 9.2022e-03, 8.9803e-03, 9.5502e-03, 9.3654e-03, 8.7980e-03,\n",
            "        9.3746e-03, 9.6157e-03, 9.5408e-03, 9.4297e-03, 9.3746e-03, 9.3746e-03,\n",
            "        9.4573e-03, 9.1843e-03, 9.6911e-03, 9.4573e-03, 9.6439e-03, 9.2926e-03,\n",
            "        9.4113e-03, 9.6439e-03, 9.5502e-03, 9.3746e-03, 9.5222e-03, 8.7894e-03,\n",
            "        9.4021e-03, 9.5502e-03, 9.5129e-03, 9.4666e-03, 9.5595e-03, 9.4944e-03,\n",
            "        9.5408e-03, 9.6533e-03, 9.4297e-03, 9.4297e-03, 9.4481e-03, 9.4944e-03,\n",
            "        9.2473e-03, 9.2473e-03, 9.5595e-03, 9.4021e-03, 9.3198e-03, 9.2383e-03,\n",
            "        9.5129e-03, 9.5502e-03, 9.4481e-03, 9.6816e-03, 9.3198e-03, 9.2835e-03,\n",
            "        9.3746e-03, 9.5222e-03, 9.4021e-03, 9.2926e-03, 9.4021e-03, 9.2473e-03,\n",
            "        9.6439e-03, 9.5502e-03, 9.5129e-03, 9.7576e-03, 9.6439e-03, 9.4113e-03,\n",
            "        9.3198e-03, 9.5969e-03, 8.9540e-03, 9.5129e-03, 9.4944e-03, 9.5688e-03,\n",
            "        9.3380e-03, 9.5595e-03, 8.9278e-03, 9.5688e-03, 9.4758e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [79]\n",
            "DEBUGGING: logits looks like: tensor([1319.8629, 1320.6313, 1320.6365, 1320.6348, 1320.6351, 1320.6334,\n",
            "        1320.6343, 1320.6354, 1320.6364, 1320.6333, 1320.6354, 1320.6354,\n",
            "        1320.6334, 1320.6364, 1320.6356, 1320.6349, 1320.6343, 1320.6339,\n",
            "        1320.6357, 1320.6367, 1320.6345, 1320.6364, 1320.6357, 1320.6349,\n",
            "        1320.6356, 1320.6348, 1320.6349, 1320.6367, 1320.6334, 1320.6326,\n",
            "        1320.6354, 1320.6348, 1320.6335, 1320.6316, 1320.6357, 1320.6348,\n",
            "        1320.6348, 1320.6321, 1320.6296, 1320.6357, 1320.6338, 1320.6276,\n",
            "        1320.6339, 1320.6365, 1320.6356, 1320.6345, 1320.6339, 1320.6339,\n",
            "        1320.6348, 1320.6318, 1320.6372, 1320.6348, 1320.6367, 1320.6331,\n",
            "        1320.6343, 1320.6367, 1320.6357, 1320.6339, 1320.6355, 1320.6274,\n",
            "        1320.6342, 1320.6357, 1320.6354, 1320.6349, 1320.6359, 1320.6351,\n",
            "        1320.6356, 1320.6368, 1320.6345, 1320.6345, 1320.6346, 1320.6351,\n",
            "        1320.6326, 1320.6326, 1320.6359, 1320.6342, 1320.6333, 1320.6324,\n",
            "        1320.6354, 1320.6357, 1320.6346, 1320.6371, 1320.6333, 1320.6329,\n",
            "        1320.6339, 1320.6355, 1320.6342, 1320.6331, 1320.6342, 1320.6326,\n",
            "        1320.6367, 1320.6357, 1320.6354, 1320.6379, 1320.6367, 1320.6343,\n",
            "        1320.6333, 1320.6362, 1320.6293, 1320.6354, 1320.6351, 1320.6360,\n",
            "        1320.6335, 1320.6359, 1320.6290, 1320.6360, 1320.6350],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.10954631587674157 and immediate abs rewards look like: [0.017294578184191778, 0.011014779996003199, 0.008970019261596462, 0.016124257560477417, 0.004231098425407254, 0.004791104357082077, 0.003802886301855324, 0.003862809267047851, 0.0002448850245855283, 0.0005093627810310863, 0.0020266730057301174, 0.013234000783995725, 0.0010561316016719502, 9.518794740870362e-05, 0.00033996139381997637, 0.013755983260125504, 0.0001999606311073876, 0.0008206003794839489, 0.00019207699187973049, 0.00016925024283409584, 0.0002460529076415696, 0.0019439213961049973, 0.0002007743100875814, 0.0005473018200063962, 0.0004778324191647698, 8.976749995781574e-05, 0.00012729864511129563, 0.000365941877134901, 4.542657870842959e-05, 1.8234980416309554e-05, 0.0002007930615945952, 0.0003128803468825936, 0.0002095769154948357, 0.0005600164745374059, 0.0003429028847676818, 1.2059416349075036e-05, 0.000518988414114574, 9.901368684950285e-06, 7.743237802060321e-06, 6.582554306078237e-05, 0.00012183348462713184, 6.921728208908462e-05, 0.00017032682126227883, 2.335173121537082e-06, 1.537760272185551e-05, 4.030987884107162e-05, 3.638083398982417e-07, 4.382132738101063e-05, 2.653046067280229e-06, 4.122995733268908e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 31.562767342743808 and immediate relative rewards look like: [0.5991038410894446, 0.76772848236173, 0.9414272601117304, 2.263481012871865, 0.7466632788621359, 1.0161026165560476, 0.9425364905600796, 1.0956332576869001, 0.0782477546444637, 0.18085566429565006, 0.7916985088577804, 5.643760120798219, 0.4902356586744162, 0.0476011352539758, 0.18215577295136884, 7.86296682692752, 0.12204156853575134, 0.5303343505422062, 0.1310697469744349, 0.12158017692657358, 0.18559987217084928, 1.536277401948918, 0.16599981995728946, 0.47221645726794415, 0.42954044603366454, 0.0839374066034726, 0.12361313900250909, 0.36852513665926007, 0.04738732178628081, 0.019678309622509875, 0.223910509341665, 0.3601834179455257, 0.24882941704217723, 0.6851044786112626, 0.4319204720502548, 0.015625970278101323, 0.6911614000856664, 0.013545032503591473, 0.01087151263516153, 0.09478910518837591, 0.1798310979315182, 0.10466395817677031, 0.2636912033302826, 0.0036994957948712484, 0.02491565416066478, 0.06676408057563697, 0.0006156733568410122, 0.07573675164901586, 0.004680881341512132, 0.07422839420992372]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([2.7739e-07, 9.9172e-03, 6.8906e-02, 1.5943e-01, 1.3608e-02, 8.2781e-03,\n",
            "        5.2056e-03, 7.3268e-03, 7.9514e-11, 9.1719e-03, 2.5247e-03, 6.9572e-03,\n",
            "        1.8783e-02, 5.7061e-03, 3.2170e-02, 7.7462e-03, 9.7254e-03, 1.0322e-02,\n",
            "        6.4659e-03, 1.4815e-02, 3.1150e-02, 7.7299e-04, 1.7853e-02, 2.0448e-02,\n",
            "        5.2107e-03, 1.6221e-03, 3.9294e-03, 4.9672e-03, 7.1442e-02, 3.4206e-03,\n",
            "        1.0252e-02, 1.2807e-03, 2.2565e-03, 2.0750e-02, 1.6834e-03, 1.1812e-02,\n",
            "        1.7955e-03, 3.1272e-02, 4.4186e-02, 1.1869e-02, 1.1083e-03, 2.6168e-05,\n",
            "        4.0541e-03, 9.3972e-04, 6.0377e-04, 3.5292e-03, 2.4738e-02, 3.2008e-03,\n",
            "        1.9244e-03, 2.4283e-02, 1.8964e-03, 9.6780e-03, 1.0152e-02, 3.1150e-02,\n",
            "        7.8070e-03, 3.6382e-02, 4.8576e-02, 2.5644e-03, 7.6560e-03, 4.1335e-04,\n",
            "        1.3021e-03, 1.1139e-02, 1.2871e-02, 4.8057e-02, 1.7694e-03, 1.8345e-03,\n",
            "        2.0971e-03, 5.2107e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [15]\n",
            "DEBUGGING: logits looks like: tensor([1309.3617, 1310.4102, 1310.6040, 1310.6879, 1310.4418, 1310.3921,\n",
            "        1310.3457, 1310.3799, 1308.5460, 1310.4023, 1310.2733, 1310.3748,\n",
            "        1310.4740, 1310.3549, 1310.5278, 1310.3855, 1310.4082, 1310.4142,\n",
            "        1310.3674, 1310.4503, 1310.5247, 1310.1550, 1310.4690, 1310.4825,\n",
            "        1310.3458, 1310.2291, 1310.3176, 1310.3411, 1310.6077, 1310.3037,\n",
            "        1310.4135, 1310.2054, 1310.2621, 1310.4840, 1310.2328, 1310.4276,\n",
            "        1310.2393, 1310.5250, 1310.5596, 1310.4281, 1310.1910, 1309.8164,\n",
            "        1310.3207, 1310.1746, 1310.1302, 1310.3069, 1310.5016, 1310.2971,\n",
            "        1310.2462, 1310.4998, 1310.2448, 1310.4077, 1310.4125, 1310.5247,\n",
            "        1310.3862, 1310.5402, 1310.5691, 1310.2749, 1310.3843, 1310.0924,\n",
            "        1310.2072, 1310.4218, 1310.4363, 1310.5680, 1310.2378, 1310.2415,\n",
            "        1310.2548, 1310.3458], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([6.2882e-06, 1.1594e-02, 6.5097e-03, 1.5955e-02, 7.8140e-03, 9.8297e-03,\n",
            "        7.6928e-03, 8.7512e-03, 4.8851e-03, 9.6208e-03, 1.8892e-02, 1.4471e-02,\n",
            "        1.8097e-02, 1.0691e-02, 1.6705e-02, 9.8875e-03, 1.3741e-02, 1.9973e-02,\n",
            "        2.7839e-02, 1.3754e-02, 1.3741e-02, 1.5479e-02, 4.4697e-03, 1.2114e-02,\n",
            "        8.8804e-03, 1.0311e-02, 1.3150e-02, 1.1470e-02, 1.0423e-02, 1.2770e-02,\n",
            "        1.0515e-02, 8.0463e-03, 2.1893e-02, 1.2585e-02, 8.6662e-03, 2.0228e-02,\n",
            "        9.8201e-03, 1.5003e-02, 1.1369e-02, 1.0712e-02, 2.4022e-02, 2.5126e-02,\n",
            "        1.8364e-02, 1.2186e-02, 1.1492e-02, 1.1526e-02, 8.5402e-03, 6.7229e-03,\n",
            "        1.2858e-02, 5.7617e-03, 1.5329e-02, 1.4177e-02, 1.3150e-02, 3.2515e-02,\n",
            "        1.0827e-02, 1.0525e-02, 1.1962e-02, 6.3218e-03, 9.1802e-03, 1.7540e-02,\n",
            "        1.8873e-02, 1.1822e-02, 1.3567e-02, 1.0352e-02, 1.0082e-02, 1.0923e-02,\n",
            "        1.7904e-02, 1.4959e-02, 9.9068e-03, 1.5754e-02, 2.3465e-02, 1.8186e-02,\n",
            "        8.7427e-03, 1.5616e-02, 8.1491e-03, 1.3781e-02, 1.1436e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [2]\n",
            "DEBUGGING: logits looks like: tensor([1309.6934, 1310.4453, 1310.3876, 1310.4773, 1310.4059, 1310.4288,\n",
            "        1310.4043, 1310.4172, 1310.3589, 1310.4266, 1310.4941, 1310.4675,\n",
            "        1310.4899, 1310.4373, 1310.4818, 1310.4294, 1310.4623, 1310.4998,\n",
            "        1310.5330, 1310.4624, 1310.4623, 1310.4742, 1310.3500, 1310.4497,\n",
            "        1310.4187, 1310.4336, 1310.4579, 1310.4442, 1310.4347, 1310.4550,\n",
            "        1310.4355, 1310.4088, 1310.5089, 1310.4535, 1310.4163, 1310.5010,\n",
            "        1310.4287, 1310.4711, 1310.4434, 1310.4374, 1310.5182, 1310.5227,\n",
            "        1310.4913, 1310.4503, 1310.4445, 1310.4447, 1310.4148, 1310.3909,\n",
            "        1310.4557, 1310.3754, 1310.4733, 1310.4655, 1310.4579, 1310.5485,\n",
            "        1310.4385, 1310.4357, 1310.4485, 1310.3846, 1310.4220, 1310.4867,\n",
            "        1310.4940, 1310.4473, 1310.4611, 1310.4340, 1310.4314, 1310.4393,\n",
            "        1310.4888, 1310.4708, 1310.4296, 1310.4760, 1310.5159, 1310.4904,\n",
            "        1310.4171, 1310.4751, 1310.4100, 1310.4626, 1310.4440],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.4184e-05, 1.4052e-02, 1.2971e-02, 7.0454e-03, 1.1258e-02, 5.1144e-03,\n",
            "        1.2079e-02, 1.4274e-02, 8.1568e-03, 1.1949e-02, 1.4527e-02, 9.6299e-03,\n",
            "        8.5066e-03, 7.7303e-03, 1.4025e-02, 1.3448e-02, 1.0743e-02, 7.5144e-03,\n",
            "        9.1263e-03, 1.4527e-02, 1.3727e-02, 7.3475e-03, 1.4204e-02, 8.6744e-03,\n",
            "        1.1425e-02, 7.1913e-03, 1.2173e-02, 1.1961e-02, 1.0965e-02, 1.2757e-02,\n",
            "        1.1938e-02, 1.0331e-02, 1.6285e-02, 9.6299e-03, 1.0494e-02, 1.1182e-02,\n",
            "        1.3821e-02, 9.0111e-03, 1.0112e-02, 1.2511e-02, 1.2560e-02, 1.0859e-02,\n",
            "        8.6322e-03, 1.1741e-02, 9.8006e-03, 1.6509e-02, 1.0231e-02, 1.0494e-02,\n",
            "        9.7529e-03, 1.1041e-02, 8.3829e-03, 1.1369e-02, 6.7755e-03, 1.1347e-02,\n",
            "        1.3727e-02, 1.0774e-02, 1.3227e-02, 1.0545e-02, 1.3292e-02, 2.6925e-03,\n",
            "        1.1425e-02, 1.0597e-02, 8.8196e-03, 1.0670e-02, 1.0494e-02, 1.0933e-02,\n",
            "        1.6445e-02, 1.2293e-02, 1.0082e-02, 1.1492e-02, 1.1833e-02, 1.0013e-02,\n",
            "        9.6017e-03, 1.3501e-02, 1.2807e-02, 1.3862e-02, 8.7595e-03, 1.4274e-02,\n",
            "        9.2339e-03, 1.4163e-02, 1.4988e-02, 1.4756e-02, 1.1537e-02, 1.2031e-02,\n",
            "        1.2269e-02, 1.2683e-02, 9.1352e-03, 1.4025e-02, 1.1127e-02, 9.9647e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [36]\n",
            "DEBUGGING: logits looks like: tensor([1309.9304, 1310.6202, 1310.6122, 1310.5511, 1310.5980, 1310.5192,\n",
            "        1310.6051, 1310.6218, 1310.5658, 1310.6040, 1310.6235, 1310.5824,\n",
            "        1310.5701, 1310.5604, 1310.6200, 1310.6158, 1310.5934, 1310.5576,\n",
            "        1310.5770, 1310.6235, 1310.6179, 1310.5554, 1310.6213, 1310.5720,\n",
            "        1310.5995, 1310.5532, 1310.6058, 1310.6041, 1310.5955, 1310.6106,\n",
            "        1310.6039, 1310.5895, 1310.6350, 1310.5824, 1310.5911, 1310.5974,\n",
            "        1310.6185, 1310.5758, 1310.5873, 1310.6086, 1310.6090, 1310.5945,\n",
            "        1310.5715, 1310.6023, 1310.5842, 1310.6364, 1310.5885, 1310.5911,\n",
            "        1310.5837, 1310.5961, 1310.5686, 1310.5990, 1310.5472, 1310.5989,\n",
            "        1310.6179, 1310.5936, 1310.6141, 1310.5916, 1310.6146, 1310.4550,\n",
            "        1310.5995, 1310.5920, 1310.5736, 1310.5927, 1310.5911, 1310.5951,\n",
            "        1310.6360, 1310.6068, 1310.5870, 1310.6001, 1310.6030, 1310.5863,\n",
            "        1310.5822, 1310.6162, 1310.6110, 1310.6189, 1310.5730, 1310.6218,\n",
            "        1310.5782, 1310.6210, 1310.6267, 1310.6251, 1310.6005, 1310.6047,\n",
            "        1310.6067, 1310.6100, 1310.5771, 1310.6200, 1310.5969, 1310.5858],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.5029e-05, 1.0735e-02, 1.1988e-02, 1.1022e-02, 1.0894e-02, 1.1965e-02,\n",
            "        1.0174e-02, 8.5590e-03, 1.1240e-02, 1.0194e-02, 1.0134e-02, 1.0344e-02,\n",
            "        1.0979e-02, 9.9772e-03, 1.0662e-02, 1.1417e-02, 1.0756e-02, 1.0652e-02,\n",
            "        1.0507e-02, 1.0036e-02, 1.1350e-02, 1.0579e-02, 1.1328e-02, 1.0254e-02,\n",
            "        1.0046e-02, 1.0631e-02, 9.6420e-03, 1.1619e-02, 1.0904e-02, 1.0559e-02,\n",
            "        1.0704e-02, 8.5340e-03, 1.0507e-02, 1.1585e-02, 1.0354e-02, 1.0683e-02,\n",
            "        9.7842e-03, 1.0354e-02, 1.0841e-02, 9.7461e-03, 9.0137e-03, 1.1240e-02,\n",
            "        1.0204e-02, 8.8307e-03, 1.0254e-02, 1.0046e-02, 1.0820e-02, 9.1110e-03,\n",
            "        8.7023e-03, 1.1240e-02, 1.0841e-02, 9.0313e-03, 1.1163e-02, 1.1284e-02,\n",
            "        1.0947e-02, 1.1033e-02, 9.0313e-03, 9.7461e-03, 1.0124e-02, 1.1001e-02,\n",
            "        1.0714e-02, 1.0375e-02, 1.1240e-02, 1.0046e-02, 8.9174e-03, 1.0425e-02,\n",
            "        1.1461e-02, 1.1174e-02, 1.1185e-02, 7.3711e-03, 8.6599e-03, 8.8913e-03,\n",
            "        9.6986e-03, 1.0324e-02, 1.0174e-02, 1.0354e-02, 1.0194e-02, 1.0425e-02,\n",
            "        9.0578e-03, 1.0294e-02, 1.0841e-02, 1.0641e-02, 1.0425e-02, 1.0641e-02,\n",
            "        9.8996e-03, 9.6044e-03, 7.7400e-03, 8.4676e-03, 1.0735e-02, 1.1988e-02,\n",
            "        1.0756e-02, 7.9545e-03, 1.1218e-02, 1.0631e-02, 1.1676e-02, 9.0932e-03,\n",
            "        1.0841e-02, 9.9480e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [43]\n",
            "DEBUGGING: logits looks like: tensor([1310.1172, 1310.7743, 1310.7854, 1310.7770, 1310.7758, 1310.7852,\n",
            "        1310.7689, 1310.7517, 1310.7789, 1310.7692, 1310.7686, 1310.7706,\n",
            "        1310.7766, 1310.7670, 1310.7737, 1310.7805, 1310.7745, 1310.7736,\n",
            "        1310.7722, 1310.7676, 1310.7799, 1310.7728, 1310.7797, 1310.7698,\n",
            "        1310.7677, 1310.7733, 1310.7635, 1310.7822, 1310.7759, 1310.7727,\n",
            "        1310.7740, 1310.7513, 1310.7722, 1310.7820, 1310.7708, 1310.7738,\n",
            "        1310.7650, 1310.7708, 1310.7753, 1310.7646, 1310.7568, 1310.7789,\n",
            "        1310.7693, 1310.7548, 1310.7698, 1310.7677, 1310.7751, 1310.7579,\n",
            "        1310.7533, 1310.7789, 1310.7753, 1310.7571, 1310.7782, 1310.7793,\n",
            "        1310.7762, 1310.7771, 1310.7571, 1310.7646, 1310.7684, 1310.7767,\n",
            "        1310.7742, 1310.7709, 1310.7789, 1310.7677, 1310.7557, 1310.7714,\n",
            "        1310.7809, 1310.7783, 1310.7784, 1310.7367, 1310.7528, 1310.7555,\n",
            "        1310.7642, 1310.7704, 1310.7689, 1310.7708, 1310.7692, 1310.7714,\n",
            "        1310.7573, 1310.7701, 1310.7753, 1310.7734, 1310.7714, 1310.7734,\n",
            "        1310.7662, 1310.7632, 1310.7416, 1310.7506, 1310.7743, 1310.7854,\n",
            "        1310.7745, 1310.7444, 1310.7787, 1310.7733, 1310.7827, 1310.7577,\n",
            "        1310.7753, 1310.7667], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.5063e-05, 9.3389e-03, 9.0340e-03, 9.1852e-03, 9.5046e-03, 8.8939e-03,\n",
            "        9.0605e-03, 9.2482e-03, 9.1048e-03, 9.2482e-03, 9.2121e-03, 9.2844e-03,\n",
            "        9.2301e-03, 9.1852e-03, 9.1673e-03, 9.1048e-03, 9.4214e-03, 9.2753e-03,\n",
            "        9.1048e-03, 9.5698e-03, 9.1942e-03, 9.1048e-03, 9.5138e-03, 9.2301e-03,\n",
            "        9.4214e-03, 9.1852e-03, 9.0340e-03, 9.2031e-03, 8.9899e-03, 9.3663e-03,\n",
            "        9.1942e-03, 9.1852e-03, 8.9812e-03, 9.1226e-03, 8.9812e-03, 9.1673e-03,\n",
            "        9.3755e-03, 8.5950e-03, 9.1852e-03, 9.5791e-03, 9.2121e-03, 8.8075e-03,\n",
            "        9.1852e-03, 8.9287e-03, 9.1226e-03, 9.2482e-03, 9.4122e-03, 8.6034e-03,\n",
            "        9.1942e-03, 9.2031e-03, 9.1137e-03, 9.0251e-03, 9.0605e-03, 9.3207e-03,\n",
            "        9.1673e-03, 9.2753e-03, 9.2031e-03, 9.1048e-03, 9.2482e-03, 9.1942e-03,\n",
            "        9.1494e-03, 9.2301e-03, 9.2844e-03, 9.1404e-03, 9.1048e-03, 9.1494e-03,\n",
            "        9.0959e-03, 9.2482e-03, 9.3298e-03, 9.2031e-03, 9.1404e-03, 9.3298e-03,\n",
            "        9.2844e-03, 9.2753e-03, 9.2844e-03, 9.1673e-03, 9.2482e-03, 8.9200e-03,\n",
            "        9.3938e-03, 9.0959e-03, 9.1048e-03, 9.3481e-03, 9.1942e-03, 8.6287e-03,\n",
            "        9.2844e-03, 9.2844e-03, 9.2482e-03, 9.1494e-03, 8.9287e-03, 9.4214e-03,\n",
            "        9.1048e-03, 9.2121e-03, 9.2753e-03, 9.0516e-03, 9.1852e-03, 8.5867e-03,\n",
            "        9.4306e-03, 9.0251e-03, 9.0959e-03, 9.1852e-03, 9.4122e-03, 9.0251e-03,\n",
            "        9.0693e-03, 9.1494e-03, 9.3389e-03, 8.9637e-03, 9.0251e-03, 9.3389e-03,\n",
            "        9.4398e-03, 8.9899e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [102]\n",
            "DEBUGGING: logits looks like: tensor([1310.2673, 1310.9103, 1310.9070, 1310.9086, 1310.9120, 1310.9054,\n",
            "        1310.9072, 1310.9093, 1310.9077, 1310.9093, 1310.9089, 1310.9097,\n",
            "        1310.9091, 1310.9086, 1310.9084, 1310.9077, 1310.9111, 1310.9095,\n",
            "        1310.9077, 1310.9127, 1310.9087, 1310.9077, 1310.9121, 1310.9091,\n",
            "        1310.9111, 1310.9086, 1310.9070, 1310.9088, 1310.9065, 1310.9105,\n",
            "        1310.9087, 1310.9086, 1310.9064, 1310.9080, 1310.9064, 1310.9084,\n",
            "        1310.9106, 1310.9020, 1310.9086, 1310.9128, 1310.9089, 1310.9044,\n",
            "        1310.9086, 1310.9058, 1310.9080, 1310.9093, 1310.9110, 1310.9021,\n",
            "        1310.9087, 1310.9088, 1310.9078, 1310.9069, 1310.9072, 1310.9100,\n",
            "        1310.9084, 1310.9095, 1310.9088, 1310.9077, 1310.9093, 1310.9087,\n",
            "        1310.9082, 1310.9091, 1310.9097, 1310.9081, 1310.9077, 1310.9082,\n",
            "        1310.9076, 1310.9093, 1310.9102, 1310.9088, 1310.9081, 1310.9102,\n",
            "        1310.9097, 1310.9095, 1310.9097, 1310.9084, 1310.9093, 1310.9056,\n",
            "        1310.9109, 1310.9076, 1310.9077, 1310.9104, 1310.9087, 1310.9023,\n",
            "        1310.9097, 1310.9097, 1310.9093, 1310.9082, 1310.9058, 1310.9111,\n",
            "        1310.9077, 1310.9089, 1310.9095, 1310.9071, 1310.9086, 1310.9019,\n",
            "        1310.9113, 1310.9069, 1310.9076, 1310.9086, 1310.9110, 1310.9069,\n",
            "        1310.9073, 1310.9082, 1310.9103, 1310.9061, 1310.9069, 1310.9103,\n",
            "        1310.9114, 1310.9065], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.1601183477359882 and immediate abs rewards look like: [0.04164546393121782, 0.0025865620191325434, 0.035761963975801336, 0.004318381637403945, 0.02553931731108605, 0.007563602687696402, 0.011396109211091243, 0.005315734639680159, 0.003704405603457417, 0.0029832879363311804, 0.0035896971085094265, 0.0027741791600419674, 0.007073429411320831, 0.00046721611033717636, 0.0008136787064358941, 6.403060842785635e-05, 2.4649989427416585e-05, 0.00016622833709334373, 0.00038988833875919227, 8.622261930213426e-05, 0.0001687732724349189, 5.6296196362382034e-05, 0.00035362010521566845, 7.782863758620806e-05, 1.3385301826929208e-05, 6.259517249418423e-06, 9.688272211860749e-05, 8.910406450013397e-05, 0.00025173496760544367, 3.432823405091767e-05, 7.806884605088271e-05, 4.714723445431446e-05, 0.00017414274589100387, 0.00034275148436790914, 0.0006095350704526936, 0.00013576955279859249, 0.00020249154476914555, 8.200148386094952e-05, 0.00019222341097702156, 0.00012486422428992228, 0.0002419794436718803, 0.00012852520831074798, 0.00014562368323822739, 4.1509110815241e-07, 1.0970861694659106e-06, 6.190852673171321e-06, 8.893548056221334e-06, 3.207446115993662e-05, 7.067700198604143e-05, 8.161340019796626e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 23.848442889321717 and immediate relative rewards look like: [1.123044343965312, 0.1410870022492018, 2.9280817975307842, 0.47608144430240473, 3.5236822438304727, 1.2611561866716332, 2.2215565633297247, 1.188054884392716, 0.9328025026686645, 0.8355533588689663, 1.1068595989462933, 0.9341035424468462, 2.5822057226964015, 0.18404618115518515, 0.3434648293123513, 0.028836671360807586, 0.011795354636285713, 0.08422207225115623, 0.2085271105610422, 0.04854757630523513, 0.09978145984324538, 0.03486978400633493, 0.2289914104979081, 0.052595467298603, 0.009422699541591579, 0.0045827164991697755, 0.07365795634606069, 0.07025495542004537, 0.20557668435170257, 0.029002525558402784, 0.06815641730457817, 0.042489639795865425, 0.16184598965199357, 0.3282178346902784, 0.6009143621222494, 0.13769726044154876, 0.21107929788418023, 0.08779445914095374, 0.21122373620156037, 0.1407321655801395, 0.27955867055401473, 0.1521170365281433, 0.1764641326986882, 0.0005147186550443659, 0.0013913202518150017, 0.008025688283100381, 0.011780064241686929, 0.04338868018701732, 0.0976009305112793, 0.11500583775302733]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 150 number of matrices\n",
            "DEBUGGING: ACT_MAT has 150 number of matrices\n",
            "DEBUGGING: VAL looks like: [[24.80958867650111, 24.620771735097527, 24.720158177566702, 15.884655207742526, 14.553015595080907, 13.272323879664423, 12.980710759366872, 11.800296630689358, 10.039363876338445, 9.869007042033603, 6.0311125256648035, 4.659125346525493, 4.408095716054497, 4.3736546295858405, 4.304993744640951, 3.550808384285435, 3.0942283594889686, 2.7721548411482506, 2.6494733137065727, 2.6760298887515637, 2.56826535796736, 2.587661416503635, 2.4808357347634904, 2.0913957757791004, 1.9467964817617949, 1.9645621967051288, 1.9649398248489547, 1.8071104776940203, 1.801217855191957, 1.7957889892507903, 1.4830853438618694, 1.3042232190631897, 0.9843489187914864, 0.970535889257462, 0.9477918028877299, 0.8486064059318595, 0.8560348885588519, 0.849899911313342, 0.8577510610561021, 0.8228825397710342, 0.8093948295184397, 0.6562055207247797, 0.6557522050170222, 0.654676785643195, 0.6441222614158449, 0.6237581948951745, 0.5859309697566849, 0.5309938048427729, 0.013125200870704722, 0.00047296836983330107], [27.46843464941387, 27.140738190226692, 26.639403745318145, 25.957552005259004, 23.93340504281529, 23.42095127672036, 22.631160262792235, 21.90770078003248, 21.0222904266117, 21.155598658552762, 21.186609085108195, 20.600919773990316, 15.108242073931411, 14.765663045714136, 14.866729202485011, 14.832902454074386, 7.040339017320066, 6.988179241196278, 6.523075647125324, 6.456571616314029, 6.3989812519065215, 6.276142807813811, 4.787742834206963, 4.668427287120882, 4.238596797831251, 3.847531668482411, 3.8016103655342808, 3.715148713668456, 3.3804278555648444, 3.366707609877337, 3.380837677025078, 3.188815320892336, 2.8572039423705156, 2.634721742755897, 1.9693103678228632, 1.5529190866389984, 1.5528213296574718, 0.8703635652240459, 0.8654732653741963, 0.8632340936757927, 0.7762070590781989, 0.6023999607542229, 0.5027636389671238, 0.24148730872408206, 0.24018971002950587, 0.2174485412816577, 0.15220652596567752, 0.1531220733422591, 0.07816699160933661, 0.07422839420992372], [21.52072938861621, 20.60372226732414, 20.669328550580747, 17.920451265707033, 17.620575577176393, 14.239286195298911, 13.109222230936645, 10.997642088491837, 9.908673943534465, 9.066536808955354, 8.314124697056958, 7.280065755667337, 6.41006284163686, 3.8665223423640986, 3.719672890110014, 3.4103111725228916, 3.4156308092546306, 3.438217630927621, 3.3878743016933988, 3.211461809224603, 3.1948628615347148, 3.1263448501934032, 3.1227020870576445, 2.922940077333067, 2.899337989933802, 2.9191063539315256, 2.943963270133693, 2.899298296755184, 2.85761953670216, 2.678831163990361, 2.676594584274705, 2.6347860272425527, 2.6184811994410984, 2.4814497068576813, 2.174981689057983, 1.5899669969047816, 1.4669391277406392, 1.268545282683292, 1.1926775995377155, 0.9913675387233889, 0.8592276496396459, 0.5855242212986174, 0.437785035121691, 0.2639605074979826, 0.2661068574171093, 0.2673894314800953, 0.26198357898686353, 0.2527308229749259, 0.21145670988677634, 0.11500583775302733]]\n",
            "DEBUGGING: traj_returns = [24.80958867650111, 27.46843464941387, 21.52072938861621]\n",
            "DEBUGGING: actions = [[8], [22], [50], [54], [23], [64], [46], [14], [59], [16], [13], [67], [5], [45], [5], [46], [61], [2], [37], [76], [34], [38], [65], [35], [19], [75], [27], [29], [3], [9], [7], [35], [39], [55], [42], [91], [90], [62], [3], [72], [62], [80], [61], [1], [23], [82], [31], [60], [51], [56], [17], [27], [16], [55], [42], [16], [62], [12], [17], [11], [17], [22], [62], [51], [17], [32], [65], [65], [18], [32], [29], [56], [71], [23], [37], [82], [79], [33], [36], [12], [30], [54], [53], [54], [62], [9], [22], [28], [88], [18], [50], [76], [25], [85], [43], [61], [91], [7], [28], [79], [50], [38], [28], [7], [31], [39], [7], [6], [25], [15], [2], [18], [7], [53], [66], [60], [67], [75], [49], [2], [20], [28], [29], [81], [33], [70], [22], [18], [33], [36], [41], [32], [23], [27], [47], [34], [35], [2], [91], [43], [31], [93], [63], [61], [37], [9], [38], [52], [84], [102]]\n",
            "DEBUGGING: actions length = 150\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[  6.7976,   7.0808,  11.9417,  ...,   4.4227, -12.8340, -19.6740],\n",
            "        [  6.8525,   7.1657,  12.0563,  ...,   4.4549, -12.9455, -19.8645],\n",
            "        [  6.7747,   7.0745,  11.9115,  ...,   4.3975, -12.7680, -19.5802],\n",
            "        ...,\n",
            "        [  6.8577,   7.1543,  12.0545,  ...,   4.4591, -12.9343, -19.8500],\n",
            "        [  6.8577,   7.1542,  12.0544,  ...,   4.4591, -12.9342, -19.8500],\n",
            "        [  6.8577,   7.1542,  12.0544,  ...,   4.4591, -12.9342, -19.8499]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[  6.8549,   7.1499,  12.0467,  ...,   4.4572, -12.9293, -19.8389],\n",
            "        [  6.8577,   7.1542,  12.0544,  ...,   4.4591, -12.9342, -19.8500],\n",
            "        [  6.8577,   7.1542,  12.0544,  ...,   4.4591, -12.9342, -19.8499],\n",
            "        ...,\n",
            "        [  6.8577,   7.1542,  12.0544,  ...,   4.4591, -12.9342, -19.8500],\n",
            "        [  6.8577,   7.1543,  12.0545,  ...,   4.4591, -12.9342, -19.8500],\n",
            "        [  6.8577,   7.1542,  12.0544,  ...,   4.4591, -12.9342, -19.8499]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([1310.2673, 1310.9103, 1310.9070, 1310.9086, 1310.9120, 1310.9054,\n",
            "        1310.9072, 1310.9093, 1310.9077, 1310.9093, 1310.9089, 1310.9097,\n",
            "        1310.9091, 1310.9086, 1310.9084, 1310.9077, 1310.9111, 1310.9095,\n",
            "        1310.9077, 1310.9127, 1310.9087, 1310.9077, 1310.9121, 1310.9091,\n",
            "        1310.9111, 1310.9086, 1310.9070, 1310.9088, 1310.9065, 1310.9105,\n",
            "        1310.9087, 1310.9086, 1310.9064, 1310.9080, 1310.9064, 1310.9084,\n",
            "        1310.9106, 1310.9020, 1310.9086, 1310.9128, 1310.9089, 1310.9044,\n",
            "        1310.9086, 1310.9058, 1310.9080, 1310.9093, 1310.9110, 1310.9021,\n",
            "        1310.9087, 1310.9088, 1310.9078, 1310.9069, 1310.9072, 1310.9100,\n",
            "        1310.9084, 1310.9095, 1310.9088, 1310.9077, 1310.9093, 1310.9087,\n",
            "        1310.9082, 1310.9091, 1310.9097, 1310.9081, 1310.9077, 1310.9082,\n",
            "        1310.9076, 1310.9093, 1310.9102, 1310.9088, 1310.9081, 1310.9102,\n",
            "        1310.9097, 1310.9095, 1310.9097, 1310.9084, 1310.9093, 1310.9056,\n",
            "        1310.9109, 1310.9076, 1310.9077, 1310.9104, 1310.9087, 1310.9023,\n",
            "        1310.9097, 1310.9097, 1310.9093, 1310.9082, 1310.9058, 1310.9111,\n",
            "        1310.9077, 1310.9089, 1310.9095, 1310.9071, 1310.9086, 1310.9019,\n",
            "        1310.9113, 1310.9069, 1310.9076, 1310.9086, 1310.9110, 1310.9069,\n",
            "        1310.9073, 1310.9082, 1310.9103, 1310.9061, 1310.9069, 1310.9103,\n",
            "        1310.9114, 1310.9065], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[24.59958424 24.12174406 24.00963016 19.92088616 18.70233207 16.97752045\n",
            "  16.24036442 14.90187983 13.65677608 13.36371417 11.84394877 10.84670363\n",
            "   8.64213354  7.66861334  7.63046528  7.264674    4.51673273  4.39951724\n",
            "   4.18680775  4.11468777  4.05403649  3.99671636  3.46376022  3.22758771\n",
            "   3.02824376  2.91040007  2.90350449  2.80718583  2.67975508  2.61377592\n",
            "   2.51350587  2.37594152  2.15334469  2.02890245  1.69736129  1.3304975\n",
            "   1.29193178  0.99626959  0.97196731  0.89249472  0.81494318  0.6147099\n",
            "   0.53210029  0.3867082   0.38347294  0.36953206  0.33337369  0.31228223\n",
            "   0.1009163   0.06323573]]\n",
            "DEBUGGING: baseline2 looks like: 24.599584238177062\n",
            "DEBUGGING: ADS looks like: [ 2.10004438e-01  4.99027671e-01  7.10528020e-01 -4.03623095e+00\n",
            " -4.14931648e+00 -3.70519657e+00 -3.25965366e+00 -3.10158320e+00\n",
            " -3.61741221e+00 -3.49470713e+00 -5.81283624e+00 -6.18757828e+00\n",
            " -4.23403783e+00 -3.29495871e+00 -3.32547153e+00 -3.71386562e+00\n",
            " -1.42250437e+00 -1.62736240e+00 -1.53733444e+00 -1.43865788e+00\n",
            " -1.48577113e+00 -1.40905494e+00 -9.82924484e-01 -1.13619194e+00\n",
            " -1.08144727e+00 -9.45837876e-01 -9.38564662e-01 -1.00007535e+00\n",
            " -8.78537227e-01 -8.17986932e-01 -1.03042052e+00 -1.07171830e+00\n",
            " -1.16899577e+00 -1.05836656e+00 -7.49569484e-01 -4.81891091e-01\n",
            " -4.35896893e-01 -1.46369675e-01 -1.14216248e-01 -6.96121843e-02\n",
            " -5.54834989e-03  4.14956198e-02  1.23651912e-01  2.67968585e-01\n",
            "  2.60649318e-01  2.54226139e-01  2.52557278e-01  2.18711571e-01\n",
            " -8.77910999e-02 -6.27627651e-02  2.86885041e+00  3.01899413e+00\n",
            "  2.62977359e+00  6.03666585e+00  5.23107297e+00  6.44343083e+00\n",
            "  6.39079585e+00  7.00582095e+00  7.36551434e+00  7.79188449e+00\n",
            "  9.34266032e+00  9.75421615e+00  6.46610853e+00  7.09704971e+00\n",
            "  7.23626392e+00  7.56822845e+00  2.52360629e+00  2.58866200e+00\n",
            "  2.33626789e+00  2.34188384e+00  2.34494476e+00  2.27942645e+00\n",
            "  1.32398262e+00  1.44083957e+00  1.21035304e+00  9.37131595e-01\n",
            "  8.98105879e-01  9.07962884e-01  7.00672773e-01  7.52931689e-01\n",
            "  8.67331809e-01  8.12873798e-01  7.03859256e-01  6.05819296e-01\n",
            "  2.71949081e-01  2.22421590e-01  2.60889548e-01 -1.25906021e-01\n",
            " -1.06494043e-01 -2.92606304e-02 -3.87361203e-02 -1.23099402e-02\n",
            " -2.93366541e-02 -1.45220892e-01 -1.43283233e-01 -1.52083515e-01\n",
            " -1.81167166e-01 -1.59160160e-01 -2.27493092e-02  1.09926608e-02\n",
            " -3.07885485e+00 -3.51802180e+00 -3.34030161e+00 -2.00043489e+00\n",
            " -1.08175649e+00 -2.73823426e+00 -3.13114219e+00 -3.90423774e+00\n",
            " -3.74810214e+00 -4.29717736e+00 -3.52982407e+00 -3.56663787e+00\n",
            " -2.23207070e+00 -3.80209100e+00 -3.91079239e+00 -3.85436283e+00\n",
            " -1.10110192e+00 -9.61299607e-01 -7.98933452e-01 -9.03225962e-01\n",
            " -8.59173629e-01 -8.70371508e-01 -3.41058132e-01 -3.04647636e-01\n",
            " -1.28905767e-01  8.70628089e-03  4.04587833e-02  9.21124674e-02\n",
            "  1.77864454e-01  6.50552430e-02  1.63088716e-01  2.58844505e-01\n",
            "  4.65136513e-01  4.52547261e-01  4.77620402e-01  2.59469500e-01\n",
            "  1.75007346e-01  2.72275696e-01  2.20710291e-01  9.88728147e-02\n",
            "  4.42844702e-02 -2.91856796e-02 -9.43152579e-02 -1.22747693e-01\n",
            " -1.17366086e-01 -1.02142624e-01 -7.13901126e-02 -5.95514107e-02\n",
            "  1.10540409e-01  5.17701043e-02]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(-0.6332, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.2868, -0.2953,  0.1331,  ..., -0.0941, -0.4046, -0.1150],\n",
            "        [-0.1070,  0.1102, -0.0497,  ...,  0.0351,  0.1509,  0.0434],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0942, -0.0970,  0.0437,  ..., -0.0309, -0.1328, -0.0362],\n",
            "        [ 0.2089, -0.2151,  0.0970,  ..., -0.0685, -0.2947, -0.0806],\n",
            "        [ 0.1355, -0.1395,  0.0629,  ..., -0.0445, -0.1912, -0.0557]])\n",
            "   Last layer:\n",
            "tensor([[-0.0105, -0.0121, -0.0164,  0.0000,  0.0000,  0.0000,  0.0000, -0.0132,\n",
            "          0.0000,  0.0000, -0.0147, -0.0211, -0.0009,  0.0000, -0.0290,  0.0000,\n",
            "         -0.0141,  0.0000, -0.0204,  0.0000],\n",
            "        [-0.0125, -0.0153, -0.0185,  0.0000,  0.0000,  0.0000,  0.0000, -0.0158,\n",
            "          0.0000,  0.0000, -0.0166, -0.0239, -0.0017,  0.0000, -0.0317,  0.0000,\n",
            "         -0.0160,  0.0000, -0.0223,  0.0000],\n",
            "        [-0.0258, -0.0336, -0.0361,  0.0000,  0.0000,  0.0000,  0.0000, -0.0330,\n",
            "          0.0000,  0.0000, -0.0324, -0.0470, -0.0052,  0.0000, -0.0595,  0.0000,\n",
            "         -0.0314,  0.0000, -0.0419,  0.0000],\n",
            "        [ 0.0153,  0.0193,  0.0221,  0.0000,  0.0000,  0.0000,  0.0000,  0.0195,\n",
            "          0.0000,  0.0000,  0.0198,  0.0286,  0.0026,  0.0000,  0.0370,  0.0000,\n",
            "          0.0191,  0.0000,  0.0261,  0.0000],\n",
            "        [ 0.0126,  0.0110,  0.0239,  0.0000,  0.0000,  0.0000,  0.0000,  0.0152,\n",
            "          0.0000,  0.0000,  0.0213,  0.0299, -0.0018,  0.0000,  0.0460,  0.0000,\n",
            "          0.0199,  0.0000,  0.0323,  0.0000],\n",
            "        [ 0.0313,  0.0406,  0.0438,  0.0000,  0.0000,  0.0000,  0.0000,  0.0400,\n",
            "          0.0000,  0.0000,  0.0393,  0.0569,  0.0063,  0.0000,  0.0721,  0.0000,\n",
            "          0.0380,  0.0000,  0.0508,  0.0000],\n",
            "        [-0.0061, -0.0043, -0.0128,  0.0000,  0.0000,  0.0000,  0.0000, -0.0072,\n",
            "          0.0000,  0.0000, -0.0114, -0.0159,  0.0017,  0.0000, -0.0256,  0.0000,\n",
            "         -0.0106,  0.0000, -0.0180,  0.0000],\n",
            "        [-0.0047, -0.0042, -0.0088,  0.0000,  0.0000,  0.0000,  0.0000, -0.0057,\n",
            "          0.0000,  0.0000, -0.0079, -0.0111,  0.0006,  0.0000, -0.0170,  0.0000,\n",
            "         -0.0074,  0.0000, -0.0119,  0.0000],\n",
            "        [ 0.0197,  0.0226,  0.0311,  0.0000,  0.0000,  0.0000,  0.0000,  0.0247,\n",
            "          0.0000,  0.0000,  0.0278,  0.0397,  0.0015,  0.0000,  0.0549,  0.0000,\n",
            "          0.0265,  0.0000,  0.0386,  0.0000],\n",
            "        [ 0.0335,  0.0401,  0.0508,  0.0000,  0.0000,  0.0000,  0.0000,  0.0421,\n",
            "          0.0000,  0.0000,  0.0455,  0.0654,  0.0039,  0.0000,  0.0880,  0.0000,\n",
            "          0.0435,  0.0000,  0.0619,  0.0000]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-0.0122, -0.1080,  0.1470,  ..., -0.0495, -0.0711, -0.0046],\n",
            "        [ 0.0050,  0.0446, -0.0607,  ...,  0.0204,  0.0293, -0.0033],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [-0.0042, -0.0368,  0.0501,  ..., -0.0169, -0.0242, -0.0036],\n",
            "        [-0.0093, -0.0819,  0.1115,  ..., -0.0375, -0.0539, -0.0039],\n",
            "        [-0.0053, -0.0471,  0.0641,  ..., -0.0216, -0.0310,  0.0004]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0140,  0.0013, -0.0014,  0.0000,  0.0000,  0.0000,  0.0000, -0.0044,\n",
            "          0.0000,  0.0000,  0.0096,  0.0015,  0.0040,  0.0000,  0.0133,  0.0000,\n",
            "          0.0022,  0.0000,  0.0004,  0.0000],\n",
            "        [ 0.0146,  0.0012, -0.0015,  0.0000,  0.0000,  0.0000,  0.0000, -0.0047,\n",
            "          0.0000,  0.0000,  0.0099,  0.0014,  0.0041,  0.0000,  0.0138,  0.0000,\n",
            "          0.0023,  0.0000,  0.0003,  0.0000],\n",
            "        [ 0.0179, -0.0091, -0.0089,  0.0000,  0.0000,  0.0000,  0.0000, -0.0168,\n",
            "          0.0000,  0.0000,  0.0109, -0.0066,  0.0036,  0.0000,  0.0158,  0.0000,\n",
            "         -0.0022,  0.0000, -0.0048,  0.0000],\n",
            "        [-0.0123,  0.0048,  0.0052,  0.0000,  0.0000,  0.0000,  0.0000,  0.0101,\n",
            "          0.0000,  0.0000, -0.0077,  0.0034, -0.0027,  0.0000, -0.0110,  0.0000,\n",
            "          0.0008,  0.0000,  0.0026,  0.0000],\n",
            "        [-0.0139,  0.0172,  0.0137,  0.0000,  0.0000,  0.0000,  0.0000,  0.0238,\n",
            "          0.0000,  0.0000, -0.0072,  0.0130, -0.0015,  0.0000, -0.0112,  0.0000,\n",
            "          0.0064,  0.0000,  0.0087,  0.0000],\n",
            "        [-0.0215,  0.0114,  0.0110,  0.0000,  0.0000,  0.0000,  0.0000,  0.0208,\n",
            "          0.0000,  0.0000, -0.0131,  0.0082, -0.0043,  0.0000, -0.0189,  0.0000,\n",
            "          0.0029,  0.0000,  0.0060,  0.0000],\n",
            "        [ 0.0059, -0.0141, -0.0104,  0.0000,  0.0000,  0.0000,  0.0000, -0.0173,\n",
            "          0.0000,  0.0000,  0.0023, -0.0108, -0.0003,  0.0000,  0.0040,  0.0000,\n",
            "         -0.0059,  0.0000, -0.0070,  0.0000],\n",
            "        [ 0.0072, -0.0024, -0.0027,  0.0000,  0.0000,  0.0000,  0.0000, -0.0055,\n",
            "          0.0000,  0.0000,  0.0045, -0.0016,  0.0016,  0.0000,  0.0065,  0.0000,\n",
            "         -0.0003,  0.0000, -0.0013,  0.0000],\n",
            "        [-0.0108,  0.0238,  0.0176,  0.0000,  0.0000,  0.0000,  0.0000,  0.0293,\n",
            "          0.0000,  0.0000, -0.0043,  0.0182,  0.0003,  0.0000, -0.0075,  0.0000,\n",
            "          0.0099,  0.0000,  0.0119,  0.0000],\n",
            "        [-0.0248,  0.0228,  0.0192,  0.0000,  0.0000,  0.0000,  0.0000,  0.0340,\n",
            "          0.0000,  0.0000, -0.0139,  0.0170, -0.0036,  0.0000, -0.0207,  0.0000,\n",
            "          0.0078,  0.0000,  0.0116,  0.0000]])\n",
            "DEBUGGING: training for one iteration takes 0.003441 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 16\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([2.7254e-17, 1.0456e-04, 2.0352e-04, 7.9271e-02, 2.2031e-03, 8.1396e-08,\n",
            "        3.0463e-04, 1.7562e-04, 4.0904e-12, 6.3855e-05, 5.4380e-08, 4.1305e-12,\n",
            "        9.4017e-04, 1.3106e-02, 5.9568e-06, 2.1595e-06, 1.2131e-03, 2.1605e-03,\n",
            "        1.1525e-06, 4.4628e-04, 1.8469e-07, 8.3026e-06, 3.1400e-04, 5.0643e-14,\n",
            "        7.2417e-06, 8.3608e-05, 2.5926e-05, 9.3939e-03, 1.0526e-05, 3.1894e-04,\n",
            "        6.5139e-09, 2.6775e-05, 6.9266e-03, 5.7536e-03, 1.7423e-05, 1.0990e-04,\n",
            "        8.0303e-07, 1.0009e-09, 2.0743e-01, 1.6136e-02, 1.3681e-02, 6.3030e-07,\n",
            "        2.4346e-01, 2.7907e-09, 2.2771e-04, 2.4430e-04, 1.9494e-05, 2.9025e-01,\n",
            "        1.8625e-03, 4.6353e-05, 5.1715e-11, 1.1385e-03, 6.4023e-07, 2.2813e-05,\n",
            "        2.2898e-06, 1.8609e-02, 1.9608e-05, 1.7318e-06, 8.0641e-05, 4.1504e-06,\n",
            "        1.8604e-04, 3.3437e-08, 2.4075e-04, 1.8625e-03, 1.9499e-03, 6.3668e-05,\n",
            "        2.0334e-23, 6.4196e-02, 1.5070e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [42]\n",
            "DEBUGGING: logits looks like: tensor([1425.0175, 1427.9150, 1427.9817, 1428.5781, 1428.2198, 1427.1992,\n",
            "        1428.0220, 1427.9669, 1426.2094, 1427.8657, 1427.1589, 1426.2103,\n",
            "        1428.1346, 1428.3982, 1427.6285, 1427.5271, 1428.1602, 1428.2179,\n",
            "        1427.4642, 1428.0602, 1427.2811, 1427.6617, 1428.0250, 1425.7703,\n",
            "        1427.6481, 1427.8927, 1427.7756, 1428.3649, 1427.6854, 1428.0266,\n",
            "        1426.9467, 1427.7788, 1428.3344, 1428.3158, 1427.7358, 1427.9200,\n",
            "        1427.4281, 1426.7594, 1428.6743, 1428.4189, 1428.4025, 1427.4039,\n",
            "        1428.6903, 1426.8619, 1427.9929, 1427.9999, 1427.7471, 1428.7079,\n",
            "        1428.2030, 1427.8337, 1426.4631, 1428.1538, 1427.4055, 1427.7628,\n",
            "        1427.5330, 1428.4332, 1427.7477, 1427.5050, 1427.8890, 1427.5924,\n",
            "        1427.9727, 1427.1102, 1427.9984, 1428.2030, 1428.2076, 1427.8655,\n",
            "        1423.6067, 1428.5570, 1428.4121], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([3.4330e-16, 1.1512e-02, 3.6330e-03, 4.0135e-03, 4.8697e-03, 7.7947e-05,\n",
            "        2.2996e-05, 9.6200e-02, 1.0991e-05, 6.5904e-04, 3.0312e-06, 1.8432e-02,\n",
            "        3.4531e-03, 2.5758e-04, 2.2252e-03, 3.8939e-03, 3.9282e-03, 1.0360e-02,\n",
            "        1.7184e-07, 3.5144e-03, 1.2301e-03, 4.8224e-03, 4.1537e-02, 1.4325e-03,\n",
            "        8.0017e-06, 1.6327e-03, 1.9241e-02, 2.9619e-04, 4.6642e-04, 2.5141e-03,\n",
            "        8.0354e-04, 1.7349e-02, 4.8555e-03, 1.4910e-03, 1.5044e-02, 8.3080e-03,\n",
            "        4.0847e-03, 3.2982e-03, 6.0664e-03, 1.7787e-05, 6.5244e-06, 8.2075e-06,\n",
            "        1.8903e-03, 3.4531e-03, 2.5712e-03, 1.5424e-05, 1.2482e-03, 1.0562e-03,\n",
            "        1.5577e-04, 1.8215e-03, 2.0559e-03, 8.4211e-04, 4.3567e-03, 6.9813e-04,\n",
            "        2.3896e-03, 1.0002e-02, 1.2878e-03, 4.6467e-03, 1.2916e-03, 2.2441e-05,\n",
            "        1.1599e-04, 2.0184e-02, 5.6592e-04, 9.4958e-04, 1.1001e-05, 3.6836e-02,\n",
            "        1.2943e-02, 4.0175e-03, 3.5628e-03, 1.8574e-03, 9.8645e-04, 5.2773e-01,\n",
            "        5.0292e-03, 4.7849e-03, 1.2049e-04, 2.7878e-04, 1.8429e-03, 3.6800e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [71]\n",
            "DEBUGGING: logits looks like: tensor([1425.7250, 1428.8394, 1428.7240, 1428.7340, 1428.7533, 1428.3398,\n",
            "        1428.2178, 1429.0516, 1428.1439, 1428.5533, 1428.0151, 1428.8865,\n",
            "        1428.7190, 1428.4594, 1428.6750, 1428.7310, 1428.7318, 1428.8289,\n",
            "        1427.7281, 1428.7207, 1428.6157, 1428.7523, 1428.9677, 1428.6310,\n",
            "        1428.1122, 1428.6440, 1428.8907, 1428.4734, 1428.5188, 1428.6873,\n",
            "        1428.5731, 1428.8804, 1428.7531, 1428.6350, 1428.8661, 1428.8068,\n",
            "        1428.7357, 1428.7144, 1428.7753, 1428.1921, 1428.0918, 1428.1147,\n",
            "        1428.6587, 1428.7190, 1428.6895, 1428.1779, 1428.6172, 1428.6005,\n",
            "        1428.4091, 1428.6550, 1428.6671, 1428.5779, 1428.7422, 1428.5591,\n",
            "        1428.6821, 1428.8253, 1428.6204, 1428.7487, 1428.6206, 1428.2153,\n",
            "        1428.3796, 1428.8955, 1428.5381, 1428.5898, 1428.1440, 1428.9557,\n",
            "        1428.8511, 1428.7341, 1428.7220, 1428.6570, 1428.5936, 1429.2219,\n",
            "        1428.7566, 1428.7516, 1428.3834, 1428.4673, 1428.6561, 1428.9556],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.5486e-03, 4.6331e-02, 3.7155e-02, 5.5543e-04, 5.6868e-03, 2.3430e-03,\n",
            "        9.4652e-05, 3.6717e-03, 4.1022e-06, 1.1275e-03, 8.7257e-20, 3.4085e-04,\n",
            "        1.0079e-02, 1.0088e-22, 6.4892e-02, 5.0375e-04, 1.1614e-07, 9.8038e-05,\n",
            "        4.3136e-03, 6.9472e-03, 5.8322e-04, 2.3660e-03, 1.0088e-22, 6.0882e-04,\n",
            "        4.8547e-03, 9.9321e-03, 1.0076e-04, 1.3028e-03, 2.3292e-10, 8.1277e-05,\n",
            "        5.1484e-02, 7.4971e-03, 5.9396e-06, 2.0279e-09, 9.5940e-06, 1.3963e-03,\n",
            "        5.7981e-04, 1.3470e-02, 1.5902e-02, 6.7756e-07, 4.0630e-05, 5.3475e-03,\n",
            "        2.9313e-07, 8.1503e-06, 4.6986e-06, 1.0468e-03, 1.2015e-02, 2.0969e-07,\n",
            "        4.3938e-04, 8.6727e-02, 4.3354e-02, 6.9734e-04, 1.1233e-02, 1.1885e-03,\n",
            "        7.4098e-03, 1.1057e-03, 6.2083e-04, 2.1252e-09, 6.0723e-02, 1.4362e-04,\n",
            "        4.8547e-03, 2.8488e-02, 1.7375e-04, 4.7848e-02, 4.7152e-02, 1.4313e-01,\n",
            "        6.2518e-03, 8.9453e-04, 1.3718e-04, 2.7661e-03, 8.0656e-04, 3.7588e-03,\n",
            "        4.5650e-03, 1.5761e-03, 3.5064e-04, 2.2133e-05, 1.0448e-03, 3.9155e-04,\n",
            "        3.4849e-06, 9.0711e-02, 1.8496e-04, 5.7777e-08, 1.7412e-03, 1.0420e-08,\n",
            "        3.7155e-02, 2.2273e-02, 1.1156e-02, 1.4593e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [87]\n",
            "DEBUGGING: logits looks like: tensor([1429.1565, 1429.4963, 1429.4742, 1429.0540, 1429.2865, 1429.1979,\n",
            "        1428.8770, 1429.2428, 1428.5631, 1429.1248, 1425.4149, 1429.0051,\n",
            "        1429.3438, 1424.7386, 1429.5300, 1429.0442, 1428.2067, 1428.8805,\n",
            "        1429.2589, 1429.3065, 1429.0588, 1429.1989, 1424.7386, 1429.0631,\n",
            "        1429.2708, 1429.3423, 1428.8832, 1429.1392, 1427.5854, 1428.8617,\n",
            "        1429.5068, 1429.3142, 1428.6001, 1427.8019, 1428.6481, 1429.1461,\n",
            "        1429.0582, 1429.3728, 1429.3894, 1428.3831, 1428.7924, 1429.2804,\n",
            "        1428.2992, 1428.6317, 1428.5767, 1429.1173, 1429.3613, 1428.2657,\n",
            "        1429.0305, 1429.5590, 1429.4896, 1429.0767, 1429.3546, 1429.1300,\n",
            "        1429.3130, 1429.1228, 1429.0651, 1427.8065, 1429.5233, 1428.9187,\n",
            "        1429.2708, 1429.4476, 1428.9377, 1429.4995, 1429.4980, 1429.6091,\n",
            "        1429.2960, 1429.1016, 1428.9141, 1429.2145, 1429.0912, 1429.2451,\n",
            "        1429.2645, 1429.1582, 1429.0079, 1428.7317, 1429.1171, 1429.0189,\n",
            "        1428.5468, 1429.5635, 1428.9440, 1428.1368, 1429.1682, 1427.9656,\n",
            "        1429.4742, 1429.4231, 1429.3539, 1429.3807], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.7711e-11, 1.2807e-04, 2.4068e-04, 7.5081e-04, 6.0753e-03, 3.0913e-02,\n",
            "        5.0267e-03, 1.4545e-02, 1.2223e-03, 2.2905e-02, 4.1511e-03, 6.7313e-03,\n",
            "        4.2537e-03, 2.7264e-06, 1.8423e-02, 2.2089e-03, 2.7495e-02, 9.3898e-04,\n",
            "        2.2397e-02, 5.3301e-03, 1.7408e-02, 1.0125e-02, 2.2657e-03, 3.3003e-02,\n",
            "        2.6823e-04, 8.0957e-03, 1.1361e-02, 8.7693e-04, 2.8693e-04, 1.0820e-02,\n",
            "        1.8155e-02, 2.5603e-02, 2.0096e-02, 1.9383e-02, 1.0579e-02, 1.0579e-02,\n",
            "        1.8692e-03, 9.5484e-03, 6.7708e-03, 1.4472e-03, 2.9064e-03, 2.4815e-02,\n",
            "        2.3864e-02, 2.6057e-02, 1.0204e-02, 8.2958e-03, 3.0109e-02, 2.7900e-02,\n",
            "        6.7973e-03, 3.3941e-04, 2.0870e-04, 2.5624e-03, 1.5959e-02, 5.0513e-03,\n",
            "        2.6619e-03, 6.1409e-03, 5.8768e-03, 2.0214e-02, 1.6354e-02, 1.7122e-02,\n",
            "        1.5258e-02, 1.6870e-03, 4.4188e-03, 6.0339e-03, 3.8692e-03, 1.3611e-02,\n",
            "        1.6530e-02, 3.3616e-03, 7.6649e-03, 1.5892e-04, 2.2790e-03, 2.1413e-02,\n",
            "        1.1608e-02, 1.2563e-02, 4.1470e-03, 5.2826e-04, 2.6433e-04, 3.1303e-03,\n",
            "        2.0745e-05, 1.7631e-02, 8.5174e-03, 1.4657e-03, 1.3704e-02, 7.4581e-03,\n",
            "        3.0973e-02, 9.1633e-04, 7.8390e-03, 1.7752e-02, 1.7717e-02, 1.2023e-02,\n",
            "        3.1858e-03, 1.3413e-02, 1.8490e-04, 2.0380e-06, 2.8834e-04, 6.7642e-03,\n",
            "        3.0913e-02, 8.3364e-03, 2.6649e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [96]\n",
            "DEBUGGING: logits looks like: tensor([1427.4786, 1429.0580, 1429.1211, 1429.2349, 1429.4440, 1429.6067,\n",
            "        1429.4250, 1429.5312, 1429.2836, 1429.5767, 1429.4059, 1429.4542,\n",
            "        1429.4083, 1428.6731, 1429.5549, 1429.3428, 1429.5950, 1429.2572,\n",
            "        1429.5745, 1429.4309, 1429.5492, 1429.4950, 1429.3453, 1429.6132,\n",
            "        1429.1320, 1429.4727, 1429.5066, 1429.2504, 1429.1387, 1429.5017,\n",
            "        1429.5535, 1429.5878, 1429.5636, 1429.5599, 1429.4994, 1429.4994,\n",
            "        1429.3260, 1429.4891, 1429.4548, 1429.3005, 1429.3702, 1429.5847,\n",
            "        1429.5808, 1429.5896, 1429.4958, 1429.4751, 1429.6040, 1429.5964,\n",
            "        1429.4552, 1429.1555, 1429.1068, 1429.3577, 1429.5405, 1429.4255,\n",
            "        1429.3615, 1429.4451, 1429.4407, 1429.5642, 1429.5430, 1429.5476,\n",
            "        1429.5360, 1429.3158, 1429.4121, 1429.4432, 1429.3988, 1429.5247,\n",
            "        1429.5441, 1429.3848, 1429.4672, 1429.0796, 1429.3459, 1429.5699,\n",
            "        1429.5087, 1429.5166, 1429.4058, 1429.1997, 1429.1305, 1429.3777,\n",
            "        1428.8760, 1429.5505, 1429.4778, 1429.3018, 1429.5253, 1429.4645,\n",
            "        1429.6068, 1429.2548, 1429.4695, 1429.5511, 1429.5510, 1429.5122,\n",
            "        1429.3794, 1429.5232, 1429.0947, 1428.6439, 1429.1392, 1429.4547,\n",
            "        1429.6067, 1429.4756, 1429.5918], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([3.8418e-11, 1.1032e-02, 1.7138e-02, 5.2574e-03, 7.5088e-03, 4.0474e-02,\n",
            "        5.3350e-03, 7.0333e-03, 4.3204e-03, 7.6794e-03, 5.5367e-03, 2.6878e-03,\n",
            "        1.3921e-01, 2.4094e-03, 6.2861e-03, 7.9464e-03, 6.4478e-03, 2.4620e-02,\n",
            "        2.6565e-03, 6.6720e-03, 9.0045e-03, 4.4925e-03, 4.7358e-03, 9.3540e-03,\n",
            "        6.5749e-03, 8.8909e-03, 1.1022e-02, 4.8528e-03, 1.1107e-03, 7.8167e-02,\n",
            "        1.5558e-02, 1.0756e-02, 4.3246e-03, 6.5047e-03, 1.0787e-02, 1.1107e-03,\n",
            "        7.3564e-03, 1.5238e-04, 5.9342e-03, 1.1043e-02, 1.2129e-02, 5.0609e-03,\n",
            "        1.0230e-04, 7.7927e-03, 1.1192e-04, 3.3158e-03, 6.9445e-03, 5.9458e-03,\n",
            "        1.1641e-02, 1.0496e-02, 5.5529e-03, 1.3570e-02, 1.2236e-02, 8.7445e-03,\n",
            "        3.2740e-03, 6.5878e-03, 8.1507e-03, 5.4296e-03, 5.9168e-03, 5.4936e-03,\n",
            "        8.5336e-03, 5.0215e-03, 1.9722e-03, 5.0560e-03, 2.0814e-02, 3.0014e-03,\n",
            "        4.3799e-03, 2.3329e-03, 2.4047e-03, 5.6019e-03, 3.6098e-03, 5.4882e-03,\n",
            "        1.0304e-02, 4.1630e-03, 5.2012e-03, 1.0968e-02, 7.2424e-03, 5.6184e-03,\n",
            "        6.1046e-03, 1.1528e-02, 3.6631e-03, 7.8308e-03, 9.3632e-03, 3.7026e-03,\n",
            "        2.5427e-02, 5.7180e-03, 7.2071e-03, 3.1825e-03, 1.0599e-02, 9.7266e-03,\n",
            "        1.8874e-03, 4.4925e-03, 6.0276e-03, 6.8302e-03, 6.4730e-03, 6.6785e-03,\n",
            "        5.6019e-03, 5.3090e-03, 6.4604e-03, 9.9963e-03, 4.9389e-03, 5.2574e-03,\n",
            "        3.1485e-03, 6.7112e-03, 6.6071e-03, 1.0861e-02, 9.2994e-03, 7.0677e-03,\n",
            "        1.0104e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [36]\n",
            "DEBUGGING: logits looks like: tensor([1427.7820, 1429.7295, 1429.7736, 1429.6554, 1429.6910, 1429.8595,\n",
            "        1429.6569, 1429.6844, 1429.6357, 1429.6932, 1429.6605, 1429.5883,\n",
            "        1429.9830, 1429.5774, 1429.6732, 1429.6967, 1429.6758, 1429.8098,\n",
            "        1429.5872, 1429.6792, 1429.7092, 1429.6396, 1429.6449, 1429.7130,\n",
            "        1429.6777, 1429.7079, 1429.7294, 1429.6473, 1429.4999, 1429.9253,\n",
            "        1429.7639, 1429.7269, 1429.6359, 1429.6766, 1429.7273, 1429.4999,\n",
            "        1429.6890, 1429.3013, 1429.6675, 1429.7296, 1429.7390, 1429.6516,\n",
            "        1429.2615, 1429.6947, 1429.2704, 1429.6093, 1429.6832, 1429.6677,\n",
            "        1429.7349, 1429.7245, 1429.6609, 1429.7502, 1429.7399, 1429.7063,\n",
            "        1429.6080, 1429.6780, 1429.6992, 1429.6586, 1429.6672, 1429.6598,\n",
            "        1429.7039, 1429.6508, 1429.5574, 1429.6515, 1429.7930, 1429.5994,\n",
            "        1429.6371, 1429.5741, 1429.5771, 1429.6617, 1429.6178, 1429.6597,\n",
            "        1429.7227, 1429.6321, 1429.6543, 1429.7289, 1429.6874, 1429.6620,\n",
            "        1429.6703, 1429.7339, 1429.6193, 1429.6952, 1429.7131, 1429.6204,\n",
            "        1429.8130, 1429.6638, 1429.6869, 1429.6052, 1429.7255, 1429.7169,\n",
            "        1429.5530, 1429.6396, 1429.6691, 1429.6815, 1429.6761, 1429.6793,\n",
            "        1429.6617, 1429.6564, 1429.6760, 1429.7196, 1429.6492, 1429.6554,\n",
            "        1429.6041, 1429.6798, 1429.6782, 1429.7279, 1429.7124, 1429.6849,\n",
            "        1429.7207], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.13105571243386294 and immediate abs rewards look like: [0.01472099603006427, 0.003817258723302075, 0.013557903691435058, 0.050915616845031764, 0.0010659916206350317, 0.00017500329749964294, 0.0003856510056721163, 0.0013259742399895913, 0.0008236013763962546, 1.4847430065856315e-05, 1.6435697943961713e-05, 0.0003813964881373977, 0.00013324794872460188, 0.0001933577359523042, 0.00035957886757387314, 0.000204218450562621, 0.00017960234072234016, 0.00014397909535546205, 0.00016272256107185967, 0.0018251369742756651, 0.0004794105625478551, 0.005278948153318197, 2.6861878268391592e-05, 0.0037543691291830328, 0.0015663287740608212, 4.3761539473052835e-05, 6.159751274026348e-05, 0.001729274862100283, 0.0010676878055164707, 0.0006470777884715062, 0.00266852449885846, 0.001159631967311725, 0.003438642187120422, 0.0019517658533914073, 0.001792579904304148, 0.006795255440010806, 0.0001539811951261072, 0.00022523407915286953, 0.00011299355719529558, 0.0005640909985231701, 0.0019280509950476699, 0.0009354801904919441, 0.00028094338904338656, 8.184146281564608e-05, 0.0019081859113612154, 0.0012076808870915556, 7.452660793205723e-05, 1.766206514730584e-05, 0.00023819454463591683, 0.0004626082732102077]\n",
            "DEBUGGING: the total relative reward of the trajectory = 55.847165416849194 and immediate relative rewards look like: [0.47467008632435814, 0.24734471417148557, 1.3193872283996286, 6.635653477983331, 0.17658812286986375, 0.034800748646708055, 0.08947646194385533, 0.35163887776799224, 0.24582288994993734, 0.004925299825185475, 0.005997418571142681, 0.1518251879726801, 0.05747046708678387, 0.089815156327344, 0.17896715082151857, 0.1084313047298197, 0.1013281400351506, 0.08601357316611422, 0.10261649322100079, 1.2116151985509376, 0.33437155527840834, 3.857817381588033, 0.020558812596256935, 2.9983747295544796, 1.3046786186205255, 0.03792916263111959, 0.05544221735800974, 1.6141527433698701, 1.0327977542913103, 0.647747055891614, 2.7609234770016142, 1.2395915376371052, 3.792081290346061, 2.2201518826300144, 2.10042075887338, 8.194618293080135, 0.1912844009814935, 0.28737586861620434, 0.14797342666320756, 0.7576891740656972, 2.6550124818409833, 1.3204726318450695, 0.4061340052746749, 0.12107351812098939, 2.887142712700455, 1.8690624180740092, 0.117896114004633, 0.028535395190592415, 0.392854420492239, 0.7786135798661646]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([3.7036e-18, 5.2733e-06, 1.6473e-09, 1.7609e-07, 5.4747e-10, 2.8044e-10,\n",
            "        6.8725e-11, 3.3069e-05, 5.7820e-04, 2.3248e-04, 6.7361e-08, 1.0734e-06,\n",
            "        2.9098e-05, 2.6848e-01, 2.4091e-14, 8.4960e-10, 1.5265e-09, 4.4034e-10,\n",
            "        1.7344e-04, 8.5749e-07, 5.0561e-13, 1.9835e-01, 8.7559e-11, 4.8660e-08,\n",
            "        1.0184e-12, 7.0880e-07, 4.0253e-16, 1.0502e-15, 3.2182e-04, 1.0635e-03,\n",
            "        4.5483e-09, 3.5697e-03, 8.7236e-03, 1.3751e-02, 1.4425e-02, 2.8671e-19,\n",
            "        2.5441e-02, 1.2151e-13, 2.9701e-05, 1.2351e-08, 2.2386e-02, 9.2175e-07,\n",
            "        1.1780e-05, 7.4478e-22, 1.3675e-13, 7.7695e-07, 3.8366e-04, 1.3461e-14,\n",
            "        3.8387e-07, 2.6105e-06, 3.1467e-04, 4.4146e-06, 6.4736e-06, 4.7501e-06,\n",
            "        6.3512e-03, 6.6977e-07, 2.7711e-05, 2.4013e-03, 3.4503e-02, 1.4116e-03,\n",
            "        6.4204e-09, 3.9679e-01, 1.2653e-10, 2.9788e-05, 4.9016e-05, 1.9034e-09,\n",
            "        5.1783e-10, 4.8968e-05, 4.8968e-05], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [13]\n",
            "DEBUGGING: logits looks like: tensor([1432.0592, 1434.8577, 1434.0505, 1434.5177, 1433.9403, 1433.8734,\n",
            "        1433.7328, 1435.0413, 1435.3274, 1435.2362, 1434.4216, 1434.6985,\n",
            "        1435.0284, 1435.9414, 1432.9373, 1433.9843, 1434.0428, 1433.9186,\n",
            "        1435.2069, 1434.6760, 1433.2416, 1435.9111, 1433.7571, 1434.3890,\n",
            "        1433.3116, 1434.6570, 1432.5281, 1432.6239, 1435.2688, 1435.3883,\n",
            "        1434.1521, 1435.5094, 1435.5988, 1435.6443, 1435.6490, 1431.8033,\n",
            "        1435.7058, 1433.0990, 1435.0305, 1434.2520, 1435.6930, 1434.6832,\n",
            "        1434.9380, 1431.2080, 1433.1108, 1434.6661, 1435.2864, 1432.8790,\n",
            "        1434.5956, 1434.7874, 1435.2665, 1434.8398, 1434.8782, 1434.8472,\n",
            "        1435.5670, 1434.6512, 1435.0236, 1435.4697, 1435.7362, 1435.4166,\n",
            "        1434.1865, 1435.9805, 1433.7938, 1435.0308, 1435.0806, 1434.0649,\n",
            "        1433.9348, 1435.0804, 1435.0804], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.0772e-16, 6.3710e-09, 2.7760e-07, 3.4132e-03, 1.9773e-03, 2.8807e-01,\n",
            "        2.5564e-03, 6.5313e-06, 1.4326e-03, 3.6276e-07, 1.5011e-04, 2.8403e-04,\n",
            "        2.3055e-08, 9.9494e-06, 3.6262e-03, 2.0766e-02, 1.1536e-08, 3.6997e-06,\n",
            "        7.7108e-06, 3.3724e-05, 2.4013e-10, 2.6764e-03, 2.2240e-07, 4.2679e-04,\n",
            "        2.3299e-03, 2.0899e-05, 2.2694e-09, 6.2901e-03, 1.6195e-19, 1.2565e-05,\n",
            "        8.0379e-09, 3.5733e-23, 4.4634e-05, 5.6164e-03, 1.2635e-07, 1.5934e-10,\n",
            "        1.7467e-03, 4.6224e-06, 4.3629e-07, 3.6262e-03, 3.1465e-05, 4.9658e-10,\n",
            "        2.3376e-07, 1.6932e-02, 2.1841e-04, 2.6474e-04, 1.2315e-02, 4.5586e-01,\n",
            "        8.0361e-04, 1.1121e-05, 7.2742e-04, 1.6313e-03, 1.1886e-04, 3.2795e-09,\n",
            "        6.7003e-05, 2.6417e-12, 2.7579e-05, 1.8112e-02, 9.4333e-03, 3.2122e-04,\n",
            "        1.6913e-03, 1.9309e-05, 3.3714e-07, 1.6244e-05, 3.0861e-04, 5.2378e-06,\n",
            "        1.2744e-02, 1.2594e-09, 3.2682e-06, 2.9683e-03, 2.0107e-02, 3.6262e-03,\n",
            "        2.0683e-09, 7.6233e-04, 2.1650e-04, 2.1712e-11, 6.2901e-03, 8.9239e-02,\n",
            "        4.9561e-10, 3.4701e-10], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [47]\n",
            "DEBUGGING: logits looks like: tensor([1433.2102, 1434.9998, 1435.3772, 1436.3188, 1436.2643, 1436.7625,\n",
            "        1436.2899, 1435.6930, 1436.2321, 1435.4039, 1436.0065, 1436.0702,\n",
            "        1435.1283, 1435.7351, 1436.3250, 1436.4994, 1435.0591, 1435.6361,\n",
            "        1435.7096, 1435.8572, 1434.6719, 1436.2946, 1435.3550, 1436.1110,\n",
            "        1436.2806, 1435.8093, 1434.8965, 1436.3800, 1432.5602, 1435.7584,\n",
            "        1435.0229, 1431.7183, 1435.8851, 1436.3687, 1435.2985, 1434.6309,\n",
            "        1436.2518, 1435.6584, 1435.4224, 1436.3250, 1435.8502, 1434.7445,\n",
            "        1435.3600, 1436.4790, 1436.0439, 1436.0632, 1436.4471, 1436.8083,\n",
            "        1436.1742, 1435.7462, 1436.1643, 1436.2450, 1435.9832, 1434.9333,\n",
            "        1435.9258, 1434.2209, 1435.8370, 1436.4857, 1436.4205, 1436.0825,\n",
            "        1436.2487, 1435.8014, 1435.3966, 1435.7841, 1436.0785, 1435.6709,\n",
            "        1436.4506, 1434.8376, 1435.6238, 1436.3049, 1436.4962, 1436.3250,\n",
            "        1434.8872, 1436.1689, 1436.0431, 1434.4315, 1436.3800, 1436.6453,\n",
            "        1434.7444, 1434.7087], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.9070e-17, 2.8630e-36, 1.9618e-44, 2.1456e-32, 9.6690e-44, 1.6356e-05,\n",
            "        3.5608e-01, 8.9740e-04, 1.9675e-04, 1.8438e-40, 1.0085e-26, 1.2970e-41,\n",
            "        1.0691e-01, 0.0000e+00, 9.8429e-26, 7.6841e-23, 8.0958e-07, 4.3898e-12,\n",
            "        2.3528e-03, 6.8859e-25, 1.2505e-11, 1.2399e-16, 1.8507e-15, 4.6142e-05,\n",
            "        2.8722e-08, 3.7907e-07, 4.9772e-08, 1.8174e-32, 4.2092e-12, 1.8009e-21,\n",
            "        5.3451e-21, 1.2118e-06, 1.6456e-10, 1.1463e-05, 2.8383e-09, 3.0787e-27,\n",
            "        2.7623e-01, 2.0361e-36, 4.1950e-15, 1.7956e-08, 2.5299e-01, 3.5820e-07,\n",
            "        4.4196e-19, 8.9586e-09, 1.5787e-07, 6.3684e-12, 6.3684e-12, 1.3531e-06,\n",
            "        2.0711e-07, 7.1317e-06, 2.1804e-09, 1.7494e-06, 7.7326e-07, 4.4565e-09,\n",
            "        2.9224e-03, 6.8451e-19, 4.2301e-05, 1.1018e-41, 1.4940e-10, 1.9696e-10,\n",
            "        2.9821e-05, 8.0509e-05, 2.2957e-04, 1.7911e-05, 2.1437e-05, 3.8976e-17,\n",
            "        5.6306e-06, 5.6023e-07, 0.0000e+00, 6.1641e-21, 3.6491e-07, 2.3951e-08,\n",
            "        1.4068e-07, 8.9740e-04, 2.3398e-14, 1.3186e-09, 1.9215e-12, 2.5504e-19,\n",
            "        7.4925e-09, 6.5978e-30, 1.1097e-20, 1.4815e-14, 4.6665e-08, 2.0999e-06,\n",
            "        7.5133e-10, 1.7195e-30, 1.2637e-06], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [6]\n",
            "DEBUGGING: logits looks like: tensor([1433.7683, 1429.4340, 1427.5499, 1430.3262, 1427.7131, 1436.5160,\n",
            "        1437.5149, 1436.9165, 1436.7648, 1428.4690, 1431.6322, 1428.2035,\n",
            "        1437.3945, 1426.1326, 1431.8601, 1432.5261, 1436.2155, 1435.0029,\n",
            "        1437.0129, 1432.0546, 1435.1077, 1433.9554, 1434.2258, 1436.6198,\n",
            "        1435.8816, 1436.1395, 1435.9365, 1430.3096, 1434.9988, 1432.8416,\n",
            "        1432.9503, 1436.2557, 1435.3654, 1436.4805, 1435.6501, 1431.5135,\n",
            "        1437.4895, 1429.3999, 1434.3076, 1435.8346, 1437.4807, 1436.1339,\n",
            "        1433.3918, 1435.7650, 1436.0520, 1435.0402, 1435.0402, 1436.2668,\n",
            "        1436.0791, 1436.4330, 1435.6238, 1436.2925, 1436.2108, 1435.6952,\n",
            "        1437.0345, 1433.4355, 1436.6111, 1428.1873, 1435.3557, 1435.3833,\n",
            "        1436.5760, 1436.6754, 1436.7802, 1436.5251, 1436.5431, 1433.8397,\n",
            "        1436.4094, 1436.1786, 1425.1512, 1432.9646, 1436.1357, 1435.8634,\n",
            "        1436.0404, 1436.9165, 1434.4795, 1435.5735, 1434.9203, 1433.3368,\n",
            "        1435.7472, 1430.8990, 1433.0233, 1434.4338, 1435.9301, 1436.3108,\n",
            "        1435.5172, 1430.7645, 1436.2600], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([3.5445e-17, 1.1384e-04, 2.3500e-03, 1.1744e-05, 4.6545e-04, 2.7242e-01,\n",
            "        1.7173e-04, 3.3135e-04, 4.1089e-02, 4.8458e-09, 4.9685e-05, 3.8966e-04,\n",
            "        4.6486e-06, 5.9127e-04, 8.2114e-02, 1.3846e-01, 1.4435e-03, 4.9373e-08,\n",
            "        3.2038e-07, 1.3741e-06, 1.1340e-04, 1.9763e-05, 6.0629e-06, 1.3429e-03,\n",
            "        9.7770e-04, 5.3990e-11, 1.4478e-03, 1.8136e-05, 1.6348e-07, 2.0120e-03,\n",
            "        3.2877e-04, 4.8739e-03, 9.3370e-05, 3.6923e-05, 5.1579e-03, 2.2929e-04,\n",
            "        9.0879e-03, 7.7990e-07, 1.3577e-08, 1.7263e-02, 5.5474e-06, 1.4377e-04,\n",
            "        9.0409e-05, 2.4062e-08, 1.9568e-06, 9.8522e-05, 3.8733e-05, 6.8790e-04,\n",
            "        2.6841e-02, 1.0266e-03, 8.1850e-04, 1.6499e-04, 1.1580e-01, 1.7598e-04,\n",
            "        4.6048e-04, 1.7495e-04, 1.0639e-06, 2.4282e-06, 3.2722e-03, 2.2533e-03,\n",
            "        3.1648e-04, 1.6568e-09, 8.2114e-02, 3.2877e-04, 5.2078e-04, 6.3177e-05,\n",
            "        9.3735e-05, 1.8020e-02, 5.8381e-04, 4.1852e-03, 2.7984e-04, 1.3280e-06,\n",
            "        1.1778e-05, 2.8966e-02, 1.9850e-02, 2.6657e-09, 1.0067e-10, 2.2293e-03,\n",
            "        9.9976e-05, 3.9086e-03, 8.3151e-03, 3.1706e-05, 6.0876e-05, 1.0096e-04,\n",
            "        1.1066e-04, 1.5259e-04, 3.3292e-05, 4.9458e-03, 2.6860e-04, 7.3873e-04,\n",
            "        1.3269e-05, 8.2114e-02, 5.3634e-03, 2.6098e-07, 8.4683e-05, 2.0251e-12,\n",
            "        3.3558e-04, 6.8055e-04, 7.1439e-06], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [62]\n",
            "DEBUGGING: logits looks like: tensor([1434.2770, 1437.1567, 1437.4595, 1436.9296, 1437.2976, 1437.9348,\n",
            "        1437.1979, 1437.2635, 1437.7456, 1436.1503, 1437.0739, 1437.2798,\n",
            "        1436.8369, 1437.3215, 1437.8148, 1437.8671, 1437.4108, 1436.3824,\n",
            "        1436.5695, 1436.7151, 1437.1564, 1436.9817, 1436.8635, 1437.4036,\n",
            "        1437.3718, 1435.7006, 1437.4110, 1436.9730, 1436.5022, 1437.4440,\n",
            "        1437.2628, 1437.5325, 1437.1370, 1437.0442, 1437.5381, 1437.2268,\n",
            "        1437.5947, 1436.6584, 1436.2533, 1437.6589, 1436.8546, 1437.1801,\n",
            "        1437.1337, 1436.3105, 1436.7504, 1437.1423, 1437.0490, 1437.3367,\n",
            "        1437.7030, 1437.3767, 1437.3540, 1437.1938, 1437.8492, 1437.2003,\n",
            "        1437.2965, 1437.1997, 1436.6895, 1436.7720, 1437.4926, 1437.4553,\n",
            "        1437.2590, 1436.0430, 1437.8148, 1437.2628, 1437.3088, 1437.0979,\n",
            "        1437.1373, 1437.6632, 1437.3202, 1437.5172, 1437.2467, 1436.7117,\n",
            "        1436.9299, 1437.7107, 1437.6729, 1436.0906, 1435.7629, 1437.4542,\n",
            "        1437.1438, 1437.5104, 1437.5858, 1437.0289, 1437.0941, 1437.1448,\n",
            "        1437.1539, 1437.1860, 1437.0338, 1437.5339, 1437.2426, 1437.3438,\n",
            "        1436.9418, 1437.8148, 1437.5420, 1436.5490, 1437.1272, 1435.3723,\n",
            "        1437.2649, 1437.3356, 1436.8799], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.7208e-16, 2.6816e-02, 1.4337e-03, 2.9823e-03, 4.4335e-03, 2.8118e-05,\n",
            "        2.8854e-02, 2.4536e-02, 4.1210e-02, 1.4879e-03, 8.1625e-03, 4.9452e-04,\n",
            "        2.9190e-03, 9.3858e-03, 9.1697e-02, 2.5958e-04, 4.3684e-04, 2.8681e-03,\n",
            "        1.1624e-02, 5.1222e-04, 8.2631e-06, 4.9012e-05, 1.3641e-03, 2.5735e-03,\n",
            "        1.1133e-03, 9.3949e-03, 1.1431e-03, 2.9157e-04, 6.5322e-04, 5.2291e-03,\n",
            "        4.8361e-03, 3.4601e-02, 1.8666e-02, 5.9120e-05, 1.0984e-02, 8.2253e-04,\n",
            "        1.8938e-03, 2.6830e-05, 8.7742e-03, 4.7758e-02, 5.6706e-03, 5.4533e-03,\n",
            "        2.8681e-03, 1.9543e-02, 6.9749e-03, 1.7931e-03, 1.0970e-04, 2.1104e-04,\n",
            "        3.3275e-02, 1.1876e-02, 2.8292e-03, 1.0677e-02, 5.5772e-03, 9.8170e-03,\n",
            "        4.5749e-02, 2.4777e-02, 4.6282e-03, 4.9799e-03, 1.2097e-03, 6.5386e-04,\n",
            "        2.7690e-03, 5.7815e-04, 1.7535e-02, 5.1114e-05, 7.8935e-05, 1.6990e-04,\n",
            "        1.9521e-03, 1.8938e-03, 7.9578e-03, 2.7345e-02, 6.2523e-03, 5.0831e-03,\n",
            "        6.6685e-03, 5.6328e-02, 9.8651e-03, 1.6645e-04, 6.6211e-05, 2.0358e-03,\n",
            "        1.6537e-02, 2.1798e-03, 2.1905e-03, 1.0930e-02, 1.2829e-02, 2.2446e-03,\n",
            "        1.3377e-03, 2.1356e-03, 1.6008e-04, 6.2523e-03, 2.7106e-02, 1.2642e-02,\n",
            "        1.7638e-02, 4.6056e-03, 6.0422e-03, 5.0534e-03, 7.2446e-04, 4.2910e-06,\n",
            "        8.4463e-03, 1.6615e-03, 2.0183e-02, 2.3897e-02, 1.2677e-03, 1.0158e-02,\n",
            "        9.2737e-05, 5.5492e-04, 4.9508e-03, 4.1124e-03, 1.6648e-03, 5.7690e-12,\n",
            "        9.4409e-03, 2.7106e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [73]\n",
            "DEBUGGING: logits looks like: tensor([1434.6807, 1437.9028, 1437.6100, 1437.6832, 1437.7229, 1437.2168,\n",
            "        1437.9102, 1437.8939, 1437.9458, 1437.6136, 1437.7839, 1437.5035,\n",
            "        1437.6810, 1437.7979, 1438.0258, 1437.4391, 1437.4911, 1437.6793,\n",
            "        1437.8192, 1437.5071, 1437.0944, 1437.2723, 1437.6050, 1437.6685,\n",
            "        1437.5847, 1437.7980, 1437.5873, 1437.4507, 1437.5314, 1437.7394,\n",
            "        1437.7316, 1437.9283, 1437.8666, 1437.2911, 1437.8136, 1437.5544,\n",
            "        1437.6378, 1437.2122, 1437.7911, 1437.9606, 1437.7474, 1437.7435,\n",
            "        1437.6793, 1437.8712, 1437.7682, 1437.6323, 1437.3529, 1437.4183,\n",
            "        1437.9244, 1437.8214, 1437.6780, 1437.8108, 1437.7458, 1437.8024,\n",
            "        1437.9563, 1437.8949, 1437.7272, 1437.7345, 1437.5930, 1437.5315,\n",
            "        1437.6758, 1437.5192, 1437.8604, 1437.2766, 1437.3201, 1437.3967,\n",
            "        1437.6409, 1437.6378, 1437.7814, 1437.9048, 1437.7572, 1437.7366,\n",
            "        1437.7637, 1437.9771, 1437.8029, 1437.3947, 1437.3025, 1437.6450,\n",
            "        1437.8545, 1437.6519, 1437.6523, 1437.8131, 1437.8291, 1437.6548,\n",
            "        1437.6030, 1437.6498, 1437.3907, 1437.7572, 1437.9039, 1437.8276,\n",
            "        1437.8610, 1437.7267, 1437.7538, 1437.7360, 1437.5417, 1437.0288,\n",
            "        1437.7874, 1437.6248, 1437.8744, 1437.8914, 1437.5977, 1437.8058,\n",
            "        1437.3362, 1437.5150, 1437.7339, 1437.7153, 1437.6249, 1435.6769,\n",
            "        1437.7985, 1437.9039], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.051454287197884696 and immediate abs rewards look like: [0.001628004127269378, 0.0018067069577227812, 0.006974937901759404, 0.00054018023001845, 0.003591665435124014, 0.002813842654632026, 0.0019815276214103505, 0.0010778848372865468, 0.0021794943741042516, 0.0022711795045324834, 0.0006737855483152089, 5.532840623345692e-05, 7.626841215824243e-05, 6.107914032327244e-06, 9.827185294852825e-06, 0.00030496209456032375, 0.0009863108348326932, 2.8325547646090854e-05, 0.000555496567812952, 0.002364930858675507, 6.703582403133623e-05, 5.3059290621604305e-05, 0.00017687057015791652, 0.002088312520754698, 0.003427882075357047, 0.0015720895985396055, 0.0002488141808498767, 0.0002337322853236401, 0.004008255180906417, 9.211228507410851e-05, 0.00012636811879929155, 1.1303176961519057e-05, 0.00033997387072304264, 0.0007393095243060088, 3.433814799791435e-05, 6.151124080133741e-05, 0.005748281715568737, 0.0002837613023984886, 0.00021570451735897223, 0.00022204642982615042, 0.00029611268337248475, 2.1125747935002437e-05, 3.393066026546876e-05, 7.83246687205974e-05, 9.494801543041831e-05, 6.575237785000354e-05, 0.0011483837442938238, 1.1288467703707283e-05, 1.0139063761016587e-05, 1.675289877312025e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 33.65615409489496 and immediate relative rewards look like: [0.060166174884518614, 0.1336213914446697, 0.7743015514523204, 0.08016218963136222, 0.6663828597406221, 0.6273186459385952, 0.515928612425584, 0.3209770665320303, 0.7304394131420812, 0.8464279849357255, 0.27645260393175747, 0.02477107619521883, 0.03699239851694004, 0.003190492615154873, 0.005499942965839248, 0.1820560931973955, 0.625678913511159, 0.01903265974946622, 0.39399275551263474, 1.7660043376549153, 0.052608173217914764, 0.043623647415043355, 0.15203020385981966, 1.8731903334625377, 3.2053846517664493, 1.5308128643101875, 0.251748058879239, 0.24527002192687472, 4.356714869688422, 0.1037283635230153, 0.14705268074076638, 0.013578282464783382, 0.4211682810499984, 0.9437496982513214, 0.04513537815400256, 0.08316388362727992, 7.987807213951966, 0.4058477748828203, 0.3166625007943446, 0.3343580934246942, 0.4570726390440728, 0.033408283347198905, 0.05493599530506514, 0.12976364094095527, 0.16088405102943315, 0.11389362338391082, 2.032477573051069, 0.020412911275297728, 0.018716493892517363, 0.03155674425597337]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([4.3709e-20, 7.2848e-26, 1.4013e-45, 6.5363e-13, 1.0642e-24, 2.5141e-09,\n",
            "        2.8589e-05, 8.1492e-01, 8.7311e-10, 1.1939e-06, 6.5734e-34, 1.1229e-05,\n",
            "        8.1695e-04, 7.3960e-03, 1.6816e-08, 4.3751e-07, 2.1640e-06, 9.2364e-06,\n",
            "        1.5617e-06, 4.0677e-11, 2.3199e-11, 8.2726e-05, 4.7431e-09, 3.8648e-07,\n",
            "        1.5343e-07, 3.6997e-05, 8.8620e-15, 1.5940e-13, 2.6564e-13, 4.4064e-05,\n",
            "        9.8966e-08, 5.8530e-07, 1.5742e-05, 1.1787e-07, 1.0924e-06, 8.1885e-08,\n",
            "        2.3826e-09, 3.6986e-07, 5.8236e-08, 9.9146e-22, 9.8714e-12, 3.3102e-11,\n",
            "        2.8660e-08, 8.5326e-07, 2.9521e-06, 4.9681e-06, 1.2042e-14, 1.0057e-04,\n",
            "        7.7452e-08, 3.0651e-03, 8.1431e-06, 1.3333e-12, 4.8312e-10, 5.3916e-14,\n",
            "        1.0295e-04, 1.4471e-13, 1.1402e-07, 1.6426e-08, 1.5557e-06, 3.7151e-10,\n",
            "        9.9368e-07, 1.5454e-11, 4.2253e-18, 8.4796e-03, 1.5953e-01, 5.3012e-03,\n",
            "        3.0852e-05, 3.0095e-21, 7.2848e-26, 7.0670e-20],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [7]\n",
            "DEBUGGING: logits looks like: tensor([1431.6976, 1430.3672, 1425.8317, 1433.3497, 1430.6354, 1434.1752,\n",
            "        1435.1091, 1436.1349, 1434.0695, 1434.7915, 1428.5149, 1435.0156,\n",
            "        1435.4443, 1435.6647, 1434.3652, 1434.6912, 1434.8510, 1434.9961,\n",
            "        1434.8184, 1433.7628, 1433.7067, 1435.2153, 1434.2386, 1434.6787,\n",
            "        1434.5863, 1435.1349, 1432.9197, 1433.2086, 1433.2596, 1435.1523,\n",
            "        1434.5425, 1434.7202, 1435.0494, 1434.5599, 1434.7826, 1434.5236,\n",
            "        1434.1698, 1434.6743, 1434.4895, 1431.3191, 1433.6212, 1433.7422,\n",
            "        1434.4186, 1434.7579, 1434.8821, 1434.9341, 1432.9503, 1435.2349,\n",
            "        1434.5179, 1435.5765, 1434.9835, 1433.4210, 1434.0103, 1433.1002,\n",
            "        1435.2372, 1433.1990, 1434.5566, 1434.3629, 1434.8180, 1433.9840,\n",
            "        1434.7732, 1433.6660, 1432.1548, 1435.6783, 1435.9718, 1435.6313,\n",
            "        1435.1167, 1431.4301, 1430.3672, 1431.7457], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.1157e-20, 6.3081e-01, 9.8337e-23, 1.8316e-03, 9.2649e-10, 1.3901e-06,\n",
            "        1.2059e-03, 2.6867e-01, 2.6170e-07, 5.5598e-03, 2.9905e-03, 5.8018e-12,\n",
            "        3.0458e-11, 9.5039e-16, 2.0010e-06, 2.8723e-05, 1.0833e-02, 3.6072e-03,\n",
            "        1.5412e-08, 1.2915e-08, 1.0263e-04, 3.6026e-05, 3.9743e-08, 1.9483e-08,\n",
            "        4.1230e-04, 2.1848e-06, 3.2638e-06, 2.1678e-06, 9.5848e-05, 1.8545e-05,\n",
            "        4.2348e-08, 1.4375e-04, 7.4406e-07, 7.1524e-10, 4.4084e-07, 1.2835e-04,\n",
            "        1.0682e-04, 1.9416e-05, 1.6093e-13, 3.6742e-04, 1.0146e-02, 2.2332e-03,\n",
            "        3.1548e-11, 9.6884e-05, 1.5104e-06, 2.1930e-07, 1.1496e-03, 1.7760e-07,\n",
            "        3.4568e-07, 1.1750e-07, 2.6164e-02, 2.9555e-10, 1.4703e-03, 1.8007e-06,\n",
            "        3.9139e-06, 6.7306e-05, 2.8944e-06, 2.6064e-08, 4.3883e-05, 6.5737e-06,\n",
            "        2.8747e-06, 1.4067e-05, 2.5493e-06, 7.8019e-23, 6.3926e-10, 1.1761e-07,\n",
            "        3.0047e-04, 2.8231e-03, 1.8662e-02, 1.3894e-03, 1.4461e-03, 5.3766e-05,\n",
            "        2.1527e-07, 1.6023e-03, 2.6145e-07, 1.3372e-04, 5.1269e-03, 4.5765e-05,\n",
            "        2.5898e-05], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [7]\n",
            "DEBUGGING: logits looks like: tensor([1433.1652, 1437.7133, 1432.6920, 1437.1292, 1435.6794, 1436.4108,\n",
            "        1437.0873, 1437.6279, 1436.2438, 1437.2401, 1437.1781, 1435.1721,\n",
            "        1435.3379, 1434.3004, 1436.4471, 1436.7136, 1437.3069, 1437.1969,\n",
            "        1435.9606, 1435.9429, 1436.8409, 1436.7362, 1436.0553, 1435.9840,\n",
            "        1436.9800, 1436.4559, 1436.4961, 1436.4552, 1436.8341, 1436.6698,\n",
            "        1436.0616, 1436.8746, 1436.3483, 1435.6536, 1436.2959, 1436.8633,\n",
            "        1436.8450, 1436.6744, 1434.8136, 1436.9685, 1437.3003, 1437.1489,\n",
            "        1435.3414, 1436.8352, 1436.4191, 1436.2261, 1437.0825, 1436.2050,\n",
            "        1436.2716, 1436.1637, 1437.3950, 1435.5652, 1437.1072, 1436.4366,\n",
            "        1436.5143, 1436.7987, 1436.4841, 1436.0131, 1436.7560, 1436.5662,\n",
            "        1436.4834, 1436.6422, 1436.4714, 1432.6688, 1435.6423, 1436.1638,\n",
            "        1436.9484, 1437.1724, 1437.3612, 1437.1014, 1437.1055, 1436.7762,\n",
            "        1436.2242, 1437.1157, 1436.2437, 1436.8674, 1437.2321, 1436.7601,\n",
            "        1436.7032], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([6.0185e-18, 3.9349e-06, 1.3898e-04, 2.6866e-11, 1.5296e-03, 1.0161e-02,\n",
            "        1.0382e-02, 1.7313e-04, 1.2720e-02, 8.1757e-07, 4.5440e-10, 4.8509e-04,\n",
            "        3.5484e-05, 1.1603e-03, 7.8160e-01, 1.0503e-03, 1.5634e-07, 2.2581e-04,\n",
            "        2.4097e-07, 1.0532e-04, 4.7663e-04, 3.4140e-02, 1.8717e-05, 1.4291e-07,\n",
            "        5.5779e-04, 4.0695e-03, 1.4900e-02, 5.6602e-04, 7.0037e-23, 1.7863e-04,\n",
            "        2.8513e-05, 2.3268e-06, 8.7734e-25, 2.2442e-06, 4.7678e-02, 1.5641e-04,\n",
            "        7.0009e-06, 3.0564e-04, 1.1323e-03, 8.1249e-03, 1.3382e-09, 1.2124e-03,\n",
            "        3.5495e-03, 5.8963e-05, 1.6718e-03, 1.8551e-06, 5.1680e-05, 4.8691e-05,\n",
            "        9.1515e-04, 1.2978e-05, 1.3249e-04, 8.3639e-05, 1.7983e-05, 1.2253e-04,\n",
            "        1.1543e-05, 5.8676e-05, 1.9074e-16, 2.2151e-02, 1.2067e-02, 5.0350e-03,\n",
            "        2.7125e-12, 9.4102e-07, 2.7635e-05, 6.2174e-03, 1.0147e-05, 5.6943e-03,\n",
            "        8.6984e-04, 1.1191e-03, 2.0738e-05, 3.1132e-05, 6.1123e-06, 2.3829e-10,\n",
            "        8.4404e-16, 3.5150e-03, 2.7993e-04, 5.7316e-05, 2.3595e-04, 4.9708e-04,\n",
            "        5.4234e-09, 1.1345e-03, 2.1484e-04, 4.3216e-06, 7.8013e-07, 4.2145e-04,\n",
            "        1.2614e-12, 4.0209e-05, 6.8193e-12, 6.1312e-05, 2.2581e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [14]\n",
            "DEBUGGING: logits looks like: tensor([1433.8677, 1436.5883, 1436.9447, 1435.3988, 1437.1846, 1437.3739,\n",
            "        1437.3761, 1436.9667, 1437.3964, 1436.4312, 1435.6816, 1437.0697,\n",
            "        1436.8082, 1437.1570, 1437.8082, 1437.1470, 1436.2657, 1436.9933,\n",
            "        1436.3090, 1436.9170, 1437.0680, 1437.4951, 1436.7443, 1436.2567,\n",
            "        1437.0837, 1437.2825, 1437.4122, 1437.0852, 1432.7316, 1436.9698,\n",
            "        1436.7864, 1436.5358, 1432.2936, 1436.5321, 1437.5286, 1436.9565,\n",
            "        1436.6459, 1437.0236, 1437.1545, 1437.3516, 1435.7897, 1437.1614,\n",
            "        1437.2688, 1436.8590, 1437.1935, 1436.5131, 1436.8458, 1436.8398,\n",
            "        1437.1332, 1436.7076, 1436.9399, 1436.8939, 1436.7402, 1436.9321,\n",
            "        1436.6959, 1436.8585, 1434.2133, 1437.4519, 1437.3911, 1437.3037,\n",
            "        1435.1696, 1436.4452, 1436.7832, 1437.3248, 1436.6830, 1437.3160,\n",
            "        1437.1282, 1437.1533, 1436.7545, 1436.7952, 1436.6323, 1435.6171,\n",
            "        1434.3621, 1437.2678, 1437.0148, 1436.8562, 1436.9977, 1437.0721,\n",
            "        1435.9296, 1437.1547, 1436.9883, 1436.5977, 1436.4265, 1437.0557,\n",
            "        1435.0930, 1436.8207, 1435.2617, 1436.8629, 1436.9933],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([4.4751e-17, 1.3336e-02, 8.7202e-03, 8.8576e-03, 1.3091e-02, 4.8064e-03,\n",
            "        8.6439e-03, 8.8662e-03, 1.2787e-02, 9.7567e-03, 1.3129e-02, 9.8910e-03,\n",
            "        7.7635e-03, 1.4003e-02, 1.2274e-02, 2.2268e-02, 6.6600e-03, 1.0884e-02,\n",
            "        8.3862e-03, 1.4003e-02, 6.5953e-03, 6.7057e-03, 4.0751e-03, 7.4953e-03,\n",
            "        1.4141e-02, 1.3559e-02, 9.4012e-03, 3.8545e-03, 1.0611e-02, 1.4224e-02,\n",
            "        1.3206e-02, 1.2516e-02, 1.0758e-02, 8.2240e-03, 1.4733e-02, 1.0106e-02,\n",
            "        4.0002e-03, 1.2725e-02, 1.3519e-02, 5.2071e-03, 9.7567e-03, 1.0601e-02,\n",
            "        1.8624e-02, 4.7134e-03, 8.9096e-03, 8.8662e-03, 8.5099e-03, 7.5837e-03,\n",
            "        6.3240e-03, 9.6524e-03, 8.2642e-03, 6.3736e-03, 9.4935e-03, 2.1103e-02,\n",
            "        4.3337e-03, 1.4863e-02, 8.8576e-03, 5.2020e-03, 8.9009e-03, 8.6778e-03,\n",
            "        7.6208e-03, 8.1361e-03, 7.6956e-03, 1.1362e-02, 1.4935e-02, 5.8488e-03,\n",
            "        8.9009e-03, 2.9525e-03, 1.2166e-02, 9.1655e-03, 2.1880e-02, 1.7393e-02,\n",
            "        8.4850e-03, 8.5516e-03, 8.5516e-03, 2.5134e-02, 7.8781e-03, 1.1861e-02,\n",
            "        1.0185e-02, 1.9913e-05, 5.8374e-03, 1.2750e-02, 8.4355e-03, 1.0768e-02,\n",
            "        7.0619e-03, 1.2334e-02, 2.1562e-02, 8.8662e-03, 1.0096e-02, 1.5200e-02,\n",
            "        6.2687e-03, 1.3219e-02, 1.1034e-02, 4.8393e-03, 1.2406e-02, 1.0570e-02,\n",
            "        1.9177e-02, 7.4588e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [49]\n",
            "DEBUGGING: logits looks like: tensor([1434.3665, 1437.6992, 1437.6567, 1437.6583, 1437.6974, 1437.5972,\n",
            "        1437.6559, 1437.6584, 1437.6951, 1437.6680, 1437.6976, 1437.6693,\n",
            "        1437.6451, 1437.7041, 1437.6909, 1437.7505, 1437.6298, 1437.6790,\n",
            "        1437.6528, 1437.7041, 1437.6288, 1437.6305, 1437.5807, 1437.6416,\n",
            "        1437.7051, 1437.7009, 1437.6643, 1437.5751, 1437.6764, 1437.7057,\n",
            "        1437.6982, 1437.6929, 1437.6777, 1437.6509, 1437.7092, 1437.6715,\n",
            "        1437.5789, 1437.6946, 1437.7006, 1437.6052, 1437.6680, 1437.6763,\n",
            "        1437.7327, 1437.5952, 1437.6589, 1437.6584, 1437.6543, 1437.6428,\n",
            "        1437.6246, 1437.6669, 1437.6514, 1437.6254, 1437.6653, 1437.7451,\n",
            "        1437.5868, 1437.7101, 1437.6583, 1437.6051, 1437.6588, 1437.6562,\n",
            "        1437.6433, 1437.6498, 1437.6443, 1437.6832, 1437.7106, 1437.6168,\n",
            "        1437.6588, 1437.5485, 1437.6901, 1437.6617, 1437.7488, 1437.7258,\n",
            "        1437.6541, 1437.6548, 1437.6548, 1437.7626, 1437.6466, 1437.6875,\n",
            "        1437.6722, 1437.0486, 1437.6166, 1437.6947, 1437.6534, 1437.6779,\n",
            "        1437.6356, 1437.6914, 1437.7473, 1437.6584, 1437.6714, 1437.7123,\n",
            "        1437.6238, 1437.6984, 1437.6803, 1437.5979, 1437.6920, 1437.6760,\n",
            "        1437.7356, 1437.6411], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([4.0001e-16, 8.4269e-03, 9.2823e-03, 1.1518e-02, 9.2010e-03, 7.5317e-03,\n",
            "        9.9974e-03, 7.5760e-03, 9.0407e-03, 9.1116e-03, 8.6099e-03, 9.9974e-03,\n",
            "        9.9390e-03, 1.1153e-02, 1.0066e-02, 1.1284e-02, 1.0305e-02, 9.9681e-03,\n",
            "        9.6993e-03, 1.0037e-02, 8.3043e-03, 8.7969e-03, 1.1012e-02, 1.2357e-02,\n",
            "        1.0653e-02, 1.0215e-02, 1.0315e-02, 1.0295e-02, 8.8227e-03, 1.1930e-02,\n",
            "        1.1186e-02, 1.1575e-02, 1.1077e-02, 9.0850e-03, 9.8040e-03, 7.8394e-03,\n",
            "        5.5644e-03, 1.0135e-02, 7.1309e-03, 1.1919e-02, 1.2912e-02, 9.8713e-03,\n",
            "        1.0747e-02, 8.5429e-03, 9.3825e-03, 1.0096e-02, 7.1309e-03, 1.2938e-02,\n",
            "        8.6351e-03, 7.6503e-03, 1.0465e-03, 1.0653e-02, 8.2317e-03, 1.0884e-02,\n",
            "        9.5396e-03, 9.6144e-03, 8.9441e-03, 2.6068e-06, 7.8088e-03, 1.0539e-02,\n",
            "        8.5013e-03, 9.0407e-03, 1.3921e-02, 8.0961e-03, 1.2166e-02, 1.0969e-02,\n",
            "        1.0831e-02, 9.8713e-03, 7.9395e-03, 8.3531e-03, 1.0549e-02, 9.6993e-03,\n",
            "        1.2416e-03, 1.4732e-02, 9.0761e-03, 8.9791e-03, 7.2149e-03, 3.3487e-03,\n",
            "        9.2551e-03, 1.1012e-02, 1.0705e-02, 8.8919e-03, 7.4149e-03, 1.1240e-02,\n",
            "        7.9940e-03, 8.6436e-03, 7.2928e-03, 1.0498e-02, 1.1340e-02, 1.0234e-02,\n",
            "        1.5364e-02, 1.0185e-02, 1.2024e-02, 1.0365e-02, 6.7712e-03, 1.1207e-02,\n",
            "        7.4222e-03, 9.2642e-03, 6.9115e-03, 7.8317e-03, 6.4801e-03, 1.0406e-02,\n",
            "        1.3989e-02, 8.5512e-03, 8.4022e-03, 9.8520e-03, 9.9974e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [27]\n",
            "DEBUGGING: logits looks like: tensor([1434.7427, 1437.8105, 1437.8202, 1437.8418, 1437.8193, 1437.7993,\n",
            "        1437.8276, 1437.7999, 1437.8176, 1437.8184, 1437.8127, 1437.8276,\n",
            "        1437.8270, 1437.8386, 1437.8284, 1437.8397, 1437.8307, 1437.8274,\n",
            "        1437.8246, 1437.8280, 1437.8091, 1437.8148, 1437.8373, 1437.8489,\n",
            "        1437.8340, 1437.8298, 1437.8308, 1437.8306, 1437.8152, 1437.8453,\n",
            "        1437.8389, 1437.8423, 1437.8379, 1437.8181, 1437.8257, 1437.8033,\n",
            "        1437.7690, 1437.8290, 1437.7938, 1437.8452, 1437.8533, 1437.8264,\n",
            "        1437.8348, 1437.8119, 1437.8213, 1437.8286, 1437.7938, 1437.8534,\n",
            "        1437.8130, 1437.8009, 1437.6019, 1437.8340, 1437.8082, 1437.8362,\n",
            "        1437.8230, 1437.8237, 1437.8165, 1437.0024, 1437.8030, 1437.8329,\n",
            "        1437.8114, 1437.8176, 1437.8607, 1437.8065, 1437.8473, 1437.8369,\n",
            "        1437.8357, 1437.8264, 1437.8046, 1437.8097, 1437.8330, 1437.8246,\n",
            "        1437.6190, 1437.8665, 1437.8180, 1437.8169, 1437.7950, 1437.7183,\n",
            "        1437.8199, 1437.8373, 1437.8345, 1437.8159, 1437.7977, 1437.8394,\n",
            "        1437.8053, 1437.8131, 1437.7961, 1437.8325, 1437.8402, 1437.8300,\n",
            "        1437.8706, 1437.8295, 1437.8461, 1437.8313, 1437.7887, 1437.8391,\n",
            "        1437.7979, 1437.8201, 1437.7908, 1437.8032, 1437.7843, 1437.8317,\n",
            "        1437.8612, 1437.8120, 1437.8103, 1437.8262, 1437.8276],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.052117844714757666 and immediate abs rewards look like: [0.001628004127269378, 0.0018067069577227812, 0.006974937901759404, 0.00054018023001845, 0.003591665435124014, 0.0020299402899581764, 0.0013187492832003045, 0.006717742574892327, 5.079304764876724e-05, 0.00011969085653618095, 0.000268441979187628, 0.003426883863085095, 0.0019284097611489415, 0.007192151943399949, 0.00032697077267584973, 0.0004304289045649057, 0.004548181889276748, 0.00029448082068483927, 0.00020212336949043674, 1.6777028577052988e-05, 4.758971954288427e-07, 0.00040339113138543325, 0.0007836409663468658, 0.0008639193292765412, 0.003971177059611364, 1.1110094874311471e-05, 3.909100678356481e-05, 8.020768655114807e-05, 8.899780732463114e-05, 0.0003373581498635758, 8.9357495198783e-06, 1.9230732050345978e-05, 9.729432167659979e-05, 0.00016092217583718593, 0.0003433885417507554, 1.545883969811257e-05, 2.6507111670071026e-05, 0.000407527421884879, 6.296691572060809e-05, 0.00022270594081419404, 2.2014759906596737e-05, 0.0005554476988436363, 9.008776032715105e-06, 2.377649252593983e-06, 7.657425931029138e-05, 1.7171087165479548e-06, 6.843709979875712e-05, 1.083607003238285e-06, 5.735644663218409e-06, 1.78801951733476e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 23.86078416552166 and immediate relative rewards look like: [0.060166174884518614, 0.1336213914446697, 0.7743015514523204, 0.08016218963136222, 0.6663828597406221, 0.4525552954912083, 0.34326150941555106, 1.9993608996947514, 0.017049489475658007, 0.04464098822373103, 0.11013752941671758, 1.5339681110797279, 0.9363406734280744, 3.763492229101334, 0.18381179367416792, 0.25813554646035214, 2.898566181869467, 0.19905226139353274, 0.1442300504456795, 0.012602701027960139, 0.0003753649957515638, 0.33332695484977765, 0.6770678332664039, 0.7791113154665175, 3.7317741041059107, 0.010874166099593326, 0.03973262726957238, 0.08454483398622795, 0.09716357207087421, 0.38102474397760067, 0.010430102148004777, 0.023170912525725985, 0.12089321348485331, 0.20602086715767703, 0.4525812505474031, 0.020959372229642288, 0.036937333140315325, 0.583238485934221, 0.0925016395530201, 0.3355633311110117, 0.03400297752076085, 0.8788509009873431, 0.014596471087809749, 0.003941990424218789, 0.12984068782478053, 0.0029763475636151167, 0.12120422416982604, 0.0019599840695283454, 0.010590537350641659, 0.033688593251623725]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 150 number of matrices\n",
            "DEBUGGING: ACT_MAT has 150 number of matrices\n",
            "DEBUGGING: VAL looks like: [[42.79132916139595, 42.74410007582989, 42.92601551682667, 42.02689726103742, 35.748731093994024, 35.93145754659006, 36.25924929085187, 36.53512406960406, 36.54897494124855, 36.66985055686729, 37.03527803741626, 37.40331375640921, 37.627766230743966, 37.94979370066382, 38.24240257003684, 38.44791456486396, 38.72675076781226, 39.01557841189607, 39.322792766393896, 39.616339669871614, 38.792650981132, 38.846746894801605, 35.34235304365007, 35.67858003136749, 33.01030838566971, 32.025888653585035, 32.31107019288274, 32.58144239951993, 31.280090561767736, 30.552821017652956, 30.207145415920547, 27.723456503958516, 26.751378753860013, 23.191209559105, 21.18288654189393, 19.27521796264702, 11.19252491875443, 11.112364159366603, 10.934331606818585, 10.89531129308624, 10.240022342444991, 7.6616261218222315, 6.405205545431477, 6.059668222380608, 5.99858050935315, 3.1428664612653483, 1.2866707506983226, 1.180580441104737, 1.163681864559742, 0.7786135798661646], [25.870398374532968, 26.070941615806515, 26.199313357941257, 25.681830107564583, 25.86027062417497, 25.448371479226612, 25.071770538674766, 24.803880733585032, 24.73020572429596, 24.242188193084726, 23.63208101833232, 23.591543852929863, 23.804820986600653, 24.007907664731025, 24.247189062743306, 24.486554666441883, 24.549998558832815, 24.165979439718846, 24.390855333302405, 24.239255129080576, 22.700253324672385, 22.876409243893402, 23.063419794422586, 23.14281776824522, 21.484472156346143, 18.463724752100703, 17.1039514018086, 17.022427619120567, 16.946623835549186, 12.71707976349572, 12.74075898987142, 12.720915463768337, 12.835694122528842, 12.539925092402871, 11.71330847894096, 11.786033435138341, 11.821080355061678, 3.8719930718279936, 3.5011568656011853, 3.216660974552364, 2.9114170516441114, 2.479135770303069, 2.47043180500593, 2.439894757273601, 2.333465774073379, 2.1945269929736826, 2.1016498682724967, 0.06987100527416942, 0.049957670705931004, 0.03155674425597337], [20.04261416447925, 20.18429089858054, 20.253201522359465, 19.67565653626984, 19.79342863296816, 19.32024825578539, 19.05827571746887, 18.904054755609412, 17.07544833930774, 17.230705908921298, 17.359661536058148, 17.42376162287013, 16.050296476555964, 15.266622023361503, 11.61932302450522, 11.55102144528389, 11.40695545335711, 8.594332597462264, 8.480081147544173, 8.4200516132308, 8.492372638588728, 8.57777502383129, 8.327725322203548, 7.727936857512268, 7.019015699036112, 3.3204460554850517, 3.3430019084701597, 3.336635637576351, 3.2849402056465893, 3.2199763975512274, 2.8676279329026535, 2.886058414903686, 2.891805557957535, 2.7989013580532136, 2.6190712029247845, 2.1883736892700822, 2.1893073909499394, 2.1741111695046706, 1.6069421046166157, 1.5297378434985816, 1.2062368811995654, 1.1840746501806108, 0.30830681736693705, 0.29667711745366393, 0.2956920475044901, 0.16752662593910056, 0.16621240239948024, 0.045462806292579996, 0.04394224466974914, 0.033688593251623725]]\n",
            "DEBUGGING: traj_returns = [42.79132916139595, 25.870398374532968, 20.04261416447925]\n",
            "DEBUGGING: actions = [[12], [7], [39], [8], [12], [22], [53], [59], [62], [42], [70], [17], [20], [22], [3], [1], [31], [54], [61], [71], [31], [34], [33], [7], [2], [4], [52], [1], [67], [87], [78], [6], [66], [88], [26], [6], [90], [29], [23], [96], [19], [44], [44], [77], [87], [30], [31], [39], [83], [36], [55], [1], [48], [7], [15], [56], [65], [50], [66], [13], [49], [7], [7], [73], [74], [68], [47], [6], [41], [47], [6], [79], [70], [61], [14], [24], [48], [73], [83], [6], [47], [20], [9], [21], [81], [9], [14], [14], [19], [62], [79], [73], [85], [42], [74], [66], [89], [95], [86], [73], [55], [1], [48], [7], [15], [1], [6], [47], [41], [7], [6], [14], [33], [37], [69], [72], [8], [7], [7], [7], [73], [1], [6], [52], [8], [25], [52], [80], [17], [14], [75], [27], [68], [71], [80], [38], [70], [32], [21], [49], [4], [36], [80], [76], [79], [31], [65], [95], [11], [27]]\n",
            "DEBUGGING: actions length = 150\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[  7.0955,   7.4946,  12.3990,  ...,   4.4654, -13.3211, -20.4075],\n",
            "        [  7.1810,   7.6024,  12.5586,  ...,   4.5184, -13.4829, -20.6483],\n",
            "        [  7.2521,   7.6683,  12.6912,  ...,   4.5675, -13.6283, -20.8636],\n",
            "        ...,\n",
            "        [  7.2252,   7.6405,  12.6249,  ...,   4.5444, -13.5589, -20.7654],\n",
            "        [  7.2251,   7.6404,  12.6247,  ...,   4.5443, -13.5587, -20.7650],\n",
            "        [  7.2249,   7.6403,  12.6244,  ...,   4.5443, -13.5585, -20.7647]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[  7.2083,   7.6220,  12.5960,  ...,   4.5352, -13.5317, -20.7215],\n",
            "        [  7.2248,   7.6401,  12.6243,  ...,   4.5442, -13.5583, -20.7645],\n",
            "        [  7.2249,   7.6402,  12.6244,  ...,   4.5442, -13.5584, -20.7646],\n",
            "        ...,\n",
            "        [  7.2248,   7.6401,  12.6243,  ...,   4.5442, -13.5583, -20.7645],\n",
            "        [  7.2249,   7.6402,  12.6244,  ...,   4.5443, -13.5585, -20.7647],\n",
            "        [  7.2249,   7.6402,  12.6244,  ...,   4.5443, -13.5585, -20.7647]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([1434.7427, 1437.8105, 1437.8202, 1437.8418, 1437.8193, 1437.7993,\n",
            "        1437.8276, 1437.7999, 1437.8176, 1437.8184, 1437.8127, 1437.8276,\n",
            "        1437.8270, 1437.8386, 1437.8284, 1437.8397, 1437.8307, 1437.8274,\n",
            "        1437.8246, 1437.8280, 1437.8091, 1437.8148, 1437.8373, 1437.8489,\n",
            "        1437.8340, 1437.8298, 1437.8308, 1437.8306, 1437.8152, 1437.8453,\n",
            "        1437.8389, 1437.8423, 1437.8379, 1437.8181, 1437.8257, 1437.8033,\n",
            "        1437.7690, 1437.8290, 1437.7938, 1437.8452, 1437.8533, 1437.8264,\n",
            "        1437.8348, 1437.8119, 1437.8213, 1437.8286, 1437.7938, 1437.8534,\n",
            "        1437.8130, 1437.8009, 1437.6019, 1437.8340, 1437.8082, 1437.8362,\n",
            "        1437.8230, 1437.8237, 1437.8165, 1437.0024, 1437.8030, 1437.8329,\n",
            "        1437.8114, 1437.8176, 1437.8607, 1437.8065, 1437.8473, 1437.8369,\n",
            "        1437.8357, 1437.8264, 1437.8046, 1437.8097, 1437.8330, 1437.8246,\n",
            "        1437.6190, 1437.8665, 1437.8180, 1437.8169, 1437.7950, 1437.7183,\n",
            "        1437.8199, 1437.8373, 1437.8345, 1437.8159, 1437.7977, 1437.8394,\n",
            "        1437.8053, 1437.8131, 1437.7961, 1437.8325, 1437.8402, 1437.8300,\n",
            "        1437.8706, 1437.8295, 1437.8461, 1437.8313, 1437.7887, 1437.8391,\n",
            "        1437.7979, 1437.8201, 1437.7908, 1437.8032, 1437.7843, 1437.8317,\n",
            "        1437.8612, 1437.8120, 1437.8103, 1437.8262, 1437.8276],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[29.5681139  29.6664442  29.79284347 29.12812797 27.13414345 26.90002576\n",
            "  26.79643185 26.74768652 26.11820967 26.04758155 26.00900686 26.13953974\n",
            "  25.8276279  25.74144113 24.70297155 24.82849689 24.89456826 23.92529682\n",
            "  24.06457642 24.09188214 23.32842565 23.43364372 22.24449939 22.18311155\n",
            "  20.50459875 17.93668649 17.58600783 17.64683522 17.17055153 15.49662573\n",
            "  15.27184411 14.44347679 14.15962614 12.84334534 11.83842207 11.08320836\n",
            "   8.40097089  5.71948947  5.34747686  5.21390337  4.78589209  3.77494551\n",
            "   3.06131472  2.93208003  2.87591278  1.83497336  1.18484434  0.43197142\n",
            "   0.41919393  0.28128631]]\n",
            "DEBUGGING: baseline2 looks like: 29.568113900136055\n",
            "DEBUGGING: ADS looks like: [ 13.22321526  13.07765588  13.13317205  12.89876929   8.61458764\n",
            "   9.03143179   9.46281744   9.78743755  10.43076527  10.622269\n",
            "  11.02627117  11.26377401  11.80013833  12.20835257  13.53943102\n",
            "  13.61941767  13.83218251  15.0902816   15.25821635  15.52445753\n",
            "  15.46422533  15.41310317  13.09785366  13.49546848  12.50570964\n",
            "  14.08920217  14.72506236  14.93460718  14.10953903  15.05619529\n",
            "  14.9353013   13.27997971  12.59175261  10.34786422   9.34446447\n",
            "   8.1920096    2.79155403   5.39287469   5.58685475   5.68140792\n",
            "   5.45413025   3.88668061   3.34389082   3.12758819   3.12266773\n",
            "   1.3078931    0.10182641   0.74860902   0.74448794   0.49732727\n",
            "  -3.69771553  -3.59550258  -3.59353011  -3.44629786  -1.27387283\n",
            "  -1.45165428  -1.72466131  -1.94380579  -1.38800394  -1.80539336\n",
            "  -2.37692585  -2.54799589  -2.02280691  -1.73353346  -0.45578249\n",
            "  -0.34194223  -0.3445697    0.24068262   0.32627892   0.14737299\n",
            "  -0.62817232  -0.55723448   0.81892041   0.95970622   0.97987341\n",
            "   0.52703827  -0.48205643  -0.6244076   -0.2239277   -2.77954596\n",
            "  -2.53108512  -1.72256133  -1.32393202  -0.30342024  -0.1251136\n",
            "   0.70282507   3.42010947  -1.8474964   -1.84631999  -1.9972424\n",
            "  -1.87447504  -1.29580974  -0.59088292  -0.49218528  -0.542447\n",
            "   0.35955363   0.91680553  -0.36210041  -0.36923626  -0.24972956\n",
            "  -9.52549974  -9.4821533   -9.53964194  -9.45247143  -7.34071482\n",
            "  -7.5797775   -7.73815613  -7.84363176  -9.04276133  -8.81687564\n",
            "  -8.64934533  -8.71577812  -9.77733142 -10.47481911 -13.08364853\n",
            " -13.27747545 -13.48761281 -15.33096422 -15.58449527 -15.67183052\n",
            " -14.83605301 -14.8558687  -13.91677406 -14.45517469 -13.48558305\n",
            " -14.61624043 -14.24300593 -14.31019958 -13.88561133 -12.27664933\n",
            " -12.40421618 -11.55741838 -11.26782059 -10.04444398  -9.21935087\n",
            "  -8.89483467  -6.2116635   -3.5453783   -3.74053475  -3.68416553\n",
            "  -3.57965521  -2.59087086  -2.75300791  -2.63540291  -2.58022073\n",
            "  -1.66744673  -1.01863194  -0.38650861  -0.37525168  -0.24759771]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(1.1619, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-0.0122, -0.1080,  0.1470,  ..., -0.0495, -0.0711, -0.0046],\n",
            "        [ 0.0050,  0.0446, -0.0607,  ...,  0.0204,  0.0293, -0.0033],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [-0.0042, -0.0368,  0.0501,  ..., -0.0169, -0.0242, -0.0036],\n",
            "        [-0.0093, -0.0819,  0.1115,  ..., -0.0375, -0.0539, -0.0039],\n",
            "        [-0.0053, -0.0471,  0.0641,  ..., -0.0216, -0.0310,  0.0004]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0140,  0.0013, -0.0014,  0.0000,  0.0000,  0.0000,  0.0000, -0.0044,\n",
            "          0.0000,  0.0000,  0.0096,  0.0015,  0.0040,  0.0000,  0.0133,  0.0000,\n",
            "          0.0022,  0.0000,  0.0004,  0.0000],\n",
            "        [ 0.0146,  0.0012, -0.0015,  0.0000,  0.0000,  0.0000,  0.0000, -0.0047,\n",
            "          0.0000,  0.0000,  0.0099,  0.0014,  0.0041,  0.0000,  0.0138,  0.0000,\n",
            "          0.0023,  0.0000,  0.0003,  0.0000],\n",
            "        [ 0.0179, -0.0091, -0.0089,  0.0000,  0.0000,  0.0000,  0.0000, -0.0168,\n",
            "          0.0000,  0.0000,  0.0109, -0.0066,  0.0036,  0.0000,  0.0158,  0.0000,\n",
            "         -0.0022,  0.0000, -0.0048,  0.0000],\n",
            "        [-0.0123,  0.0048,  0.0052,  0.0000,  0.0000,  0.0000,  0.0000,  0.0101,\n",
            "          0.0000,  0.0000, -0.0077,  0.0034, -0.0027,  0.0000, -0.0110,  0.0000,\n",
            "          0.0008,  0.0000,  0.0026,  0.0000],\n",
            "        [-0.0139,  0.0172,  0.0137,  0.0000,  0.0000,  0.0000,  0.0000,  0.0238,\n",
            "          0.0000,  0.0000, -0.0072,  0.0130, -0.0015,  0.0000, -0.0112,  0.0000,\n",
            "          0.0064,  0.0000,  0.0087,  0.0000],\n",
            "        [-0.0215,  0.0114,  0.0110,  0.0000,  0.0000,  0.0000,  0.0000,  0.0208,\n",
            "          0.0000,  0.0000, -0.0131,  0.0082, -0.0043,  0.0000, -0.0189,  0.0000,\n",
            "          0.0029,  0.0000,  0.0060,  0.0000],\n",
            "        [ 0.0059, -0.0141, -0.0104,  0.0000,  0.0000,  0.0000,  0.0000, -0.0173,\n",
            "          0.0000,  0.0000,  0.0023, -0.0108, -0.0003,  0.0000,  0.0040,  0.0000,\n",
            "         -0.0059,  0.0000, -0.0070,  0.0000],\n",
            "        [ 0.0072, -0.0024, -0.0027,  0.0000,  0.0000,  0.0000,  0.0000, -0.0055,\n",
            "          0.0000,  0.0000,  0.0045, -0.0016,  0.0016,  0.0000,  0.0065,  0.0000,\n",
            "         -0.0003,  0.0000, -0.0013,  0.0000],\n",
            "        [-0.0108,  0.0238,  0.0176,  0.0000,  0.0000,  0.0000,  0.0000,  0.0293,\n",
            "          0.0000,  0.0000, -0.0043,  0.0182,  0.0003,  0.0000, -0.0075,  0.0000,\n",
            "          0.0099,  0.0000,  0.0119,  0.0000],\n",
            "        [-0.0248,  0.0228,  0.0192,  0.0000,  0.0000,  0.0000,  0.0000,  0.0340,\n",
            "          0.0000,  0.0000, -0.0139,  0.0170, -0.0036,  0.0000, -0.0207,  0.0000,\n",
            "          0.0078,  0.0000,  0.0116,  0.0000]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.2113,  0.0585,  0.1790,  ..., -0.0562, -0.2985, -0.1294],\n",
            "        [-0.0941, -0.0261, -0.0797,  ...,  0.0249,  0.1328,  0.0432],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0747,  0.0206,  0.0632,  ..., -0.0199, -0.1055, -0.0512],\n",
            "        [ 0.1657,  0.0458,  0.1404,  ..., -0.0441, -0.2341, -0.1040],\n",
            "        [ 0.0862,  0.0239,  0.0730,  ..., -0.0229, -0.1217, -0.0459]])\n",
            "   Last layer:\n",
            "tensor([[-1.0380e-03, -1.0589e-02, -7.4804e-03,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -2.4380e-02,  0.0000e+00,  0.0000e+00,\n",
            "          4.9940e-03,  2.2171e-03,  2.3227e-03,  0.0000e+00,  1.5578e-02,\n",
            "          0.0000e+00, -1.4547e-02,  0.0000e+00, -2.3893e-02,  0.0000e+00],\n",
            "        [-7.1075e-03, -2.1617e-02, -1.3721e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -3.4063e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -1.8134e-04, -6.0758e-03, -5.8604e-04,  0.0000e+00,  9.4765e-03,\n",
            "          0.0000e+00, -2.0869e-02,  0.0000e+00, -3.0316e-02,  0.0000e+00],\n",
            "        [-1.3147e-02, -3.7792e-02, -2.3911e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -5.8274e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -1.5544e-03, -1.1752e-02, -1.5579e-03,  0.0000e+00,  1.4165e-02,\n",
            "          0.0000e+00, -3.5670e-02,  0.0000e+00, -5.1102e-02,  0.0000e+00],\n",
            "        [ 9.0926e-03,  2.5397e-02,  1.6068e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  3.8419e-02,  0.0000e+00,  0.0000e+00,\n",
            "          1.3574e-03,  8.0159e-03,  1.2109e-03,  0.0000e+00, -8.7068e-03,\n",
            "          0.0000e+00,  2.3676e-02,  0.0000e+00,  3.3686e-02,  0.0000e+00],\n",
            "        [ 3.6466e-02,  7.7349e-02,  4.6586e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  9.0933e-02,  0.0000e+00,  0.0000e+00,\n",
            "          2.1828e-02,  4.2672e-02,  1.2669e-02,  0.0000e+00,  1.0967e-02,\n",
            "          0.0000e+00,  5.7500e-02,  0.0000e+00,  7.1325e-02,  0.0000e+00],\n",
            "        [ 2.6136e-02,  6.3013e-02,  3.8900e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  8.4429e-02,  0.0000e+00,  0.0000e+00,\n",
            "          1.0846e-02,  2.7945e-02,  6.8557e-03,  0.0000e+00, -5.8162e-03,\n",
            "          0.0000e+00,  5.2592e-02,  0.0000e+00,  7.0345e-02,  0.0000e+00],\n",
            "        [-2.1429e-02, -4.5752e-02, -2.7528e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -5.3966e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -1.2636e-02, -2.5002e-02, -7.4115e-03,  0.0000e+00, -6.0987e-03,\n",
            "          0.0000e+00, -3.4088e-02,  0.0000e+00, -4.2411e-02,  0.0000e+00],\n",
            "        [-3.3614e-03, -1.1261e-02, -7.2651e-03,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -1.9093e-02,  0.0000e+00,  0.0000e+00,\n",
            "          7.1499e-04, -2.3078e-03,  1.1830e-04,  0.0000e+00,  6.6562e-03,\n",
            "          0.0000e+00, -1.1586e-02,  0.0000e+00, -1.7244e-02,  0.0000e+00],\n",
            "        [ 3.9101e-02,  8.2437e-02,  4.9500e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  9.5829e-02,  0.0000e+00,  0.0000e+00,\n",
            "          2.3605e-02,  4.5766e-02,  1.3689e-02,  0.0000e+00,  1.2652e-02,\n",
            "          0.0000e+00,  6.0745e-02,  0.0000e+00,  7.4981e-02,  0.0000e+00],\n",
            "        [ 5.5739e-02,  1.1946e-01,  7.1852e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  1.4142e-01,  0.0000e+00,  0.0000e+00,\n",
            "          3.2740e-02,  6.4531e-02,  1.9024e-02,  0.0000e+00,  1.5160e-02,\n",
            "          0.0000e+00,  8.9435e-02,  0.0000e+00,  1.1152e-01,  0.0000e+00]])\n",
            "DEBUGGING: training for one iteration takes 0.003927 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 17\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([2.7144e-08, 2.2385e-04, 1.4324e-05, 2.3137e-05, 9.2796e-03, 3.2838e-08,\n",
            "        2.9553e-01, 3.2474e-04, 6.2254e-08, 4.8088e-04, 1.1357e-03, 3.1378e-05,\n",
            "        3.7020e-03, 2.2604e-04, 2.2182e-06, 2.7503e-05, 1.3382e-03, 6.2385e-07,\n",
            "        1.0657e-04, 1.3185e-04, 3.8829e-04, 7.7616e-09, 1.4061e-05, 9.3433e-03,\n",
            "        7.0183e-03, 2.1703e-02, 1.1366e-04, 5.1711e-08, 1.0102e-02, 1.1983e-03,\n",
            "        6.8630e-09, 4.0735e-10, 3.2697e-04, 8.6541e-06, 9.1001e-03, 3.5771e-04,\n",
            "        4.8396e-07, 2.7839e-02, 4.5263e-04, 1.8926e-03, 1.3316e-10, 2.2741e-03,\n",
            "        9.7616e-04, 1.2608e-03, 8.7759e-04, 3.1909e-04, 2.4561e-04, 7.7587e-05,\n",
            "        4.8066e-07, 1.7972e-03, 1.3443e-05, 3.0009e-03, 6.3068e-06, 3.4743e-03,\n",
            "        6.0257e-04, 9.6196e-04, 9.0341e-06, 1.6316e-03, 8.8361e-04, 5.2695e-06,\n",
            "        4.1663e-03, 1.8128e-04, 1.1358e-09, 1.6449e-01, 2.5318e-10, 1.7041e-06,\n",
            "        3.2384e-03, 1.1097e-01, 2.9610e-01], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [67]\n",
            "DEBUGGING: logits looks like: tensor([1558.5999, 1559.5016, 1559.2267, 1559.2747, 1559.8740, 1558.6189,\n",
            "        1560.2201, 1559.5388, 1558.6829, 1559.5780, 1559.6639, 1559.3051,\n",
            "        1559.7821, 1559.5026, 1559.0402, 1559.2919, 1559.6804, 1558.9133,\n",
            "        1559.4274, 1559.4486, 1559.5566, 1558.4746, 1559.2249, 1559.8748,\n",
            "        1559.8461, 1559.9590, 1559.4338, 1558.6643, 1559.8826, 1559.6693,\n",
            "        1558.4623, 1558.1799, 1559.5394, 1559.1763, 1559.8721, 1559.5485,\n",
            "        1558.8879, 1559.9839, 1559.5720, 1559.7151, 1558.0681, 1559.7334,\n",
            "        1559.6488, 1559.6744, 1559.6382, 1559.5370, 1559.5109, 1559.3956,\n",
            "        1558.8872, 1559.7098, 1559.2203, 1559.7611, 1559.1447, 1559.7758,\n",
            "        1559.6006, 1559.6473, 1559.1805, 1559.7002, 1559.6389, 1559.1267,\n",
            "        1559.7939, 1559.4805, 1558.2825, 1560.1615, 1558.1323, 1559.0138,\n",
            "        1559.7688, 1560.1222, 1560.2203], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.7293e-09, 1.6636e-02, 8.9923e-03, 2.8134e-02, 7.7216e-03, 1.1682e-02,\n",
            "        1.5921e-02, 1.6932e-02, 5.4222e-03, 1.3685e-02, 1.5568e-02, 1.7265e-02,\n",
            "        1.4426e-02, 6.4769e-03, 8.5972e-03, 2.7109e-02, 1.5537e-02, 6.5277e-03,\n",
            "        1.0741e-02, 1.9679e-02, 1.7537e-02, 1.8741e-02, 1.2906e-02, 9.2777e-03,\n",
            "        8.8528e-03, 1.0564e-02, 6.0489e-03, 1.7936e-02, 9.3231e-03, 2.2695e-02,\n",
            "        6.4642e-03, 1.7418e-02, 9.7040e-03, 1.7435e-02, 1.1412e-02, 1.5462e-02,\n",
            "        1.0910e-02, 8.5387e-03, 4.0531e-03, 9.9632e-03, 1.3290e-02, 1.0826e-02,\n",
            "        9.7610e-03, 2.1175e-02, 8.5972e-03, 7.7216e-03, 1.8165e-02, 1.4942e-02,\n",
            "        2.1804e-02, 1.5207e-02, 1.2231e-02, 1.3007e-02, 1.0804e-02, 1.2448e-02,\n",
            "        1.1456e-02, 1.9488e-02, 1.4582e-02, 1.4482e-02, 1.1301e-02, 1.3712e-02,\n",
            "        1.2781e-02, 1.1367e-02, 7.4185e-03, 1.8112e-02, 3.8637e-03, 1.0804e-02,\n",
            "        1.0140e-02, 1.4582e-02, 3.8262e-03, 1.9622e-02, 1.5598e-02, 1.1257e-02,\n",
            "        9.3322e-03, 9.9147e-03, 1.7215e-02, 1.0190e-02, 1.4942e-02, 1.1740e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [53]\n",
            "DEBUGGING: logits looks like: tensor([1558.6068, 1560.1692, 1560.1077, 1560.2217, 1560.0924, 1560.1338,\n",
            "        1560.1648, 1560.1709, 1560.0570, 1560.1497, 1560.1625, 1560.1729,\n",
            "        1560.1549, 1560.0748, 1560.1031, 1560.2180, 1560.1624, 1560.0756,\n",
            "        1560.1254, 1560.1859, 1560.1744, 1560.1810, 1560.1438, 1560.1107,\n",
            "        1560.1061, 1560.1238, 1560.0680, 1560.1766, 1560.1112, 1560.2002,\n",
            "        1560.0746, 1560.1737, 1560.1152, 1560.1738, 1560.1315, 1560.1619,\n",
            "        1560.1270, 1560.1024, 1560.0280, 1560.1179, 1560.1467, 1560.1262,\n",
            "        1560.1158, 1560.1932, 1560.1031, 1560.0924, 1560.1780, 1560.1584,\n",
            "        1560.1962, 1560.1602, 1560.1384, 1560.1445, 1560.1260, 1560.1401,\n",
            "        1560.1318, 1560.1849, 1560.1560, 1560.1553, 1560.1305, 1560.1498,\n",
            "        1560.1428, 1560.1311, 1560.0884, 1560.1776, 1560.0232, 1560.1260,\n",
            "        1560.1196, 1560.1560, 1560.0222, 1560.1857, 1560.1627, 1560.1301,\n",
            "        1560.1113, 1560.1174, 1560.1726, 1560.1201, 1560.1584, 1560.1343],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([3.3845e-09, 1.2673e-02, 1.1194e-02, 1.3437e-02, 1.1789e-02, 1.1709e-02,\n",
            "        1.2623e-02, 1.0303e-02, 9.4635e-03, 1.1326e-02, 1.1371e-02, 1.2872e-02,\n",
            "        1.0797e-02, 1.1382e-02, 1.1732e-02, 1.3676e-02, 1.1870e-02, 1.3649e-02,\n",
            "        1.2476e-02, 1.2549e-02, 1.4234e-02, 1.2623e-02, 1.0113e-02, 1.2307e-02,\n",
            "        9.4450e-03, 1.3062e-02, 1.2935e-02, 1.2199e-02, 1.2910e-02, 1.2562e-02,\n",
            "        1.3190e-02, 9.0125e-03, 4.4052e-03, 1.3437e-02, 1.1064e-02, 1.2525e-02,\n",
            "        9.4913e-03, 1.2935e-02, 1.0892e-02, 1.2045e-02, 1.2500e-02, 1.2319e-02,\n",
            "        1.1789e-02, 1.1371e-02, 1.2735e-02, 1.3294e-02, 1.1870e-02, 1.3516e-02,\n",
            "        1.2223e-02, 1.4686e-02, 1.1107e-02, 1.0015e-02, 1.1697e-02, 1.0839e-02,\n",
            "        1.4515e-02, 1.2722e-02, 1.3556e-02, 1.5108e-02, 1.2872e-02, 1.2022e-02,\n",
            "        1.3088e-02, 1.1674e-02, 1.0935e-02, 1.1789e-02, 1.0787e-02, 1.2935e-02,\n",
            "        1.1835e-02, 9.5751e-03, 1.0619e-02, 1.2772e-02, 8.6927e-03, 1.1140e-02,\n",
            "        1.1282e-02, 1.2116e-02, 1.1870e-02, 1.0935e-02, 7.3990e-03, 1.2235e-02,\n",
            "        1.2022e-02, 1.1709e-02, 1.0333e-02, 1.0035e-02, 1.0892e-02, 1.2562e-02,\n",
            "        1.1963e-02, 9.7735e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [83]\n",
            "DEBUGGING: logits looks like: tensor([1558.9348, 1560.4484, 1560.4359, 1560.4542, 1560.4412, 1560.4404,\n",
            "        1560.4480, 1560.4276, 1560.4192, 1560.4371, 1560.4375, 1560.4500,\n",
            "        1560.4324, 1560.4376, 1560.4407, 1560.4559, 1560.4418, 1560.4558,\n",
            "        1560.4468, 1560.4474, 1560.4600, 1560.4480, 1560.4258, 1560.4454,\n",
            "        1560.4189, 1560.4514, 1560.4504, 1560.4446, 1560.4502, 1560.4475,\n",
            "        1560.4524, 1560.4143, 1560.3427, 1560.4542, 1560.4348, 1560.4471,\n",
            "        1560.4194, 1560.4504, 1560.4332, 1560.4432, 1560.4470, 1560.4456,\n",
            "        1560.4412, 1560.4375, 1560.4489, 1560.4531, 1560.4418, 1560.4548,\n",
            "        1560.4447, 1560.4631, 1560.4352, 1560.4248, 1560.4403, 1560.4327,\n",
            "        1560.4619, 1560.4487, 1560.4551, 1560.4659, 1560.4500, 1560.4431,\n",
            "        1560.4515, 1560.4402, 1560.4336, 1560.4412, 1560.4323, 1560.4504,\n",
            "        1560.4415, 1560.4203, 1560.4307, 1560.4491, 1560.4106, 1560.4354,\n",
            "        1560.4368, 1560.4438, 1560.4418, 1560.4336, 1560.3945, 1560.4448,\n",
            "        1560.4431, 1560.4404, 1560.4280, 1560.4250, 1560.4332, 1560.4475,\n",
            "        1560.4426, 1560.4224], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.9193e-09, 1.0533e-02, 1.0574e-02, 9.9138e-03, 1.0410e-02, 1.0070e-02,\n",
            "        9.8367e-03, 1.0080e-02, 1.0109e-02, 1.0080e-02, 1.0259e-02, 1.0564e-02,\n",
            "        9.8079e-03, 1.0070e-02, 1.0451e-02, 1.0512e-02, 1.0031e-02, 1.0471e-02,\n",
            "        1.0070e-02, 1.0199e-02, 1.0119e-02, 1.0001e-02, 1.0574e-02, 1.0080e-02,\n",
            "        1.0070e-02, 1.0179e-02, 9.9138e-03, 1.0420e-02, 1.0060e-02, 1.0410e-02,\n",
            "        1.0512e-02, 1.0199e-02, 1.0199e-02, 1.0109e-02, 1.0349e-02, 1.0199e-02,\n",
            "        1.0522e-02, 9.8079e-03, 1.0451e-02, 1.0179e-02, 1.0512e-02, 1.0309e-02,\n",
            "        1.0149e-02, 1.0149e-02, 9.8559e-03, 1.0920e-02, 1.0584e-02, 1.0309e-02,\n",
            "        1.0119e-02, 1.0279e-02, 1.0149e-02, 1.0299e-02, 1.0249e-02, 1.0031e-02,\n",
            "        1.0279e-02, 1.0249e-02, 1.0522e-02, 9.8079e-03, 1.0001e-02, 9.9042e-03,\n",
            "        1.0420e-02, 1.0031e-02, 1.0001e-02, 1.0149e-02, 1.0249e-02, 1.0502e-02,\n",
            "        1.0011e-02, 1.0574e-02, 1.0229e-02, 1.0021e-02, 1.0199e-02, 9.7411e-03,\n",
            "        9.7601e-03, 9.8175e-03, 1.0410e-02, 1.0031e-02, 1.0119e-02, 1.0533e-02,\n",
            "        1.0060e-02, 1.0229e-02, 1.0119e-02, 1.0410e-02, 1.0229e-02, 1.0219e-02,\n",
            "        1.0229e-02, 1.0199e-02, 1.0119e-02, 9.8752e-03, 9.9721e-03, 1.0109e-02,\n",
            "        1.0080e-02, 1.0709e-02, 1.0349e-02, 1.0199e-02, 9.9526e-03, 1.0249e-02,\n",
            "        9.7888e-03, 1.0219e-02, 1.0825e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [31]\n",
            "DEBUGGING: logits looks like: tensor([1559.1940, 1560.7039, 1560.7042, 1560.6978, 1560.7026, 1560.6993,\n",
            "        1560.6970, 1560.6995, 1560.6997, 1560.6995, 1560.7012, 1560.7041,\n",
            "        1560.6967, 1560.6993, 1560.7030, 1560.7036, 1560.6990, 1560.7032,\n",
            "        1560.6993, 1560.7006, 1560.6998, 1560.6986, 1560.7042, 1560.6995,\n",
            "        1560.6993, 1560.7004, 1560.6978, 1560.7028, 1560.6992, 1560.7026,\n",
            "        1560.7036, 1560.7006, 1560.7006, 1560.6997, 1560.7020, 1560.7006,\n",
            "        1560.7037, 1560.6967, 1560.7030, 1560.7004, 1560.7036, 1560.7017,\n",
            "        1560.7001, 1560.7001, 1560.6971, 1560.7074, 1560.7043, 1560.7017,\n",
            "        1560.6998, 1560.7014, 1560.7001, 1560.7015, 1560.7010, 1560.6990,\n",
            "        1560.7014, 1560.7010, 1560.7037, 1560.6967, 1560.6986, 1560.6976,\n",
            "        1560.7028, 1560.6990, 1560.6986, 1560.7001, 1560.7010, 1560.7035,\n",
            "        1560.6987, 1560.7042, 1560.7009, 1560.6989, 1560.7006, 1560.6960,\n",
            "        1560.6962, 1560.6968, 1560.7026, 1560.6990, 1560.6998, 1560.7039,\n",
            "        1560.6992, 1560.7009, 1560.6998, 1560.7026, 1560.7009, 1560.7008,\n",
            "        1560.7009, 1560.7006, 1560.6998, 1560.6974, 1560.6984, 1560.6997,\n",
            "        1560.6995, 1560.7054, 1560.7020, 1560.7006, 1560.6981, 1560.7010,\n",
            "        1560.6965, 1560.7008, 1560.7065], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.8133e-09, 9.6852e-03, 7.0651e-03, 9.5724e-03, 9.1967e-03, 9.5724e-03,\n",
            "        8.2680e-03, 9.1429e-03, 8.9311e-03, 9.5164e-03, 9.1877e-03, 9.5257e-03,\n",
            "        9.0188e-03, 9.5724e-03, 9.3233e-03, 9.4979e-03, 9.5444e-03, 9.4516e-03,\n",
            "        9.1429e-03, 9.4516e-03, 9.4793e-03, 9.2056e-03, 9.4793e-03, 9.3780e-03,\n",
            "        9.4240e-03, 9.4148e-03, 9.6569e-03, 9.2869e-03, 9.3597e-03, 9.2778e-03,\n",
            "        9.1877e-03, 9.6004e-03, 9.4608e-03, 9.6004e-03, 9.5724e-03, 9.4148e-03,\n",
            "        9.3780e-03, 9.5071e-03, 9.5164e-03, 9.3689e-03, 9.5911e-03, 9.4516e-03,\n",
            "        9.0188e-03, 8.9661e-03, 9.2960e-03, 9.3233e-03, 9.4240e-03, 9.5164e-03,\n",
            "        9.5444e-03, 9.6663e-03, 9.4240e-03, 9.6569e-03, 9.5164e-03, 9.4240e-03,\n",
            "        8.8013e-03, 9.4516e-03, 9.3233e-03, 9.4240e-03, 9.3780e-03, 9.4608e-03,\n",
            "        8.4641e-03, 9.5444e-03, 9.5257e-03, 9.6098e-03, 9.0541e-03, 9.2327e-03,\n",
            "        9.3324e-03, 9.3324e-03, 9.4793e-03, 9.5164e-03, 9.4148e-03, 9.4148e-03,\n",
            "        9.5164e-03, 7.4114e-03, 9.2056e-03, 9.1340e-03, 9.5164e-03, 9.5164e-03,\n",
            "        9.3780e-03, 9.4793e-03, 9.3233e-03, 9.2056e-03, 9.4148e-03, 9.4148e-03,\n",
            "        9.3324e-03, 9.5444e-03, 9.6098e-03, 9.6947e-03, 9.3415e-03, 9.4148e-03,\n",
            "        8.8876e-03, 9.4148e-03, 9.2778e-03, 9.2960e-03, 9.1429e-03, 9.5724e-03,\n",
            "        9.6004e-03, 9.6474e-03, 9.3597e-03, 9.6474e-03, 9.3780e-03, 9.5724e-03,\n",
            "        9.4332e-03, 9.6663e-03, 9.4608e-03, 9.3324e-03, 9.4979e-03, 9.5444e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [92]\n",
            "DEBUGGING: logits looks like: tensor([1559.4054, 1560.9105, 1560.8790, 1560.9094, 1560.9054, 1560.9094,\n",
            "        1560.8948, 1560.9048, 1560.9025, 1560.9088, 1560.9053, 1560.9089,\n",
            "        1560.9034, 1560.9094, 1560.9067, 1560.9086, 1560.9091, 1560.9081,\n",
            "        1560.9048, 1560.9081, 1560.9084, 1560.9055, 1560.9084, 1560.9073,\n",
            "        1560.9078, 1560.9077, 1560.9103, 1560.9064, 1560.9071, 1560.9062,\n",
            "        1560.9053, 1560.9097, 1560.9082, 1560.9097, 1560.9094, 1560.9077,\n",
            "        1560.9073, 1560.9087, 1560.9088, 1560.9072, 1560.9095, 1560.9081,\n",
            "        1560.9034, 1560.9028, 1560.9065, 1560.9067, 1560.9078, 1560.9088,\n",
            "        1560.9091, 1560.9104, 1560.9078, 1560.9103, 1560.9088, 1560.9078,\n",
            "        1560.9010, 1560.9081, 1560.9067, 1560.9078, 1560.9073, 1560.9082,\n",
            "        1560.8971, 1560.9091, 1560.9089, 1560.9098, 1560.9038, 1560.9058,\n",
            "        1560.9069, 1560.9069, 1560.9084, 1560.9088, 1560.9077, 1560.9077,\n",
            "        1560.9088, 1560.8838, 1560.9055, 1560.9047, 1560.9088, 1560.9088,\n",
            "        1560.9073, 1560.9084, 1560.9067, 1560.9055, 1560.9077, 1560.9077,\n",
            "        1560.9069, 1560.9091, 1560.9098, 1560.9106, 1560.9070, 1560.9077,\n",
            "        1560.9020, 1560.9077, 1560.9062, 1560.9065, 1560.9048, 1560.9094,\n",
            "        1560.9097, 1560.9102, 1560.9071, 1560.9102, 1560.9073, 1560.9094,\n",
            "        1560.9080, 1560.9104, 1560.9082, 1560.9069, 1560.9086, 1560.9091],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.147144431372908 and immediate abs rewards look like: [0.04164546393121782, 0.0025865620191325434, 0.035761963975801336, 0.007810470930508018, 0.032378612149386754, 0.010383512020325725, 0.0003598142316150188, 0.00043299876551827765, 0.0005310391716193408, 0.0029757177117062383, 0.004125603109514486, 0.0001995670172618702, 0.0016405243836743466, 0.0012556843071251933, 0.0002793229386952589, 0.0014271169211497181, 0.0007441242528329894, 0.00010306188778486103, 1.3394864254223648e-05, 7.992843620741041e-05, 0.00010829328584804898, 0.0008008766617422225, 8.826111843518447e-05, 9.735900357554783e-05, 0.0006970711851863598, 0.00010771955612653983, 5.394314484874485e-05, 0.00016045416850829497, 7.454958449670812e-06, 2.230646714451723e-06, 5.812457402498694e-06, 1.8553956579125952e-05, 1.9791044906014577e-05, 5.618096565740416e-06, 4.196751388008124e-05, 8.592332960688509e-06, 1.919572696351679e-05, 1.8800155885401182e-05, 8.765737220528536e-07, 1.4040219866728876e-06, 1.4428496342588915e-05, 4.337621612648945e-05, 4.1323451114294585e-06, 8.327626801474253e-06, 1.0647846011124784e-05, 1.6785327261459315e-05, 3.549969733285252e-06, 4.361966375654447e-05, 3.0448973120655864e-08, 7.747971721983049e-07]\n",
            "DEBUGGING: the total relative reward of the trajectory = 17.782640011087512 and immediate relative rewards look like: [1.123044343965312, 0.1410870022492018, 2.9280817975307842, 0.861068009615191, 4.471614721509227, 1.736333446111782, 0.07039999195436253, 0.09683147728691675, 0.13361694853973383, 0.8320485993595719, 1.2699850230223044, 0.06709500310944441, 0.5975448259160833, 0.4927794854925364, 0.11748836799444234, 0.6403399024284699, 0.3548944870108241, 0.052055442649717655, 0.007141674020914432, 0.04485811805921036, 0.06381757608087181, 0.49444842266640854, 0.05698067080807519, 0.06558860843766665, 0.48918154324927465, 0.0786331754988559, 0.040893197704029965, 0.12614401777238515, 0.0060704434114830595, 0.001879014565625751, 0.0050594096864387365, 0.016671151337575355, 0.018338508309621953, 0.005363544306178743, 0.0412444700695436, 0.008685666649935796, 0.019943294135141874, 0.02006032636265894, 0.0009599492956250601, 0.0015769911171741211, 0.016611178633105593, 0.051156194774669116, 0.004989621556965173, 0.010289090854342745, 0.013454834573383827, 0.021681684984953375, 0.0046852194848721745, 0.05879378451145566, 4.189690247424951e-05, 0.0010878555206900677]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([3.3688e-21, 2.6639e-04, 4.3542e-03, 4.7279e-01, 7.6569e-03, 1.6366e-03,\n",
            "        9.5443e-12, 8.4856e-08, 5.7533e-14, 3.6115e-13, 7.9470e-09, 2.9734e-33,\n",
            "        7.8338e-07, 1.6656e-03, 1.8682e-06, 1.2757e-04, 7.4503e-03, 2.9515e-04,\n",
            "        2.5394e-04, 9.0717e-12, 5.5856e-16, 3.8196e-04, 5.3498e-04, 1.1517e-02,\n",
            "        8.8077e-07, 1.3065e-01, 4.1225e-03, 5.1198e-04, 6.7248e-09, 3.1424e-03,\n",
            "        2.8105e-05, 2.4083e-19, 6.2719e-05, 7.6134e-15, 5.6931e-06, 5.2369e-03,\n",
            "        2.5098e-04, 1.7230e-05, 4.1269e-09, 4.2864e-10, 4.6434e-04, 2.2017e-05,\n",
            "        9.2639e-22, 8.2660e-07, 6.8261e-07, 3.9867e-05, 5.2601e-06, 2.3235e-04,\n",
            "        1.4304e-09, 1.0527e-02, 9.2138e-06, 6.6875e-07, 3.4277e-03, 4.4854e-07,\n",
            "        1.4914e-04, 2.6810e-20, 8.2928e-05, 5.6645e-07, 1.0434e-09, 1.7414e-06,\n",
            "        6.9445e-03, 7.3129e-10, 4.3000e-02, 6.5419e-04, 6.3454e-12, 3.6115e-13,\n",
            "        1.3568e-03, 2.8012e-01], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [67]\n",
            "DEBUGGING: logits looks like: tensor([1556.9065, 1560.7974, 1561.0768, 1561.5455, 1561.1332, 1560.9789,\n",
            "        1559.0829, 1559.9922, 1558.5718, 1558.7555, 1559.7554, 1554.1309,\n",
            "        1560.2145, 1560.9807, 1560.3014, 1560.7238, 1561.1305, 1560.8076,\n",
            "        1560.7926, 1559.0779, 1558.1083, 1560.8334, 1560.8671, 1561.1741,\n",
            "        1560.2262, 1561.4169, 1561.0713, 1560.8627, 1559.7386, 1561.0442,\n",
            "        1560.5725, 1557.3334, 1560.6527, 1558.3695, 1560.4128, 1561.0952,\n",
            "        1560.7914, 1560.5236, 1559.6898, 1559.4634, 1560.8529, 1560.5481,\n",
            "        1556.7773, 1560.2198, 1560.2007, 1560.6074, 1560.4049, 1560.7837,\n",
            "        1559.5839, 1561.1650, 1560.4609, 1560.1986, 1561.0529, 1560.1587,\n",
            "        1560.7394, 1557.1139, 1560.6807, 1560.1820, 1559.5524, 1560.2943,\n",
            "        1561.1234, 1559.5168, 1561.3058, 1560.8872, 1559.0421, 1558.7555,\n",
            "        1560.9602, 1561.4932], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.5779e-19, 6.8149e-03, 2.9985e-01, 1.8607e-05, 1.3697e-03, 1.6719e-02,\n",
            "        5.0144e-04, 8.7603e-02, 1.7223e-06, 1.2399e-03, 6.9917e-08, 2.3319e-04,\n",
            "        2.7588e-03, 2.7002e-03, 4.9400e-06, 1.3432e-03, 9.9305e-06, 8.6557e-04,\n",
            "        3.4391e-05, 4.6112e-03, 5.3422e-05, 3.2008e-02, 4.3263e-05, 1.3017e-04,\n",
            "        3.9775e-12, 4.0960e-05, 7.3675e-04, 1.0926e-06, 1.9035e-03, 1.0501e-04,\n",
            "        2.0419e-04, 1.0889e-03, 4.2115e-02, 1.5983e-03, 2.6766e-03, 1.2819e-02,\n",
            "        1.5549e-04, 1.8298e-06, 1.8662e-05, 1.3461e-02, 2.0155e-06, 2.3637e-05,\n",
            "        4.2432e-04, 7.0864e-03, 4.7344e-03, 2.3006e-03, 1.1749e-04, 1.2173e-02,\n",
            "        1.6959e-05, 2.8580e-02, 4.8089e-03, 6.2050e-03, 8.1938e-05, 1.8247e-05,\n",
            "        1.6574e-08, 4.4780e-03, 3.4234e-03, 9.8163e-05, 8.7223e-05, 1.3843e-04,\n",
            "        5.4689e-05, 6.6375e-03, 1.0463e-02, 1.7223e-06, 2.9985e-01, 2.1462e-04,\n",
            "        1.4038e-02, 2.6099e-02, 2.4730e-03, 5.5342e-04, 5.5342e-04, 1.7711e-02,\n",
            "        9.9432e-04, 8.2606e-03, 1.4425e-03, 9.3443e-08, 1.0960e-05],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [64]\n",
            "DEBUGGING: logits looks like: tensor([1557.7960, 1561.5774, 1561.9558, 1560.9871, 1561.4169, 1561.6671,\n",
            "        1561.3164, 1561.8328, 1560.7490, 1561.4070, 1560.4286, 1561.2399,\n",
            "        1561.4869, 1561.4847, 1560.8544, 1561.4149, 1560.9242, 1561.3710,\n",
            "        1561.0485, 1561.5383, 1561.0925, 1561.7321, 1561.0714, 1561.1815,\n",
            "        1559.4512, 1561.0659, 1561.3549, 1560.7035, 1561.4498, 1561.1600,\n",
            "        1561.2266, 1561.3939, 1561.7595, 1561.4324, 1561.4839, 1561.6405,\n",
            "        1561.1993, 1560.7551, 1560.9873, 1561.6454, 1560.7648, 1561.0110,\n",
            "        1561.2997, 1561.5813, 1561.5409, 1561.4688, 1561.1713, 1561.6354,\n",
            "        1560.9778, 1561.7207, 1561.5425, 1561.5680, 1561.1353, 1560.9851,\n",
            "        1560.2847, 1561.5354, 1561.5085, 1561.1533, 1561.1415, 1561.1877,\n",
            "        1561.0948, 1561.5747, 1561.6202, 1560.7490, 1561.9558, 1561.2316,\n",
            "        1561.6497, 1561.7117, 1561.4760, 1561.3263, 1561.3263, 1561.6729,\n",
            "        1561.3849, 1561.5966, 1561.4221, 1560.4576, 1560.9341],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.6903e-04, 8.3107e-05, 6.1923e-07, 1.5007e-03, 7.3640e-04, 3.9953e-05,\n",
            "        5.9278e-05, 3.1259e-07, 7.3210e-04, 1.0137e-21, 2.1825e-06, 2.5813e-07,\n",
            "        4.7649e-09, 9.8389e-06, 2.7955e-03, 9.3897e-05, 1.4218e-05, 9.3961e-07,\n",
            "        1.9380e-04, 1.1951e-04, 5.8667e-09, 4.7649e-09, 1.6753e-05, 1.5489e-07,\n",
            "        1.3933e-10, 2.1455e-03, 8.3464e-09, 6.1570e-06, 4.2899e-06, 1.8229e-02,\n",
            "        1.0418e-08, 7.5721e-07, 2.9924e-05, 1.8096e-05, 3.8579e-04, 2.8844e-09,\n",
            "        4.5731e-03, 1.9862e-03, 4.2774e-06, 1.9261e-06, 3.1146e-05, 2.3127e-04,\n",
            "        1.7709e-06, 5.4307e-03, 4.9213e-02, 8.2275e-07, 5.1201e-05, 2.3886e-23,\n",
            "        1.1593e-05, 2.5405e-09, 2.9160e-08, 2.4071e-04, 1.4572e-04, 1.0049e-01,\n",
            "        1.7083e-05, 4.0194e-04, 2.1988e-02, 7.6960e-03, 1.9036e-06, 1.8228e-09,\n",
            "        5.7054e-06, 8.6346e-04, 5.0350e-06, 2.4048e-04, 3.8709e-01, 5.4458e-04,\n",
            "        8.5674e-04, 4.0729e-07, 4.3722e-03, 4.1002e-08, 3.6342e-05, 3.6187e-01,\n",
            "        2.5705e-09, 1.9903e-02, 1.0165e-09, 3.3832e-07, 1.2637e-03, 2.2868e-14,\n",
            "        1.6069e-03, 2.3101e-05, 2.8142e-04, 1.6737e-18, 6.5842e-08, 1.1306e-03,\n",
            "        3.5108e-14], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [64]\n",
            "DEBUGGING: logits looks like: tensor([1561.4486, 1561.3777, 1560.8877, 1561.6670, 1561.5958, 1561.3044,\n",
            "        1561.3439, 1560.8193, 1561.5952, 1557.4832, 1561.0137, 1560.8002,\n",
            "        1560.4010, 1561.1643, 1561.7292, 1561.3899, 1561.2010, 1560.9294,\n",
            "        1561.4623, 1561.4139, 1560.4218, 1560.4010, 1561.2175, 1560.7491,\n",
            "        1560.0477, 1561.7028, 1560.4570, 1561.1174, 1561.0813, 1561.9167,\n",
            "        1560.4792, 1560.9078, 1561.2755, 1561.2252, 1561.5311, 1560.3508,\n",
            "        1561.7784, 1561.6951, 1561.0809, 1561.0012, 1561.2795, 1561.4800,\n",
            "        1560.9928, 1561.7957, 1562.0160, 1560.9161, 1561.3292, 1557.1083,\n",
            "        1561.1807, 1560.3381, 1560.5822, 1561.4840, 1561.4338, 1562.0874,\n",
            "        1561.2195, 1561.5353, 1561.9354, 1561.8304, 1561.0000, 1560.3049,\n",
            "        1561.1097, 1561.6117, 1561.0973, 1561.4839, 1562.2223, 1561.5657,\n",
            "        1561.6110, 1560.8458, 1561.7739, 1560.6162, 1561.2949, 1562.2156,\n",
            "        1560.3392, 1561.9255, 1560.2465, 1560.8273, 1561.6498, 1559.1763,\n",
            "        1561.6738, 1561.2496, 1561.4996, 1558.2240, 1560.6636, 1561.6387,\n",
            "        1559.2191], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([3.4146e-05, 8.2822e-03, 1.7740e-02, 1.9820e-05, 6.2031e-03, 1.8161e-02,\n",
            "        7.5694e-04, 4.3262e-03, 4.3944e-03, 3.6793e-02, 1.0108e-02, 3.4391e-03,\n",
            "        2.7126e-03, 2.2158e-04, 1.2257e-06, 7.4885e-04, 3.3430e-03, 8.6290e-03,\n",
            "        2.5351e-05, 5.1821e-04, 1.0687e-02, 2.2158e-04, 1.1760e-02, 4.2089e-04,\n",
            "        4.5694e-03, 4.1652e-02, 1.6487e-02, 2.0155e-04, 1.0385e-04, 1.8550e-04,\n",
            "        3.5040e-02, 6.8729e-03, 7.9184e-03, 1.8070e-03, 1.4880e-02, 6.9879e-03,\n",
            "        2.7796e-03, 1.0781e-02, 5.3466e-04, 1.2133e-02, 1.9995e-05, 2.2466e-03,\n",
            "        4.2919e-04, 3.4593e-03, 3.3014e-02, 1.5473e-02, 2.0439e-02, 8.5214e-02,\n",
            "        5.6701e-03, 2.9680e-02, 2.1482e-02, 2.9638e-05, 5.6095e-03, 1.6153e-02,\n",
            "        1.9192e-05, 2.8582e-06, 4.8404e-03, 3.9584e-03, 4.2378e-04, 9.9468e-06,\n",
            "        4.0285e-03, 1.4241e-02, 4.8223e-02, 1.2604e-02, 2.8543e-02, 2.0119e-03,\n",
            "        2.1648e-03, 1.0216e-03, 4.0960e-03, 8.2110e-02, 1.0237e-02, 2.3709e-02,\n",
            "        2.0839e-03, 6.4818e-03, 3.1687e-02, 9.5514e-03, 3.4090e-03, 4.7733e-05,\n",
            "        7.7262e-04, 7.3592e-03, 2.1672e-02, 1.9829e-02, 4.2508e-03, 1.3600e-03,\n",
            "        4.1646e-03, 3.6578e-02, 1.7445e-03, 1.8026e-06, 2.4363e-03, 2.0761e-02,\n",
            "        1.1216e-05, 2.2861e-04, 7.6299e-03, 9.2575e-03, 6.8719e-04, 9.0608e-03,\n",
            "        2.3994e-07, 5.2903e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [52]\n",
            "DEBUGGING: logits looks like: tensor([1561.4231, 1561.9722, 1562.0483, 1561.3687, 1561.9432, 1562.0507,\n",
            "        1561.7329, 1561.9072, 1561.9088, 1562.1213, 1561.9921, 1561.8843,\n",
            "        1561.8606, 1561.6101, 1561.0903, 1561.7318, 1561.8815, 1561.9763,\n",
            "        1561.3933, 1561.6951, 1561.9977, 1561.6101, 1562.0072, 1561.6742,\n",
            "        1561.9127, 1562.1337, 1562.0410, 1561.6006, 1561.5343, 1561.5923,\n",
            "        1562.1165, 1561.9535, 1561.9677, 1561.8199, 1562.0308, 1561.9552,\n",
            "        1561.8630, 1561.9985, 1561.6981, 1562.0104, 1561.3695, 1561.8417,\n",
            "        1561.6761, 1561.8849, 1562.1105, 1562.0347, 1562.0625, 1562.2053,\n",
            "        1561.9343, 1562.0999, 1562.0675, 1561.4089, 1561.9332, 1562.0389,\n",
            "        1561.3655, 1561.1750, 1561.9185, 1561.8983, 1561.6749, 1561.2997,\n",
            "        1561.9001, 1562.0264, 1562.1483, 1562.0142, 1562.0959, 1561.8307,\n",
            "        1561.8380, 1561.7629, 1561.9017, 1562.2015, 1561.9934, 1562.0774,\n",
            "        1561.8342, 1561.9476, 1562.1063, 1561.9865, 1561.8834, 1561.4565,\n",
            "        1561.7350, 1561.9603, 1562.0684, 1562.0594, 1561.9055, 1561.7915,\n",
            "        1561.9034, 1562.1207, 1561.8164, 1561.1289, 1561.8499, 1562.0641,\n",
            "        1561.3118, 1561.6132, 1561.9640, 1561.9833, 1561.7233, 1561.9812,\n",
            "        1560.9272, 1561.9274], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.0455e-10, 6.3120e-03, 1.2541e-02, 8.7804e-03, 1.0417e-02, 8.7976e-03,\n",
            "        6.6602e-03, 1.0949e-02, 1.4058e-02, 1.1701e-02, 6.5506e-03, 4.0873e-03,\n",
            "        1.0176e-02, 8.3212e-03, 7.7034e-03, 1.1329e-02, 1.0185e-02, 1.4533e-02,\n",
            "        8.1922e-03, 7.9402e-03, 9.3741e-03, 1.5806e-02, 4.6815e-03, 1.2443e-02,\n",
            "        5.2022e-03, 1.0215e-02, 6.4239e-03, 1.0529e-02, 6.2935e-03, 1.0126e-02,\n",
            "        1.0037e-02, 1.2025e-02, 7.2863e-03, 7.5988e-03, 6.5250e-03, 9.0946e-03,\n",
            "        1.0285e-02, 9.4016e-03, 3.9576e-03, 8.2888e-03, 1.4876e-03, 9.2649e-03,\n",
            "        9.6811e-03, 1.1850e-02, 7.5618e-03, 1.0126e-02, 6.2445e-03, 9.7857e-03,\n",
            "        2.1689e-02, 7.4518e-03, 1.0366e-02, 2.3133e-02, 8.1763e-03, 8.3620e-03,\n",
            "        9.8336e-03, 7.1594e-03, 1.3297e-02, 6.5891e-03, 1.1219e-02, 7.0967e-03,\n",
            "        2.7602e-03, 2.2400e-02, 1.0136e-02, 5.0176e-03, 7.7109e-03, 7.5766e-03,\n",
            "        7.2721e-03, 4.1476e-03, 3.7580e-03, 1.1341e-02, 9.8336e-03, 1.0077e-02,\n",
            "        4.5242e-03, 4.8348e-03, 9.5497e-03, 1.9826e-02, 7.0072e-03, 9.9690e-03,\n",
            "        9.9398e-03, 1.5112e-02, 2.7982e-03, 5.7978e-03, 8.6696e-03, 9.4569e-03,\n",
            "        1.3297e-02, 9.1213e-03, 5.1116e-03, 9.5590e-03, 5.3412e-03, 1.2913e-02,\n",
            "        2.1204e-03, 1.7411e-02, 1.3520e-02, 6.7453e-03, 7.3435e-03, 1.0612e-02,\n",
            "        8.5854e-03, 7.6959e-03, 8.7291e-03, 8.4111e-03, 7.2155e-03, 1.5350e-02,\n",
            "        3.0943e-03, 1.4294e-02, 1.2346e-02, 1.3494e-02, 5.3152e-03, 9.3741e-03,\n",
            "        8.2807e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [15]\n",
            "DEBUGGING: logits looks like: tensor([1560.3463, 1562.1379, 1562.2065, 1562.1709, 1562.1880, 1562.1711,\n",
            "        1562.1433, 1562.1930, 1562.2180, 1562.1996, 1562.1416, 1562.0945,\n",
            "        1562.1857, 1562.1655, 1562.1578, 1562.1964, 1562.1858, 1562.2213,\n",
            "        1562.1639, 1562.1609, 1562.1775, 1562.2297, 1562.1080, 1562.2058,\n",
            "        1562.1185, 1562.1860, 1562.1396, 1562.1891, 1562.1376, 1562.1852,\n",
            "        1562.1843, 1562.2024, 1562.1522, 1562.1565, 1562.1412, 1562.1744,\n",
            "        1562.1868, 1562.1777, 1562.0912, 1562.1652, 1561.9934, 1562.1763,\n",
            "        1562.1807, 1562.2009, 1562.1560, 1562.1852, 1562.1368, 1562.1818,\n",
            "        1562.2614, 1562.1545, 1562.1875, 1562.2678, 1562.1638, 1562.1660,\n",
            "        1562.1823, 1562.1505, 1562.2124, 1562.1422, 1562.1954, 1562.1497,\n",
            "        1562.0552, 1562.2645, 1562.1853, 1562.1150, 1562.1580, 1562.1561,\n",
            "        1562.1521, 1562.0959, 1562.0861, 1562.1965, 1562.1823, 1562.1847,\n",
            "        1562.1046, 1562.1112, 1562.1793, 1562.2523, 1562.1483, 1562.1836,\n",
            "        1562.1833, 1562.2252, 1562.0565, 1562.1294, 1562.1697, 1562.1783,\n",
            "        1562.2124, 1562.1747, 1562.1168, 1562.1794, 1562.1212, 1562.2095,\n",
            "        1562.0288, 1562.2394, 1562.2141, 1562.1445, 1562.1531, 1562.1898,\n",
            "        1562.1687, 1562.1577, 1562.1703, 1562.1666, 1562.1512, 1562.2268,\n",
            "        1562.0667, 1562.2196, 1562.2050, 1562.2139, 1562.1207, 1562.1775,\n",
            "        1562.1650], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.11437914231055402 and immediate abs rewards look like: [0.01472099603006427, 0.003817258723302075, 0.013557903691435058, 0.050915616845031764, 0.0010659916206350317, 0.00026380521285318537, 0.00037323920469134464, 0.0003863044430545415, 9.747982630869956e-05, 0.0003062553873860452, 0.00011718101040969486, 0.0005690715493074094, 0.00023398483335768105, 0.000495217952902749, 0.00014696335301778163, 9.25998028833419e-06, 0.00019188883061360684, 0.00033962906763918, 6.946847361177788e-05, 9.473998079556623e-05, 2.292913632118143e-05, 7.283289914994384e-05, 0.0005553776727538207, 0.0009701662347652018, 0.00012993198060939903, 0.0012517901404862641, 2.149968850062578e-05, 0.004947245650782861, 0.0009204654675158963, 0.0005848983287251031, 0.00716355528220447, 0.00024335009038622957, 0.00015388915335279307, 6.918261260580039e-05, 3.9553158330818405e-05, 0.0008632094986751326, 7.971419108798727e-05, 0.0018298415070603369, 0.0016810953479762247, 0.0010605882789604948, 0.00011329918015690055, 0.00012287341496630688, 0.00014587216264771996, 0.0017852452774604899, 0.00017247929417862906, 0.00020119206010349444, 0.0003864523523589014, 3.853854241242516e-05, 0.00048033611301434576, 0.0004994815762984217]\n",
            "DEBUGGING: the total relative reward of the trajectory = 39.906931533350274 and immediate relative rewards look like: [0.47467008632435814, 0.24734471417148557, 1.3193872283996286, 6.635653477983331, 0.17658812286986375, 0.05245969096218746, 0.08659929830242323, 0.1024477675670515, 0.029086782556694814, 0.10153977608997221, 0.04274117805226643, 0.2264443866525476, 0.10088496799114359, 0.22996064647060063, 0.07313087297457752, 0.004915318515187586, 0.10822349935559035, 0.20282802478069525, 0.04379665082641908, 0.06287425359272888, 0.015978286300757125, 0.05317124022808058, 0.42389008740483974, 0.7728130615486718, 0.10784822242127862, 1.0806387439382659, 0.01928200250252301, 4.601302771293509, 0.8881351843507461, 0.5839938010635664, 7.392331986901305, 0.2598420941786518, 0.16946703619291228, 0.07849851893915359, 0.04620030325771695, 1.0370986246578764, 0.09846090998270635, 2.321320497279034, 2.190081963449046, 1.4179280056767418, 0.15531448706022416, 0.17255399308531946, 0.20973770672463204, 2.6266813528281645, 0.2596962276843458, 0.30967767261021445, 0.607805011272889, 0.06191033475728437, 0.7877230448082813, 0.8359716165127864]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([1.9494e-34, 1.3157e-05, 1.6065e-02, 3.9204e-05, 5.0883e-05, 1.3343e-03,\n",
            "        5.2732e-08, 7.6690e-11, 4.1814e-05, 8.9202e-06, 1.0885e-06, 3.2492e-07,\n",
            "        2.6523e-06, 8.6159e-03, 2.1497e-07, 5.5579e-09, 1.5672e-11, 1.6560e-08,\n",
            "        8.6992e-04, 1.3824e-01, 6.6324e-09, 1.9029e-06, 3.4372e-03, 8.4069e-04,\n",
            "        3.1353e-04, 5.5080e-04, 1.2145e-05, 1.6386e-07, 1.4524e-04, 2.4407e-07,\n",
            "        2.4663e-09, 9.0315e-08, 1.0179e-04, 8.0575e-07, 1.1579e-04, 1.2892e-04,\n",
            "        3.4424e-06, 1.9238e-05, 1.8055e-05, 1.3391e-05, 3.2280e-05, 4.0920e-06,\n",
            "        1.7329e-05, 4.2537e-08, 5.7832e-11, 3.5720e-07, 4.6946e-08, 7.0184e-03,\n",
            "        2.9215e-06, 5.0975e-06, 2.1696e-04, 5.4279e-04, 5.8588e-09, 8.6386e-05,\n",
            "        2.3617e-05, 7.7967e-05, 9.3927e-07, 1.0678e-04, 1.1004e-05, 3.4051e-07,\n",
            "        1.0035e-08, 2.2481e-08, 3.7258e-06, 2.6324e-04, 4.5189e-15, 8.1838e-01,\n",
            "        1.5523e-03, 6.6634e-04, 2.8762e-06], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [65]\n",
            "DEBUGGING: logits looks like: tensor([1557.5320, 1564.1702, 1564.8809, 1564.2793, 1564.3054, 1564.6321,\n",
            "        1563.6182, 1562.9648, 1564.2858, 1564.1312, 1563.9209, 1563.8000,\n",
            "        1564.0100, 1564.8186, 1563.7587, 1563.3932, 1562.8060, 1563.5023,\n",
            "        1564.5892, 1565.0961, 1563.4109, 1563.9768, 1564.7267, 1564.5858,\n",
            "        1564.4872, 1564.5436, 1564.1621, 1563.7316, 1564.4103, 1563.7714,\n",
            "        1563.3119, 1563.6720, 1564.3748, 1563.8909, 1564.3876, 1564.3983,\n",
            "        1564.0360, 1564.2081, 1564.2018, 1564.1719, 1564.2599, 1564.0533,\n",
            "        1564.1976, 1563.5967, 1562.9366, 1563.8094, 1563.6066, 1564.7981,\n",
            "        1564.0197, 1564.0753, 1564.4504, 1564.5421, 1563.3984, 1564.3583,\n",
            "        1564.2286, 1564.3480, 1563.9061, 1564.3795, 1564.1522, 1563.8047,\n",
            "        1563.4523, 1563.5330, 1564.0439, 1564.4697, 1561.9910, 1565.2739,\n",
            "        1564.6472, 1564.5626, 1564.0181], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([6.5778e-32, 1.0039e-05, 1.0062e-03, 7.7137e-05, 5.9392e-03, 5.1400e-03,\n",
            "        4.1369e-05, 2.3388e-05, 1.8111e-04, 3.2454e-02, 3.9531e-02, 2.0250e-02,\n",
            "        2.2284e-02, 3.8767e-02, 2.7517e-02, 3.5385e-05, 3.1211e-02, 1.0690e-03,\n",
            "        9.8209e-03, 4.3603e-06, 4.8855e-03, 2.0168e-03, 1.0839e-02, 1.1280e-03,\n",
            "        3.7343e-04, 4.0214e-05, 6.7376e-02, 2.2587e-03, 7.0266e-02, 2.3210e-04,\n",
            "        1.0322e-02, 1.4494e-05, 7.5816e-03, 3.9531e-02, 5.4966e-05, 2.7188e-04,\n",
            "        7.7994e-03, 2.6040e-05, 7.8452e-03, 1.4815e-02, 5.7195e-07, 2.5473e-02,\n",
            "        4.2879e-07, 5.1710e-02, 8.3149e-06, 2.2879e-02, 1.1357e-03, 3.2667e-04,\n",
            "        7.7236e-03, 2.9565e-05, 7.9610e-03, 6.2915e-03, 3.5189e-03, 1.2610e-02,\n",
            "        4.2433e-05, 1.1904e-02, 3.8234e-03, 1.2969e-04, 2.7169e-02, 5.5794e-03,\n",
            "        9.6078e-06, 2.0872e-02, 1.0012e-04, 3.8804e-02, 3.3742e-03, 1.2836e-01,\n",
            "        1.2139e-02, 8.4091e-09, 7.4641e-03, 3.2701e-10, 2.0426e-03, 1.7694e-03,\n",
            "        1.0055e-01, 9.4909e-03, 1.1843e-04, 2.6885e-07, 6.6377e-04, 1.1469e-03,\n",
            "        1.7369e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [28]\n",
            "DEBUGGING: logits looks like: tensor([1559.2073, 1565.2362, 1565.6970, 1565.4402, 1565.8745, 1565.8601,\n",
            "        1565.3778, 1565.3208, 1565.5255, 1566.0443, 1566.0641, 1565.9972,\n",
            "        1566.0067, 1566.0621, 1566.0278, 1565.3622, 1566.0404, 1565.7030,\n",
            "        1565.9248, 1565.1528, 1565.8550, 1565.7665, 1565.9347, 1565.7084,\n",
            "        1565.5979, 1565.3750, 1566.1174, 1565.7778, 1566.1216, 1565.5503,\n",
            "        1565.9298, 1565.2729, 1565.8989, 1566.0641, 1565.4062, 1565.5662,\n",
            "        1565.9017, 1565.3315, 1565.9023, 1565.9659, 1564.9497, 1566.0201,\n",
            "        1564.9209, 1566.0909, 1565.2174, 1566.0094, 1565.7091, 1565.5845,\n",
            "        1565.9008, 1565.3442, 1565.9038, 1565.8802, 1565.8221, 1565.9498,\n",
            "        1565.3804, 1565.9441, 1565.8304, 1565.4921, 1566.0266, 1565.8683,\n",
            "        1565.2318, 1566.0002, 1565.4662, 1566.0623, 1565.8180, 1566.1819,\n",
            "        1565.9460, 1564.5277, 1565.8973, 1564.2030, 1565.7678, 1565.7534,\n",
            "        1566.1575, 1565.9214, 1565.4830, 1564.8743, 1565.6554, 1565.7101,\n",
            "        1565.7516], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([6.3735e-31, 6.6877e-03, 3.8845e-05, 1.1919e-04, 8.5287e-03, 2.9764e-03,\n",
            "        7.3954e-03, 6.4378e-03, 2.2891e-02, 7.3954e-03, 6.9203e-03, 6.8933e-03,\n",
            "        5.0089e-03, 2.3595e-02, 2.2846e-02, 1.0898e-02, 6.5840e-03, 1.4325e-02,\n",
            "        1.8556e-02, 3.4695e-03, 6.7930e-03, 2.1800e-02, 6.3256e-03, 1.4736e-02,\n",
            "        2.1609e-02, 1.3043e-02, 1.4325e-02, 7.7503e-03, 2.6972e-02, 4.0366e-03,\n",
            "        1.3979e-02, 6.0892e-03, 7.6302e-03, 1.5580e-02, 1.8179e-02, 1.6074e-02,\n",
            "        1.4607e-02, 2.9474e-03, 2.6292e-03, 5.6647e-03, 1.6520e-02, 1.4239e-03,\n",
            "        6.9599e-04, 1.3709e-02, 2.0539e-02, 2.6502e-02, 7.0155e-03, 1.3483e-02,\n",
            "        4.0366e-03, 1.0930e-02, 1.7686e-03, 5.8095e-04, 5.7371e-03, 9.5797e-03,\n",
            "        9.2850e-03, 1.8940e-02, 1.3483e-02, 5.0679e-03, 1.0108e-02, 9.8150e-04,\n",
            "        7.1609e-03, 7.3235e-03, 3.7145e-04, 2.7051e-02, 5.4538e-02, 1.9519e-03,\n",
            "        4.7323e-04, 3.0534e-02, 1.9443e-03, 6.3442e-03, 9.3578e-03, 1.7637e-02,\n",
            "        1.3094e-02, 1.6879e-02, 2.0519e-02, 7.0155e-03, 1.1772e-02, 1.3763e-02,\n",
            "        1.0583e-02, 5.4424e-03, 1.1343e-02, 2.0985e-02, 1.3629e-02, 1.4061e-02,\n",
            "        3.7447e-02, 2.3641e-02, 2.4127e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [23]\n",
            "DEBUGGING: logits looks like: tensor([1560.0032, 1566.4552, 1565.9403, 1566.0525, 1566.4795, 1566.3743,\n",
            "        1566.4652, 1566.4514, 1566.5782, 1566.4652, 1566.4586, 1566.4583,\n",
            "        1566.4263, 1566.5813, 1566.5780, 1566.5040, 1566.4536, 1566.5314,\n",
            "        1566.5573, 1566.3895, 1566.4568, 1566.5734, 1566.4496, 1566.5342,\n",
            "        1566.5725, 1566.5220, 1566.5314, 1566.4700, 1566.5946, 1566.4047,\n",
            "        1566.5289, 1566.4458, 1566.4684, 1566.5398, 1566.5552, 1566.5428,\n",
            "        1566.5333, 1566.3733, 1566.3618, 1566.4386, 1566.5457, 1566.3005,\n",
            "        1566.2289, 1566.5270, 1566.5674, 1566.5929, 1566.4600, 1566.5253,\n",
            "        1566.4047, 1566.5043, 1566.3221, 1566.2108, 1566.4398, 1566.4911,\n",
            "        1566.4880, 1566.5593, 1566.5253, 1566.4275, 1566.4965, 1566.2633,\n",
            "        1566.4620, 1566.4642, 1566.1661, 1566.5950, 1566.6650, 1566.3320,\n",
            "        1566.1903, 1566.6071, 1566.3317, 1566.4500, 1566.4888, 1566.5521,\n",
            "        1566.5223, 1566.5477, 1566.5673, 1566.4600, 1566.5117, 1566.5273,\n",
            "        1566.5011, 1566.4346, 1566.5081, 1566.5696, 1566.5264, 1566.5295,\n",
            "        1566.6274, 1566.5814, 1566.3533], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([3.3055e-31, 9.9194e-03, 1.0135e-02, 9.3732e-03, 8.9178e-03, 9.6896e-03,\n",
            "        9.2459e-03, 9.0494e-03, 7.2714e-03, 1.0642e-02, 1.0076e-02, 1.0076e-02,\n",
            "        1.0746e-02, 1.3167e-02, 1.1120e-02, 1.1384e-02, 1.0467e-02, 9.6896e-03,\n",
            "        1.1284e-02, 9.7275e-03, 1.0135e-02, 1.0224e-02, 1.0621e-02, 8.4185e-03,\n",
            "        9.6518e-03, 1.0335e-02, 1.0224e-02, 9.4651e-03, 9.1739e-03, 8.4102e-03,\n",
            "        1.0590e-02, 1.1174e-02, 8.1994e-03, 1.0600e-02, 7.7101e-03, 1.3167e-02,\n",
            "        1.0046e-02, 9.8422e-03, 1.1055e-02, 9.2188e-03, 1.0477e-02, 8.7367e-03,\n",
            "        1.1174e-02, 1.0467e-02, 1.1620e-02, 1.1077e-02, 9.0494e-03, 1.1328e-02,\n",
            "        9.1919e-03, 9.2911e-03, 8.7453e-03, 1.0884e-02, 1.1207e-02, 9.0494e-03,\n",
            "        9.4190e-03, 1.0184e-02, 1.0958e-02, 1.0335e-02, 1.0036e-02, 1.1120e-02,\n",
            "        7.8469e-03, 1.0335e-02, 9.4098e-03, 1.0085e-02, 9.1919e-03, 9.4190e-03,\n",
            "        1.2261e-02, 1.3077e-02, 9.7370e-03, 1.0621e-02, 1.0704e-02, 1.0145e-02,\n",
            "        1.1174e-02, 1.0467e-02, 8.5929e-03, 7.0133e-03, 1.0948e-02, 9.6896e-03,\n",
            "        1.0335e-02, 1.1262e-02, 1.0224e-02, 1.1563e-02, 9.9388e-03, 1.1044e-02,\n",
            "        8.8397e-03, 1.0436e-02, 1.0621e-02, 1.0095e-02, 9.5674e-03, 9.2640e-03,\n",
            "        8.5929e-03, 1.0549e-02, 9.2640e-03, 9.1739e-03, 1.1552e-02, 9.9388e-03,\n",
            "        9.6518e-03, 1.0778e-02, 1.2737e-02, 9.2640e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [62]\n",
            "DEBUGGING: logits looks like: tensor([1560.5526, 1567.1097, 1567.1119, 1567.1041, 1567.0991, 1567.1074,\n",
            "        1567.1028, 1567.1006, 1567.0787, 1567.1168, 1567.1113, 1567.1113,\n",
            "        1567.1178, 1567.1381, 1567.1212, 1567.1235, 1567.1151, 1567.1074,\n",
            "        1567.1227, 1567.1078, 1567.1119, 1567.1128, 1567.1166, 1567.0934,\n",
            "        1567.1071, 1567.1139, 1567.1128, 1567.1051, 1567.1019, 1567.0933,\n",
            "        1567.1163, 1567.1217, 1567.0907, 1567.1165, 1567.0846, 1567.1381,\n",
            "        1567.1111, 1567.1090, 1567.1206, 1567.1024, 1567.1152, 1567.0970,\n",
            "        1567.1217, 1567.1151, 1567.1256, 1567.1208, 1567.1006, 1567.1230,\n",
            "        1567.1022, 1567.1033, 1567.0972, 1567.1190, 1567.1219, 1567.1006,\n",
            "        1567.1046, 1567.1124, 1567.1198, 1567.1139, 1567.1110, 1567.1212,\n",
            "        1567.0863, 1567.1139, 1567.1045, 1567.1115, 1567.1022, 1567.1046,\n",
            "        1567.1310, 1567.1375, 1567.1079, 1567.1166, 1567.1174, 1567.1121,\n",
            "        1567.1217, 1567.1151, 1567.0955, 1567.0751, 1567.1196, 1567.1074,\n",
            "        1567.1139, 1567.1224, 1567.1128, 1567.1251, 1567.1100, 1567.1205,\n",
            "        1567.0983, 1567.1149, 1567.1166, 1567.1116, 1567.1062, 1567.1029,\n",
            "        1567.0955, 1567.1160, 1567.1029, 1567.1019, 1567.1250, 1567.1100,\n",
            "        1567.1071, 1567.1180, 1567.1348, 1567.1029], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([3.9779e-31, 9.2425e-03, 9.2877e-03, 9.3514e-03, 9.3058e-03, 8.9406e-03,\n",
            "        9.0372e-03, 8.7591e-03, 9.2877e-03, 9.3605e-03, 9.6294e-03, 8.9756e-03,\n",
            "        9.3058e-03, 9.5265e-03, 9.3058e-03, 9.3880e-03, 9.1616e-03, 9.6671e-03,\n",
            "        9.2605e-03, 8.9319e-03, 9.2605e-03, 9.5452e-03, 9.5172e-03, 9.2605e-03,\n",
            "        9.2064e-03, 9.1348e-03, 8.2606e-03, 9.6106e-03, 8.8710e-03, 9.3605e-03,\n",
            "        9.1616e-03, 8.3417e-03, 8.9756e-03, 9.0460e-03, 9.4247e-03, 9.2425e-03,\n",
            "        9.6106e-03, 8.9058e-03, 9.2064e-03, 9.3788e-03, 9.1705e-03, 9.2425e-03,\n",
            "        9.5452e-03, 9.4709e-03, 9.0725e-03, 9.4987e-03, 9.2154e-03, 9.5732e-03,\n",
            "        9.1705e-03, 9.4987e-03, 9.4247e-03, 9.1705e-03, 8.9932e-03, 8.3825e-03,\n",
            "        9.1348e-03, 8.9058e-03, 9.0019e-03, 9.3149e-03, 9.7334e-03, 9.2064e-03,\n",
            "        9.6671e-03, 9.1705e-03, 8.9319e-03, 9.2425e-03, 9.2064e-03, 9.7334e-03,\n",
            "        9.3788e-03, 9.7144e-03, 9.0372e-03, 9.1705e-03, 9.5172e-03, 9.1348e-03,\n",
            "        9.8002e-03, 9.5732e-03, 9.1616e-03, 9.6294e-03, 8.5062e-03, 9.1526e-03,\n",
            "        9.6860e-03, 9.2154e-03, 9.6766e-03, 9.4709e-03, 9.5732e-03, 9.6860e-03,\n",
            "        9.1616e-03, 9.1616e-03, 8.8451e-03, 8.9581e-03, 9.6106e-03, 9.4987e-03,\n",
            "        8.8451e-03, 9.7334e-03, 9.3605e-03, 9.4987e-03, 9.1348e-03, 9.2064e-03,\n",
            "        9.1705e-03, 9.4709e-03, 9.1170e-03, 9.2244e-03, 9.1526e-03, 9.5172e-03,\n",
            "        8.8624e-03, 9.2154e-03, 9.6106e-03, 8.7165e-03, 9.2605e-03, 9.4987e-03,\n",
            "        9.3605e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [18]\n",
            "DEBUGGING: logits looks like: tensor([1560.9967, 1567.5282, 1567.5287, 1567.5294, 1567.5289, 1567.5249,\n",
            "        1567.5260, 1567.5228, 1567.5287, 1567.5295, 1567.5323, 1567.5253,\n",
            "        1567.5289, 1567.5312, 1567.5289, 1567.5298, 1567.5273, 1567.5327,\n",
            "        1567.5284, 1567.5248, 1567.5284, 1567.5315, 1567.5311, 1567.5284,\n",
            "        1567.5278, 1567.5271, 1567.5170, 1567.5321, 1567.5242, 1567.5295,\n",
            "        1567.5273, 1567.5179, 1567.5253, 1567.5261, 1567.5302, 1567.5282,\n",
            "        1567.5321, 1567.5245, 1567.5278, 1567.5297, 1567.5275, 1567.5282,\n",
            "        1567.5315, 1567.5306, 1567.5264, 1567.5310, 1567.5280, 1567.5317,\n",
            "        1567.5275, 1567.5310, 1567.5302, 1567.5275, 1567.5255, 1567.5184,\n",
            "        1567.5271, 1567.5245, 1567.5256, 1567.5291, 1567.5334, 1567.5278,\n",
            "        1567.5327, 1567.5275, 1567.5248, 1567.5282, 1567.5278, 1567.5334,\n",
            "        1567.5297, 1567.5332, 1567.5260, 1567.5275, 1567.5311, 1567.5271,\n",
            "        1567.5341, 1567.5317, 1567.5273, 1567.5323, 1567.5199, 1567.5272,\n",
            "        1567.5330, 1567.5280, 1567.5328, 1567.5306, 1567.5317, 1567.5330,\n",
            "        1567.5273, 1567.5273, 1567.5238, 1567.5251, 1567.5321, 1567.5310,\n",
            "        1567.5238, 1567.5334, 1567.5295, 1567.5310, 1567.5271, 1567.5278,\n",
            "        1567.5275, 1567.5306, 1567.5269, 1567.5281, 1567.5272, 1567.5311,\n",
            "        1567.5240, 1567.5280, 1567.5321, 1567.5223, 1567.5284, 1567.5310,\n",
            "        1567.5295], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.22049879263386174 and immediate abs rewards look like: [0.01569241746415173, 0.0026544313013801, 0.10759943206858225, 0.019995252120452278, 0.004893562807865237, 0.003542195942827675, 0.014073556655830544, 0.0009673237630067888, 0.0064515767128341395, 7.35521005026385e-05, 0.007507097748884917, 0.004312469772912664, 0.010886495992963319, 0.000887077232619049, 0.0013010106513320352, 0.0009546089570449112, 0.0004583256911701028, 0.003144759913084272, 0.0006093426504776289, 0.0008471012747577333, 0.0001170611462839588, 0.003152842462668559, 0.00010928042229352286, 0.0003788453195738839, 0.0034339136939252057, 8.925266661208298e-05, 2.0053214257131913e-05, 0.002270913716756695, 0.0003404993324238603, 0.0003276598049524182, 0.000727679469036957, 0.0004298922515317827, 0.00012705654989986215, 5.077461628388846e-05, 0.0009465501827889966, 0.00039325947886936774, 0.00010402795624031569, 4.905501646135235e-05, 0.00010290403838553175, 7.73657607169298e-05, 2.5218115752068115e-05, 6.380121294569108e-05, 4.59784591839707e-05, 0.00010033709349954734, 5.811588880533236e-05, 3.821935615633265e-05, 4.5110544760973426e-05, 9.721920605443302e-06, 4.006885319540743e-06, 7.805234190527699e-06]\n",
            "DEBUGGING: the total relative reward of the trajectory = 41.21873820044813 and immediate relative rewards look like: [0.4350246587545607, 0.14781513930648982, 8.994349521901603, 2.29744559250896, 0.7068953770619821, 0.6148911438151885, 2.853130348959996, 0.22503771512102194, 1.6889781221658398, 0.02143514915856172, 2.4066087718107543, 1.5114690239764714, 4.138765060809779, 0.3643456823937142, 0.5726764293148896, 0.44838236504441054, 0.2287957128505011, 1.662429407368476, 0.34032956494048594, 0.49811271680311187, 0.07229404797149122, 2.0399070490990914, 0.0739875259635692, 0.2676550509732901, 2.5274355883243893, 0.06838873067799528, 0.015956923995457166, 1.8739700679527245, 0.2912118259015848, 0.28992307411459545, 0.6653990034914697, 0.40586645225872914, 0.12371992391570308, 0.05094135533424097, 0.9776043457492732, 0.41788276314912054, 0.1136252791394859, 0.055030509324148866, 0.11847857579549646, 0.09136182884815092, 0.030525473068923392, 0.07911291225099856, 0.05837141152968579, 0.1303459120240112, 0.07721532181785366, 0.05190924811650552, 0.06260144681841584, 0.013778677425877312, 0.005797202421396214, 0.011523168927656039]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 150 number of matrices\n",
            "DEBUGGING: ACT_MAT has 150 number of matrices\n",
            "DEBUGGING: VAL looks like: [[16.512246642581, 15.544648786480495, 15.559153317405347, 12.758658100883396, 12.017767768957782, 7.6223768156046, 5.945498353023048, 5.934442788958268, 5.896577082496315, 5.821171852481395, 5.039518437496791, 3.807609509570188, 3.7782974812734786, 3.212881470057975, 2.7475777621873116, 2.656655953730171, 2.036682880102729, 1.6987761546382876, 1.6633542545339088, 1.672942000518176, 1.6445291742009753, 1.5966783819394985, 1.1133635952253433, 1.0670534590073417, 1.011580657141086, 0.5276758726179911, 0.45357848193852046, 0.41685382245908126, 0.2936462673602991, 0.2904806302513293, 0.2915167835209127, 0.2893508826610848, 0.27543407204394893, 0.2596924886205323, 0.2568979235498521, 0.21783177119223077, 0.2112586914568636, 0.1932478760825472, 0.17493691890897803, 0.17573431274076057, 0.17591648648847114, 0.1609144523791571, 0.1108669268732202, 0.10694677304672225, 0.09763402241654495, 0.08502948266985973, 0.06398767442919834, 0.0599014696407335, 0.0011188738679574165, 0.0010878555206900677], [31.04821770109133, 30.882371328047444, 30.944471327147433, 29.924327372472533, 23.523913024736565, 23.583156466532024, 23.768380581383674, 23.920991195031565, 24.05913477521668, 24.2727757501616, 24.415389872799626, 24.618837065401372, 24.63878048358467, 24.78575304605407, 24.80383070664997, 24.980504882500394, 25.227868246449702, 25.373378532418297, 25.424798492563234, 25.637375597713955, 25.83282964052649, 26.077627630531044, 26.287329687174708, 26.124686464414008, 25.60795293218721, 25.757681525016093, 24.92630583947255, 25.158609936333363, 20.76495673236349, 20.0775975232452, 19.690508810284477, 12.422400831700175, 12.285412866183357, 12.238329121202469, 12.282657174003349, 12.360057445197608, 11.437332141959326, 11.453405284824868, 9.224328068228115, 7.105299095736432, 5.744819282888576, 5.645964440230659, 5.528697421358929, 5.372686580438684, 2.7737426541520396, 2.5394408348158524, 2.2522860224299373, 1.661091930461665, 1.6153349451559398, 0.8359716165127864], [36.45636700700241, 36.38519429115944, 36.603413284699954, 27.887943194745812, 25.848987477006922, 25.39605262620701, 25.03147624484022, 22.402369591798205, 22.40134532997695, 20.92158303819304, 21.11126049397422, 18.89358759814492, 17.55769552946308, 13.55447522086192, 13.323363170169905, 12.879481556419208, 12.556665849873532, 12.452394077801042, 10.898954212558147, 10.665277421836022, 10.26986333841708, 10.300575040854131, 8.344109082580848, 8.353658137997252, 8.167679885882789, 5.697216462180202, 5.685684577274956, 5.726997629575251, 3.891947031941946, 3.637106268727637, 3.3809931258717594, 2.7430243660406965, 2.360765569476735, 2.2596420662232646, 2.2310108190798217, 1.2660671447783316, 0.8567519006355667, 0.7506329510061422, 0.7026287289717105, 0.5900506597739535, 0.5037260918442451, 0.47798042300537547, 0.40289647550947166, 0.34800511513109683, 0.21985778091624814, 0.14408329201858025, 0.09310509485058054, 0.030811765689055248, 0.017205139659775694, 0.011523168927656039]]\n",
            "DEBUGGING: traj_returns = [16.512246642581, 31.04821770109133, 36.45636700700241]\n",
            "DEBUGGING: actions = [[50], [38], [28], [39], [34], [25], [6], [26], [68], [67], [19], [24], [25], [4], [16], [41], [7], [68], [15], [53], [5], [53], [67], [54], [54], [61], [63], [37], [53], [83], [1], [38], [56], [33], [83], [14], [56], [92], [30], [31], [77], [93], [18], [79], [43], [40], [66], [26], [89], [92], [12], [7], [39], [8], [12], [40], [3], [3], [3], [67], [2], [55], [66], [3], [66], [22], [62], [1], [3], [64], [49], [70], [76], [68], [38], [56], [22], [54], [44], [64], [79], [46], [88], [39], [49], [38], [19], [17], [94], [52], [74], [43], [59], [36], [49], [10], [47], [75], [75], [15], [8], [22], [50], [14], [35], [62], [41], [28], [11], [65], [31], [11], [48], [2], [55], [1], [2], [11], [70], [28], [66], [74], [76], [42], [81], [29], [85], [13], [25], [23], [18], [81], [10], [27], [42], [88], [79], [34], [67], [62], [99], [48], [67], [92], [90], [3], [25], [67], [40], [18]]\n",
            "DEBUGGING: actions length = 150\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[  7.5229,   8.0402,  13.0567,  ...,   4.6021, -14.0651, -21.5052],\n",
            "        [  7.5609,   8.0834,  13.1276,  ...,   4.6176, -14.1168, -21.5716],\n",
            "        [  7.6319,   8.1467,  13.2164,  ...,   4.6561, -14.1982, -21.7143],\n",
            "        ...,\n",
            "        [  7.5965,   8.1214,  13.1779,  ...,   4.6347, -14.1474, -21.6317],\n",
            "        [  7.5964,   8.1213,  13.1778,  ...,   4.6346, -14.1473, -21.6315],\n",
            "        [  7.5965,   8.1214,  13.1779,  ...,   4.6347, -14.1474, -21.6316]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[  7.5640,   8.0863,  13.1200,  ...,   4.6147, -14.0907, -21.5427],\n",
            "        [  7.5964,   8.1214,  13.1778,  ...,   4.6347, -14.1473, -21.6316],\n",
            "        [  7.5964,   8.1214,  13.1778,  ...,   4.6347, -14.1473, -21.6316],\n",
            "        ...,\n",
            "        [  7.5964,   8.1214,  13.1778,  ...,   4.6347, -14.1473, -21.6316],\n",
            "        [  7.5964,   8.1214,  13.1778,  ...,   4.6347, -14.1473, -21.6316],\n",
            "        [  7.5964,   8.1214,  13.1778,  ...,   4.6347, -14.1473, -21.6316]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([1560.9967, 1567.5282, 1567.5287, 1567.5294, 1567.5289, 1567.5249,\n",
            "        1567.5260, 1567.5228, 1567.5287, 1567.5295, 1567.5323, 1567.5253,\n",
            "        1567.5289, 1567.5312, 1567.5289, 1567.5298, 1567.5273, 1567.5327,\n",
            "        1567.5284, 1567.5248, 1567.5284, 1567.5315, 1567.5311, 1567.5284,\n",
            "        1567.5278, 1567.5271, 1567.5170, 1567.5321, 1567.5242, 1567.5295,\n",
            "        1567.5273, 1567.5179, 1567.5253, 1567.5261, 1567.5302, 1567.5282,\n",
            "        1567.5321, 1567.5245, 1567.5278, 1567.5297, 1567.5275, 1567.5282,\n",
            "        1567.5315, 1567.5306, 1567.5264, 1567.5310, 1567.5280, 1567.5317,\n",
            "        1567.5275, 1567.5310, 1567.5302, 1567.5275, 1567.5255, 1567.5184,\n",
            "        1567.5271, 1567.5245, 1567.5256, 1567.5291, 1567.5334, 1567.5278,\n",
            "        1567.5327, 1567.5275, 1567.5248, 1567.5282, 1567.5278, 1567.5334,\n",
            "        1567.5297, 1567.5332, 1567.5260, 1567.5275, 1567.5311, 1567.5271,\n",
            "        1567.5341, 1567.5317, 1567.5273, 1567.5323, 1567.5199, 1567.5272,\n",
            "        1567.5330, 1567.5280, 1567.5328, 1567.5306, 1567.5317, 1567.5330,\n",
            "        1567.5273, 1567.5273, 1567.5238, 1567.5251, 1567.5321, 1567.5310,\n",
            "        1567.5238, 1567.5334, 1567.5295, 1567.5310, 1567.5271, 1567.5278,\n",
            "        1567.5275, 1567.5306, 1567.5269, 1567.5281, 1567.5272, 1567.5311,\n",
            "        1567.5240, 1567.5280, 1567.5321, 1567.5223, 1567.5284, 1567.5310,\n",
            "        1567.5295], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[28.00561045 27.60407147 27.70234598 23.52364289 20.46355609 18.8671953\n",
            "  18.24845173 17.41926786 17.4523524  17.00517688 16.8553896  15.77334472\n",
            "  15.3249245  13.85103658 13.62492388 13.50554746 13.27373899 13.17484959\n",
            "  12.66236899 12.65853167 12.58240738 12.65829368 11.91493412 11.84846602\n",
            "  11.59573783 10.66085795 10.35518963 10.4341538   8.31685001  8.00172814\n",
            "   7.78767291  5.15159203  4.97387084  4.91922123  4.92352197  4.61465212\n",
            "   4.16844758  4.1324287   3.36729791  2.62369469  2.14148729  2.09495311\n",
            "   2.01415361  1.94254616  1.03041149  0.9228512   0.80312626  0.58393506\n",
            "   0.54455299  0.28286088]]\n",
            "DEBUGGING: baseline2 looks like: 28.005610450224918\n",
            "DEBUGGING: ADS looks like: [-11.49336381 -12.05942268 -12.14319266 -10.76498479  -8.44578832\n",
            " -11.24481849 -12.30295337 -11.48482507 -11.55577531 -11.18400503\n",
            " -11.81587116 -11.96573521 -11.54662702 -10.63815511 -10.87734612\n",
            " -10.84889151 -11.23705611 -11.47607343 -10.99901473 -10.98558967\n",
            " -10.93787821 -11.0616153  -10.80157053 -10.78141256 -10.58415717\n",
            " -10.13318208  -9.90161115 -10.01729997  -8.02320374  -7.71124751\n",
            "  -7.49615612  -4.86224114  -4.69843676  -4.65952874  -4.66662405\n",
            "  -4.39682035  -3.95718889  -3.93918083  -3.19236099  -2.44796038\n",
            "  -1.9655708   -1.93403865  -1.90328668  -1.83559938  -0.93277746\n",
            "  -0.83782172  -0.73913859  -0.52403359  -0.54343411  -0.28177302\n",
            "   3.04260725   3.27829986   3.24212535   6.40068448   3.06035693\n",
            "   4.71596116   5.51992885   6.50172334   6.60678238   7.26759887\n",
            "   7.56000027   8.84549234   9.31385599  10.93471647  11.17890683\n",
            "  11.47495742  11.95412925  12.19852894  12.76242951  12.97884392\n",
            "  13.25042226  13.41933395  14.37239557  14.27622044  14.01221511\n",
            "  15.09682357  14.57111621  14.72445614  12.44810672  12.07586938\n",
            "  11.9028359    7.2708088    7.31154203   7.3191079    7.3591352\n",
            "   7.74540532   7.26888456   7.32097658   5.85703016   4.48160441\n",
            "   3.603332     3.55101134   3.51454381   3.43014042   1.74333117\n",
            "   1.61658963   1.44915976   1.07715688   1.07078196   0.55311074\n",
            "   8.45075656   8.78112282   8.90106731   4.36430031   5.38543139\n",
            "   6.52885732   6.78302452   4.98310173   4.94899293   3.91640616\n",
            "   4.25587089   3.12024287   2.23277103  -0.29656136  -0.30156071\n",
            "  -0.62606591  -0.71707314  -0.72245551  -1.76341477  -1.99325425\n",
            "  -2.31254405  -2.35771864  -3.57082504  -3.49480788  -3.42805794\n",
            "  -4.96364149  -4.66950506  -4.70715617  -4.42490298  -4.36462187\n",
            "  -4.40667978  -2.40856766  -2.61310527  -2.65957916  -2.69251115\n",
            "  -3.34858498  -3.31169568  -3.38179575  -2.66466918  -2.03364403\n",
            "  -1.6377612   -1.61697268  -1.61125713  -1.59454104  -0.8105537\n",
            "  -0.77876791  -0.71002117  -0.55312329  -0.52734785  -0.27133771]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(-3.9801, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.2113,  0.0585,  0.1790,  ..., -0.0562, -0.2985, -0.1294],\n",
            "        [-0.0941, -0.0261, -0.0797,  ...,  0.0249,  0.1328,  0.0432],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.0747,  0.0206,  0.0632,  ..., -0.0199, -0.1055, -0.0512],\n",
            "        [ 0.1657,  0.0458,  0.1404,  ..., -0.0441, -0.2341, -0.1040],\n",
            "        [ 0.0862,  0.0239,  0.0730,  ..., -0.0229, -0.1217, -0.0459]])\n",
            "   Last layer:\n",
            "tensor([[-1.0380e-03, -1.0589e-02, -7.4804e-03,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -2.4380e-02,  0.0000e+00,  0.0000e+00,\n",
            "          4.9940e-03,  2.2171e-03,  2.3227e-03,  0.0000e+00,  1.5578e-02,\n",
            "          0.0000e+00, -1.4547e-02,  0.0000e+00, -2.3893e-02,  0.0000e+00],\n",
            "        [-7.1075e-03, -2.1617e-02, -1.3721e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -3.4063e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -1.8134e-04, -6.0758e-03, -5.8604e-04,  0.0000e+00,  9.4765e-03,\n",
            "          0.0000e+00, -2.0869e-02,  0.0000e+00, -3.0316e-02,  0.0000e+00],\n",
            "        [-1.3147e-02, -3.7792e-02, -2.3911e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -5.8274e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -1.5544e-03, -1.1752e-02, -1.5579e-03,  0.0000e+00,  1.4165e-02,\n",
            "          0.0000e+00, -3.5670e-02,  0.0000e+00, -5.1102e-02,  0.0000e+00],\n",
            "        [ 9.0926e-03,  2.5397e-02,  1.6068e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  3.8419e-02,  0.0000e+00,  0.0000e+00,\n",
            "          1.3574e-03,  8.0159e-03,  1.2109e-03,  0.0000e+00, -8.7068e-03,\n",
            "          0.0000e+00,  2.3676e-02,  0.0000e+00,  3.3686e-02,  0.0000e+00],\n",
            "        [ 3.6466e-02,  7.7349e-02,  4.6586e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  9.0933e-02,  0.0000e+00,  0.0000e+00,\n",
            "          2.1828e-02,  4.2672e-02,  1.2669e-02,  0.0000e+00,  1.0967e-02,\n",
            "          0.0000e+00,  5.7500e-02,  0.0000e+00,  7.1325e-02,  0.0000e+00],\n",
            "        [ 2.6136e-02,  6.3013e-02,  3.8900e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  8.4429e-02,  0.0000e+00,  0.0000e+00,\n",
            "          1.0846e-02,  2.7945e-02,  6.8557e-03,  0.0000e+00, -5.8162e-03,\n",
            "          0.0000e+00,  5.2592e-02,  0.0000e+00,  7.0345e-02,  0.0000e+00],\n",
            "        [-2.1429e-02, -4.5752e-02, -2.7528e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -5.3966e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -1.2636e-02, -2.5002e-02, -7.4115e-03,  0.0000e+00, -6.0987e-03,\n",
            "          0.0000e+00, -3.4088e-02,  0.0000e+00, -4.2411e-02,  0.0000e+00],\n",
            "        [-3.3614e-03, -1.1261e-02, -7.2651e-03,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -1.9093e-02,  0.0000e+00,  0.0000e+00,\n",
            "          7.1499e-04, -2.3078e-03,  1.1830e-04,  0.0000e+00,  6.6562e-03,\n",
            "          0.0000e+00, -1.1586e-02,  0.0000e+00, -1.7244e-02,  0.0000e+00],\n",
            "        [ 3.9101e-02,  8.2437e-02,  4.9500e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  9.5829e-02,  0.0000e+00,  0.0000e+00,\n",
            "          2.3605e-02,  4.5766e-02,  1.3689e-02,  0.0000e+00,  1.2652e-02,\n",
            "          0.0000e+00,  6.0745e-02,  0.0000e+00,  7.4981e-02,  0.0000e+00],\n",
            "        [ 5.5739e-02,  1.1946e-01,  7.1852e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  1.4142e-01,  0.0000e+00,  0.0000e+00,\n",
            "          3.2740e-02,  6.4531e-02,  1.9024e-02,  0.0000e+00,  1.5160e-02,\n",
            "          0.0000e+00,  8.9435e-02,  0.0000e+00,  1.1152e-01,  0.0000e+00]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.3083,  0.2459, -0.0209,  ..., -0.3283, -0.3082,  0.5966],\n",
            "        [-0.1450, -0.1157,  0.0098,  ...,  0.1543,  0.1449, -0.2954],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.1131,  0.0902, -0.0077,  ..., -0.1204, -0.1131,  0.2138],\n",
            "        [ 0.2491,  0.1986, -0.0169,  ..., -0.2652, -0.2490,  0.4803],\n",
            "        [ 0.1187,  0.0947, -0.0080,  ..., -0.1263, -0.1186,  0.2367]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0903,  0.1474,  0.0722,  0.0000,  0.0000,  0.0000,  0.0000,  0.0951,\n",
            "          0.0000,  0.0000,  0.0849,  0.1273,  0.0485,  0.0000,  0.1202,  0.0000,\n",
            "          0.0721,  0.0000,  0.0495,  0.0000],\n",
            "        [ 0.0933,  0.1521,  0.0740,  0.0000,  0.0000,  0.0000,  0.0000,  0.0973,\n",
            "          0.0000,  0.0000,  0.0880,  0.1318,  0.0503,  0.0000,  0.1249,  0.0000,\n",
            "          0.0742,  0.0000,  0.0503,  0.0000],\n",
            "        [ 0.1472,  0.2399,  0.1161,  0.0000,  0.0000,  0.0000,  0.0000,  0.1523,\n",
            "          0.0000,  0.0000,  0.1390,  0.2084,  0.0797,  0.0000,  0.1978,  0.0000,\n",
            "          0.1167,  0.0000,  0.0780,  0.0000],\n",
            "        [-0.0964, -0.1571, -0.0762,  0.0000,  0.0000,  0.0000,  0.0000, -0.0997,\n",
            "          0.0000,  0.0000, -0.0910, -0.1365, -0.0522,  0.0000, -0.1297,  0.0000,\n",
            "         -0.0764,  0.0000, -0.0511,  0.0000],\n",
            "        [-0.1303, -0.2115, -0.0995,  0.0000,  0.0000,  0.0000,  0.0000, -0.1280,\n",
            "          0.0000,  0.0000, -0.1243, -0.1863, -0.0719,  0.0000, -0.1801,  0.0000,\n",
            "         -0.1008,  0.0000, -0.0631,  0.0000],\n",
            "        [-0.1717, -0.2794, -0.1342,  0.0000,  0.0000,  0.0000,  0.0000, -0.1752,\n",
            "          0.0000,  0.0000, -0.1623, -0.2433, -0.0933,  0.0000, -0.2325,  0.0000,\n",
            "         -0.1350,  0.0000, -0.0891,  0.0000],\n",
            "        [ 0.0815,  0.1324,  0.0627,  0.0000,  0.0000,  0.0000,  0.0000,  0.0811,\n",
            "          0.0000,  0.0000,  0.0775,  0.1161,  0.0447,  0.0000,  0.1119,  0.0000,\n",
            "          0.0634,  0.0000,  0.0404,  0.0000],\n",
            "        [ 0.0558,  0.0910,  0.0447,  0.0000,  0.0000,  0.0000,  0.0000,  0.0589,\n",
            "          0.0000,  0.0000,  0.0524,  0.0785,  0.0299,  0.0000,  0.0741,  0.0000,\n",
            "          0.0446,  0.0000,  0.0307,  0.0000],\n",
            "        [-0.1349, -0.2191, -0.1030,  0.0000,  0.0000,  0.0000,  0.0000, -0.1327,\n",
            "          0.0000,  0.0000, -0.1289, -0.1929, -0.0744,  0.0000, -0.1867,  0.0000,\n",
            "         -0.1045,  0.0000, -0.0652,  0.0000],\n",
            "        [-0.2073, -0.3366, -0.1583,  0.0000,  0.0000,  0.0000,  0.0000, -0.2037,\n",
            "          0.0000,  0.0000, -0.1975, -0.2958, -0.1144,  0.0000, -0.2864,  0.0000,\n",
            "         -0.1606,  0.0000, -0.1002,  0.0000]])\n",
            "DEBUGGING: training for one iteration takes 0.004879 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 18\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([1.0764e-22, 7.8127e-11, 1.0309e-04, 5.7465e-08, 6.6455e-09, 5.4369e-06,\n",
            "        2.7439e-01, 5.0849e-03, 1.3534e-06, 7.3653e-07, 1.2382e-13, 8.5825e-03,\n",
            "        8.0455e-04, 2.0505e-03, 5.3082e-03, 9.2604e-04, 4.6226e-07, 1.4451e-05,\n",
            "        1.4199e-05, 5.3422e-06, 2.2865e-06, 5.4644e-05, 9.0635e-04, 1.6766e-04,\n",
            "        1.0399e-11, 1.3298e-06, 2.3242e-01, 1.3629e-05, 2.4153e-05, 4.4871e-10,\n",
            "        5.7933e-06, 7.2533e-05, 1.6327e-05, 1.5812e-04, 1.6349e-09, 8.1938e-06,\n",
            "        1.9868e-05, 2.2913e-05, 3.4864e-06, 4.4949e-05, 5.8960e-06, 5.3660e-09,\n",
            "        4.9497e-07, 5.9000e-08, 1.1428e-07, 5.0431e-06, 2.5657e-06, 5.5147e-09,\n",
            "        2.9157e-13, 1.8108e-05, 2.7218e-03, 2.4221e-06, 4.9552e-06, 7.0270e-08,\n",
            "        1.2986e-08, 3.8377e-04, 7.4114e-11, 4.9012e-14, 5.7659e-05, 1.7516e-05,\n",
            "        7.6673e-06, 2.3242e-01, 2.3242e-01, 1.0209e-04, 4.8799e-04, 1.0189e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [26]\n",
            "DEBUGGING: logits looks like: tensor([1634.3003, 1637.0314, 1638.4407, 1637.6914, 1637.4757, 1638.1464,\n",
            "        1639.2294, 1638.8304, 1638.0073, 1637.9465, 1636.3866, 1638.8829,\n",
            "        1638.6461, 1638.7396, 1638.8347, 1638.6603, 1637.8999, 1638.2441,\n",
            "        1638.2424, 1638.1447, 1638.0598, 1638.3772, 1638.6581, 1638.4893,\n",
            "        1636.8297, 1638.0056, 1639.2126, 1638.2383, 1638.2955, 1637.2062,\n",
            "        1638.1527, 1638.4055, 1638.2563, 1638.4834, 1637.3354, 1638.1874,\n",
            "        1638.2760, 1638.2903, 1638.1019, 1638.3577, 1638.1545, 1637.4543,\n",
            "        1637.9067, 1637.6941, 1637.7601, 1638.1389, 1638.0713, 1637.4570,\n",
            "        1636.4723, 1638.2667, 1638.7679, 1638.0656, 1638.1371, 1637.7115,\n",
            "        1637.5427, 1638.5720, 1637.0261, 1636.2939, 1638.3826, 1638.2634,\n",
            "        1638.1808, 1639.2126, 1639.2126, 1638.4397, 1638.5962, 1638.4396],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.0167e-21, 1.2929e-07, 4.1403e-28, 5.5285e-34, 1.2440e-04, 1.3982e-06,\n",
            "        1.1325e-05, 8.1754e-17, 1.2355e-17, 6.4169e-17, 3.5540e-37, 1.0311e-12,\n",
            "        1.9232e-03, 3.5629e-07, 6.0272e-05, 4.1863e-39, 1.6967e-18, 1.2219e-42,\n",
            "        8.4047e-41, 2.8923e-17, 3.9921e-04, 1.6992e-15, 3.1439e-21, 2.5148e-12,\n",
            "        7.1478e-14, 4.4715e-42, 2.1655e-39, 1.2931e-06, 1.1321e-07, 6.3861e-10,\n",
            "        3.0637e-24, 2.8563e-16, 9.4607e-07, 4.2486e-12, 6.7203e-15, 7.0847e-08,\n",
            "        2.5886e-21, 6.3308e-29, 1.3841e-28, 1.4465e-14, 6.4121e-22, 1.6269e-25,\n",
            "        8.8849e-09, 3.4915e-25, 2.4337e-09, 4.4335e-08, 1.3878e-17, 3.7255e-09,\n",
            "        3.4648e-37, 6.5617e-18, 2.4872e-14, 7.7147e-13, 8.3479e-21, 2.2138e-09,\n",
            "        7.0350e-29, 1.7036e-17, 9.2514e-26, 0.0000e+00, 7.2712e-04, 3.8033e-21,\n",
            "        1.6088e-08, 4.9608e-01, 5.0563e-04, 5.0563e-04, 2.8875e-15, 2.4743e-03,\n",
            "        1.1109e-03, 3.3423e-10, 1.1682e-06, 6.2791e-12, 1.6582e-15, 6.2791e-12,\n",
            "        2.8240e-07, 4.9608e-01, 2.2037e-07, 6.8694e-25, 5.6748e-16, 1.2490e-16,\n",
            "        1.2304e-12], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [73]\n",
            "DEBUGGING: logits looks like: tensor([1635.5297, 1638.7773, 1634.0583, 1632.7057, 1639.4644, 1639.0154,\n",
            "        1639.2247, 1636.6592, 1636.4702, 1636.6350, 1631.9707, 1637.6034,\n",
            "        1639.7382, 1638.8788, 1639.3918, 1631.5266, 1636.2717, 1630.7126,\n",
            "        1631.1357, 1636.5553, 1639.5808, 1636.9626, 1635.6426, 1637.6926,\n",
            "        1637.3365, 1630.8424, 1631.4607, 1639.0077, 1638.7642, 1638.2463,\n",
            "        1634.9492, 1636.7843, 1638.9764, 1637.7450, 1637.1001, 1638.7172,\n",
            "        1635.6232, 1633.8705, 1633.9487, 1637.1768, 1635.4836, 1634.6556,\n",
            "        1638.5096, 1634.7321, 1638.3801, 1638.6704, 1636.4818, 1638.4226,\n",
            "        1631.9681, 1636.4070, 1637.2310, 1637.5745, 1635.7402, 1638.3706,\n",
            "        1633.8811, 1636.5023, 1634.5992, 1626.8411, 1639.6409, 1635.6616,\n",
            "        1638.5690, 1640.2933, 1639.6046, 1639.6046, 1637.0156, 1639.7633,\n",
            "        1639.6832, 1638.1815, 1638.9974, 1637.7841, 1636.9602, 1637.7841,\n",
            "        1638.8556, 1640.2933, 1638.8307, 1634.7997, 1636.8529, 1636.7015,\n",
            "        1637.6211], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([8.4036e-19, 5.4699e-04, 6.8484e-03, 4.0260e-03, 2.2455e-02, 8.7422e-03,\n",
            "        1.4956e-03, 8.7409e-04, 1.8182e-03, 1.6330e-03, 8.1953e-04, 8.0998e-04,\n",
            "        7.3750e-04, 4.1945e-03, 2.1637e-02, 5.0300e-03, 4.8185e-03, 5.0794e-03,\n",
            "        6.1371e-05, 9.3593e-04, 3.7673e-03, 7.2204e-02, 1.1879e-02, 1.4900e-02,\n",
            "        4.5531e-03, 1.2423e-03, 7.2475e-03, 2.7883e-04, 5.4913e-04, 5.5686e-02,\n",
            "        3.6945e-03, 2.4852e-03, 7.7440e-04, 5.2398e-04, 1.4838e-04, 8.3381e-06,\n",
            "        2.0244e-03, 8.1645e-03, 1.1202e-03, 9.5425e-05, 3.5808e-03, 1.7557e-02,\n",
            "        1.0218e-04, 3.8951e-02, 2.7401e-03, 6.9437e-02, 7.6113e-02, 4.1215e-03,\n",
            "        2.3438e-03, 1.9775e-03, 2.5491e-03, 4.8951e-02, 1.0483e-02, 7.2204e-02,\n",
            "        4.0260e-03, 1.9972e-02, 5.7887e-04, 5.6106e-04, 3.6718e-05, 1.9095e-02,\n",
            "        3.1786e-03, 4.2034e-02, 1.8723e-03, 7.6400e-03, 4.7260e-02, 4.6429e-03,\n",
            "        1.3643e-10, 1.0954e-09, 1.2449e-02, 1.8471e-02, 3.0628e-03, 5.6776e-03,\n",
            "        1.2277e-04, 5.6776e-03, 2.0971e-02, 2.8604e-03, 4.3787e-03, 8.6067e-03,\n",
            "        5.8341e-04, 2.0523e-03, 2.1136e-02, 6.3281e-09, 6.9136e-05, 5.1998e-03,\n",
            "        2.6150e-02, 3.8416e-03, 1.1225e-02, 2.3259e-02, 1.9817e-02, 1.8471e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [45]\n",
            "DEBUGGING: logits looks like: tensor([1636.3795, 1639.7905, 1640.0432, 1639.9900, 1640.1619, 1640.0676,\n",
            "        1639.8911, 1639.8373, 1639.9106, 1639.8998, 1639.8309, 1639.8297,\n",
            "        1639.8204, 1639.9943, 1640.1583, 1640.0123, 1640.0081, 1640.0133,\n",
            "        1639.5717, 1639.8441, 1639.9835, 1640.2788, 1640.0983, 1640.1210,\n",
            "        1640.0024, 1639.8726, 1640.0488, 1639.7231, 1639.7908, 1640.2527,\n",
            "        1639.9816, 1639.9418, 1639.8252, 1639.7861, 1639.6599, 1639.3721,\n",
            "        1639.9214, 1640.0608, 1639.8621, 1639.6158, 1639.9783, 1640.1373,\n",
            "        1639.6227, 1640.2170, 1639.9517, 1640.2749, 1640.2839, 1639.9924,\n",
            "        1639.9360, 1639.9189, 1639.9443, 1640.2399, 1640.0857, 1640.2788,\n",
            "        1639.9900, 1640.1503, 1639.7961, 1639.7930, 1639.5204, 1640.1458,\n",
            "        1639.9664, 1640.2247, 1639.9135, 1640.0541, 1640.2363, 1640.0044,\n",
            "        1638.2700, 1638.4783, 1640.1029, 1640.1423, 1639.9628, 1640.0245,\n",
            "        1639.6411, 1640.0245, 1640.1552, 1639.9559, 1639.9984, 1640.0660,\n",
            "        1639.7970, 1639.9227, 1640.1559, 1638.6538, 1639.5836, 1640.0157,\n",
            "        1640.1771, 1639.9855, 1640.0927, 1640.1655, 1640.1495, 1640.1423],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([5.0794e-18, 8.7617e-03, 8.9345e-03, 8.8305e-03, 1.1999e-02, 9.7554e-03,\n",
            "        1.6856e-02, 6.6008e-03, 8.2631e-03, 5.8939e-03, 5.7125e-03, 1.3439e-02,\n",
            "        1.2332e-02, 1.1076e-02, 1.2798e-02, 3.9569e-03, 1.2070e-02, 3.8054e-03,\n",
            "        1.6084e-02, 8.2631e-03, 1.3127e-02, 8.5088e-03, 1.4474e-02, 3.4962e-08,\n",
            "        5.0808e-03, 8.8824e-03, 9.5480e-03, 1.5896e-02, 1.3624e-02, 9.7554e-03,\n",
            "        9.2182e-03, 1.0777e-02, 1.4194e-02, 7.2496e-03, 9.4922e-03, 7.0265e-03,\n",
            "        1.4139e-02, 9.9478e-03, 9.2905e-03, 9.1822e-03, 5.0808e-03, 8.8305e-03,\n",
            "        8.1828e-03, 9.3086e-03, 8.4756e-03, 8.8477e-03, 7.5090e-03, 1.3865e-02,\n",
            "        9.6606e-03, 1.3204e-02, 1.0968e-02, 1.3465e-02, 5.4403e-03, 1.0026e-02,\n",
            "        6.4985e-03, 1.1698e-02, 8.5254e-03, 1.1250e-02, 1.3995e-05, 5.8138e-03,\n",
            "        9.0046e-03, 1.0304e-02, 6.7838e-03, 2.3265e-02, 1.6052e-02, 1.6052e-02,\n",
            "        1.0466e-02, 1.8333e-02, 1.6210e-02, 1.4277e-02, 6.3852e-03, 3.8054e-03,\n",
            "        5.9867e-03, 9.6229e-03, 1.0344e-02, 1.5287e-02, 8.7106e-03, 7.6421e-03,\n",
            "        6.3728e-03, 7.4360e-03, 1.2332e-02, 5.1307e-03, 1.6210e-02, 1.6465e-02,\n",
            "        1.1185e-02, 1.5559e-02, 1.1098e-02, 6.6656e-03, 1.1098e-02, 9.2723e-03,\n",
            "        2.3770e-02, 1.4587e-02, 1.3677e-02, 5.9984e-03, 1.2575e-02, 7.9466e-03,\n",
            "        1.4139e-02, 8.4426e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [49]\n",
            "DEBUGGING: logits looks like: tensor([1637.0227, 1640.5311, 1640.5330, 1640.5319, 1640.5625, 1640.5419,\n",
            "        1640.5966, 1640.5027, 1640.5251, 1640.4915, 1640.4883, 1640.5739,\n",
            "        1640.5652, 1640.5546, 1640.5690, 1640.4515, 1640.5631, 1640.4476,\n",
            "        1640.5918, 1640.5251, 1640.5715, 1640.5281, 1640.5813, 1639.2878,\n",
            "        1640.4767, 1640.5325, 1640.5397, 1640.5906, 1640.5753, 1640.5419,\n",
            "        1640.5361, 1640.5518, 1640.5793, 1640.5122, 1640.5392, 1640.5090,\n",
            "        1640.5789, 1640.5438, 1640.5370, 1640.5358, 1640.4767, 1640.5319,\n",
            "        1640.5242, 1640.5371, 1640.5278, 1640.5320, 1640.5156, 1640.5769,\n",
            "        1640.5409, 1640.5721, 1640.5535, 1640.5740, 1640.4834, 1640.5446,\n",
            "        1640.5012, 1640.5599, 1640.5284, 1640.5562, 1639.8872, 1640.4901,\n",
            "        1640.5338, 1640.5474, 1640.5055, 1640.6287, 1640.5917, 1640.5917,\n",
            "        1640.5490, 1640.6049, 1640.5927, 1640.5798, 1640.4994, 1640.4476,\n",
            "        1640.4929, 1640.5405, 1640.5476, 1640.5868, 1640.5305, 1640.5173,\n",
            "        1640.4993, 1640.5146, 1640.5652, 1640.4775, 1640.5925, 1640.5941,\n",
            "        1640.5555, 1640.5885, 1640.5548, 1640.5038, 1640.5548, 1640.5367,\n",
            "        1640.6310, 1640.5820, 1640.5756, 1640.4932, 1640.5673, 1640.5214,\n",
            "        1640.5789, 1640.5273], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([8.7614e-18, 9.3018e-03, 1.1111e-02, 9.2475e-03, 8.1768e-03, 6.1481e-03,\n",
            "        8.6702e-03, 9.4298e-03, 7.6216e-03, 1.1667e-02, 8.6702e-03, 1.2085e-02,\n",
            "        6.6737e-03, 7.5771e-03, 9.2114e-03, 9.2837e-03, 1.2468e-02, 1.1397e-02,\n",
            "        7.0214e-03, 9.3018e-03, 1.1111e-02, 8.8932e-03, 9.3018e-03, 8.2894e-03,\n",
            "        9.0332e-03, 6.4180e-03, 1.2493e-02, 9.1219e-03, 8.9280e-03, 7.5035e-03,\n",
            "        1.0418e-02, 8.3381e-03, 8.7724e-03, 8.7896e-03, 1.0769e-02, 8.9280e-03,\n",
            "        9.0332e-03, 8.6364e-03, 9.2294e-03, 8.6872e-03, 1.3481e-02, 1.0418e-02,\n",
            "        9.4298e-03, 9.1219e-03, 9.4298e-03, 9.5224e-03, 8.2894e-03, 8.0500e-03,\n",
            "        1.0018e-02, 7.9563e-03, 9.0156e-03, 7.9252e-03, 9.2837e-03, 1.0665e-02,\n",
            "        1.2014e-02, 8.9455e-03, 8.9280e-03, 6.6347e-03, 9.5597e-03, 9.6723e-03,\n",
            "        8.3707e-03, 9.8439e-03, 8.7896e-03, 1.1419e-02, 1.1242e-02, 1.1397e-02,\n",
            "        1.0540e-02, 9.8439e-03, 1.0418e-02, 1.2689e-02, 9.8631e-03, 1.0499e-02,\n",
            "        1.2889e-02, 1.1003e-02, 8.4694e-03, 7.8943e-03, 1.0623e-02, 8.2732e-03,\n",
            "        9.1934e-03, 6.5446e-03, 8.9280e-03, 8.4199e-03, 7.5181e-03, 7.8943e-03,\n",
            "        1.1967e-02, 1.1531e-02, 8.7724e-03, 7.5623e-03, 1.0236e-02, 9.6723e-03,\n",
            "        8.3707e-03, 1.0499e-02, 9.6913e-03, 9.0156e-03, 1.0748e-02, 9.5597e-03,\n",
            "        8.9805e-03, 7.5771e-03, 7.4016e-03, 9.7482e-03, 7.3153e-03, 1.0769e-02,\n",
            "        1.0316e-02, 6.1122e-03, 5.1671e-03, 8.4694e-03, 1.1397e-02, 1.0438e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [31]\n",
            "DEBUGGING: logits looks like: tensor([1637.5616, 1641.0216, 1641.0393, 1641.0209, 1641.0085, 1640.9801,\n",
            "        1641.0145, 1641.0228, 1641.0016, 1641.0442, 1641.0145, 1641.0476,\n",
            "        1640.9883, 1641.0011, 1641.0206, 1641.0212, 1641.0508, 1641.0419,\n",
            "        1640.9934, 1641.0216, 1641.0393, 1641.0170, 1641.0215, 1641.0100,\n",
            "        1641.0187, 1640.9844, 1641.0510, 1641.0195, 1641.0175, 1641.0000,\n",
            "        1641.0328, 1641.0106, 1641.0157, 1641.0159, 1641.0363, 1641.0175,\n",
            "        1641.0187, 1641.0140, 1641.0208, 1641.0148, 1641.0587, 1641.0328,\n",
            "        1641.0228, 1641.0197, 1641.0228, 1641.0238, 1641.0100, 1641.0071,\n",
            "        1641.0289, 1641.0060, 1641.0184, 1641.0055, 1641.0214, 1641.0352,\n",
            "        1641.0471, 1641.0176, 1641.0175, 1640.9877, 1641.0242, 1641.0254,\n",
            "        1641.0110, 1641.0272, 1641.0159, 1641.0421, 1641.0404, 1641.0419,\n",
            "        1641.0339, 1641.0272, 1641.0328, 1641.0526, 1641.0275, 1641.0336,\n",
            "        1641.0541, 1641.0383, 1641.0121, 1641.0051, 1641.0348, 1641.0099,\n",
            "        1641.0204, 1640.9863, 1641.0175, 1641.0115, 1641.0002, 1641.0051,\n",
            "        1641.0466, 1641.0430, 1641.0157, 1641.0009, 1641.0310, 1641.0254,\n",
            "        1641.0110, 1641.0336, 1641.0256, 1641.0184, 1641.0359, 1641.0242,\n",
            "        1641.0179, 1641.0010, 1640.9987, 1641.0262, 1640.9976, 1641.0361,\n",
            "        1641.0319, 1640.9796, 1640.9626, 1641.0121, 1641.0417, 1641.0330],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.1074883984410917 and immediate abs rewards look like: [0.017294578184191778, 0.011014779996003199, 0.007148412581955199, 0.00020473838094403618, 0.0016168682982424798, 0.006122140866864356, 0.0005589040065387962, 0.00038575721464439994, 0.00018565441359896795, 0.00047125690753091476, 0.0007530319485340442, 0.007775482802571787, 0.004575998886139132, 2.82283090200508e-05, 0.00025688592404549127, 0.00019977213560196105, 0.0009063934494406567, 0.0010554400105320383, 0.004202991701276915, 0.0009320670269516995, 0.0007261529881361639, 0.01391291158643071, 0.003579416007596592, 0.0012619399676623289, 0.008208648596337298, 0.0007430758946611604, 0.00020645747281378135, 0.004665419132834359, 0.0005563711229115142, 0.002006077333135181, 0.0006075440887798322, 0.00017116686058216146, 0.0001562883389851777, 0.000282079806765978, 0.000463542976831377, 0.00022370185843101353, 3.6637250559579115e-05, 0.0008555063254789275, 4.389514560898533e-05, 0.0008671725222484383, 0.00013847796253685374, 0.0003423228254177957, 0.00043808803411593544, 3.6579750030796276e-05, 6.676123712168192e-05, 0.0008777505236139405, 7.086056803018437e-05, 6.54663626846741e-05, 0.00017850096219262923, 1.0201893928751815e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 54.25272137510948 and immediate relative rewards look like: [0.5991038410894446, 0.76772848236173, 0.7502448183127497, 0.028722275671877493, 0.2835537704178809, 1.289115132119782, 0.13759621804955074, 0.10855770523600666, 0.05878456845516255, 0.16580653479450558, 0.2914888965757865, 3.2842759416030214, 2.099667561814935, 0.01397127959197598, 0.1362257432466911, 0.11301132250973676, 0.5448330170188095, 0.6719593583285921, 2.8256036204502206, 0.6605756961576115, 0.5405505833691011, 10.852790683533522, 2.9335159028708935, 1.0805693452128942, 7.325039287752168, 0.691638505751458, 0.19961012108419157, 4.678094524488725, 0.5787740858453682, 2.159245923583979, 0.6762158899522641, 0.1967026843171502, 0.18522851084727338, 0.34446302553825475, 0.5827653865666077, 0.28932110151187906, 0.048704324023514683, 1.1680339329564982, 0.06152664755474363, 1.2466785923035306, 0.20412157080352927, 0.516929301885669, 0.6773752190162691, 0.05788436682530526, 0.10804644453131257, 1.452154908592794, 0.11981843089003119, 0.11305549135480009, 0.31468720344302237, 0.018353594896659605]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([1.0174e-14, 2.2167e-24, 4.0352e-41, 6.8738e-25, 4.7648e-07, 1.1073e-29,\n",
            "        2.7251e-08, 4.5331e-40, 1.6509e-29, 6.3439e-26, 5.1731e-32, 1.8983e-03,\n",
            "        1.2571e-10, 1.1922e-05, 1.1130e-01, 3.1565e-05, 3.8290e-26, 2.4847e-25,\n",
            "        2.2950e-01, 6.6269e-28, 2.8596e-06, 9.6051e-21, 4.5035e-12, 8.8406e-14,\n",
            "        1.1591e-17, 6.5260e-13, 6.9048e-21, 1.3375e-20, 3.1401e-07, 6.7712e-08,\n",
            "        2.2788e-09, 1.1160e-09, 7.1148e-10, 1.8709e-09, 1.2013e-13, 8.6879e-13,\n",
            "        1.0125e-07, 2.6873e-10, 1.9686e-08, 1.5403e-16, 1.9611e-27, 3.7170e-22,\n",
            "        2.8619e-07, 1.4422e-12, 8.0615e-04, 5.6597e-12, 2.7101e-19, 1.4507e-12,\n",
            "        2.4585e-24, 1.9771e-12, 1.6913e-11, 2.2545e-09, 7.6717e-22, 1.4370e-10,\n",
            "        4.9629e-22, 5.0086e-13, 5.2632e-21, 3.2944e-26, 1.4873e-15, 8.5320e-10,\n",
            "        1.9265e-22, 6.5633e-01, 2.1480e-06, 2.1480e-06, 7.8636e-07, 1.4561e-13,\n",
            "        1.7637e-05, 7.9898e-05, 1.7637e-05], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [18]\n",
            "DEBUGGING: logits looks like: tensor([1634.5348, 1632.3101, 1628.4556, 1632.1930, 1636.3010, 1631.0894,\n",
            "        1636.0149, 1628.6975, 1631.1293, 1631.9547, 1630.5527, 1637.1300,\n",
            "        1635.4769, 1636.6229, 1637.5371, 1636.7203, 1631.9042, 1632.0912,\n",
            "        1637.6095, 1631.4985, 1636.4802, 1633.1475, 1635.1440, 1634.7510,\n",
            "        1633.8571, 1634.9509, 1633.1145, 1633.1805, 1636.2593, 1636.1058,\n",
            "        1635.7667, 1635.6953, 1635.6503, 1635.7469, 1634.7816, 1634.9795,\n",
            "        1636.1461, 1635.5530, 1635.9823, 1634.1157, 1631.6071, 1632.8223,\n",
            "        1636.2500, 1635.0302, 1637.0443, 1635.1669, 1633.4814, 1635.0308,\n",
            "        1632.3204, 1635.0618, 1635.2764, 1635.7656, 1632.8948, 1635.4904,\n",
            "        1632.8512, 1634.9244, 1633.0873, 1631.8892, 1634.3425, 1635.6685,\n",
            "        1632.7566, 1637.7146, 1636.4515, 1636.4515, 1636.3511, 1634.8009,\n",
            "        1636.6621, 1636.8132, 1636.6621], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.1309e-14, 7.9691e-03, 4.0113e-09, 1.0252e-02, 4.4877e-03, 3.9072e-02,\n",
            "        6.7887e-04, 1.1809e-04, 3.6910e-04, 5.4812e-11, 4.9392e-02, 2.7406e-03,\n",
            "        1.0650e-02, 2.6933e-02, 3.1273e-02, 6.8553e-04, 8.6406e-04, 1.7053e-02,\n",
            "        4.5533e-04, 1.5106e-03, 5.5960e-03, 7.8149e-03, 2.0812e-02, 1.0005e-02,\n",
            "        2.2065e-03, 6.6136e-09, 5.8875e-03, 4.4746e-03, 1.2391e-02, 3.0723e-03,\n",
            "        8.7938e-04, 1.5833e-02, 9.7324e-05, 1.3835e-03, 2.7644e-04, 9.1620e-04,\n",
            "        1.7574e-03, 2.3556e-03, 3.2125e-05, 6.2124e-03, 6.2960e-05, 7.8290e-04,\n",
            "        2.1713e-06, 3.0544e-03, 9.5084e-04, 2.1641e-02, 3.6946e-04, 2.1264e-02,\n",
            "        8.2865e-03, 2.4142e-02, 1.0597e-03, 1.8941e-05, 4.8761e-03, 2.9718e-10,\n",
            "        9.5148e-06, 2.0523e-04, 1.9355e-04, 1.1104e-04, 2.5717e-04, 5.1502e-03,\n",
            "        1.7564e-07, 1.4248e-02, 1.0701e-03, 5.6297e-02, 1.9779e-03, 3.1151e-02,\n",
            "        4.7222e-02, 4.2441e-04, 2.5350e-02, 5.3405e-02, 2.1662e-02, 7.3139e-02,\n",
            "        1.1872e-01, 5.4824e-03, 1.8968e-02, 2.8221e-03, 8.4132e-06, 1.0394e-02,\n",
            "        1.1872e-01], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [72]\n",
            "DEBUGGING: logits looks like: tensor([1635.6050, 1638.2698, 1636.8196, 1638.2949, 1638.2123, 1638.4288,\n",
            "        1638.0234, 1637.8485, 1637.9625, 1636.3903, 1638.4523, 1638.1630,\n",
            "        1638.2987, 1638.3915, 1638.4065, 1638.0244, 1638.0476, 1638.3458,\n",
            "        1637.9835, 1638.1034, 1638.2344, 1638.2678, 1638.3657, 1638.2925,\n",
            "        1638.1414, 1636.8695, 1638.2395, 1638.2120, 1638.3138, 1638.1744,\n",
            "        1638.0493, 1638.3384, 1637.8292, 1638.0946, 1637.9336, 1638.0535,\n",
            "        1638.1185, 1638.1478, 1637.7184, 1638.2449, 1637.7856, 1638.0377,\n",
            "        1637.4490, 1638.1738, 1638.0571, 1638.3696, 1637.9626, 1638.3679,\n",
            "        1638.2737, 1638.3806, 1638.0680, 1637.6655, 1638.2206, 1636.5593,\n",
            "        1637.5967, 1637.9038, 1637.8979, 1637.8424, 1637.9264, 1638.2261,\n",
            "        1637.1975, 1638.3279, 1638.0690, 1638.4653, 1638.1304, 1638.4061,\n",
            "        1638.4476, 1637.9764, 1638.3855, 1638.4600, 1638.3698, 1638.4915,\n",
            "        1638.5399, 1638.2323, 1638.3564, 1638.1659, 1637.5844, 1638.2963,\n",
            "        1638.5399], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([8.7421e-14, 1.2941e-02, 1.1969e-02, 1.8465e-02, 9.7115e-03, 1.1178e-02,\n",
            "        7.9108e-03, 7.4460e-03, 1.2397e-02, 3.0798e-03, 2.4844e-03, 2.0559e-02,\n",
            "        1.0178e-02, 1.3669e-02, 2.2492e-02, 1.9462e-03, 5.0186e-03, 5.4256e-04,\n",
            "        1.9314e-02, 1.8537e-02, 2.1420e-02, 3.4695e-03, 6.8596e-03, 1.2016e-02,\n",
            "        1.3457e-02, 1.2568e-02, 5.4052e-03, 1.7967e-02, 1.0020e-02, 1.5949e-02,\n",
            "        1.3402e-03, 9.6736e-03, 2.7343e-02, 2.0356e-03, 1.6879e-02, 1.7211e-02,\n",
            "        1.8357e-02, 3.1781e-02, 5.0481e-03, 7.5781e-03, 5.2904e-03, 7.6824e-03,\n",
            "        1.0542e-02, 3.1781e-02, 1.2592e-02, 1.9051e-02, 1.2641e-02, 1.3562e-02,\n",
            "        9.7876e-03, 1.1806e-02, 1.0059e-02, 1.5913e-04, 2.4654e-02, 2.8599e-02,\n",
            "        7.6974e-03, 6.0892e-03, 1.0898e-02, 1.7346e-02, 2.3342e-02, 6.4440e-03,\n",
            "        1.1806e-02, 4.1850e-03, 2.9734e-03, 6.1130e-03, 6.1130e-03, 9.5423e-03,\n",
            "        3.0979e-03, 1.1806e-02, 1.1806e-02, 1.3248e-02, 1.3068e-02, 3.7222e-03,\n",
            "        7.6375e-03, 6.9676e-03, 6.4692e-03, 1.2421e-02, 1.5071e-02, 1.7967e-02,\n",
            "        7.5044e-03, 6.0182e-03, 2.2057e-02, 1.9238e-02, 2.1417e-03, 5.6316e-03,\n",
            "        3.7155e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [12]\n",
            "DEBUGGING: logits looks like: tensor([1636.3834, 1638.9556, 1638.9476, 1638.9911, 1638.9268, 1638.9408,\n",
            "        1638.9062, 1638.9003, 1638.9512, 1638.8120, 1638.7904, 1639.0017,\n",
            "        1638.9314, 1638.9611, 1639.0107, 1638.7660, 1638.8608, 1638.6383,\n",
            "        1638.9955, 1638.9915, 1639.0060, 1638.8239, 1638.8921, 1638.9480,\n",
            "        1638.9595, 1638.9526, 1638.8683, 1638.9884, 1638.9299, 1638.9763,\n",
            "        1638.7288, 1638.9264, 1639.0304, 1638.7705, 1638.9821, 1638.9840,\n",
            "        1638.9905, 1639.0454, 1638.8615, 1638.9020, 1638.8661, 1638.9033,\n",
            "        1638.9351, 1639.0454, 1638.9528, 1638.9943, 1638.9531, 1638.9602,\n",
            "        1638.9275, 1638.9464, 1638.9303, 1638.5156, 1639.0199, 1639.0348,\n",
            "        1638.9036, 1638.8801, 1638.9384, 1638.9849, 1639.0144, 1638.8859,\n",
            "        1638.9464, 1638.8427, 1638.8085, 1638.8805, 1638.8805, 1638.9250,\n",
            "        1638.8126, 1638.9463, 1638.9463, 1638.9579, 1638.9564, 1638.8308,\n",
            "        1638.9027, 1638.8936, 1638.8862, 1638.9514, 1638.9708, 1638.9884,\n",
            "        1638.9010, 1638.8789, 1639.0088, 1638.9952, 1638.7756, 1638.8723,\n",
            "        1639.0610], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.4925e-13, 1.1352e-02, 7.0763e-03, 8.2247e-03, 9.6533e-03, 1.0276e-02,\n",
            "        1.4379e-02, 1.7378e-02, 1.0156e-02, 5.0572e-03, 8.5024e-03, 9.8053e-03,\n",
            "        1.4634e-02, 1.0276e-02, 8.7210e-03, 1.2664e-02, 8.4858e-03, 1.0623e-02,\n",
            "        1.7310e-02, 1.1553e-02, 8.7894e-03, 9.6722e-03, 1.2179e-02, 7.4595e-03,\n",
            "        1.0136e-02, 1.1198e-02, 9.6157e-03, 1.0356e-02, 1.2664e-02, 1.2640e-02,\n",
            "        1.2203e-02, 1.0917e-02, 9.6533e-03, 1.1990e-02, 1.0417e-02, 1.6166e-02,\n",
            "        8.2247e-03, 6.9124e-03, 1.0196e-02, 1.2251e-02, 1.0438e-02, 1.1464e-02,\n",
            "        9.6157e-03, 8.3054e-03, 6.8720e-03, 1.0458e-02, 1.0156e-02, 1.2203e-02,\n",
            "        9.7100e-03, 6.8052e-03, 9.9209e-03, 1.1198e-02, 1.0832e-02, 8.3054e-03,\n",
            "        1.1486e-02, 1.2108e-02, 1.1920e-02, 1.0623e-02, 7.8175e-03, 1.0896e-02,\n",
            "        9.1039e-03, 1.0832e-02, 8.3217e-03, 9.2112e-03, 1.1003e-02, 9.7290e-03,\n",
            "        8.1448e-03, 1.1967e-02, 8.7723e-03, 6.0883e-03, 1.0077e-02, 1.3428e-02,\n",
            "        1.0316e-02, 9.8629e-03, 1.0356e-02, 1.0156e-02, 1.1758e-02, 1.1690e-02,\n",
            "        1.2108e-02, 1.2965e-02, 9.1574e-03, 1.1176e-02, 1.1735e-02, 1.1486e-02,\n",
            "        9.7671e-03, 1.0875e-02, 1.0748e-02, 9.9987e-03, 8.3379e-03, 8.4033e-03,\n",
            "        8.8238e-03, 1.0981e-02, 9.1574e-03, 7.1040e-03, 8.5858e-03, 8.0342e-03,\n",
            "        1.0706e-02, 8.1289e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [77]\n",
            "DEBUGGING: logits looks like: tensor([1636.9822, 1639.4363, 1639.3892, 1639.4041, 1639.4202, 1639.4264,\n",
            "        1639.4600, 1639.4789, 1639.4253, 1639.3555, 1639.4075, 1639.4218,\n",
            "        1639.4618, 1639.4264, 1639.4100, 1639.4473, 1639.4072, 1639.4298,\n",
            "        1639.4786, 1639.4381, 1639.4108, 1639.4203, 1639.4435, 1639.3944,\n",
            "        1639.4250, 1639.4349, 1639.4197, 1639.4271, 1639.4474, 1639.4471,\n",
            "        1639.4436, 1639.4325, 1639.4202, 1639.4419, 1639.4277, 1639.4718,\n",
            "        1639.4042, 1639.3867, 1639.4257, 1639.4440, 1639.4280, 1639.4374,\n",
            "        1639.4197, 1639.4050, 1639.3861, 1639.4282, 1639.4252, 1639.4436,\n",
            "        1639.4207, 1639.3851, 1639.4229, 1639.4349, 1639.4318, 1639.4050,\n",
            "        1639.4376, 1639.4427, 1639.4413, 1639.4298, 1639.3990, 1639.4323,\n",
            "        1639.4143, 1639.4318, 1639.4053, 1639.4155, 1639.4332, 1639.4209,\n",
            "        1639.4032, 1639.4417, 1639.4105, 1639.3740, 1639.4244, 1639.4531,\n",
            "        1639.4269, 1639.4222, 1639.4271, 1639.4252, 1639.4398, 1639.4392,\n",
            "        1639.4427, 1639.4497, 1639.4148, 1639.4348, 1639.4397, 1639.4376,\n",
            "        1639.4214, 1639.4321, 1639.4309, 1639.4236, 1639.4055, 1639.4062,\n",
            "        1639.4113, 1639.4330, 1639.4149, 1639.3895, 1639.4084, 1639.4019,\n",
            "        1639.4304, 1639.4030], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.1377e-12, 1.3854e-07, 1.5528e-02, 9.5291e-03, 1.8438e-09, 2.8875e-07,\n",
            "        3.4311e-03, 1.3491e-02, 9.7933e-03, 1.1184e-02, 1.3042e-06, 1.1352e-07,\n",
            "        2.5678e-08, 5.1483e-06, 1.3838e-02, 1.0925e-02, 2.3956e-02, 1.5227e-02,\n",
            "        1.3677e-02, 9.0220e-03, 5.0601e-04, 1.4305e-02, 1.4385e-04, 1.2892e-05,\n",
            "        1.6724e-02, 1.9629e-02, 9.6952e-05, 7.3459e-06, 1.1539e-02, 1.0989e-02,\n",
            "        9.1641e-03, 1.1184e-02, 1.2892e-05, 2.5204e-02, 9.0396e-03, 8.1141e-07,\n",
            "        9.5664e-03, 9.5105e-03, 1.2109e-06, 7.7019e-03, 1.1990e-07, 8.8821e-03,\n",
            "        3.5394e-04, 1.7763e-04, 1.4385e-04, 3.9308e-08, 5.7464e-09, 1.4166e-02,\n",
            "        2.4650e-07, 1.0124e-02, 9.4365e-03, 1.3757e-02, 8.6764e-03, 1.2477e-02,\n",
            "        7.9763e-04, 8.6933e-03, 1.7733e-02, 2.7304e-09, 1.5095e-08, 3.5469e-03,\n",
            "        1.9552e-02, 3.2276e-07, 1.9667e-02, 1.4305e-02, 3.9574e-02, 2.6987e-02,\n",
            "        1.5589e-02, 1.4166e-02, 2.1812e-02, 2.2243e-02, 3.8357e-02, 1.7733e-02,\n",
            "        9.8701e-03, 1.3042e-06, 1.5021e-02, 1.9325e-02, 2.9989e-02, 1.4001e-02,\n",
            "        8.5585e-03, 6.8636e-03, 7.7774e-03, 1.2356e-02, 7.6718e-03, 2.2458e-03,\n",
            "        4.9436e-03, 1.2380e-02, 3.2043e-03, 2.0092e-03, 9.1283e-03, 5.5250e-04,\n",
            "        8.2307e-03, 3.1485e-03, 2.1224e-02, 1.6987e-02, 6.9989e-03, 5.7797e-03,\n",
            "        1.6497e-02, 7.0126e-03, 4.9244e-03, 2.1307e-02, 1.2046e-02, 4.5811e-03,\n",
            "        8.4246e-04, 1.1011e-02, 4.2203e-03, 8.3603e-03, 3.1118e-03, 1.3919e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [68]\n",
            "DEBUGGING: logits looks like: tensor([1637.4656, 1638.6366, 1639.7993, 1639.7505, 1638.2046, 1638.7100,\n",
            "        1639.6482, 1639.7853, 1639.7532, 1639.7664, 1638.8607, 1638.6167,\n",
            "        1638.4680, 1638.9980, 1639.7877, 1639.7640, 1639.8427, 1639.7974,\n",
            "        1639.7865, 1639.7449, 1639.4569, 1639.7910, 1639.3312, 1639.0900,\n",
            "        1639.8068, 1639.8226, 1639.2916, 1639.0336, 1639.7695, 1639.7648,\n",
            "        1639.7466, 1639.7665, 1639.0900, 1639.8477, 1639.7451, 1638.8134,\n",
            "        1639.7509, 1639.7502, 1638.8533, 1639.7291, 1638.6222, 1639.7434,\n",
            "        1639.4211, 1639.3522, 1639.3312, 1638.5105, 1638.3182, 1639.7902,\n",
            "        1638.6942, 1639.7565, 1639.7494, 1639.7872, 1639.7410, 1639.7773,\n",
            "        1639.5023, 1639.7412, 1639.8125, 1638.2439, 1638.4148, 1639.6516,\n",
            "        1639.8223, 1638.7211, 1639.8229, 1639.7910, 1639.8928, 1639.8546,\n",
            "        1639.7997, 1639.7902, 1639.8333, 1639.8352, 1639.8898, 1639.8125,\n",
            "        1639.7539, 1638.8607, 1639.7959, 1639.8210, 1639.8650, 1639.7889,\n",
            "        1639.7396, 1639.7177, 1639.7301, 1639.7764, 1639.7288, 1639.6060,\n",
            "        1639.6848, 1639.7766, 1639.6415, 1639.5947, 1639.7462, 1639.4657,\n",
            "        1639.7358, 1639.6398, 1639.8306, 1639.8082, 1639.7195, 1639.7004,\n",
            "        1639.8053, 1639.7197, 1639.6843, 1639.8308, 1639.7739, 1639.6771,\n",
            "        1639.5079, 1639.7649, 1639.6691, 1639.7374, 1639.6384, 1639.7883],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.12802924022435036 and immediate abs rewards look like: [0.017294578184191778, 0.011014779996003199, 0.007148412581955199, 0.0018216066796412633, 0.016124257560477417, 0.004231098425407254, 0.004965309258750494, 0.0036286814006416535, 0.030857190322876704, 0.0006061149520064646, 0.001238802114585269, 0.00037275507020240184, 0.0006080638090679713, 0.010657323582108802, 0.0017979649110202445, 0.0008305513078994409, 0.003038338663372997, 8.698415422259131e-05, 9.617320392862894e-05, 0.000106899555248674, 1.770037533788127e-05, 0.0019310003904138284, 0.0011202792497897462, 4.361131232144544e-05, 0.0003151908967993222, 0.0003893955604326038, 0.0008331033727699833, 0.00028630065799006843, 0.0009292656468460336, 0.000941757673444954, 0.000627551106390456, 0.0012349040721346682, 0.0008669658368489763, 0.00015674263613618677, 0.00020646436905735754, 0.00022589313903154107, 0.0003552804482751526, 0.00037082719290992827, 1.7037687939591706e-05, 2.0212967228872003e-05, 1.6262733879557345e-06, 7.040675427560927e-06, 3.662307335616788e-06, 3.979330358561128e-06, 4.357322177384049e-05, 1.6535884242330212e-05, 6.107468607297051e-05, 9.932385682986933e-05, 0.0003605656274885405, 1.648803572606994e-05]\n",
            "DEBUGGING: the total relative reward of the trajectory = 40.51348476782191 and immediate relative rewards look like: [0.5991038410894446, 0.76772848236173, 0.7502448183127497, 0.2555490034508542, 2.829351266089831, 0.8959959346345632, 1.2285562115611213, 1.0279036444138745, 9.846249664860254, 0.21727233723648667, 0.48858309038638703, 0.16045067792255913, 0.2835876618002586, 5.353844596041978, 0.9714625108341298, 0.4789844144213846, 1.8623018159826017, 0.056513685893079035, 0.06595721419316083, 0.07717481362897907, 0.013418013497928094, 1.5335370443695429, 0.9307781779057565, 0.03782494022724745, 0.28476615585649784, 0.36592199372234324, 0.8131074742811215, 0.2898654688609553, 0.9745383778280222, 1.0220389724409604, 0.7039888947937327, 1.430331991809199, 1.0360095036974983, 0.19304130447227488, 0.2617712798231719, 0.2946095784797294, 0.47626634781292415, 0.5106083827003076, 0.024080549722634223, 0.0293010966681974, 0.0024164310380669993, 0.010716694825910138, 0.0057071803922413445, 0.006345438007180972, 0.0710610706478651, 0.027567137563575376, 0.10403228134403116, 0.17278794783748624, 0.640345956038821, 0.02988339604124925]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([1.6813e-22, 1.5335e-04, 3.2247e-03, 4.9814e-01, 6.1254e-03, 1.1133e-03,\n",
            "        2.7171e-12, 2.7887e-08, 7.4697e-15, 6.0856e-14, 2.2317e-09, 1.6962e-35,\n",
            "        3.4373e-07, 1.5533e-03, 1.3036e-06, 7.5838e-05, 5.5718e-03, 2.2998e-04,\n",
            "        1.2166e-04, 1.9155e-12, 2.3474e-17, 2.1290e-04, 3.6216e-04, 8.9648e-03,\n",
            "        2.9401e-07, 1.2436e-01, 3.0293e-03, 4.2923e-04, 2.0439e-09, 1.9388e-03,\n",
            "        1.5392e-05, 9.5546e-21, 3.4350e-05, 1.6425e-15, 3.0817e-06, 3.4327e-03,\n",
            "        1.6500e-04, 9.4184e-06, 1.2916e-09, 1.1133e-10, 3.0024e-04, 9.2452e-06,\n",
            "        1.9349e-23, 4.0859e-07, 3.9874e-07, 1.9822e-05, 2.4024e-06, 1.1252e-04,\n",
            "        4.5651e-10, 8.3154e-03, 4.3205e-06, 1.9701e-07, 2.7102e-03, 2.4710e-07,\n",
            "        9.2286e-05, 1.0657e-21, 5.2327e-05, 1.3461e-07, 2.4387e-10, 6.8560e-07,\n",
            "        5.4962e-03, 1.5054e-10, 4.1901e-02, 5.5982e-04, 1.1859e-12, 6.0856e-14,\n",
            "        1.1736e-03, 2.7998e-01], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [25]\n",
            "DEBUGGING: logits looks like: tensor([1622.2670, 1626.4025, 1626.7070, 1627.2111, 1626.7712, 1626.6007,\n",
            "        1624.6176, 1625.5413, 1624.0280, 1624.2377, 1625.2887, 1619.2745,\n",
            "        1625.7924, 1626.6340, 1625.9257, 1626.3320, 1626.7617, 1626.4430,\n",
            "        1626.3793, 1624.5826, 1623.4517, 1626.4353, 1626.4884, 1626.8093,\n",
            "        1625.7767, 1627.0723, 1626.7008, 1626.5054, 1625.2799, 1626.6561,\n",
            "        1626.1726, 1622.6710, 1626.2528, 1623.8765, 1626.0117, 1626.7133,\n",
            "        1626.4098, 1626.1234, 1625.2340, 1624.9889, 1626.4696, 1626.1216,\n",
            "        1622.0508, 1625.8097, 1625.8073, 1626.1979, 1625.9868, 1626.3715,\n",
            "        1625.1300, 1626.8018, 1626.0455, 1625.7367, 1626.6897, 1625.7594,\n",
            "        1626.3517, 1622.4517, 1626.2949, 1625.6986, 1625.0673, 1625.8615,\n",
            "        1626.7604, 1625.0190, 1626.9635, 1626.5320, 1624.5347, 1624.2377,\n",
            "        1626.6060, 1627.1534], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([5.6670e-17, 4.4009e-10, 2.8678e-20, 1.7698e-02, 6.2723e-11, 4.2657e-03,\n",
            "        5.4143e-02, 9.3264e-03, 8.4421e-03, 8.3941e-02, 8.7541e-02, 9.2428e-24,\n",
            "        6.8800e-13, 7.1761e-12, 2.9816e-21, 2.8329e-17, 3.9328e-11, 9.1460e-03,\n",
            "        1.9623e-04, 8.9476e-06, 3.7377e-05, 2.1384e-04, 2.2737e-05, 2.9816e-21,\n",
            "        1.2036e-01, 3.6279e-02, 1.0401e-04, 8.5295e-06, 2.7066e-02, 9.5161e-12,\n",
            "        1.9514e-02, 1.3742e-22, 7.9217e-04, 2.8981e-02, 1.8439e-02, 1.8651e-04,\n",
            "        1.5759e-01, 4.1454e-05, 1.0015e-02, 1.0007e-01, 4.4785e-04, 7.8447e-04,\n",
            "        2.2855e-03, 1.0108e-06, 3.0750e-04, 6.5738e-04, 1.0893e-02, 9.2977e-04,\n",
            "        7.7866e-08, 3.2159e-05, 2.4109e-05, 1.6400e-02, 1.9416e-03, 4.4104e-02,\n",
            "        9.5648e-04, 9.0204e-04, 1.6561e-02, 1.9023e-09, 4.3160e-03, 8.8075e-07,\n",
            "        4.3669e-03, 1.7736e-14, 2.8775e-04, 1.1857e-03, 7.6791e-03, 8.3941e-02,\n",
            "        1.6773e-15, 6.3787e-03, 2.2494e-05, 3.4323e-07, 7.5261e-07, 1.4286e-04,\n",
            "        1.1819e-05, 6.9548e-06, 3.3011e-13, 1.5144e-06, 2.5545e-10, 2.4182e-24,\n",
            "        2.9816e-21, 1.2629e-06], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [36]\n",
            "DEBUGGING: logits looks like: tensor([1623.1989, 1624.7854, 1622.4399, 1626.5364, 1624.5906, 1626.3940,\n",
            "        1626.6482, 1626.4723, 1626.4623, 1626.6920, 1626.6962, 1621.6360,\n",
            "        1624.1393, 1624.3738, 1622.2136, 1623.1295, 1624.5438, 1626.4703,\n",
            "        1626.0862, 1625.7773, 1625.9203, 1626.0947, 1625.8706, 1622.2136,\n",
            "        1626.7280, 1626.6082, 1626.0227, 1625.7726, 1626.5789, 1624.4020,\n",
            "        1626.5461, 1621.9059, 1626.2257, 1626.5857, 1626.5404, 1626.0811,\n",
            "        1626.7550, 1625.9307, 1626.4794, 1626.7096, 1626.1687, 1626.2247,\n",
            "        1626.3317, 1625.5593, 1626.1311, 1626.2070, 1626.4878, 1626.2417,\n",
            "        1625.3030, 1625.9053, 1625.8765, 1626.5287, 1626.3153, 1626.6277,\n",
            "        1626.2445, 1626.2386, 1626.5297, 1624.9318, 1626.3953, 1625.5455,\n",
            "        1626.3964, 1623.7734, 1626.1244, 1626.2660, 1626.4529, 1626.6920,\n",
            "        1623.5376, 1626.4343, 1625.8695, 1625.4513, 1625.5298, 1626.0544,\n",
            "        1625.8052, 1625.7522, 1624.0658, 1625.5997, 1624.7310, 1621.5018,\n",
            "        1622.2136, 1625.5815], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.6010e-05, 1.9527e-02, 3.9717e-02, 2.4522e-07, 5.0726e-05, 2.7111e-02,\n",
            "        7.6545e-03, 8.3822e-03, 8.0375e-03, 6.4899e-03, 9.0873e-18, 2.8280e-07,\n",
            "        1.2951e-05, 7.8661e-10, 1.8570e-05, 1.4729e-07, 1.6173e-02, 1.2695e-08,\n",
            "        8.4232e-03, 1.1094e-02, 7.0310e-03, 1.5424e-12, 1.8810e-04, 5.6330e-03,\n",
            "        4.3365e-02, 1.3632e-02, 3.3245e-03, 4.3009e-05, 1.9546e-02, 7.1417e-03,\n",
            "        1.4173e-03, 9.7983e-04, 4.2060e-04, 2.5025e-02, 1.4812e-02, 6.2404e-04,\n",
            "        7.8743e-03, 4.6844e-02, 3.2132e-02, 1.1223e-03, 4.9719e-02, 3.5701e-03,\n",
            "        1.9912e-02, 8.2337e-05, 2.1155e-02, 1.4677e-11, 1.5102e-03, 5.3333e-03,\n",
            "        5.2506e-03, 4.8655e-03, 2.9946e-03, 1.1479e-02, 6.4836e-03, 1.0132e-01,\n",
            "        1.1400e-03, 1.7351e-02, 1.0149e-03, 2.7781e-02, 4.2364e-08, 1.8627e-04,\n",
            "        9.2887e-02, 2.8935e-04, 1.8501e-04, 1.3128e-06, 2.0144e-03, 8.0375e-03,\n",
            "        1.1616e-08, 4.0415e-03, 2.9746e-02, 1.3046e-02, 2.9191e-04, 1.3606e-02,\n",
            "        4.3827e-03, 4.4214e-03, 2.2538e-03, 1.5252e-02, 4.0723e-11, 1.5440e-05,\n",
            "        6.7157e-16, 2.3280e-02, 5.4651e-03, 4.3070e-02, 3.8570e-02, 4.9655e-04,\n",
            "        7.5801e-03, 2.5895e-02, 1.5866e-06, 1.4535e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [82]\n",
            "DEBUGGING: logits looks like: tensor([1626.8755, 1627.5376, 1627.6086, 1626.4091, 1626.9423, 1627.5704,\n",
            "        1627.4440, 1627.4530, 1627.4489, 1627.4275, 1624.0072, 1626.4233,\n",
            "        1626.8058, 1625.8348, 1626.8418, 1626.3582, 1627.5188, 1626.1130,\n",
            "        1627.4535, 1627.4811, 1627.4354, 1625.2114, 1627.0734, 1627.4133,\n",
            "        1627.6174, 1627.5017, 1627.3606, 1626.9258, 1627.5377, 1627.4370,\n",
            "        1627.2753, 1627.2384, 1627.1538, 1627.5624, 1627.5100, 1627.1932,\n",
            "        1627.4468, 1627.6251, 1627.5874, 1627.2520, 1627.6311, 1627.3677,\n",
            "        1627.5396, 1626.9907, 1627.5457, 1625.4368, 1627.2816, 1627.4078,\n",
            "        1627.4062, 1627.3987, 1627.3501, 1627.4845, 1627.4274, 1627.7023,\n",
            "        1627.2535, 1627.5258, 1627.2419, 1627.5729, 1626.2335, 1627.0724,\n",
            "        1627.6936, 1627.1165, 1627.0717, 1626.5769, 1627.3104, 1627.4489,\n",
            "        1626.1041, 1627.3801, 1627.5797, 1627.4973, 1627.1173, 1627.5015,\n",
            "        1627.3882, 1627.3890, 1627.3217, 1627.5129, 1625.5388, 1626.8234,\n",
            "        1624.4375, 1627.5552, 1627.4103, 1627.6167, 1627.6057, 1627.1704,\n",
            "        1627.4430, 1627.5658, 1626.5958, 1627.0476], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([9.4993e-13, 1.8269e-01, 1.2583e-06, 1.7955e-06, 1.5304e-03, 7.1952e-03,\n",
            "        6.5439e-04, 2.3983e-03, 6.9524e-04, 9.2104e-04, 1.3247e-02, 7.9620e-05,\n",
            "        1.0938e-03, 1.6910e-02, 1.6710e-03, 9.8347e-03, 1.2739e-02, 1.5435e-05,\n",
            "        5.0872e-03, 3.5135e-03, 9.7868e-03, 1.5425e-03, 3.9273e-03, 6.1285e-05,\n",
            "        1.8911e-05, 1.1769e-03, 3.0830e-02, 6.8102e-05, 9.2931e-03, 1.4908e-02,\n",
            "        4.1191e-04, 4.2346e-02, 2.1304e-05, 6.1474e-04, 3.7763e-04, 1.1572e-05,\n",
            "        2.1481e-02, 4.7956e-06, 1.6960e-02, 1.8187e-05, 4.2742e-05, 3.2247e-02,\n",
            "        1.3297e-03, 3.5968e-03, 4.9888e-03, 6.9060e-03, 4.3605e-02, 9.9506e-03,\n",
            "        7.5394e-04, 2.2863e-03, 1.7893e-03, 1.8880e-03, 4.3848e-04, 3.5866e-09,\n",
            "        1.9028e-03, 9.4302e-03, 1.9556e-03, 4.7194e-02, 1.6697e-02, 1.1908e-03,\n",
            "        2.7717e-02, 6.2504e-04, 6.9524e-04, 5.6578e-04, 1.7808e-02, 1.5412e-02,\n",
            "        2.2933e-02, 4.8543e-03, 3.6392e-03, 3.1438e-02, 1.0205e-03, 7.3891e-08,\n",
            "        2.2317e-08, 8.6271e-04, 8.4551e-08, 1.9028e-03, 2.1272e-02, 1.6075e-01,\n",
            "        2.6311e-04, 1.8106e-02, 8.3197e-05, 6.9310e-05, 3.1675e-04, 6.7771e-05,\n",
            "        2.9299e-03, 4.1238e-03, 2.9418e-02, 2.1328e-04, 9.0207e-06, 6.7482e-14,\n",
            "        1.0539e-03, 2.7717e-02, 5.2020e-04, 7.2152e-04, 5.5809e-04],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [60]\n",
            "DEBUGGING: logits looks like: tensor([1625.2778, 1627.8761, 1626.6875, 1626.7230, 1627.3978, 1627.5526,\n",
            "        1627.3129, 1627.4427, 1627.3190, 1627.3470, 1627.6136, 1627.1023,\n",
            "        1627.3643, 1627.6381, 1627.4066, 1627.5839, 1627.6097, 1626.9382,\n",
            "        1627.5179, 1627.4810, 1627.5834, 1627.3987, 1627.4921, 1627.0760,\n",
            "        1626.9585, 1627.3716, 1627.6981, 1627.0867, 1627.5782, 1627.6255,\n",
            "        1627.2666, 1627.7299, 1626.9705, 1627.3066, 1627.2579, 1626.9094,\n",
            "        1627.6620, 1626.8213, 1627.6384, 1626.9546, 1627.0400, 1627.7026,\n",
            "        1627.3838, 1627.4833, 1627.5160, 1627.5486, 1627.7328, 1627.5851,\n",
            "        1627.3270, 1627.4380, 1627.4135, 1627.4188, 1627.2728, 1626.1014,\n",
            "        1627.4197, 1627.5797, 1627.4224, 1627.7407, 1627.6368, 1627.3728,\n",
            "        1627.6875, 1627.3083, 1627.3190, 1627.2983, 1627.6433, 1627.6288,\n",
            "        1627.6686, 1627.5133, 1627.4845, 1627.7001, 1627.3573, 1626.4041,\n",
            "        1626.2843, 1627.3406, 1626.4175, 1627.4197, 1627.6610, 1627.8633,\n",
            "        1627.2218, 1627.6449, 1627.1067, 1627.0884, 1627.2404, 1627.0862,\n",
            "        1627.4628, 1627.4969, 1627.6935, 1627.2008, 1626.8845, 1625.0134,\n",
            "        1627.3606, 1627.6875, 1627.2899, 1627.3226, 1627.2970],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([0.0056, 0.0156, 0.0051, 0.0023, 0.0117, 0.0062, 0.0121, 0.0040, 0.0034,\n",
            "        0.0023, 0.0078, 0.0260, 0.0056, 0.0065, 0.0002, 0.0234, 0.0046, 0.0004,\n",
            "        0.0061, 0.0061, 0.0042, 0.0140, 0.0211, 0.0078, 0.0038, 0.0077, 0.0069,\n",
            "        0.0042, 0.0016, 0.0176, 0.0091, 0.0070, 0.0036, 0.0027, 0.0163, 0.0039,\n",
            "        0.0116, 0.0213, 0.0084, 0.0038, 0.0067, 0.0144, 0.0031, 0.0051, 0.0072,\n",
            "        0.0052, 0.0100, 0.0064, 0.0065, 0.0034, 0.0085, 0.0128, 0.0389, 0.0060,\n",
            "        0.0059, 0.0041, 0.0187, 0.0122, 0.0120, 0.0111, 0.0101, 0.0046, 0.0183,\n",
            "        0.0090, 0.0135, 0.0140, 0.0042, 0.0141, 0.0094, 0.0022, 0.0066, 0.0064,\n",
            "        0.0183, 0.0070, 0.0009, 0.0063, 0.0155, 0.0084, 0.0046, 0.0117, 0.0031,\n",
            "        0.0069, 0.0003, 0.0005, 0.0263, 0.0140, 0.0113, 0.0053, 0.1090, 0.0095,\n",
            "        0.0106, 0.0085, 0.0055, 0.0075, 0.0006, 0.0037, 0.0045, 0.0094, 0.0126,\n",
            "        0.0053, 0.0028, 0.0034, 0.0070, 0.0006, 0.0118, 0.0051],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [84]\n",
            "DEBUGGING: logits looks like: tensor([1627.7499, 1627.8519, 1627.7401, 1627.6610, 1627.8226, 1627.7595,\n",
            "        1627.8267, 1627.7153, 1627.7008, 1627.6587, 1627.7817, 1627.9027,\n",
            "        1627.7493, 1627.7634, 1627.4365, 1627.8921, 1627.7305, 1627.4796,\n",
            "        1627.7581, 1627.7577, 1627.7205, 1627.8407, 1627.8817, 1627.7827,\n",
            "        1627.7107, 1627.7805, 1627.7708, 1627.7206, 1627.6240, 1627.8638,\n",
            "        1627.7977, 1627.7715, 1627.7053, 1627.6752, 1627.8560, 1627.7133,\n",
            "        1627.8218, 1627.8827, 1627.7902, 1627.7107, 1627.7678, 1627.8436,\n",
            "        1627.6909, 1627.7395, 1627.7745, 1627.7424, 1627.8075, 1627.7618,\n",
            "        1627.7649, 1627.6992, 1627.7904, 1627.8315, 1627.9430, 1627.7563,\n",
            "        1627.7552, 1627.7190, 1627.8698, 1627.8274, 1627.8251, 1627.8180,\n",
            "        1627.8079, 1627.7296, 1627.8674, 1627.7971, 1627.8370, 1627.8406,\n",
            "        1627.7206, 1627.8414, 1627.8013, 1627.6543, 1627.7664, 1627.7631,\n",
            "        1627.8679, 1627.7711, 1627.5623, 1627.7616, 1627.8512, 1627.7894,\n",
            "        1627.7303, 1627.8226, 1627.6886, 1627.7697, 1627.4584, 1627.5074,\n",
            "        1627.9041, 1627.8411, 1627.8192, 1627.7445, 1628.0461, 1627.8020,\n",
            "        1627.8127, 1627.7908, 1627.7483, 1627.7781, 1627.5225, 1627.7080,\n",
            "        1627.7279, 1627.8009, 1627.8306, 1627.7439, 1627.6782, 1627.6997,\n",
            "        1627.7714, 1627.5320, 1627.8237, 1627.7402], grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.1107232364297488 and immediate abs rewards look like: [0.01472099603006427, 0.003817258723302075, 0.013557903691435058, 0.050915616845031764, 0.0010659916206350317, 0.00026380521285318537, 0.00037323920469134464, 0.0003863044430545415, 9.747982630869956e-05, 0.00021180362227823935, 0.00015759947791593731, 0.0004204324927741254, 7.723554517724551e-06, 2.4567419131926727e-05, 0.0008040668981266208, 2.8111799110774882e-06, 0.00037549101125478046, 0.00010984167602146044, 0.0003893626749231771, 0.00017240640454474487, 0.0007256228445839952, 0.0010201746972597903, 9.373405055157491e-05, 0.0020084008688172617, 0.0002325082086827024, 8.173470450856257e-05, 0.0005985522598166426, 0.00013897863755119033, 0.00033393131798220566, 0.0009222872190548514, 3.860215747408802e-05, 0.001706372152966651, 0.0023771104688421474, 4.853323389397701e-05, 6.842891161795706e-05, 0.00010371271764597623, 0.00039373593108393834, 0.000549554507870198, 8.599367083661491e-05, 0.0001407773920618638, 0.0021925611599726835, 0.0021335877577257634, 0.00015932346195768332, 0.0015231004290399142, 0.0007896529882600589, 0.002748749709553522, 0.000649125706331688, 7.536768544014194e-05, 0.0001034591600728163, 0.0008048604095165501]\n",
            "DEBUGGING: the total relative reward of the trajectory = 38.2816760049957 and immediate relative rewards look like: [0.47467008632435814, 0.24734471417148557, 1.3193872283996286, 6.635653477983331, 0.17658812286986375, 0.05245969096218746, 0.08659929830242323, 0.1024477675670515, 0.029086782556694814, 0.07022404590084097, 0.05748180840754605, 0.16729508316355768, 0.0033298661562210902, 0.011406565323513258, 0.3999947600035417, 0.0014920909926523628, 0.211755918124567, 0.06559652703007168, 0.24545107319207635, 0.11441857008219704, 0.5056711930235359, 0.7449717243442141, 0.07158381970661827, 1.6005336418963743, 0.19313953725412397, 0.07061651576379602, 0.5370368358276753, 0.12933936024309112, 0.32188433263876465, 0.9197723313073616, 0.03979232719334918, 1.8157471667001182, 2.610005629658232, 0.054946484475590404, 0.07975105906130467, 0.12432921552546786, 0.4851325896942268, 0.6955125893728384, 0.11171750178904939, 0.18758385982884793, 2.9947357113019955, 2.9874460013790225, 0.22855855164991742, 2.2359062335493225, 1.1861562844541125, 4.221828975488937, 1.0196075621893301, 0.12092804237687796, 0.169463657964243, 1.345293791823549]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 150 number of matrices\n",
            "DEBUGGING: ACT_MAT has 150 number of matrices\n",
            "DEBUGGING: VAL looks like: [[43.45887817852826, 43.2927013509483, 42.95451804907734, 42.63057902097434, 43.03217853060855, 43.18042905069764, 42.314458503614, 42.60289119753985, 42.92356918414529, 43.297762238070845, 43.56763202351146, 43.71327588579361, 40.83737368100059, 39.12899607998551, 39.51012606100357, 39.77161648258271, 40.05919713138684, 39.913499105422254, 39.63791893645824, 37.184156884856584, 36.89250625121108, 36.71914713923432, 26.12763278353616, 23.428400889560876, 22.573567216513116, 15.402553463394895, 14.859510058225695, 14.807979734486366, 10.232207282825902, 9.750942623212662, 7.668380504675437, 7.062792540124418, 6.935444298795221, 6.818399785806008, 6.539330060876519, 6.016731994252436, 5.7852635280207645, 5.794504246461869, 4.673202336874112, 4.658258272039766, 3.446040080541652, 3.2746651613516393, 2.785591777238354, 2.129511674971803, 2.0925528365116137, 2.0045519110912133, 0.5579767702004235, 0.4425841811216083, 0.3328572623907154, 0.018353594896659605], [34.97526465786625, 34.723394764421016, 34.298652810160895, 33.88728079984661, 33.97144625898561, 31.45666160898563, 30.86935926702128, 29.940205106525415, 29.204344911223778, 19.55363156198336, 19.5316759845928, 19.235447367885264, 19.267673424204755, 19.17584420444899, 13.96161576606769, 13.121366924478343, 12.770083343491876, 11.017961138898258, 11.072169144449674, 11.117385788137893, 11.151728257079712, 11.250818427860388, 9.815435740899844, 8.974401578781906, 9.02684508944915, 8.830382761204698, 8.549960371194297, 7.815002926174925, 7.601148946781787, 6.693546029246228, 5.728795006874007, 5.075561729374014, 3.6820502399644592, 2.6727684204716775, 2.504774864645861, 2.265660186689585, 1.9909602103129858, 1.5299938005051128, 1.029682240206874, 1.0157592833174138, 0.9964224107567843, 1.0040464441603205, 1.003363383166071, 1.0077335381553836, 1.0115031314628309, 0.9499414755706724, 0.9316912505122192, 0.8360191607759475, 0.6699305181196578, 0.02988339604124925], [29.161411711031, 28.97650669162287, 29.019355532779176, 27.979765964019748, 21.559709581854964, 21.599112584833435, 21.7642958523952, 21.8966631859523, 22.014359008469945, 22.207345682740655, 22.360728926100823, 22.52853244211442, 22.58710844338471, 22.81189755275605, 23.030798977204586, 22.859398199192977, 23.0887940486872, 23.108119323800636, 23.2752755522935, 23.262448968789318, 23.38184888758295, 23.107250196524664, 22.588160072909545, 22.744016417376695, 21.357053308565984, 21.37769067809279, 21.522297133665653, 21.197232624078765, 21.28070026650068, 21.170521145315067, 20.455301832331017, 20.62172677286633, 18.99593899612749, 16.551447844918442, 16.663132687316015, 16.750890533590617, 16.79450638188399, 16.474114941605823, 15.93798217397271, 15.986125931498647, 15.958123304716969, 13.094330902439367, 10.208974647535703, 10.08122837968261, 7.924567824377058, 6.80647630295247, 2.6107548762257915, 1.6072195091277388, 1.5013045118695565, 1.345293791823549]]\n",
            "DEBUGGING: traj_returns = [43.45887817852826, 34.97526465786625, 29.161411711031]\n",
            "DEBUGGING: actions = [[17], [16], [59], [11], [59], [11], [58], [53], [60], [26], [65], [8], [8], [65], [48], [63], [59], [75], [62], [73], [63], [6], [17], [61], [64], [18], [61], [69], [58], [45], [84], [75], [69], [88], [60], [86], [63], [36], [69], [49], [25], [70], [41], [64], [62], [99], [62], [56], [67], [31], [17], [16], [59], [17], [55], [42], [16], [64], [42], [18], [14], [9], [11], [71], [71], [59], [66], [73], [72], [72], [20], [54], [78], [27], [54], [45], [78], [72], [66], [12], [51], [64], [65], [8], [47], [41], [37], [10], [43], [77], [80], [26], [12], [55], [55], [72], [105], [4], [78], [68], [12], [7], [39], [8], [12], [13], [3], [3], [3], [25], [36], [29], [22], [65], [15], [67], [14], [30], [78], [36], [77], [76], [21], [55], [76], [48], [48], [32], [59], [82], [68], [79], [76], [4], [4], [93], [31], [79], [61], [60], [31], [88], [64], [78], [81], [30], [28], [14], [93], [84]]\n",
            "DEBUGGING: actions length = 150\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[  7.7255,   8.3688,  13.4719,  ...,   4.5871, -14.5671, -22.2054],\n",
            "        [  7.6064,   8.2338,  13.2585,  ...,   4.5265, -14.3834, -21.9260],\n",
            "        [  7.5584,   8.1817,  13.1876,  ...,   4.4941, -14.2941, -21.7902],\n",
            "        ...,\n",
            "        [  7.6752,   8.3068,  13.3826,  ...,   4.5635, -14.4871, -22.0831],\n",
            "        [  7.6739,   8.3053,  13.3803,  ...,   4.5627, -14.4851, -22.0799],\n",
            "        [  7.6729,   8.3042,  13.3784,  ...,   4.5621, -14.4832, -22.0768]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[  7.6724,   8.3037,  13.3776,  ...,   4.5618, -14.4824, -22.0757],\n",
            "        [  7.6729,   8.3042,  13.3785,  ...,   4.5622, -14.4833, -22.0770],\n",
            "        [  7.6724,   8.3037,  13.3775,  ...,   4.5618, -14.4823, -22.0755],\n",
            "        ...,\n",
            "        [  7.6714,   8.3026,  13.3757,  ...,   4.5612, -14.4805, -22.0727],\n",
            "        [  7.6728,   8.3041,  13.3782,  ...,   4.5620, -14.4831, -22.0767],\n",
            "        [  7.6724,   8.3037,  13.3775,  ...,   4.5618, -14.4823, -22.0755]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([1627.7499, 1627.8519, 1627.7401, 1627.6610, 1627.8226, 1627.7595,\n",
            "        1627.8267, 1627.7153, 1627.7008, 1627.6587, 1627.7817, 1627.9027,\n",
            "        1627.7493, 1627.7634, 1627.4365, 1627.8921, 1627.7305, 1627.4796,\n",
            "        1627.7581, 1627.7577, 1627.7205, 1627.8407, 1627.8817, 1627.7827,\n",
            "        1627.7107, 1627.7805, 1627.7708, 1627.7206, 1627.6240, 1627.8638,\n",
            "        1627.7977, 1627.7715, 1627.7053, 1627.6752, 1627.8560, 1627.7133,\n",
            "        1627.8218, 1627.8827, 1627.7902, 1627.7107, 1627.7678, 1627.8436,\n",
            "        1627.6909, 1627.7395, 1627.7745, 1627.7424, 1627.8075, 1627.7618,\n",
            "        1627.7649, 1627.6992, 1627.7904, 1627.8315, 1627.9430, 1627.7563,\n",
            "        1627.7552, 1627.7190, 1627.8698, 1627.8274, 1627.8251, 1627.8180,\n",
            "        1627.8079, 1627.7296, 1627.8674, 1627.7971, 1627.8370, 1627.8406,\n",
            "        1627.7206, 1627.8414, 1627.8013, 1627.6543, 1627.7664, 1627.7631,\n",
            "        1627.8679, 1627.7711, 1627.5623, 1627.7616, 1627.8512, 1627.7894,\n",
            "        1627.7303, 1627.8226, 1627.6886, 1627.7697, 1627.4584, 1627.5074,\n",
            "        1627.9041, 1627.8411, 1627.8192, 1627.7445, 1628.0461, 1627.8020,\n",
            "        1627.8127, 1627.7908, 1627.7483, 1627.7781, 1627.5225, 1627.7080,\n",
            "        1627.7279, 1627.8009, 1627.8306, 1627.7439, 1627.6782, 1627.6997,\n",
            "        1627.7714, 1627.5320, 1627.8237, 1627.7402], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[35.86518485 35.66420094 35.42417546 34.83254193 32.85444479 32.07873441\n",
            "  31.64937121 31.47991983 31.3807577  28.35291316 28.48667898 28.49241857\n",
            "  27.56405185 27.03891261 25.50084693 25.25079387 25.30602484 24.67985986\n",
            "  24.66178788 23.85466388 23.80869447 23.69240525 19.51040953 18.38227296\n",
            "  17.65248854 15.2035423  14.97725585 14.60673843 13.03801883 12.5383366\n",
            "  11.28415911 10.92002701  9.87114451  8.68087202  8.5690792   8.34442757\n",
            "   8.19024337  7.932871    7.21362225  7.22004783  6.80019527  5.79101417\n",
            "   4.6659766   4.40615786  3.67620793  3.25365656  1.36680763  0.96194095\n",
            "   0.83469743  0.46451026]]\n",
            "DEBUGGING: baseline2 looks like: 35.86518484914183\n",
            "DEBUGGING: ADS looks like: [  7.59369333   7.62850042   7.53034259   7.79803709  10.17773374\n",
            "  11.10169464  10.6650873   11.12297137  11.54281148  14.94484908\n",
            "  15.08095305  15.22085732  13.27332183  12.09008347  14.00927913\n",
            "  14.52082261  14.75317229  15.23363925  14.97613106  13.329493\n",
            "  13.08381179  13.02674188   6.61722325   5.04612793   4.92107868\n",
            "   0.19901116  -0.1177458    0.20124131  -2.80581155  -2.78739398\n",
            "  -3.61577861  -3.85723447  -2.93570021  -1.86247223  -2.02974914\n",
            "  -2.32769558  -2.40497985  -2.13836675  -2.54041991  -2.56178956\n",
            "  -3.35415518  -2.51634901  -1.88038483  -2.27664619  -1.58365509\n",
            "  -1.24910465  -0.80883086  -0.51935677  -0.50184017  -0.44615667\n",
            "  -0.88992019  -0.94080617  -1.12552265  -0.94526113   1.11700147\n",
            "  -0.62207281  -0.78001194  -1.53971472  -2.17641279  -8.7992816\n",
            "  -8.95500299  -9.2569712   -8.29637843  -7.86306841 -11.53923117\n",
            " -12.12942694 -12.5359415  -13.66189872 -13.58961873 -12.73727809\n",
            " -12.65696621 -12.44158683  -9.69497379  -9.40787138  -8.62564345\n",
            "  -6.37315954  -6.42729548  -6.7917355   -5.43686989  -5.84479057\n",
            "  -5.55536411  -5.84446528  -6.18909427  -6.0081036   -6.06430434\n",
            "  -6.07876738  -6.19928316  -6.4028772   -6.18394001  -6.20428855\n",
            "  -5.80377285  -4.78696773  -3.66261322  -3.39842433  -2.6647048\n",
            "  -2.30371509  -0.43511638  -0.12592179  -0.16476691  -0.43462686\n",
            "  -6.70377314  -6.68769424  -6.40481993  -6.85277596 -11.29473521\n",
            " -10.47962183  -9.88507536  -9.58325664  -9.36639869  -6.14556748\n",
            "  -6.12595005  -5.96388612  -4.97694341  -4.22701506  -2.47004796\n",
            "  -2.39139567  -2.21723079  -1.57174053  -1.38651233  -0.59221491\n",
            "  -0.42684558  -0.58515506   3.07775054   4.36174346   3.70456477\n",
            "   6.17414838   6.54504128   6.5904942    8.24268143   8.63218455\n",
            "   9.17114272   9.70169976   9.12479448   7.87057583   8.09405348\n",
            "   8.40646296   8.60426301   8.54124395   8.72435992   8.7660781\n",
            "   9.15792804   7.30331673   5.54299804   5.67507052   4.24835989\n",
            "   3.55281974   1.24394724   0.64527856   0.66660708   0.88078353]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(-2.3684, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[ 0.3083,  0.2459, -0.0209,  ..., -0.3283, -0.3082,  0.5966],\n",
            "        [-0.1450, -0.1157,  0.0098,  ...,  0.1543,  0.1449, -0.2954],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [ 0.1131,  0.0902, -0.0077,  ..., -0.1204, -0.1131,  0.2138],\n",
            "        [ 0.2491,  0.1986, -0.0169,  ..., -0.2652, -0.2490,  0.4803],\n",
            "        [ 0.1187,  0.0947, -0.0080,  ..., -0.1263, -0.1186,  0.2367]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0903,  0.1474,  0.0722,  0.0000,  0.0000,  0.0000,  0.0000,  0.0951,\n",
            "          0.0000,  0.0000,  0.0849,  0.1273,  0.0485,  0.0000,  0.1202,  0.0000,\n",
            "          0.0721,  0.0000,  0.0495,  0.0000],\n",
            "        [ 0.0933,  0.1521,  0.0740,  0.0000,  0.0000,  0.0000,  0.0000,  0.0973,\n",
            "          0.0000,  0.0000,  0.0880,  0.1318,  0.0503,  0.0000,  0.1249,  0.0000,\n",
            "          0.0742,  0.0000,  0.0503,  0.0000],\n",
            "        [ 0.1472,  0.2399,  0.1161,  0.0000,  0.0000,  0.0000,  0.0000,  0.1523,\n",
            "          0.0000,  0.0000,  0.1390,  0.2084,  0.0797,  0.0000,  0.1978,  0.0000,\n",
            "          0.1167,  0.0000,  0.0780,  0.0000],\n",
            "        [-0.0964, -0.1571, -0.0762,  0.0000,  0.0000,  0.0000,  0.0000, -0.0997,\n",
            "          0.0000,  0.0000, -0.0910, -0.1365, -0.0522,  0.0000, -0.1297,  0.0000,\n",
            "         -0.0764,  0.0000, -0.0511,  0.0000],\n",
            "        [-0.1303, -0.2115, -0.0995,  0.0000,  0.0000,  0.0000,  0.0000, -0.1280,\n",
            "          0.0000,  0.0000, -0.1243, -0.1863, -0.0719,  0.0000, -0.1801,  0.0000,\n",
            "         -0.1008,  0.0000, -0.0631,  0.0000],\n",
            "        [-0.1717, -0.2794, -0.1342,  0.0000,  0.0000,  0.0000,  0.0000, -0.1752,\n",
            "          0.0000,  0.0000, -0.1623, -0.2433, -0.0933,  0.0000, -0.2325,  0.0000,\n",
            "         -0.1350,  0.0000, -0.0891,  0.0000],\n",
            "        [ 0.0815,  0.1324,  0.0627,  0.0000,  0.0000,  0.0000,  0.0000,  0.0811,\n",
            "          0.0000,  0.0000,  0.0775,  0.1161,  0.0447,  0.0000,  0.1119,  0.0000,\n",
            "          0.0634,  0.0000,  0.0404,  0.0000],\n",
            "        [ 0.0558,  0.0910,  0.0447,  0.0000,  0.0000,  0.0000,  0.0000,  0.0589,\n",
            "          0.0000,  0.0000,  0.0524,  0.0785,  0.0299,  0.0000,  0.0741,  0.0000,\n",
            "          0.0446,  0.0000,  0.0307,  0.0000],\n",
            "        [-0.1349, -0.2191, -0.1030,  0.0000,  0.0000,  0.0000,  0.0000, -0.1327,\n",
            "          0.0000,  0.0000, -0.1289, -0.1929, -0.0744,  0.0000, -0.1867,  0.0000,\n",
            "         -0.1045,  0.0000, -0.0652,  0.0000],\n",
            "        [-0.2073, -0.3366, -0.1583,  0.0000,  0.0000,  0.0000,  0.0000, -0.2037,\n",
            "          0.0000,  0.0000, -0.1975, -0.2958, -0.1144,  0.0000, -0.2864,  0.0000,\n",
            "         -0.1606,  0.0000, -0.1002,  0.0000]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-6.1971e-01, -5.3391e-01, -9.8053e-03,  ...,  7.9417e-02,\n",
            "         -3.7560e-01,  1.9859e-02],\n",
            "        [ 3.0658e-01,  2.6415e-01,  4.9008e-03,  ..., -3.9224e-02,\n",
            "          1.8583e-01,  6.7195e-03],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [-2.3415e-01, -2.0173e-01, -3.6885e-03,  ...,  3.0028e-02,\n",
            "         -1.4191e-01,  1.3257e-02],\n",
            "        [-5.1409e-01, -4.4291e-01, -8.1305e-03,  ...,  6.5883e-02,\n",
            "         -3.1158e-01,  1.8489e-02],\n",
            "        [-2.2346e-01, -1.9253e-01, -3.5597e-03,  ...,  2.8606e-02,\n",
            "         -1.3545e-01, -7.8132e-05]])\n",
            "   Last layer:\n",
            "tensor([[-1.1176e-02, -2.3728e-02, -1.9698e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -1.9193e-03,  0.0000e+00,  0.0000e+00,\n",
            "         -1.8821e-02, -3.2211e-02, -1.3882e-02,  0.0000e+00, -3.4614e-02,\n",
            "          0.0000e+00,  6.4665e-03,  0.0000e+00,  1.9101e-02,  0.0000e+00],\n",
            "        [ 1.0486e-03, -3.5453e-03, -8.8532e-03,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  1.5796e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -8.6752e-03, -1.7282e-02, -8.9373e-03,  0.0000e+00, -2.2684e-02,\n",
            "          0.0000e+00,  1.8866e-02,  0.0000e+00,  3.1417e-02,  0.0000e+00],\n",
            "        [-4.7908e-03, -1.6617e-02, -2.0458e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  1.6521e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -1.9713e-02, -3.6338e-02, -1.7498e-02,  0.0000e+00, -4.3941e-02,\n",
            "          0.0000e+00,  2.4455e-02,  0.0000e+00,  4.5228e-02,  0.0000e+00],\n",
            "        [ 3.3806e-03,  1.1517e-02,  1.3566e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -1.0423e-02,  0.0000e+00,  0.0000e+00,\n",
            "          1.3148e-02,  2.4197e-02,  1.1520e-02,  0.0000e+00,  2.8999e-02,\n",
            "          0.0000e+00, -1.5699e-02,  0.0000e+00, -2.9327e-02,  0.0000e+00],\n",
            "        [-2.3073e-02, -2.9645e-02, -5.2217e-03,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -5.5017e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -4.5641e-03,  2.9306e-04,  4.9562e-03,  0.0000e+00,  1.4066e-02,\n",
            "          0.0000e+00, -5.0756e-02,  0.0000e+00, -6.9914e-02,  0.0000e+00],\n",
            "        [-9.1883e-03, -5.0347e-03,  1.0711e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -4.0576e-02,  0.0000e+00,  0.0000e+00,\n",
            "          1.0783e-02,  2.4252e-02,  1.4230e-02,  0.0000e+00,  3.6807e-02,\n",
            "          0.0000e+00, -4.3528e-02,  0.0000e+00, -6.7643e-02,  0.0000e+00],\n",
            "        [ 1.0496e-02,  1.2276e-02, -5.4585e-05,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  2.8725e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -3.1651e-04, -4.5647e-03, -4.6274e-03,  0.0000e+00, -1.2409e-02,\n",
            "          0.0000e+00,  2.7676e-02,  0.0000e+00,  3.9556e-02,  0.0000e+00],\n",
            "        [-4.8168e-03, -1.1046e-02, -1.0007e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  1.2911e-03,  0.0000e+00,  0.0000e+00,\n",
            "         -9.5870e-03, -1.6753e-02, -7.4153e-03,  0.0000e+00, -1.8562e-02,\n",
            "          0.0000e+00,  5.4546e-03,  0.0000e+00,  1.2826e-02,  0.0000e+00],\n",
            "        [-2.2791e-02, -2.8898e-02, -4.2821e-03,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -5.5831e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -3.5540e-03,  1.9839e-03,  5.8130e-03,  0.0000e+00,  1.6151e-02,\n",
            "          0.0000e+00, -5.1837e-02,  0.0000e+00, -7.2000e-02,  0.0000e+00],\n",
            "        [-3.4450e-02, -4.3746e-02, -6.3024e-03,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -8.4539e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -5.3343e-03,  3.1399e-03,  8.8817e-03,  0.0000e+00,  2.4665e-02,\n",
            "          0.0000e+00, -7.8953e-02,  0.0000e+00, -1.0946e-01,  0.0000e+00]])\n",
            "DEBUGGING: training for one iteration takes 0.003299 min:\n",
            "==========================================================================================================\n",
            "Outer iteration no 19\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 0\n",
            "DEBUGGING: the action_prob is: tensor([4.1299e-41, 7.3587e-05, 3.7298e-04, 1.7311e-04, 1.6294e-04, 7.6945e-07,\n",
            "        2.1969e-04, 1.7552e-03, 1.7826e-04, 1.0815e-02, 1.3482e-04, 6.0413e-05,\n",
            "        3.3817e-06, 4.3605e-04, 1.8397e-02, 6.6740e-05, 6.6083e-19, 1.5074e-02,\n",
            "        2.4645e-06, 3.2856e-03, 1.2085e-04, 1.6931e-09, 7.3875e-05, 1.8938e-04,\n",
            "        1.7549e-04, 4.3520e-04, 6.1235e-06, 1.1241e-05, 1.7513e-05, 1.5397e-04,\n",
            "        9.1787e-03, 3.6292e-04, 1.1669e-03, 5.4129e-08, 5.4784e-06, 5.1495e-02,\n",
            "        6.0631e-07, 4.6796e-02, 2.1296e-03, 5.4595e-03, 3.5329e-14, 1.1078e-11,\n",
            "        1.5245e-05, 3.8947e-02, 1.0500e-04, 2.2568e-07, 2.9974e-03, 1.7722e-04,\n",
            "        1.1375e-04, 4.1440e-05, 3.1797e-13, 1.3118e-04, 2.8938e-03, 1.1028e-02,\n",
            "        2.9857e-03, 4.0093e-04, 8.3711e-05, 1.8536e-04, 3.4912e-02, 2.5135e-05,\n",
            "        4.3763e-06, 8.5722e-03, 1.9889e-03, 6.3847e-01, 7.1045e-05, 8.4571e-02,\n",
            "        3.8182e-04, 6.9681e-04, 1.2134e-03], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [63]\n",
            "DEBUGGING: logits looks like: tensor([1678.7836, 1687.1306, 1687.2930, 1687.2163, 1687.2102, 1686.6746,\n",
            "        1687.2400, 1687.4479, 1687.2191, 1687.6298, 1687.1912, 1687.1110,\n",
            "        1686.8226, 1687.3087, 1687.6829, 1687.1208, 1683.8964, 1687.6628,\n",
            "        1686.7910, 1687.5106, 1687.1803, 1686.0627, 1687.1311, 1687.2252,\n",
            "        1687.2177, 1687.3083, 1686.8821, 1686.9427, 1686.9872, 1687.2045,\n",
            "        1687.6133, 1687.2903, 1687.4070, 1686.4092, 1686.8708, 1687.7858,\n",
            "        1686.6508, 1687.7762, 1687.4673, 1687.5614, 1684.9850, 1685.5598,\n",
            "        1686.9733, 1687.7579, 1687.1663, 1686.5520, 1687.5015, 1687.2185,\n",
            "        1687.1742, 1687.0732, 1685.2047, 1687.1885, 1687.4978, 1687.6317,\n",
            "        1687.5011, 1687.3003, 1687.1437, 1687.2230, 1687.7469, 1687.0233,\n",
            "        1686.8485, 1687.6066, 1687.4604, 1688.0375, 1687.1272, 1687.8353,\n",
            "        1687.2953, 1687.3555, 1687.4110], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([2.2676e-41, 2.6236e-06, 7.9120e-04, 5.5768e-05, 5.2618e-02, 1.0240e-02,\n",
            "        1.4555e-02, 7.1769e-03, 3.5041e-04, 5.6003e-03, 2.1256e-03, 6.7675e-04,\n",
            "        4.0030e-02, 1.0666e-04, 3.0572e-02, 3.3251e-02, 1.1695e-02, 4.3707e-02,\n",
            "        2.6150e-02, 1.3226e-02, 3.6300e-03, 1.1926e-02, 1.0837e-02, 9.7906e-03,\n",
            "        3.5737e-03, 3.2354e-02, 1.3911e-04, 3.2480e-02, 1.4217e-02, 5.7443e-03,\n",
            "        1.0753e-02, 2.4949e-03, 2.2017e-03, 2.3575e-03, 1.7937e-02, 2.9168e-03,\n",
            "        3.4503e-03, 3.4301e-03, 5.6655e-04, 8.1963e-03, 1.7183e-02, 1.7935e-03,\n",
            "        3.6656e-03, 3.2083e-06, 1.6720e-02, 6.0083e-03, 9.7334e-03, 2.9286e-02,\n",
            "        6.2111e-03, 1.4498e-02, 1.1244e-04, 6.2598e-03, 4.5798e-03, 3.5528e-03,\n",
            "        2.1426e-02, 2.3810e-02, 5.8348e-03, 2.5296e-02, 1.0042e-02, 3.1358e-02,\n",
            "        1.9132e-02, 9.1258e-03, 2.7351e-02, 4.5435e-04, 5.3127e-03, 2.5341e-03,\n",
            "        2.5296e-02, 1.3278e-02, 5.3447e-02, 1.4813e-02, 2.4137e-02, 8.7079e-03,\n",
            "        1.6079e-02, 1.4134e-02, 2.1256e-03, 1.5164e-02, 5.6003e-03, 7.6100e-03,\n",
            "        4.9713e-03, 2.1426e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [12]\n",
            "DEBUGGING: logits looks like: tensor([1679.9049, 1687.9786, 1688.5494, 1688.2842, 1688.9691, 1688.8054,\n",
            "        1688.8406, 1688.7700, 1688.4680, 1688.7452, 1688.6482, 1688.5338,\n",
            "        1688.9419, 1688.3491, 1688.9149, 1688.9232, 1688.8188, 1688.9506,\n",
            "        1688.8992, 1688.8311, 1688.7018, 1688.8208, 1688.8112, 1688.8010,\n",
            "        1688.7003, 1688.9205, 1688.3756, 1688.9209, 1688.8383, 1688.7477,\n",
            "        1688.8103, 1688.6643, 1688.6519, 1688.6586, 1688.8616, 1688.6799,\n",
            "        1688.6967, 1688.6960, 1688.5160, 1688.7832, 1688.8572, 1688.6313,\n",
            "        1688.7028, 1687.9987, 1688.8546, 1688.7522, 1688.8004, 1688.9106,\n",
            "        1688.7555, 1688.8402, 1688.3542, 1688.7563, 1688.7251, 1688.6996,\n",
            "        1688.8794, 1688.8899, 1688.7493, 1688.8960, 1688.8036, 1688.9175,\n",
            "        1688.8680, 1688.7939, 1688.9037, 1688.4940, 1688.7399, 1688.6658,\n",
            "        1688.8960, 1688.8315, 1688.9707, 1688.8424, 1688.8912, 1688.7893,\n",
            "        1688.8507, 1688.8378, 1688.6483, 1688.8447, 1688.7452, 1688.7758,\n",
            "        1688.7332, 1688.8794], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.9087e-41, 7.0906e-03, 3.2027e-02, 1.4521e-02, 5.5438e-03, 1.0812e-02,\n",
            "        2.2933e-02, 1.1782e-02, 1.6811e-02, 3.0860e-02, 6.0649e-03, 1.3118e-02,\n",
            "        4.0243e-03, 7.2861e-04, 1.2014e-02, 1.0277e-02, 1.6073e-02, 1.5040e-02,\n",
            "        1.1509e-02, 6.8859e-03, 3.1464e-03, 4.8448e-03, 1.1265e-02, 1.0707e-02,\n",
            "        5.9476e-03, 2.1969e-02, 7.6668e-03, 7.7118e-03, 5.4154e-03, 1.0897e-02,\n",
            "        7.9256e-03, 1.8356e-02, 3.2463e-03, 8.4039e-03, 2.6812e-02, 1.7244e-02,\n",
            "        8.6876e-03, 1.4323e-02, 1.4408e-02, 5.0575e-03, 1.9010e-03, 9.3204e-03,\n",
            "        1.0078e-02, 9.0160e-03, 1.3195e-02, 1.7549e-02, 6.0886e-03, 6.4687e-03,\n",
            "        6.5322e-03, 1.0812e-02, 3.2851e-02, 1.6844e-02, 8.9284e-03, 3.5933e-03,\n",
            "        3.4355e-03, 4.5773e-04, 9.4119e-03, 1.1463e-03, 1.4379e-02, 2.2402e-02,\n",
            "        9.7868e-03, 9.5042e-03, 1.4046e-02, 6.0886e-03, 1.1622e-02, 1.4720e-02,\n",
            "        8.7386e-03, 1.6648e-02, 1.2204e-02, 9.1580e-03, 1.2348e-02, 8.7203e-04,\n",
            "        1.3377e-02, 1.1805e-02, 1.3694e-02, 2.3113e-02, 6.4813e-03, 1.0357e-02,\n",
            "        8.7728e-03, 7.0069e-04, 1.0603e-02, 1.1199e-02, 8.8416e-03, 1.7549e-02,\n",
            "        1.0117e-02, 9.6917e-03, 2.3523e-02, 1.1805e-02, 1.6073e-02],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [35]\n",
            "DEBUGGING: logits looks like: tensor([1680.7479, 1689.6289, 1689.7797, 1689.7007, 1689.6042, 1689.6711,\n",
            "        1689.7463, 1689.6798, 1689.7152, 1689.7760, 1689.6133, 1689.6904,\n",
            "        1689.5724, 1689.4015, 1689.6818, 1689.6661, 1689.7108, 1689.7042,\n",
            "        1689.6774, 1689.6261, 1689.5477, 1689.5909, 1689.6752, 1689.6702,\n",
            "        1689.6113, 1689.7419, 1689.6367, 1689.6373, 1689.6021, 1689.6719,\n",
            "        1689.6401, 1689.7240, 1689.5508, 1689.6459, 1689.7620, 1689.7179,\n",
            "        1689.6492, 1689.6992, 1689.6998, 1689.5952, 1689.4973, 1689.6562,\n",
            "        1689.6642, 1689.6530, 1689.6910, 1689.7195, 1689.6138, 1689.6198,\n",
            "        1689.6207, 1689.6711, 1689.7823, 1689.7155, 1689.6520, 1689.5610,\n",
            "        1689.5565, 1689.3549, 1689.6573, 1689.4468, 1689.6996, 1689.7439,\n",
            "        1689.6611, 1689.6583, 1689.6974, 1689.6138, 1689.6783, 1689.7019,\n",
            "        1689.6499, 1689.7142, 1689.6832, 1689.6545, 1689.6843, 1689.4194,\n",
            "        1689.6924, 1689.6799, 1689.6948, 1689.7472, 1689.6199, 1689.6667,\n",
            "        1689.6503, 1689.3975, 1689.6692, 1689.6746, 1689.6510, 1689.7196,\n",
            "        1689.6646, 1689.6602, 1689.7488, 1689.6799, 1689.7107],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([3.6647e-41, 1.3041e-02, 9.9988e-03, 3.2652e-03, 9.2835e-03, 1.3324e-02,\n",
            "        1.4748e-02, 1.0685e-02, 1.0685e-02, 1.0176e-02, 1.1464e-02, 1.0377e-02,\n",
            "        1.4128e-02, 8.8584e-03, 9.2835e-03, 8.9979e-03, 1.1920e-02, 1.1046e-02,\n",
            "        8.8067e-03, 5.9010e-03, 1.2037e-02, 1.3015e-02, 9.3017e-03, 1.2889e-02,\n",
            "        9.5223e-03, 9.5970e-03, 7.3726e-03, 8.0186e-03, 9.0862e-03, 8.1448e-03,\n",
            "        1.1851e-02, 8.1448e-03, 1.0499e-02, 1.2615e-02, 1.0458e-02, 1.2061e-02,\n",
            "        1.0156e-02, 1.1781e-02, 1.2155e-02, 8.1131e-03, 8.6363e-03, 9.2654e-03,\n",
            "        1.0982e-02, 9.4852e-03, 1.2061e-02, 6.0174e-03, 1.0176e-02, 1.3169e-02,\n",
            "        1.2764e-02, 9.2293e-03, 1.4981e-02, 8.7211e-03, 1.2061e-02, 7.8942e-03,\n",
            "        1.3613e-02, 8.1448e-03, 8.8757e-03, 9.6345e-03, 6.4055e-03, 9.6722e-03,\n",
            "        1.1154e-02, 1.0748e-02, 6.8720e-03, 9.2835e-03, 1.6778e-02, 1.0077e-02,\n",
            "        8.4693e-03, 9.2293e-03, 1.1758e-02, 1.3909e-02, 6.7260e-03, 1.0136e-02,\n",
            "        1.2155e-02, 1.3936e-02, 7.8328e-03, 9.8054e-03, 1.3015e-02, 8.6195e-03,\n",
            "        1.3774e-02, 9.9016e-03, 9.1396e-03, 1.1198e-02, 1.2864e-02, 6.9803e-03,\n",
            "        6.8720e-03, 1.3828e-02, 6.8586e-03, 9.2654e-03, 7.4160e-03, 8.6363e-03,\n",
            "        1.2419e-02, 1.2739e-02, 1.5246e-02, 1.1330e-02, 1.2347e-02, 1.2347e-02,\n",
            "        1.1735e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [37]\n",
            "DEBUGGING: logits looks like: tensor([1681.4116, 1690.2883, 1690.2617, 1690.1498, 1690.2543, 1690.2904,\n",
            "        1690.3005, 1690.2683, 1690.2684, 1690.2634, 1690.2755, 1690.2655,\n",
            "        1690.2963, 1690.2496, 1690.2543, 1690.2512, 1690.2793, 1690.2717,\n",
            "        1690.2490, 1690.2091, 1690.2803, 1690.2881, 1690.2545, 1690.2871,\n",
            "        1690.2568, 1690.2576, 1690.2312, 1690.2397, 1690.2522, 1690.2412,\n",
            "        1690.2787, 1690.2413, 1690.2667, 1690.2850, 1690.2662, 1690.2805,\n",
            "        1690.2633, 1690.2782, 1690.2814, 1690.2408, 1690.2472, 1690.2542,\n",
            "        1690.2711, 1690.2565, 1690.2805, 1690.2111, 1690.2634, 1690.2893,\n",
            "        1690.2863, 1690.2537, 1690.3021, 1690.2480, 1690.2805, 1690.2380,\n",
            "        1690.2926, 1690.2413, 1690.2499, 1690.2581, 1690.2172, 1690.2584,\n",
            "        1690.2727, 1690.2690, 1690.2242, 1690.2543, 1690.3135, 1690.2626,\n",
            "        1690.2451, 1690.2537, 1690.2780, 1690.2948, 1690.2222, 1690.2631,\n",
            "        1690.2812, 1690.2949, 1690.2374, 1690.2598, 1690.2881, 1690.2468,\n",
            "        1690.2937, 1690.2607, 1690.2528, 1690.2731, 1690.2870, 1690.2258,\n",
            "        1690.2242, 1690.2942, 1690.2241, 1690.2542, 1690.2318, 1690.2472,\n",
            "        1690.2834, 1690.2860, 1690.3040, 1690.2743, 1690.2828, 1690.2828,\n",
            "        1690.2778], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([8.9442e-40, 9.2431e-03, 9.4070e-03, 9.8392e-03, 9.4254e-03, 9.3887e-03,\n",
            "        9.6867e-03, 9.4808e-03, 9.2431e-03, 8.9587e-03, 9.3521e-03, 9.1533e-03,\n",
            "        9.4623e-03, 8.8026e-03, 9.6867e-03, 9.1712e-03, 9.5179e-03, 9.2431e-03,\n",
            "        9.1176e-03, 9.3156e-03, 9.2974e-03, 8.9238e-03, 9.2974e-03, 9.4808e-03,\n",
            "        9.3156e-03, 9.4808e-03, 9.3887e-03, 9.3887e-03, 9.4808e-03, 8.6662e-03,\n",
            "        9.3704e-03, 9.3156e-03, 8.8544e-03, 9.1712e-03, 9.5552e-03, 9.2071e-03,\n",
            "        9.2974e-03, 9.4254e-03, 9.3338e-03, 9.0290e-03, 9.3887e-03, 9.3156e-03,\n",
            "        9.0821e-03, 9.2612e-03, 9.2431e-03, 9.7246e-03, 9.1712e-03, 8.9938e-03,\n",
            "        9.4808e-03, 1.0271e-02, 9.1176e-03, 9.5365e-03, 9.3156e-03, 9.3338e-03,\n",
            "        9.4623e-03, 8.9938e-03, 9.4808e-03, 9.6301e-03, 9.3338e-03, 9.4808e-03,\n",
            "        9.4254e-03, 8.9238e-03, 9.1176e-03, 9.8778e-03, 9.2974e-03, 9.6113e-03,\n",
            "        9.1176e-03, 9.4623e-03, 9.1176e-03, 9.6113e-03, 9.2974e-03, 9.1712e-03,\n",
            "        9.5365e-03, 9.3887e-03, 9.8778e-03, 9.4254e-03, 9.0290e-03, 9.4808e-03,\n",
            "        9.3704e-03, 9.3156e-03, 1.0014e-02, 9.3156e-03, 9.4254e-03, 9.1533e-03,\n",
            "        8.8890e-03, 9.3887e-03, 9.6867e-03, 9.0821e-03, 9.2071e-03, 9.1712e-03,\n",
            "        9.2071e-03, 9.3521e-03, 9.8009e-03, 9.2071e-03, 9.3156e-03, 9.4808e-03,\n",
            "        9.2793e-03, 9.2251e-03, 9.4808e-03, 9.4808e-03, 8.9413e-03, 9.6301e-03,\n",
            "        9.8200e-03, 9.4070e-03, 9.2431e-03, 9.3887e-03, 9.4070e-03, 9.1533e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [50]\n",
            "DEBUGGING: logits looks like: tensor([1682.2758, 1690.7987, 1690.8004, 1690.8049, 1690.8007, 1690.8003,\n",
            "        1690.8033, 1690.8013, 1690.7987, 1690.7955, 1690.7999, 1690.7977,\n",
            "        1690.8010, 1690.7938, 1690.8033, 1690.7979, 1690.8015, 1690.7987,\n",
            "        1690.7974, 1690.7994, 1690.7993, 1690.7952, 1690.7993, 1690.8013,\n",
            "        1690.7994, 1690.8013, 1690.8003, 1690.8002, 1690.8013, 1690.7922,\n",
            "        1690.8000, 1690.7994, 1690.7944, 1690.7980, 1690.8020, 1690.7983,\n",
            "        1690.7993, 1690.8007, 1690.7997, 1690.7963, 1690.8003, 1690.7994,\n",
            "        1690.7969, 1690.7988, 1690.7987, 1690.8037, 1690.7980, 1690.7960,\n",
            "        1690.8011, 1690.8092, 1690.7974, 1690.8019, 1690.7994, 1690.7997,\n",
            "        1690.8010, 1690.7959, 1690.8013, 1690.8029, 1690.7997, 1690.8011,\n",
            "        1690.8007, 1690.7952, 1690.7974, 1690.8053, 1690.7993, 1690.8026,\n",
            "        1690.7974, 1690.8010, 1690.7974, 1690.8025, 1690.7993, 1690.7980,\n",
            "        1690.8019, 1690.8002, 1690.8053, 1690.8007, 1690.7963, 1690.8013,\n",
            "        1690.8000, 1690.7994, 1690.8066, 1690.7994, 1690.8007, 1690.7976,\n",
            "        1690.7947, 1690.8003, 1690.8033, 1690.7970, 1690.7982, 1690.7979,\n",
            "        1690.7983, 1690.7999, 1690.8046, 1690.7982, 1690.7994, 1690.8011,\n",
            "        1690.7991, 1690.7985, 1690.8013, 1690.8013, 1690.7953, 1690.8027,\n",
            "        1690.8048, 1690.8004, 1690.7987, 1690.8002, 1690.8004, 1690.7976],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.21216047718644404 and immediate abs rewards look like: [0.01569241746415173, 0.0026544313013801, 0.10759943206858225, 0.019995252120452278, 0.00573608452850749, 0.00621044158310724, 0.00405993843082797, 0.008208318932929615, 0.012417121149610466, 0.0008606550602507923, 0.005204951811947467, 0.011555571519920704, 0.00039971661772142397, 0.000649525501557946, 7.188249583123252e-06, 1.4748150988452835e-05, 2.4055742869677488e-05, 8.533219624951016e-05, 0.0011631346919784846, 0.0010432307692553877, 1.3343077853278373e-05, 0.000478729062479033, 0.00011405942836972827, 0.00035763540745392675, 0.0003229694891615509, 0.001594932102079838, 6.085566951696819e-05, 0.0017115801713316614, 0.0013512948023617355, 0.00026309156282877666, 0.00010100736744789174, 7.391529197775526e-05, 0.00021663001189153874, 0.0003178579913765134, 0.00020397066350597015, 0.00025708604789542733, 8.077933352979016e-05, 0.0003351619375280279, 0.00019017619047190237, 8.131825893542555e-05, 4.471323973120889e-05, 0.00024048358773143264, 2.0302720713516464e-06, 6.836731972725829e-05, 7.989783625816926e-07, 7.1994736572378315e-06, 4.969484280081815e-06, 7.811498448972998e-05, 4.647047717298847e-06, 1.2110388070141198e-06]\n",
            "DEBUGGING: the total relative reward of the trajectory = 34.96629961314224 and immediate relative rewards look like: [0.4350246587545607, 0.14781513930648982, 8.994349521901603, 2.29744559250896, 0.8286011225035386, 1.0783357724411915, 0.823908524772514, 1.9059749539513244, 3.2514144777130665, 0.2513100421632974, 1.6722425547340969, 4.056236552889147, 0.15251643395528683, 0.2669293219667846, 0.0031656963807041175, 0.006928086911878242, 0.012006746578410044, 0.045096843585617746, 0.6488662842586103, 0.6128163194329294, 0.008232435660930964, 0.30943341267253704, 0.07708588241871617, 0.252221514062281, 0.23728895626313162, 1.218800970744465, 0.04831541172534059, 1.4092366369428089, 1.152909947992105, 0.23229943215689972, 0.09216549265410627, 0.06962268855205082, 0.21043042262839773, 0.31813811985406387, 0.21017451324161987, 0.27249051280229825, 0.08800457317712852, 0.37501778983394846, 0.21841235104473672, 0.09579190908966012, 0.0539897306929798, 0.2974620852534011, 0.0025712857380781333, 0.08859906429167005, 0.0010589712794667706, 0.009754282528468206, 0.006879341230198691, 0.11043682102245227, 0.006706895084318836, 0.0017835157939680103]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 1\n",
            "DEBUGGING: the action_prob is: tensor([5.5832e-10, 5.4041e-06, 9.6193e-03, 4.2750e-06, 5.1698e-02, 5.8187e-08,\n",
            "        6.7386e-06, 8.5235e-02, 8.5543e-04, 4.9101e-07, 1.0381e-02, 3.6643e-05,\n",
            "        6.7813e-03, 1.0851e-06, 3.9153e-06, 2.0245e-02, 1.9272e-05, 1.7468e-09,\n",
            "        2.6612e-02, 2.5063e-11, 1.5429e-03, 1.7314e-03, 3.8918e-07, 1.5220e-03,\n",
            "        1.0836e-02, 1.0604e-03, 5.1072e-05, 3.6325e-11, 4.6698e-03, 7.0355e-05,\n",
            "        2.8939e-03, 3.5096e-06, 5.9370e-04, 1.9356e-02, 4.9605e-04, 3.6358e-05,\n",
            "        1.1266e-03, 9.7913e-02, 1.9619e-03, 4.1360e-05, 5.3539e-03, 5.0100e-03,\n",
            "        8.8777e-04, 9.6193e-03, 1.4047e-04, 3.2274e-05, 1.2089e-02, 3.4016e-06,\n",
            "        7.7596e-03, 2.7935e-04, 2.7506e-03, 4.1285e-04, 9.2689e-03, 2.1137e-01,\n",
            "        4.1615e-03, 2.0872e-07, 2.7834e-02, 4.9702e-04, 1.6982e-02, 1.3174e-02,\n",
            "        8.7362e-07, 4.5871e-05, 3.1422e-01, 3.0191e-07, 2.5774e-07, 6.6882e-04,\n",
            "        2.4457e-05], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [62]\n",
            "DEBUGGING: logits looks like: tensor([1679.6637, 1680.5814, 1681.3298, 1680.5580, 1681.4980, 1680.1284,\n",
            "        1680.6036, 1681.5481, 1681.0880, 1680.3416, 1681.3375, 1680.7728,\n",
            "        1681.2950, 1680.4210, 1680.5492, 1681.4044, 1680.7086, 1679.7777,\n",
            "        1681.4316, 1679.3533, 1681.1469, 1681.1584, 1680.3185, 1681.1456,\n",
            "        1681.3419, 1681.1095, 1680.8060, 1679.3904, 1681.2576, 1680.8381,\n",
            "        1681.2097, 1680.5383, 1681.0514, 1681.3999, 1681.0334, 1680.7721,\n",
            "        1681.1155, 1681.5620, 1681.1710, 1680.7849, 1681.2712, 1681.2646,\n",
            "        1681.0916, 1681.3298, 1680.9072, 1680.7601, 1681.3528, 1680.5352,\n",
            "        1681.3083, 1680.9761, 1681.2047, 1681.0150, 1681.3263, 1681.6389,\n",
            "        1681.2461, 1680.2561, 1681.4362, 1681.0336, 1681.3867, 1681.3615,\n",
            "        1680.3992, 1680.7953, 1681.6785, 1680.2931, 1680.2772, 1681.0632,\n",
            "        1680.7324], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.1160e-09, 1.2610e-02, 1.6673e-02, 1.2127e-02, 5.9809e-02, 1.0172e-02,\n",
            "        2.9263e-02, 9.2620e-03, 8.9946e-03, 1.4827e-03, 1.4975e-02, 1.1042e-02,\n",
            "        1.0850e-02, 1.5122e-02, 1.2660e-02, 1.4946e-02, 1.1893e-02, 9.2620e-03,\n",
            "        1.6608e-02, 3.3742e-03, 1.3582e-02, 2.0669e-02, 1.6804e-02, 1.4234e-02,\n",
            "        1.4317e-02, 8.9407e-04, 9.1363e-03, 7.4423e-03, 2.2609e-03, 1.2080e-02,\n",
            "        8.0470e-03, 1.3582e-02, 2.0429e-02, 2.1036e-02, 2.5623e-02, 5.2972e-04,\n",
            "        4.5228e-03, 4.6120e-03, 1.2784e-02, 3.1024e-03, 8.1737e-03, 9.8209e-03,\n",
            "        8.8725e-03, 3.7282e-02, 1.1663e-02, 4.7029e-03, 1.5941e-02, 1.5848e-02,\n",
            "        1.1663e-02, 1.0015e-02, 1.0578e-02, 1.1708e-02, 9.7636e-03, 7.9688e-03,\n",
            "        8.3187e-03, 8.8725e-03, 9.3165e-03, 1.1893e-02, 1.1963e-02, 1.4543e-02,\n",
            "        8.1418e-03, 1.7033e-03, 1.2056e-02, 3.8390e-02, 1.0192e-02, 7.3126e-03,\n",
            "        9.2620e-03, 1.5972e-02, 4.8428e-03, 1.5972e-02, 4.9778e-02, 1.4458e-02,\n",
            "        1.0828e-02, 6.9099e-03, 8.4497e-03, 8.8034e-03, 6.6842e-03, 5.7397e-03,\n",
            "        6.6582e-03, 1.2127e-02], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [1]\n",
            "DEBUGGING: logits looks like: tensor([1680.0737, 1681.6978, 1681.7257, 1681.6938, 1681.8534, 1681.6763,\n",
            "        1681.7819, 1681.6669, 1681.6639, 1681.4836, 1681.7148, 1681.6843,\n",
            "        1681.6827, 1681.7159, 1681.6981, 1681.7146, 1681.6919, 1681.6669,\n",
            "        1681.7252, 1681.5659, 1681.7051, 1681.7472, 1681.7263, 1681.7098,\n",
            "        1681.7104, 1681.4330, 1681.6655, 1681.6450, 1681.5258, 1681.6935,\n",
            "        1681.6528, 1681.7051, 1681.7458, 1681.7488, 1681.7686, 1681.3807,\n",
            "        1681.5951, 1681.5972, 1681.6990, 1681.5574, 1681.6543, 1681.6726,\n",
            "        1681.6626, 1681.8060, 1681.6898, 1681.5991, 1681.7211, 1681.7206,\n",
            "        1681.6898, 1681.6747, 1681.6802, 1681.6903, 1681.6721, 1681.6517,\n",
            "        1681.6560, 1681.6626, 1681.6675, 1681.6919, 1681.6925, 1681.7120,\n",
            "        1681.6539, 1681.4974, 1681.6932, 1681.8091, 1681.6764, 1681.6432,\n",
            "        1681.6667, 1681.7213, 1681.6021, 1681.7213, 1681.8351, 1681.7114,\n",
            "        1681.6824, 1681.6375, 1681.6576, 1681.6617, 1681.6343, 1681.6190,\n",
            "        1681.6339, 1681.6938], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.2372e-09, 2.6580e-02, 1.2122e-02, 8.4293e-03, 1.5900e-03, 8.4420e-06,\n",
            "        3.1817e-01, 3.0114e-03, 1.3600e-03, 2.6942e-03, 6.4504e-03, 1.2480e-03,\n",
            "        2.7259e-03, 2.2776e-03, 2.4179e-08, 5.7035e-03, 3.8223e-02, 1.2335e-03,\n",
            "        1.6088e-03, 1.4311e-02, 1.2977e-03, 1.7947e-03, 2.2996e-04, 7.4243e-03,\n",
            "        1.6182e-03, 2.0610e-05, 3.8511e-04, 4.8683e-04, 2.3545e-03, 1.1297e-03,\n",
            "        4.6363e-04, 1.6501e-03, 1.4055e-05, 8.9716e-04, 1.8514e-04, 7.0557e-04,\n",
            "        1.1862e-03, 6.2641e-03, 3.4402e-01, 3.1869e-03, 7.4814e-04, 3.4191e-03,\n",
            "        3.5207e-03, 4.8029e-03, 1.4879e-03, 6.8777e-05, 2.1950e-02, 3.0232e-03,\n",
            "        2.2072e-04, 5.3371e-03, 1.4337e-03, 1.9634e-03, 1.9182e-02, 4.6825e-03,\n",
            "        1.4337e-03, 5.0137e-03, 1.5172e-03, 5.8274e-03, 4.5466e-04, 1.7125e-03,\n",
            "        3.8813e-04, 6.6681e-03, 2.0139e-03, 3.3189e-06, 1.9749e-03, 2.3591e-03,\n",
            "        1.9749e-03, 4.5295e-03, 1.8772e-03, 3.9501e-04, 4.4768e-03, 1.3337e-03,\n",
            "        1.0127e-03, 1.9982e-03, 7.4087e-04, 1.5138e-05, 8.0748e-03, 2.8567e-03,\n",
            "        8.1859e-03, 1.4565e-02, 1.4763e-03, 3.8511e-04, 4.3306e-03, 6.8129e-03,\n",
            "        2.1438e-03, 2.6369e-03, 4.8880e-03, 1.0286e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [60]\n",
            "DEBUGGING: logits looks like: tensor([1680.5055, 1682.1938, 1682.1154, 1682.0789, 1681.9122, 1681.3883,\n",
            "        1682.4420, 1681.9760, 1681.8966, 1681.9648, 1682.0521, 1681.8879,\n",
            "        1681.9661, 1681.9480, 1680.8029, 1682.0398, 1682.2301, 1681.8867,\n",
            "        1681.9133, 1682.1318, 1681.8918, 1681.9242, 1681.7188, 1682.0662,\n",
            "        1681.9138, 1681.4775, 1681.7704, 1681.7937, 1681.9514, 1681.8779,\n",
            "        1681.7888, 1681.9158, 1681.4392, 1681.8549, 1681.6971, 1681.8309,\n",
            "        1681.8829, 1682.0493, 1682.4498, 1681.9817, 1681.8367, 1681.9886,\n",
            "        1681.9916, 1682.0227, 1681.9055, 1681.5981, 1682.1747, 1681.9764,\n",
            "        1681.7147, 1682.0333, 1681.9017, 1681.9332, 1682.1611, 1682.0201,\n",
            "        1681.9017, 1682.0270, 1681.9075, 1682.0420, 1681.7869, 1681.9196,\n",
            "        1681.7711, 1682.0554, 1681.9358, 1681.2949, 1681.9338, 1681.9515,\n",
            "        1681.9338, 1682.0168, 1681.9287, 1681.7729, 1682.0157, 1681.8947,\n",
            "        1681.8671, 1681.9351, 1681.8357, 1681.4467, 1682.0746, 1681.9707,\n",
            "        1682.0760, 1682.1335, 1681.9048, 1681.7704, 1682.0123, 1682.0576,\n",
            "        1681.9420, 1681.9626, 1682.0245, 1681.8687], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.4888e-08, 1.2162e-02, 1.3384e-02, 1.2426e-02, 1.0546e-02, 1.9857e-02,\n",
            "        8.3101e-03, 7.7157e-03, 1.0945e-02, 1.1139e-02, 1.2426e-02, 1.1788e-02,\n",
            "        1.1161e-02, 1.0796e-02, 1.0505e-02, 7.4201e-03, 1.0754e-02, 1.2068e-02,\n",
            "        1.4415e-02, 1.0650e-02, 4.5447e-03, 1.2548e-02, 1.1161e-02, 9.5462e-03,\n",
            "        1.0505e-02, 1.1950e-02, 6.5996e-03, 1.0302e-02, 1.1560e-02, 1.1139e-02,\n",
            "        8.7944e-03, 8.5739e-03, 1.0629e-02, 1.0546e-02, 1.1292e-02, 1.2021e-02,\n",
            "        7.6407e-03, 1.1336e-02, 9.9265e-03, 1.1095e-02, 1.2426e-02, 9.4535e-03,\n",
            "        1.1974e-02, 1.3254e-02, 9.9265e-03, 9.2706e-03, 3.3445e-03, 9.2345e-03,\n",
            "        1.2021e-02, 1.3280e-02, 1.1292e-02, 7.8679e-03, 1.1052e-02, 1.0526e-02,\n",
            "        9.0559e-03, 1.0302e-02, 9.3799e-03, 1.3594e-02, 1.1381e-02, 8.3426e-03,\n",
            "        3.9101e-03, 1.0587e-02, 1.1270e-02, 1.0838e-02, 1.1139e-02, 1.0838e-02,\n",
            "        1.1052e-02, 1.3254e-02, 1.2696e-02, 9.7345e-03, 8.4906e-03, 9.2706e-03,\n",
            "        1.0282e-02, 7.1358e-03, 7.7914e-03, 1.1359e-02, 8.3264e-03, 9.7155e-03,\n",
            "        1.0526e-02, 6.9163e-03, 1.0733e-02, 9.8300e-03, 1.2622e-02, 4.4655e-03,\n",
            "        9.2887e-03, 1.1448e-02, 1.1052e-02, 1.2138e-02, 8.1176e-03, 1.1583e-02,\n",
            "        1.9664e-02, 1.5894e-02, 8.3753e-03, 1.2068e-02, 1.0817e-02, 9.1985e-03,\n",
            "        4.1861e-04], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [38]\n",
            "DEBUGGING: logits looks like: tensor([1680.8121, 1682.1735, 1682.1831, 1682.1757, 1682.1593, 1682.2224,\n",
            "        1682.1354, 1682.1281, 1682.1628, 1682.1647, 1682.1757, 1682.1704,\n",
            "        1682.1648, 1682.1615, 1682.1588, 1682.1240, 1682.1613, 1682.1726,\n",
            "        1682.1906, 1682.1602, 1682.0751, 1682.1766, 1682.1648, 1682.1493,\n",
            "        1682.1588, 1682.1718, 1682.1124, 1682.1569, 1682.1685, 1682.1647,\n",
            "        1682.1411, 1682.1384, 1682.1600, 1682.1593, 1682.1660, 1682.1724,\n",
            "        1682.1271, 1682.1665, 1682.1532, 1682.1643, 1682.1757, 1682.1482,\n",
            "        1682.1719, 1682.1821, 1682.1531, 1682.1464, 1682.0443, 1682.1459,\n",
            "        1682.1724, 1682.1823, 1682.1660, 1682.1300, 1682.1638, 1682.1589,\n",
            "        1682.1440, 1682.1569, 1682.1476, 1682.1847, 1682.1669, 1682.1357,\n",
            "        1682.0599, 1682.1597, 1682.1659, 1682.1620, 1682.1647, 1682.1620,\n",
            "        1682.1639, 1682.1820, 1682.1777, 1682.1512, 1682.1376, 1682.1464,\n",
            "        1682.1566, 1682.1201, 1682.1289, 1682.1666, 1682.1356, 1682.1510,\n",
            "        1682.1591, 1682.1169, 1682.1610, 1682.1521, 1682.1771, 1682.0732,\n",
            "        1682.1465, 1682.1675, 1682.1638, 1682.1733, 1682.1331, 1682.1686,\n",
            "        1682.2214, 1682.2003, 1682.1362, 1682.1726, 1682.1617, 1682.1455,\n",
            "        1681.8365], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([9.9762e-09, 1.2234e-02, 7.5224e-03, 7.8068e-03, 2.0408e-02, 8.1020e-03,\n",
            "        1.3568e-02, 8.5909e-03, 7.0529e-03, 8.9331e-03, 8.5241e-03, 1.3125e-02,\n",
            "        8.2941e-03, 8.2457e-03, 9.0032e-03, 7.5814e-03, 9.0032e-03, 6.6906e-03,\n",
            "        8.8983e-03, 6.1277e-03, 9.9074e-03, 1.0363e-02, 1.0650e-02, 6.4848e-03,\n",
            "        1.2972e-02, 1.2475e-02, 1.0712e-02, 5.6782e-03, 8.8636e-03, 1.7524e-02,\n",
            "        7.5814e-03, 8.0233e-03, 1.0182e-02, 5.6782e-03, 1.1628e-02, 1.0988e-02,\n",
            "        1.2573e-02, 8.3755e-03, 8.4412e-03, 9.8303e-03, 1.2672e-02, 9.2709e-03,\n",
            "        6.3098e-03, 7.7612e-03, 9.0032e-03, 8.3755e-03, 7.2202e-03, 3.8421e-03,\n",
            "        1.1904e-02, 8.1337e-03, 1.0383e-02, 7.7310e-03, 8.7262e-03, 1.1834e-02,\n",
            "        9.6779e-03, 1.0629e-02, 5.7452e-03, 8.1975e-03, 9.3618e-03, 1.5770e-02,\n",
            "        8.4577e-03, 1.2871e-02, 9.4907e-03, 8.4908e-03, 1.3306e-02, 1.1719e-02,\n",
            "        9.4537e-03, 7.0529e-03, 9.4537e-03, 1.0464e-02, 7.8989e-03, 8.8636e-03,\n",
            "        7.2061e-03, 8.5741e-03, 9.5465e-03, 8.1178e-03, 9.9074e-03, 6.9707e-03,\n",
            "        9.1628e-03, 7.3626e-03, 7.4639e-03, 1.4081e-02, 7.2343e-03, 7.5814e-03,\n",
            "        7.8527e-03, 9.9656e-03, 1.1270e-02, 9.0915e-03, 7.9298e-03, 8.6583e-03,\n",
            "        1.0546e-02, 1.1765e-02, 2.1895e-02, 7.7764e-03, 7.9764e-03, 9.0384e-03,\n",
            "        8.3592e-03, 6.9844e-03, 7.9920e-03, 8.1655e-03, 8.6583e-03, 7.4058e-03,\n",
            "        6.7563e-03, 7.7008e-03, 8.1496e-03, 6.9707e-03, 8.0389e-03, 9.1271e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [70]\n",
            "DEBUGGING: logits looks like: tensor([1681.0784, 1682.4803, 1682.4318, 1682.4353, 1682.5315, 1682.4391,\n",
            "        1682.4907, 1682.4449, 1682.4252, 1682.4489, 1682.4442, 1682.4874,\n",
            "        1682.4414, 1682.4409, 1682.4496, 1682.4324, 1682.4496, 1682.4200,\n",
            "        1682.4485, 1682.4111, 1682.4592, 1682.4636, 1682.4664, 1682.4169,\n",
            "        1682.4862, 1682.4822, 1682.4670, 1682.4036, 1682.4481, 1682.5162,\n",
            "        1682.4325, 1682.4381, 1682.4619, 1682.4036, 1682.4752, 1682.4696,\n",
            "        1682.4830, 1682.4424, 1682.4431, 1682.4584, 1682.4839, 1682.4525,\n",
            "        1682.4142, 1682.4348, 1682.4496, 1682.4424, 1682.4275, 1682.3645,\n",
            "        1682.4775, 1682.4395, 1682.4639, 1682.4344, 1682.4465, 1682.4771,\n",
            "        1682.4569, 1682.4663, 1682.4048, 1682.4403, 1682.4536, 1682.5056,\n",
            "        1682.4435, 1682.4855, 1682.4550, 1682.4438, 1682.4886, 1682.4761,\n",
            "        1682.4546, 1682.4252, 1682.4546, 1682.4647, 1682.4365, 1682.4481,\n",
            "        1682.4274, 1682.4447, 1682.4554, 1682.4393, 1682.4592, 1682.4241,\n",
            "        1682.4514, 1682.4294, 1682.4309, 1682.4944, 1682.4277, 1682.4325,\n",
            "        1682.4359, 1682.4597, 1682.4722, 1682.4507, 1682.4370, 1682.4458,\n",
            "        1682.4655, 1682.4763, 1682.5385, 1682.4349, 1682.4375, 1682.4501,\n",
            "        1682.4421, 1682.4243, 1682.4377, 1682.4398, 1682.4458, 1682.4301,\n",
            "        1682.4210, 1682.4340, 1682.4397, 1682.4241, 1682.4382, 1682.4509],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.12201641513638606 and immediate abs rewards look like: [0.04164546393121782, 0.0025865620191325434, 0.035761963975801336, 0.0004704418242909014, 0.0020335368740234117, 0.01139824711071924, 0.003797492238390987, 0.00012642984665944823, 0.00040804581203701673, 0.001887899713437946, 0.0012215698875479575, 0.0009346254964839318, 0.0036014232609886676, 0.0011310367103760655, 0.00015796775505805272, 0.00028228492146809003, 0.0003882995761159691, 0.0009833766480369377, 0.0010486908527127525, 0.00011153022569487803, 0.00016892449821170885, 0.002660787994045677, 6.843036226200638e-05, 0.00012993625932722352, 7.141592914194916e-05, 6.817367693656706e-05, 0.0005267450446808652, 0.003854320906157227, 0.00044062970528102596, 1.6765776763350004e-05, 0.0007670959862480231, 7.705968982918421e-05, 0.00021384104729804676, 1.5121100659598596e-05, 0.00028213776249685907, 0.0005009436754335184, 0.00033560557130840607, 0.0006397247238965065, 0.0003893908783538791, 6.0834400755993556e-05, 1.833534952311311e-06, 2.2821989659860265e-05, 4.467811322683701e-06, 0.0001532988148937875, 0.0004957513901899802, 4.366354187368415e-05, 8.505457117280457e-06, 1.5116414488147711e-05, 4.477223683352349e-06, 1.7052889234037139e-06]\n",
            "DEBUGGING: the total relative reward of the trajectory = 21.59876658079299 and immediate relative rewards look like: [1.123044343965312, 0.1410870022492018, 2.9280817975307842, 0.0518640180452676, 0.2802712906354826, 1.886207140277233, 0.7354657176591788, 0.02801325889820569, 0.10171632924510042, 0.5229585298771419, 0.37241443973374033, 0.31094346754790536, 1.2983525442771255, 0.43955559600392086, 0.06579685842301067, 0.12542155080444958, 0.18332191534793668, 0.4916293245847711, 0.5535605068396001, 0.06198878773818071, 0.09858616201924436, 1.626886927024242, 0.04377461835261444, 0.08673523523128372, 0.04965977575565677, 0.049302432555152195, 0.395594950685391, 3.0023136091796117, 0.3558671063354319, 0.014009231364169141, 0.6623427792426558, 0.06869757986359842, 0.19659774804721666, 0.014323914552910644, 0.2751252764610015, 0.5024892422855071, 0.34604045860480015, 0.6775063097065723, 0.4233157532805921, 0.0678375910590473, 0.0020957602900180854, 0.026722160852648558, 0.005355929137638718, 0.18804576509310353, 0.6219666509021664, 0.05600508592427528, 0.011146832607396562, 0.02023238223213228, 0.006117355156351321, 0.002377537307009269]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Running trajectories: 2\n",
            "DEBUGGING: the action_prob is: tensor([1.2226e-28, 1.4705e-34, 0.0000e+00, 1.7305e-16, 4.7205e-32, 4.9136e-12,\n",
            "        1.0803e-06, 7.6377e-01, 8.5900e-12, 1.8122e-08, 1.5835e-43, 7.9971e-07,\n",
            "        4.6850e-04, 1.3165e-03, 5.4079e-11, 4.4934e-09, 7.8412e-08, 1.6311e-07,\n",
            "        1.2455e-08, 5.0384e-14, 1.0727e-14, 7.8743e-06, 4.1952e-11, 6.8516e-09,\n",
            "        1.1012e-09, 2.7107e-06, 7.2684e-19, 3.7426e-17, 2.5274e-17, 1.9486e-06,\n",
            "        1.2724e-09, 4.3466e-09, 3.8146e-07, 1.8878e-09, 1.3441e-08, 7.0819e-10,\n",
            "        3.1111e-12, 2.2995e-09, 1.6788e-10, 6.7780e-29, 2.8094e-15, 1.7687e-14,\n",
            "        8.9335e-11, 1.5683e-08, 5.2336e-08, 8.6119e-08, 2.0868e-18, 8.1560e-06,\n",
            "        1.6755e-10, 4.8527e-04, 3.9511e-07, 2.1245e-16, 7.3463e-13, 5.0453e-18,\n",
            "        6.4143e-06, 1.5814e-18, 1.5529e-09, 6.1639e-11, 1.3599e-08, 3.6296e-13,\n",
            "        7.2651e-09, 8.5027e-15, 1.4165e-23, 1.5094e-03, 2.3067e-01, 1.7441e-03,\n",
            "        1.1168e-06, 1.2204e-27, 1.4705e-34, 6.0194e-26],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [7]\n",
            "DEBUGGING: logits looks like: tensor([1686.6942, 1685.3311, 1679.4756, 1689.4919, 1685.9082, 1690.5175,\n",
            "        1691.7476, 1693.0944, 1690.5734, 1691.3387, 1683.2661, 1691.7174,\n",
            "        1692.3547, 1692.4581, 1690.7572, 1691.1993, 1691.4852, 1691.5585,\n",
            "        1691.3011, 1690.0594, 1689.9048, 1691.9460, 1690.7318, 1691.2415,\n",
            "        1691.0586, 1691.8395, 1688.9447, 1689.3390, 1689.2996, 1691.8064,\n",
            "        1691.0731, 1691.1959, 1691.6434, 1691.1125, 1691.3088, 1691.0144,\n",
            "        1690.4718, 1691.1323, 1690.8706, 1686.6351, 1689.7708, 1689.9547,\n",
            "        1690.8075, 1691.3242, 1691.4448, 1691.4946, 1689.0502, 1691.9497,\n",
            "        1690.8704, 1692.3582, 1691.6469, 1689.5126, 1690.3274, 1689.1385,\n",
            "        1691.9255, 1689.0226, 1691.0930, 1690.7704, 1691.3099, 1690.2568,\n",
            "        1691.2473, 1689.8815, 1687.8602, 1692.4718, 1692.9747, 1692.4861,\n",
            "        1691.7509, 1686.9243, 1685.3312, 1687.3141], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([1.6239e-30, 4.1699e-32, 4.2228e-13, 3.2793e-06, 1.8305e-13, 1.5796e-06,\n",
            "        1.8982e-05, 2.6979e-05, 1.2970e-05, 9.1091e-05, 3.5811e-05, 3.9337e-17,\n",
            "        3.1221e-08, 7.8420e-14, 2.0804e-06, 4.4474e-06, 2.8050e-06, 4.5687e-09,\n",
            "        8.2456e-18, 1.8979e-06, 3.3556e-09, 1.2201e-09, 2.0602e-06, 4.0831e-16,\n",
            "        1.4839e-06, 2.8975e-11, 4.5440e-06, 9.6908e-09, 6.9968e-06, 1.5159e-07,\n",
            "        1.4832e-09, 1.8293e-04, 2.9001e-05, 8.6399e-06, 1.2159e-06, 3.6157e-06,\n",
            "        3.0448e-06, 2.0282e-06, 2.9272e-08, 3.0161e-04, 2.6240e-08, 1.1777e-10,\n",
            "        7.6845e-06, 3.4590e-15, 2.2478e-11, 7.4829e-14, 2.2269e-08, 9.9908e-01,\n",
            "        5.0283e-08, 8.3577e-06, 1.4969e-13, 3.7457e-05, 1.1623e-07, 3.8920e-10,\n",
            "        3.9771e-09, 3.9837e-11, 4.1523e-08, 4.6420e-07, 1.1668e-07, 2.1937e-17,\n",
            "        1.3442e-14, 5.6544e-33, 6.8040e-10, 1.5248e-07, 1.5370e-06, 8.2133e-05,\n",
            "        5.6331e-06, 1.5798e-05, 2.0845e-06, 1.2080e-10, 2.2532e-21, 1.7813e-12,\n",
            "        2.8427e-08, 5.7503e-12, 2.7727e-18, 5.3389e-12, 5.6331e-06],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [47]\n",
            "DEBUGGING: logits looks like: tensor([1688.6434, 1688.2771, 1692.6534, 1694.2399, 1692.5698, 1694.1667,\n",
            "        1694.4154, 1694.4506, 1694.3773, 1694.5724, 1694.4790, 1691.7252,\n",
            "        1693.7745, 1692.4850, 1694.1945, 1694.2704, 1694.2242, 1693.5823,\n",
            "        1691.5690, 1694.1852, 1693.5514, 1693.4502, 1694.1935, 1691.9592,\n",
            "        1694.1606, 1693.0762, 1694.2726, 1693.6575, 1694.3157, 1693.9325,\n",
            "        1693.4697, 1694.6420, 1694.4579, 1694.3367, 1694.1406, 1694.2496,\n",
            "        1694.2325, 1694.1919, 1693.7679, 1694.6920, 1693.7571, 1693.2164,\n",
            "        1694.3250, 1692.1729, 1693.0508, 1692.4802, 1693.7407, 1695.5026,\n",
            "        1693.8220, 1694.3335, 1692.5497, 1694.4834, 1693.9059, 1693.3361,\n",
            "        1693.5685, 1693.1080, 1693.8030, 1694.0443, 1693.9062, 1691.6667,\n",
            "        1692.3087, 1688.0774, 1693.3918, 1693.9330, 1694.1642, 1694.5619,\n",
            "        1694.2941, 1694.3971, 1694.1946, 1693.2190, 1690.7484, 1692.7972,\n",
            "        1693.7650, 1692.9146, 1691.4601, 1692.9070, 1694.2941],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([3.7563e-32, 1.5553e-12, 0.0000e+00, 1.1105e-05, 7.4322e-14, 1.5243e-03,\n",
            "        4.7220e-04, 3.3109e-01, 3.4073e-05, 1.7679e-04, 1.4146e-06, 4.9117e-41,\n",
            "        1.3158e-07, 2.1194e-06, 1.8561e-05, 2.8015e-08, 1.4152e-03, 2.1364e-05,\n",
            "        4.4539e-03, 1.3425e-03, 4.2910e-04, 1.4843e-11, 1.5658e-06, 1.7002e-04,\n",
            "        7.2971e-06, 3.9070e-04, 7.2971e-06, 5.2678e-04, 4.3143e-07, 3.6314e-10,\n",
            "        1.2705e-06, 1.1341e-08, 1.8584e-10, 3.0483e-05, 1.2801e-08, 1.6385e-03,\n",
            "        7.6175e-06, 3.3353e-04, 8.9594e-05, 3.1693e-06, 9.9755e-05, 8.9218e-07,\n",
            "        3.5643e-04, 1.4810e-13, 2.2599e-08, 6.1725e-02, 1.2599e-10, 7.0049e-05,\n",
            "        1.7374e-03, 1.2013e-02, 2.5762e-07, 2.0175e-09, 5.3187e-05, 1.9148e-06,\n",
            "        1.2189e-09, 2.6796e-05, 2.9549e-04, 1.2151e-04, 3.3610e-05, 2.5222e-05,\n",
            "        1.0238e-13, 3.5505e-17, 1.7442e-03, 3.0369e-04, 4.4794e-04, 7.3864e-03,\n",
            "        7.8628e-03, 9.0664e-04, 1.0581e-02, 3.0958e-06, 1.0292e-04, 7.0461e-05,\n",
            "        1.5746e-08, 1.5029e-06, 6.7894e-05, 2.4690e-04, 5.2781e-04, 8.9232e-06,\n",
            "        1.0052e-05, 1.1821e-05, 5.5747e-04, 1.1598e-02, 3.4340e-05, 4.2660e-04,\n",
            "        3.1465e-02, 1.7762e-25, 1.7379e-01, 3.3109e-01],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [87]\n",
            "DEBUGGING: logits looks like: tensor([1689.7335, 1694.2504, 1682.7552, 1695.8286, 1693.9463, 1696.3208,\n",
            "        1696.2036, 1696.8589, 1695.9407, 1696.1053, 1695.6226, 1687.6879,\n",
            "        1695.3850, 1695.6630, 1695.8799, 1695.2303, 1696.3132, 1695.8939,\n",
            "        1696.4280, 1696.3080, 1696.1940, 1694.4761, 1695.6327, 1696.1014,\n",
            "        1695.7865, 1696.1846, 1695.7865, 1696.2145, 1695.5037, 1694.7958,\n",
            "        1695.6118, 1695.1399, 1694.7288, 1695.9294, 1695.1520, 1696.3280,\n",
            "        1695.7908, 1696.1687, 1696.0374, 1695.7032, 1696.0481, 1695.5764,\n",
            "        1696.1754, 1694.0153, 1695.2087, 1696.6908, 1694.6899, 1696.0127,\n",
            "        1696.3337, 1696.5272, 1695.4523, 1694.9673, 1695.9851, 1695.6527,\n",
            "        1694.9167, 1695.9166, 1696.1567, 1696.0677, 1695.9392, 1695.9105,\n",
            "        1693.9783, 1693.1818, 1696.3342, 1696.1594, 1696.1982, 1696.4786,\n",
            "        1696.4847, 1696.2688, 1696.5145, 1695.7008, 1696.0513, 1696.0133,\n",
            "        1695.1726, 1695.6285, 1696.0095, 1696.1387, 1696.2147, 1695.8068,\n",
            "        1695.8186, 1695.8348, 1696.2202, 1696.5237, 1695.9415, 1696.1935,\n",
            "        1696.6235, 1691.2704, 1696.7944, 1696.8589], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([6.7833e-28, 1.0734e-14, 9.4959e-38, 1.3518e-13, 1.0892e-08, 2.4317e-05,\n",
            "        2.3242e-07, 5.8369e-01, 2.9691e-02, 2.3431e-05, 4.2794e-13, 5.7404e-08,\n",
            "        1.1095e-02, 2.4748e-05, 2.4995e-04, 2.6812e-05, 9.4132e-05, 9.3021e-06,\n",
            "        9.8088e-04, 1.9274e-05, 2.5263e-11, 4.9821e-15, 1.5909e-08, 1.6761e-12,\n",
            "        5.6319e-05, 1.6377e-10, 5.3950e-05, 1.2273e-06, 2.9500e-19, 4.3664e-09,\n",
            "        2.2622e-05, 3.7348e-09, 3.1782e-04, 9.7427e-10, 3.2143e-07, 2.2228e-05,\n",
            "        2.6452e-04, 3.3771e-03, 1.8248e-05, 1.9274e-05, 6.8620e-03, 2.0437e-05,\n",
            "        8.2798e-14, 1.4019e-05, 3.2477e-03, 1.6963e-10, 2.9336e-04, 3.8929e-06,\n",
            "        1.3669e-04, 2.9218e-05, 4.1278e-06, 5.1766e-07, 5.0076e-07, 1.9654e-05,\n",
            "        1.3889e-02, 1.6167e-05, 1.6874e-06, 2.9060e-02, 1.2989e-06, 2.9161e-05,\n",
            "        2.3847e-05, 2.7431e-09, 6.0667e-04, 9.8177e-11, 6.4144e-10, 1.9396e-02,\n",
            "        6.9565e-03, 4.5629e-02, 9.4358e-02, 1.4351e-05, 2.3665e-04, 3.0331e-03,\n",
            "        3.8176e-06, 4.7504e-07, 4.8762e-02, 5.1860e-08, 4.6403e-07, 3.2022e-06,\n",
            "        2.9500e-06, 2.8378e-04, 6.8332e-05, 6.5203e-05, 2.8264e-18, 7.4018e-06,\n",
            "        4.3611e-04, 1.9081e-07, 4.3611e-04, 5.6319e-05, 9.5657e-02, 8.6031e-06,\n",
            "        1.3197e-04, 1.1375e-05, 2.6325e-10, 2.1235e-10, 1.5445e-10, 1.0218e-04,\n",
            "        7.3002e-07], grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [8]\n",
            "DEBUGGING: logits looks like: tensor([1690.5554, 1693.5948, 1688.2865, 1693.8481, 1694.9778, 1695.7488,\n",
            "        1695.2838, 1696.7574, 1696.4596, 1695.7452, 1693.9633, 1695.1440,\n",
            "        1696.3611, 1695.7506, 1695.9818, 1695.7585, 1695.8843, 1695.6528,\n",
            "        1696.1187, 1695.7257, 1694.3711, 1693.5179, 1695.0156, 1694.0999,\n",
            "        1695.8329, 1694.5580, 1695.8285, 1695.4503, 1692.5446, 1694.8864,\n",
            "        1695.7416, 1694.8707, 1696.0059, 1694.7365, 1695.3162, 1695.7399,\n",
            "        1695.9875, 1696.2423, 1695.7202, 1695.7256, 1696.3131, 1695.7316,\n",
            "        1693.7991, 1695.6938, 1696.2383, 1694.5615, 1695.9979, 1695.5657,\n",
            "        1695.9215, 1695.7672, 1695.5715, 1695.3639, 1695.3606, 1695.7275,\n",
            "        1696.3835, 1695.7080, 1695.4821, 1696.4575, 1695.4558, 1695.7671,\n",
            "        1695.7469, 1694.8398, 1696.0706, 1694.5070, 1694.6946, 1696.4171,\n",
            "        1696.3145, 1696.5026, 1696.5753, 1695.6960, 1695.9763, 1696.2316,\n",
            "        1695.5637, 1695.3552, 1696.5093, 1695.1338, 1695.3529, 1695.5461,\n",
            "        1695.5378, 1695.9946, 1695.8522, 1695.8475, 1692.7705, 1695.6300,\n",
            "        1696.0376, 1695.2642, 1696.0376, 1695.8329, 1696.5767, 1695.6450,\n",
            "        1695.9180, 1695.6730, 1694.6056, 1694.5840, 1694.5521, 1695.8923,\n",
            "        1695.3983], grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: the action_prob is: tensor([4.8725e-27, 2.3878e-03, 2.0424e-03, 3.9594e-04, 1.7201e-02, 1.9716e-04,\n",
            "        1.6406e-05, 1.3344e-02, 1.7068e-02, 3.7571e-02, 1.1063e-02, 8.7857e-03,\n",
            "        1.4231e-03, 9.8380e-04, 8.2212e-03, 8.6990e-04, 1.0251e-02, 2.2950e-07,\n",
            "        2.4349e-03, 3.0362e-03, 1.3795e-02, 4.4698e-03, 4.9580e-02, 1.9790e-05,\n",
            "        1.2412e-03, 1.2487e-02, 9.1343e-04, 1.2485e-03, 8.8532e-04, 4.2078e-02,\n",
            "        1.8168e-02, 2.0141e-05, 2.1279e-03, 4.6934e-03, 5.2257e-03, 1.1279e-03,\n",
            "        4.4873e-03, 5.8183e-03, 6.7089e-04, 1.8491e-02, 3.3806e-03, 4.6934e-03,\n",
            "        3.4271e-03, 4.1097e-03, 1.2068e-08, 2.0862e-05, 2.4733e-03, 5.2667e-03,\n",
            "        2.9717e-03, 1.2907e-03, 1.2196e-03, 4.3728e-06, 2.5622e-02, 1.1040e-03,\n",
            "        2.6178e-02, 1.4284e-04, 1.2292e-03, 1.5327e-03, 1.2338e-04, 2.1823e-04,\n",
            "        3.3477e-03, 7.8118e-05, 1.2806e-03, 2.6791e-04, 1.9680e-03, 6.0374e-04,\n",
            "        6.8013e-04, 4.1153e-07, 8.9066e-03, 1.0251e-02, 1.8516e-06, 3.8834e-03,\n",
            "        7.2978e-03, 5.8402e-04, 8.7672e-04, 3.4607e-03, 1.8168e-02, 9.6869e-03,\n",
            "        4.5675e-02, 1.7954e-03, 2.7168e-02, 4.2491e-02, 1.9075e-03, 8.2212e-03,\n",
            "        9.6869e-03, 1.5721e-03, 5.7505e-03, 2.0827e-03, 7.5874e-04, 3.6911e-03,\n",
            "        2.3431e-12, 2.9029e-03, 1.2317e-02, 2.0581e-04, 1.4426e-03, 9.2628e-02,\n",
            "        1.4684e-02, 4.8995e-03, 7.3838e-03, 9.4072e-03, 3.6339e-03, 5.9197e-05,\n",
            "        5.5837e-04, 1.7101e-02, 1.7954e-03, 1.9571e-01, 1.0011e-04, 3.1757e-03],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "DEBUGGING: the actual action to take is: [4]\n",
            "DEBUGGING: logits looks like: tensor([1691.1554, 1696.6101, 1696.5946, 1696.4304, 1696.8077, 1696.3607,\n",
            "        1696.1122, 1696.7823, 1696.8069, 1696.8857, 1696.7634, 1696.7405,\n",
            "        1696.5583, 1696.5216, 1696.7338, 1696.5092, 1696.7560, 1695.6852,\n",
            "        1696.6121, 1696.6342, 1696.7856, 1696.6730, 1696.9136, 1696.1310,\n",
            "        1696.5447, 1696.7756, 1696.5142, 1696.5454, 1696.5110, 1696.8971,\n",
            "        1696.8131, 1696.1326, 1696.5988, 1696.6779, 1696.6886, 1696.5353,\n",
            "        1696.6732, 1696.6992, 1696.4833, 1696.8148, 1696.6450, 1696.6779,\n",
            "        1696.6464, 1696.6646, 1695.3907, 1696.1362, 1696.6138, 1696.6892,\n",
            "        1696.6321, 1696.5487, 1696.5430, 1695.9800, 1696.8475, 1696.5330,\n",
            "        1696.8496, 1696.3286, 1696.5438, 1696.5659, 1696.3138, 1696.3710,\n",
            "        1696.6439, 1696.2682, 1696.5479, 1696.3915, 1696.5909, 1696.4728,\n",
            "        1696.4846, 1695.7435, 1696.7418, 1696.7560, 1695.8940, 1696.6588,\n",
            "        1696.7219, 1696.4694, 1696.5100, 1696.6472, 1696.8131, 1696.7502,\n",
            "        1696.9053, 1696.5817, 1696.8533, 1696.8981, 1696.5876, 1696.7339,\n",
            "        1696.7502, 1696.5685, 1696.6981, 1696.5964, 1696.4956, 1696.6537,\n",
            "        1694.5359, 1696.6298, 1696.7742, 1696.3650, 1696.5598, 1696.9761,\n",
            "        1696.7919, 1696.6820, 1696.7231, 1696.7473, 1696.6522, 1696.2405,\n",
            "        1696.4650, 1696.8070, 1696.5817, 1697.0508, 1696.2930, 1696.6388],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "-------------------------------------------------------------------------------------------\n",
            "DEBUGGING: the total abs reward of the trajectory = 0.07093902281440023 and immediate abs rewards look like: [0.001628004127269378, 0.0018067069577227812, 0.006974937901759404, 0.00054018023001845, 0.003591665435124014, 0.0020299402899581764, 0.0013187492832003045, 0.006717742574892327, 5.079304764876724e-05, 0.00011969085653618095, 5.57084981664957e-05, 9.986635586756165e-05, 0.0035397509882386657, 0.0019284097611489415, 0.006832118333022663, 3.755121497306391e-05, 0.00032903235023695743, 0.00045331579303820035, 0.0006644121808676573, 0.000647535186544701, 0.00011704315602401039, 0.0019842994142891257, 0.0006551303267769981, 0.005808406843243574, 0.001313538087742927, 0.005259012249098305, 0.0001672055254857696, 3.6524956612993265e-05, 9.109112397709396e-06, 1.0815213499881793e-05, 0.0014579042740479053, 0.004525028726220626, 0.0005213982817622309, 0.00158545654039699, 0.0020240605012986634, 3.211490684407181e-05, 0.00029099765060891514, 0.0003789434263126168, 0.003100521517353627, 0.0006906597136548953, 2.435805981804151e-06, 2.8612320875254227e-05, 0.0007167531102822977, 4.29290139436489e-06, 2.6603574951877818e-06, 3.175506890329416e-05, 4.440311386133544e-05, 0.000547030414963956, 3.683838986034971e-05, 0.00018995954087586142]\n",
            "DEBUGGING: the total relative reward of the trajectory = 48.785576335571044 and immediate relative rewards look like: [0.060166174884518614, 0.1336213914446697, 0.7743015514523204, 0.08016218963136222, 0.6663828597406221, 0.4525552954912083, 0.34326150941555106, 1.9993608996947514, 0.017049489475658007, 0.04464098822373103, 0.02285632215252403, 0.044699399190771844, 1.7164591754115919, 1.0083668790763878, 3.8304586012119426, 0.022514305757903648, 0.2096081746919097, 0.305807125993367, 0.47319399332358447, 0.48556746417157226, 0.09217793645716801, 1.637233458959467, 0.5655351295565733, 5.2333420022536625, 1.2354966287133509, 5.146963600348324, 0.17027407819635376, 0.038575296965984426, 0.009964180361370764, 0.012238420339971277, 1.704753097399624, 5.464884620522412, 0.650482362993659, 2.038312951035588, 2.680338092142563, 0.043776388148906775, 0.4076873602051325, 0.5453080012568569, 4.579790155534993, 1.0475641610389985, 0.0037878852897737444, 0.04557986637828635, 1.1689970773386764, 0.00716633418191157, 0.0045419953828595965, 0.05541987011779584, 0.07917920370223885, 0.9962305890622396, 0.06850054508885307, 0.3604412561615003]\n",
            "+++++++++++++++++++ The policy roll-out has finished! ++++++++++++++++++++++++++++++++\n",
            "DEBUGGING: OBS_MAT has 150 number of matrices\n",
            "DEBUGGING: ACT_MAT has 150 number of matrices\n",
            "DEBUGGING: VAL looks like: [[31.408822292891447, 31.286664276905945, 31.453382967272177, 22.68589236906119, 20.59439068338609, 19.965444000891466, 19.07788709944472, 18.438362196638593, 16.69938105321946, 13.583804621723631, 13.467166241980136, 11.914064330551554, 7.937199775416572, 7.863316506526551, 7.6731183682421875, 7.747426941274226, 7.818685711477119, 7.885534307978494, 7.919633802417048, 7.344209614301452, 6.799387166533861, 6.859752253407, 6.616483677509558, 6.605452318273578, 6.4174048527386836, 6.242541309571265, 5.074485190734141, 5.07693917071596, 3.7047500341142943, 2.577616248608272, 2.3690068853044166, 2.2998397905558687, 2.252744547478604, 2.062943560454754, 1.7624297379804947, 1.5679345704433079, 1.3085293511525349, 1.232853311086269, 0.8665005265174954, 0.6546345206795543, 0.5644874864544385, 0.5156542987489482, 0.22039617524802738, 0.22002514091914066, 0.13275361275502082, 0.1330248903793475, 0.1245157655059387, 0.11882467098559596, 0.008472575720347167, 0.0017835157939680103], [18.277905855271115, 17.328142940712933, 17.360662564104782, 14.578364410680807, 14.67323271983388, 14.53834487797818, 12.779937108788836, 12.166132718312785, 12.260726726681392, 12.281828684279084, 11.877646620608022, 11.62144664734776, 11.424750686666519, 10.228684992312518, 9.888009491220805, 9.921426901815952, 9.894954900011617, 9.809730287539072, 9.412223194903333, 8.948144129357306, 8.975914486483966, 8.966998307540122, 7.414253919713009, 7.444928587232722, 7.4325185373751905, 7.457433092544983, 7.482960262615991, 7.158954860535959, 4.198627526622573, 3.881576182108224, 3.906633283579853, 3.2770611154921183, 3.240771248109616, 3.074922727335757, 3.091513952305905, 2.8448370463079837, 2.3660078828509867, 2.0403711356022085, 1.3766311372683193, 0.9629448323108356, 0.9041487285371599, 0.9111646143910523, 0.8933762156953574, 0.8969901884421401, 0.7161054781303399, 0.09508972447290251, 0.03947943287740124, 0.028618788151519872, 0.008471117090290498, 0.002377537307009269], [37.9503691508634, 38.27293229896857, 38.52455647224637, 38.1315706270647, 38.43576609841751, 38.15089216027968, 38.07912814625098, 38.117037006904475, 36.482501118393664, 36.8337895241596, 37.16075609690491, 37.513030075507466, 37.846798662946156, 36.49529241165107, 35.84537932583301, 32.3383037622435, 32.64221157220767, 32.760205452036125, 32.78222053135632, 32.63538034144721, 32.47455846189458, 32.70947527821961, 31.386102847737515, 31.131886584021153, 26.160146042189382, 25.17641354896569, 20.231767624866027, 20.264134895625933, 20.429858180464596, 20.62615555565982, 20.8221385205251, 19.31049032638937, 13.985460308956526, 13.469674692891786, 11.54683004227899, 8.95605247488528, 9.002299077511488, 8.681425977077126, 8.21830098567704, 3.6752634647899463, 2.6542417209605533, 2.677226096637151, 2.6582285154129943, 1.5042741798730486, 1.5122301471627648, 1.5229173250302073, 1.4823206615276883, 1.4173146038640905, 0.4253373886887383, 0.3604412561615003]]\n",
            "DEBUGGING: traj_returns = [31.408822292891447, 18.277905855271115, 37.9503691508634]\n",
            "DEBUGGING: actions = [[8], [22], [50], [14], [32], [23], [34], [40], [13], [63], [45], [10], [57], [65], [61], [41], [6], [64], [53], [12], [61], [17], [17], [29], [84], [41], [73], [16], [82], [35], [64], [26], [9], [34], [7], [63], [32], [59], [10], [37], [69], [69], [19], [49], [33], [62], [24], [87], [26], [50], [50], [38], [28], [35], [11], [35], [23], [11], [63], [62], [39], [34], [65], [4], [66], [15], [2], [11], [3], [1], [48], [18], [4], [77], [44], [21], [27], [81], [80], [60], [44], [7], [44], [18], [51], [3], [6], [50], [27], [38], [51], [38], [15], [54], [24], [23], [63], [84], [95], [70], [55], [1], [48], [7], [15], [1], [6], [47], [41], [7], [46], [15], [13], [33], [37], [3], [68], [69], [78], [47], [71], [39], [26], [69], [11], [76], [7], [48], [47], [87], [83], [83], [37], [85], [8], [84], [14], [1], [35], [8], [6], [23], [94], [67], [53], [33], [102], [8], [42], [4]]\n",
            "DEBUGGING: actions length = 150\n",
            "DEBUGGING: what does the model output in this round of roll-out?\n",
            "DEBUGGING: obs_attention looks like: tensor([[  7.6334,   8.3308,  13.3505,  ...,   4.4272, -14.5372, -22.1160],\n",
            "        [  7.7249,   8.4469,  13.5190,  ...,   4.4796, -14.7089, -22.3708],\n",
            "        [  7.8337,   8.5569,  13.7175,  ...,   4.5452, -14.9237, -22.6925],\n",
            "        ...,\n",
            "        [  7.8002,   8.5211,  13.6411,  ...,   4.5209, -14.8432, -22.5776],\n",
            "        [  7.7999,   8.5208,  13.6405,  ...,   4.5207, -14.8427, -22.5768],\n",
            "        [  7.8029,   8.5242,  13.6463,  ...,   4.5224, -14.8482, -22.5852]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: act_attention looks like: tensor([[  7.7732,   8.4906,  13.5937,  ...,   4.5068, -14.7972, -22.5047],\n",
            "        [  7.7994,   8.5202,  13.6397,  ...,   4.5204, -14.8419, -22.5755],\n",
            "        [  7.7994,   8.5201,  13.6396,  ...,   4.5204, -14.8417, -22.5753],\n",
            "        ...,\n",
            "        [  7.8015,   8.5226,  13.6435,  ...,   4.5216, -14.8455, -22.5812],\n",
            "        [  7.7979,   8.5185,  13.6370,  ...,   4.5195, -14.8392, -22.5714],\n",
            "        [  7.7994,   8.5203,  13.6399,  ...,   4.5205, -14.8422, -22.5759]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "DEBUGGING: logits looks like: tensor([1691.1554, 1696.6101, 1696.5946, 1696.4304, 1696.8077, 1696.3607,\n",
            "        1696.1122, 1696.7823, 1696.8069, 1696.8857, 1696.7634, 1696.7405,\n",
            "        1696.5583, 1696.5216, 1696.7338, 1696.5092, 1696.7560, 1695.6852,\n",
            "        1696.6121, 1696.6342, 1696.7856, 1696.6730, 1696.9136, 1696.1310,\n",
            "        1696.5447, 1696.7756, 1696.5142, 1696.5454, 1696.5110, 1696.8971,\n",
            "        1696.8131, 1696.1326, 1696.5988, 1696.6779, 1696.6886, 1696.5353,\n",
            "        1696.6732, 1696.6992, 1696.4833, 1696.8148, 1696.6450, 1696.6779,\n",
            "        1696.6464, 1696.6646, 1695.3907, 1696.1362, 1696.6138, 1696.6892,\n",
            "        1696.6321, 1696.5487, 1696.5430, 1695.9800, 1696.8475, 1696.5330,\n",
            "        1696.8496, 1696.3286, 1696.5438, 1696.5659, 1696.3138, 1696.3710,\n",
            "        1696.6439, 1696.2682, 1696.5479, 1696.3915, 1696.5909, 1696.4728,\n",
            "        1696.4846, 1695.7435, 1696.7418, 1696.7560, 1695.8940, 1696.6588,\n",
            "        1696.7219, 1696.4694, 1696.5100, 1696.6472, 1696.8131, 1696.7502,\n",
            "        1696.9053, 1696.5817, 1696.8533, 1696.8981, 1696.5876, 1696.7339,\n",
            "        1696.7502, 1696.5685, 1696.6981, 1696.5964, 1696.4956, 1696.6537,\n",
            "        1694.5359, 1696.6298, 1696.7742, 1696.3650, 1696.5598, 1696.9761,\n",
            "        1696.7919, 1696.6820, 1696.7231, 1696.7473, 1696.6522, 1696.2405,\n",
            "        1696.4650, 1696.8070, 1696.5817, 1697.0508, 1696.2930, 1696.6388],\n",
            "       grad_fn=<MeanBackward1>)\n",
            "DEBUGGING: baseline2 looks like: [[29.21236577 28.96257984 29.11286733 25.13194247 24.5677965  24.21822701\n",
            "  23.31231745 22.90717731 21.81420297 20.89980761 20.83518965 20.34951368\n",
            "  19.06958304 18.19576464 17.80216906 16.66905254 16.78528406 16.81849002\n",
            "  16.70469251 16.3092447  16.0832867  16.17874195 15.13894681 15.06075583\n",
            "  13.33668981 12.95879598 10.92973769 10.83334298  9.44441191  9.02844933\n",
            "   9.0325929   8.29579708  6.49299203  6.20251366  5.46692458  4.4562747\n",
            "   4.2256121   3.98488347  3.48714422  1.76428094  1.37429265  1.368015\n",
            "   1.25733364  0.87376317  0.78702975  0.58367731  0.54877195  0.52158602\n",
            "   0.14742703  0.1215341 ]]\n",
            "DEBUGGING: baseline2 looks like: 29.212365766341986\n",
            "DEBUGGING: ADS looks like: [  2.19645653   2.32408444   2.34051563  -2.4460501   -3.97340582\n",
            "  -4.25278301  -4.23443035  -4.46881511  -5.11482191  -7.31600299\n",
            "  -7.36802341  -8.43544935 -11.13238327 -10.33244813 -10.12905069\n",
            "  -8.92162559  -8.96659835  -8.93295571  -8.78505871  -8.96503508\n",
            "  -9.28389954  -9.31898969  -8.52246314  -8.45530351  -6.91928496\n",
            "  -6.71625467  -5.8552525   -5.7564038   -5.73966188  -6.45083308\n",
            "  -6.66358601  -5.99595729  -4.24024749  -4.1395701   -3.70449484\n",
            "  -2.88834013  -2.91708275  -2.75203016  -2.62064369  -1.10964642\n",
            "  -0.80980516  -0.8523607   -1.03693746  -0.65373803  -0.65427613\n",
            "  -0.45065242  -0.42425619  -0.40276135  -0.13895445  -0.11975059\n",
            " -10.93445991 -11.6344369  -11.75220477 -10.55357806  -9.89456378\n",
            "  -9.67988214 -10.53238034 -10.74104459  -9.55347624  -8.61797893\n",
            "  -8.95754303  -8.72806704  -7.64483236  -7.96707964  -7.91415957\n",
            "  -6.74762563  -6.89032916  -7.00875973  -7.29246931  -7.36110057\n",
            "  -7.10737222  -7.21174364  -7.7246929   -7.61582724  -5.90417127\n",
            "  -5.50136289  -3.44677743  -3.67438812  -5.24578439  -5.14687315\n",
            "  -5.12595961  -5.01873596  -3.25222079  -3.12759093  -2.37541063\n",
            "  -1.61143765  -1.85960422  -1.94451234  -2.11051308  -0.80133611\n",
            "  -0.47014392  -0.45685039  -0.36395742   0.02322702  -0.07092427\n",
            "  -0.48858759  -0.50929252  -0.49296723  -0.13895591  -0.11915657\n",
            "   8.73800338   9.31035246   9.41168914  12.99962816  13.8679696\n",
            "  13.93266515  14.76681069  15.2098597   14.66829815  15.93398191\n",
            "  16.32556644  17.16351639  18.77721562  18.29952777  18.04321026\n",
            "  15.66925123  15.85692751  15.94171544  16.07752802  16.32613565\n",
            "  16.39127176  16.53073333  16.24715603  16.07113075  12.82345623\n",
            "  12.21761757   9.30202993   9.43079192  10.98544627  11.59770623\n",
            "  11.78954562  11.01469325   7.49246827   7.26716103   6.07990546\n",
            "   4.49977778   4.77668697   4.6965425    4.73115677   1.91098253\n",
            "   1.27994908   1.30921109   1.40089488   0.63051101   0.7252004\n",
            "   0.93924001   0.93354871   0.89572858   0.27791036   0.23890715]\n",
            "DEBUGGING: I'm inside the training now!\n",
            "DEBUGGING: the loss = tensor(-6.9010, grad_fn=<NegBackward0>)\n",
            "DEBUGGING: BEFORE the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-6.1971e-01, -5.3391e-01, -9.8053e-03,  ...,  7.9417e-02,\n",
            "         -3.7560e-01,  1.9859e-02],\n",
            "        [ 3.0658e-01,  2.6415e-01,  4.9008e-03,  ..., -3.9224e-02,\n",
            "          1.8583e-01,  6.7195e-03],\n",
            "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00],\n",
            "        ...,\n",
            "        [-2.3415e-01, -2.0173e-01, -3.6885e-03,  ...,  3.0028e-02,\n",
            "         -1.4191e-01,  1.3257e-02],\n",
            "        [-5.1409e-01, -4.4291e-01, -8.1305e-03,  ...,  6.5883e-02,\n",
            "         -3.1158e-01,  1.8489e-02],\n",
            "        [-2.2346e-01, -1.9253e-01, -3.5597e-03,  ...,  2.8606e-02,\n",
            "         -1.3545e-01, -7.8132e-05]])\n",
            "   Last layer:\n",
            "tensor([[-1.1176e-02, -2.3728e-02, -1.9698e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -1.9193e-03,  0.0000e+00,  0.0000e+00,\n",
            "         -1.8821e-02, -3.2211e-02, -1.3882e-02,  0.0000e+00, -3.4614e-02,\n",
            "          0.0000e+00,  6.4665e-03,  0.0000e+00,  1.9101e-02,  0.0000e+00],\n",
            "        [ 1.0486e-03, -3.5453e-03, -8.8532e-03,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  1.5796e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -8.6752e-03, -1.7282e-02, -8.9373e-03,  0.0000e+00, -2.2684e-02,\n",
            "          0.0000e+00,  1.8866e-02,  0.0000e+00,  3.1417e-02,  0.0000e+00],\n",
            "        [-4.7908e-03, -1.6617e-02, -2.0458e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  1.6521e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -1.9713e-02, -3.6338e-02, -1.7498e-02,  0.0000e+00, -4.3941e-02,\n",
            "          0.0000e+00,  2.4455e-02,  0.0000e+00,  4.5228e-02,  0.0000e+00],\n",
            "        [ 3.3806e-03,  1.1517e-02,  1.3566e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -1.0423e-02,  0.0000e+00,  0.0000e+00,\n",
            "          1.3148e-02,  2.4197e-02,  1.1520e-02,  0.0000e+00,  2.8999e-02,\n",
            "          0.0000e+00, -1.5699e-02,  0.0000e+00, -2.9327e-02,  0.0000e+00],\n",
            "        [-2.3073e-02, -2.9645e-02, -5.2217e-03,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -5.5017e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -4.5641e-03,  2.9306e-04,  4.9562e-03,  0.0000e+00,  1.4066e-02,\n",
            "          0.0000e+00, -5.0756e-02,  0.0000e+00, -6.9914e-02,  0.0000e+00],\n",
            "        [-9.1883e-03, -5.0347e-03,  1.0711e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -4.0576e-02,  0.0000e+00,  0.0000e+00,\n",
            "          1.0783e-02,  2.4252e-02,  1.4230e-02,  0.0000e+00,  3.6807e-02,\n",
            "          0.0000e+00, -4.3528e-02,  0.0000e+00, -6.7643e-02,  0.0000e+00],\n",
            "        [ 1.0496e-02,  1.2276e-02, -5.4585e-05,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  2.8725e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -3.1651e-04, -4.5647e-03, -4.6274e-03,  0.0000e+00, -1.2409e-02,\n",
            "          0.0000e+00,  2.7676e-02,  0.0000e+00,  3.9556e-02,  0.0000e+00],\n",
            "        [-4.8168e-03, -1.1046e-02, -1.0007e-02,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00,  1.2911e-03,  0.0000e+00,  0.0000e+00,\n",
            "         -9.5870e-03, -1.6753e-02, -7.4153e-03,  0.0000e+00, -1.8562e-02,\n",
            "          0.0000e+00,  5.4546e-03,  0.0000e+00,  1.2826e-02,  0.0000e+00],\n",
            "        [-2.2791e-02, -2.8898e-02, -4.2821e-03,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -5.5831e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -3.5540e-03,  1.9839e-03,  5.8130e-03,  0.0000e+00,  1.6151e-02,\n",
            "          0.0000e+00, -5.1837e-02,  0.0000e+00, -7.2000e-02,  0.0000e+00],\n",
            "        [-3.4450e-02, -4.3746e-02, -6.3024e-03,  0.0000e+00,  0.0000e+00,\n",
            "          0.0000e+00,  0.0000e+00, -8.4539e-02,  0.0000e+00,  0.0000e+00,\n",
            "         -5.3343e-03,  3.1399e-03,  8.8817e-03,  0.0000e+00,  2.4665e-02,\n",
            "          0.0000e+00, -7.8953e-02,  0.0000e+00, -1.0946e-01,  0.0000e+00]])\n",
            "DEBUGGING: AFTER the backward pass, the gradients of the network looks like:\n",
            "   First layer:\n",
            "tensor([[-0.2746, -0.0376, -0.1096,  ..., -0.0837,  0.2117,  0.4386],\n",
            "        [ 0.1427,  0.0195,  0.0570,  ...,  0.0435, -0.1100, -0.2259],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        ...,\n",
            "        [-0.1066, -0.0146, -0.0425,  ..., -0.0325,  0.0821,  0.1655],\n",
            "        [-0.2345, -0.0321, -0.0936,  ..., -0.0715,  0.1808,  0.3710],\n",
            "        [-0.0955, -0.0131, -0.0381,  ..., -0.0291,  0.0736,  0.1533]])\n",
            "   Last layer:\n",
            "tensor([[ 0.0368,  0.1011,  0.0295,  0.0000,  0.0000,  0.0000,  0.0000,  0.0520,\n",
            "          0.0000,  0.0000,  0.0515,  0.0870,  0.0110,  0.0000,  0.0658,  0.0000,\n",
            "          0.0457,  0.0000,  0.0415,  0.0000],\n",
            "        [ 0.0463,  0.1207,  0.0380,  0.0000,  0.0000,  0.0000,  0.0000,  0.0651,\n",
            "          0.0000,  0.0000,  0.0618,  0.1033,  0.0149,  0.0000,  0.0788,  0.0000,\n",
            "          0.0554,  0.0000,  0.0503,  0.0000],\n",
            "        [ 0.0752,  0.1951,  0.0620,  0.0000,  0.0000,  0.0000,  0.0000,  0.1058,\n",
            "          0.0000,  0.0000,  0.0999,  0.1669,  0.0244,  0.0000,  0.1275,  0.0000,\n",
            "          0.0899,  0.0000,  0.0817,  0.0000],\n",
            "        [-0.0411, -0.1136, -0.0330,  0.0000,  0.0000,  0.0000,  0.0000, -0.0583,\n",
            "          0.0000,  0.0000, -0.0579, -0.0978, -0.0123,  0.0000, -0.0740,  0.0000,\n",
            "         -0.0513,  0.0000, -0.0466,  0.0000],\n",
            "        [-0.0669, -0.1836, -0.0538,  0.0000,  0.0000,  0.0000,  0.0000, -0.0946,\n",
            "          0.0000,  0.0000, -0.0937, -0.1583, -0.0201,  0.0000, -0.1197,  0.0000,\n",
            "         -0.0832,  0.0000, -0.0755,  0.0000],\n",
            "        [-0.0941, -0.2423, -0.0778,  0.0000,  0.0000,  0.0000,  0.0000, -0.1325,\n",
            "          0.0000,  0.0000, -0.1242, -0.2072, -0.0307,  0.0000, -0.1582,  0.0000,\n",
            "         -0.1119,  0.0000, -0.1017,  0.0000],\n",
            "        [ 0.0413,  0.1126,  0.0334,  0.0000,  0.0000,  0.0000,  0.0000,  0.0584,\n",
            "          0.0000,  0.0000,  0.0575,  0.0969,  0.0126,  0.0000,  0.0734,  0.0000,\n",
            "          0.0511,  0.0000,  0.0464,  0.0000],\n",
            "        [ 0.0263,  0.0670,  0.0218,  0.0000,  0.0000,  0.0000,  0.0000,  0.0369,\n",
            "          0.0000,  0.0000,  0.0343,  0.0571,  0.0087,  0.0000,  0.0438,  0.0000,\n",
            "          0.0310,  0.0000,  0.0281,  0.0000],\n",
            "        [-0.0799, -0.2088, -0.0654,  0.0000,  0.0000,  0.0000,  0.0000, -0.1124,\n",
            "          0.0000,  0.0000, -0.1069, -0.1788, -0.0255,  0.0000, -0.1363,  0.0000,\n",
            "         -0.0960,  0.0000, -0.0870,  0.0000],\n",
            "        [-0.1047, -0.2896, -0.0842,  0.0000,  0.0000,  0.0000,  0.0000, -0.1484,\n",
            "          0.0000,  0.0000, -0.1477, -0.2497, -0.0312,  0.0000, -0.1884,  0.0000,\n",
            "         -0.1308,  0.0000, -0.1187,  0.0000]])\n",
            "DEBUGGING: training for one iteration takes 0.003495 min:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256,
          "referenced_widgets": [
            "591549f95fdc4d90afb7c4772bde1f92",
            "c116081950dc471abc1a6f55dfb2d265",
            "3618d19faefb447b80d30184c47c2d9f",
            "593bb22f5b6e493b8bd86db7f50155ad",
            "7f752cec13d74e34a1dec1920105ec6b",
            "6877226f417e42d59c4834127bdf2fbe",
            "880332d08e6745cbb0c87304acbac072",
            "c8a09347cb234bb0904a023c8fae1e9b"
          ]
        },
        "id": "Oe4fCU1V-kAs",
        "outputId": "2f907fcf-1232-4451-dea9-a85ff64f985f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "591549f95fdc4d90afb7c4772bde1f92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training reward (easy config)</td><td>â–â–‡â–‚â–‚â–‡â–‡â–‡â–†â–ˆâ–â–ƒâ–ƒâ–‚â–â–‚â–‚â–â–‚â–‚â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training reward (easy config)</td><td>0.07094</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">silver-monkey-2705</strong>: <a href=\"https://wandb.ai/ieor4575-spring2022/finalproject/runs/1am91bic\" target=\"_blank\">https://wandb.ai/ieor4575-spring2022/finalproject/runs/1am91bic</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220508_222731-1am91bic/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [   54246.9141, 27220988.0000,  3948314.5000,  3902082.5000,\n",
        "        27219886.0000,  3816622.7500, 27175632.0000,  3976903.5000,\n",
        "         3977309.0000,  3961905.7500,  3904790.7500, 23420360.0000,\n",
        "        27218672.0000, 27206276.0000, 27190054.0000,  3976984.7500,\n",
        "         3931598.0000,  3963138.5000, 19419398.0000,  3931559.5000,\n",
        "         7862683.0000, 19299310.0000,  3915878.7500, 15562425.0000,\n",
        "        27141808.0000, 27323768.0000, 11622510.0000, 15451909.0000,\n",
        "        23389744.0000,  7781165.5000, 11871555.0000, 11657742.0000,\n",
        "        27473456.0000, 11592561.0000,  4054315.2500,  7718911.0000,\n",
        "        27136936.0000,  3914171.2500, 23255876.0000, 15599427.0000,\n",
        "        19661078.0000,  3915166.7500,  7554840.5000, 27196042.0000,\n",
        "        11791202.0000, 23477022.0000, 15708443.0000, 23297932.0000,\n",
        "        23511102.0000,  7689591.5000, 27405178.0000,  4021836.7500,\n",
        "        15558291.0000,  3948567.5000,  7915618.5000,  3864714.5000,\n",
        "         3995934.2500, 19536616.0000,  3890406.7500, 27284138.0000,\n",
        "        11731948.0000, 23232848.0000, 19200360.0000, 22949674.0000,\n",
        "        26724900.0000,  3268551.2500, 22647966.0000, 25925040.0000,\n",
        "        25380838.0000,  5669201.5000,  7810961.0000, 13092715.0000,\n",
        "        14364957.0000, 15622157.0000, 27473452.0000]"
      ],
      "metadata": {
        "id": "R5xFgG-ZGZkL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_t = torch.FloatTensor(a)\n",
        "print(a_t)\n",
        "b_t = a_t /1000000\n",
        "print(b_t)\n",
        "print(torch.nn.functional.softmax(b_t, dim=0))\n",
        "b_t = a_t / a_t.max()\n",
        "print(b_t)\n",
        "torch.nn.functional.softmax(b_t, dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5GfEt5DGbcN",
        "outputId": "e15b41c2-9748-4971-cc4f-9ffbc250c973"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   54246.9141, 27220988.0000,  3948314.5000,  3902082.5000,\n",
            "        27219886.0000,  3816622.7500, 27175632.0000,  3976903.5000,\n",
            "         3977309.0000,  3961905.7500,  3904790.7500, 23420360.0000,\n",
            "        27218672.0000, 27206276.0000, 27190054.0000,  3976984.7500,\n",
            "         3931598.0000,  3963138.5000, 19419398.0000,  3931559.5000,\n",
            "         7862683.0000, 19299310.0000,  3915878.7500, 15562425.0000,\n",
            "        27141808.0000, 27323768.0000, 11622510.0000, 15451909.0000,\n",
            "        23389744.0000,  7781165.5000, 11871555.0000, 11657742.0000,\n",
            "        27473456.0000, 11592561.0000,  4054315.2500,  7718911.0000,\n",
            "        27136936.0000,  3914171.2500, 23255876.0000, 15599427.0000,\n",
            "        19661078.0000,  3915166.7500,  7554840.5000, 27196042.0000,\n",
            "        11791202.0000, 23477022.0000, 15708443.0000, 23297932.0000,\n",
            "        23511102.0000,  7689591.5000, 27405178.0000,  4021836.7500,\n",
            "        15558291.0000,  3948567.5000,  7915618.5000,  3864714.5000,\n",
            "         3995934.2500, 19536616.0000,  3890406.7500, 27284138.0000,\n",
            "        11731948.0000, 23232848.0000, 19200360.0000, 22949674.0000,\n",
            "        26724900.0000,  3268551.2500, 22647966.0000, 25925040.0000,\n",
            "        25380838.0000,  5669201.5000,  7810961.0000, 13092715.0000,\n",
            "        14364957.0000, 15622157.0000, 27473452.0000])\n",
            "tensor([ 0.0542, 27.2210,  3.9483,  3.9021, 27.2199,  3.8166, 27.1756,  3.9769,\n",
            "         3.9773,  3.9619,  3.9048, 23.4204, 27.2187, 27.2063, 27.1901,  3.9770,\n",
            "         3.9316,  3.9631, 19.4194,  3.9316,  7.8627, 19.2993,  3.9159, 15.5624,\n",
            "        27.1418, 27.3238, 11.6225, 15.4519, 23.3897,  7.7812, 11.8716, 11.6577,\n",
            "        27.4735, 11.5926,  4.0543,  7.7189, 27.1369,  3.9142, 23.2559, 15.5994,\n",
            "        19.6611,  3.9152,  7.5548, 27.1960, 11.7912, 23.4770, 15.7084, 23.2979,\n",
            "        23.5111,  7.6896, 27.4052,  4.0218, 15.5583,  3.9486,  7.9156,  3.8647,\n",
            "         3.9959, 19.5366,  3.8904, 27.2841, 11.7319, 23.2328, 19.2004, 22.9497,\n",
            "        26.7249,  3.2686, 22.6480, 25.9250, 25.3808,  5.6692,  7.8110, 13.0927,\n",
            "        14.3650, 15.6222, 27.4735])\n",
            "tensor([1.0010e-13, 6.2920e-02, 4.9158e-12, 4.6937e-12, 6.2851e-02, 4.3093e-12,\n",
            "        6.0130e-02, 5.0584e-12, 5.0605e-12, 4.9831e-12, 4.7065e-12, 1.4067e-03,\n",
            "        6.2775e-02, 6.2001e-02, 6.1004e-02, 5.0588e-12, 4.8344e-12, 4.9893e-12,\n",
            "        2.5740e-05, 4.8342e-12, 2.4637e-10, 2.2827e-05, 4.7589e-12, 5.4393e-07,\n",
            "        5.8130e-02, 6.9731e-02, 1.0579e-08, 4.8702e-07, 1.3643e-03, 2.2708e-10,\n",
            "        1.3571e-08, 1.0959e-08, 8.0991e-02, 1.0267e-08, 5.4655e-12, 2.1338e-10,\n",
            "        5.7848e-02, 4.7508e-12, 1.1933e-03, 5.6443e-07, 3.2777e-05, 4.7556e-12,\n",
            "        1.8109e-10, 6.1370e-02, 1.2523e-08, 1.4887e-03, 6.2944e-07, 1.2446e-03,\n",
            "        1.5403e-03, 2.0721e-10, 7.5646e-02, 5.2909e-12, 5.4168e-07, 4.9171e-12,\n",
            "        2.5976e-10, 4.5216e-12, 5.1556e-12, 2.8941e-05, 4.6393e-12, 6.7022e-02,\n",
            "        1.1803e-08, 1.1662e-03, 2.0676e-05, 8.7858e-04, 3.8313e-02, 2.4910e-12,\n",
            "        6.4976e-04, 1.7217e-02, 9.9914e-03, 2.7477e-11, 2.3395e-10, 4.6021e-08,\n",
            "        1.6424e-07, 5.7741e-07, 8.0991e-02])\n",
            "tensor([0.0020, 0.9908, 0.1437, 0.1420, 0.9908, 0.1389, 0.9892, 0.1448, 0.1448,\n",
            "        0.1442, 0.1421, 0.8525, 0.9907, 0.9903, 0.9897, 0.1448, 0.1431, 0.1443,\n",
            "        0.7068, 0.1431, 0.2862, 0.7025, 0.1425, 0.5665, 0.9879, 0.9946, 0.4230,\n",
            "        0.5624, 0.8514, 0.2832, 0.4321, 0.4243, 1.0000, 0.4220, 0.1476, 0.2810,\n",
            "        0.9878, 0.1425, 0.8465, 0.5678, 0.7156, 0.1425, 0.2750, 0.9899, 0.4292,\n",
            "        0.8545, 0.5718, 0.8480, 0.8558, 0.2799, 0.9975, 0.1464, 0.5663, 0.1437,\n",
            "        0.2881, 0.1407, 0.1454, 0.7111, 0.1416, 0.9931, 0.4270, 0.8456, 0.6989,\n",
            "        0.8353, 0.9728, 0.1190, 0.8244, 0.9436, 0.9238, 0.2064, 0.2843, 0.4766,\n",
            "        0.5229, 0.5686, 1.0000])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0074, 0.0199, 0.0085, 0.0085, 0.0199, 0.0085, 0.0199, 0.0085, 0.0085,\n",
              "        0.0085, 0.0085, 0.0173, 0.0199, 0.0199, 0.0199, 0.0085, 0.0085, 0.0085,\n",
              "        0.0150, 0.0085, 0.0098, 0.0149, 0.0085, 0.0130, 0.0198, 0.0200, 0.0113,\n",
              "        0.0130, 0.0173, 0.0098, 0.0114, 0.0113, 0.0201, 0.0113, 0.0086, 0.0098,\n",
              "        0.0198, 0.0085, 0.0172, 0.0130, 0.0151, 0.0085, 0.0097, 0.0199, 0.0113,\n",
              "        0.0174, 0.0131, 0.0172, 0.0174, 0.0098, 0.0200, 0.0085, 0.0130, 0.0085,\n",
              "        0.0099, 0.0085, 0.0085, 0.0150, 0.0085, 0.0199, 0.0113, 0.0172, 0.0149,\n",
              "        0.0170, 0.0195, 0.0083, 0.0168, 0.0190, 0.0186, 0.0091, 0.0098, 0.0119,\n",
              "        0.0125, 0.0130, 0.0201])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYdGyAom2SMj",
        "outputId": "2e1634b4-bfe9-46f4-8c1a-9cfdd1a238a7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 3., 2., 3., 4., 0., 4., 3., 4., 3., 0., 3., 1., 2., 1., 0.,\n",
              "       4., 2., 4., 0., 4., 4., 0., 0., 4., 3., 2., 0., 3., 2., 4., 2., 2.,\n",
              "       2., 2., 2., 0., 4., 0., 2., 0., 3., 2., 4., 3., 4., 2., 1., 0., 3.,\n",
              "       4., 0., 3., 0., 3., 0., 3., 3., 3.])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s[1][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WUaedhX198a",
        "outputId": "259827b7-8a08-49f2-ae24-b8be4db2e806"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "157421.0"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s[-2] / np.max(s[-2], axis=1, keepdims=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmmYGIMyEQNl",
        "outputId": "7e60ac12-9142-4c28-f5d0-e08e6f54da24"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6       , 0.5       , 0.9       , ..., 0.7       , 0.6       ,\n",
              "        0.7       ],\n",
              "       [0.56670342, 0.35060639, 0.74531422, ..., 0.52701213, 0.62072767,\n",
              "        0.5292172 ],\n",
              "       [0.56317044, 0.35220501, 0.74076281, ..., 0.52085816, 0.62097735,\n",
              "        0.52920143],\n",
              "       ...,\n",
              "       [0.56477039, 0.35092529, 0.74366004, ..., 0.52501714, 0.62097327,\n",
              "        0.52707334],\n",
              "       [0.56531532, 0.34797297, 0.7454955 , ..., 0.52252252, 0.62274775,\n",
              "        0.52477477],\n",
              "       [0.5625    , 0.35416667, 0.74333333, ..., 0.52416667, 0.62083333,\n",
              "        0.53      ]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(s[-2]), len(s[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GEP-MOCEZKu",
        "outputId": "0ce37ce5-0275-4bd8-d156-e306c030b1b5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(108, 110)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([0.0057, 0.0235, 0.0144, 0.0181, 0.0181, 0.0123, 0.0293, 0.0095, 0.0122,\n",
        "        0.0146, 0.0152, 0.0095, 0.0184, 0.0151, 0.0143, 0.0095, 0.0220, 0.0120,\n",
        "        0.0209, 0.0226, 0.0142, 0.0124, 0.0145, 0.0133, 0.0218, 0.0146, 0.0098,\n",
        "        0.0186, 0.0146, 0.0126, 0.0182, 0.0204, 0.0155, 0.0180, 0.0098, 0.0184,\n",
        "        0.0248, 0.0150, 0.0215, 0.0114, 0.0186, 0.0175, 0.0141, 0.0199, 0.0250,\n",
        "        0.0178, 0.0310, 0.0170, 0.0153, 0.0204, 0.0121, 0.0247, 0.0187, 0.0197,\n",
        "        0.0130, 0.0127, 0.0240, 0.0189, 0.0104, 0.0125])\n",
        "a.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlcbwh-Ts6Jt",
        "outputId": "8aafd61a-fd2d-43ce-a73a-78201b38b425"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.env_now.env.remain_gap"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "aIRTZjAPgkW_",
        "outputId": "55d687f2-f8f7-497b-ed5d-957a6003ce82"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-c243c5b8551f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv_now\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremain_gap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'GurobiOriginalEnv' object has no attribute 'remain_gap'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.env_now.env.oldobj"
      ],
      "metadata": {
        "id": "gg-stUzCuAdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.env_now.env.newobj\n"
      ],
      "metadata": {
        "id": "kyF1UWObuLoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env.env_now.env.ip_obj"
      ],
      "metadata": {
        "id": "aPL2qJZ0nNrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OH notes:\n",
        "\n",
        "baseline is what you use to interprete the reward\n",
        "\n",
        "don't use nn, use \"mean\" of rewards in this episode (I think so)\n",
        "\n",
        "Maybe look in to the instances, and look at how your agent is solving them\n",
        "\n",
        "Cutting off early, but only after solved some LP's\n",
        "- counterfactual exploration\n",
        "  - more than to do it more random\n",
        "- all prob entirely the same\n",
        "- activation function ?\n",
        "\n",
        "not learning? \n",
        "\n",
        "reward shaping?\n",
        "- someone: amplify the reward (shouldn't, since every step wil GIVE a reward), compare it to other POSSIBLE states\n",
        "- pre-trained on the instances and pre-trained the baseline?\n",
        "- get the max reward from the LP solver (isn't this cheating lol)\n",
        "- recalcluate the max-gap-to-go (lol remaining max gap) every step\n",
        "- go in the environment to make if return the shaped new-gap reward\n",
        "- the original reward doesn't help you across LPs?\n",
        "- moving average of *returns* from all *previous* episodes\n",
        "  - return is the discounted sum of the reward\n",
        "- advantage? Q - running averaged RETURN (but different states are mixed in, how do you deal with that)\n",
        "- Think about what's wrong with this base line, and write it down\n",
        "  - something about the states\n",
        "\n",
        "\n",
        "differences between LPs\n",
        "\n",
        "mode: \n",
        "- standardize the constraints, and the b vector by itself\n",
        "  - do you normalize by row or columns?\n",
        "  - He thinks it's more sense to normalize by rows\n",
        "  - Normalize it twice? LOL\n",
        "- or a normalization layer\\\n",
        "\n",
        "\n",
        "When doing softmax you can use a lamda (parameter) to mitigate large score difference\n",
        "- softmax comes with a scalar parameter\n",
        "\n",
        "Professor didn't think normalizing the input is necessary & and it shouldn't make a difference anyways (but come numerical value can be lost after normalization)\n",
        "\n",
        "iteration: \n",
        "\n",
        "plot random policy together, (as a bseline to see if your model is really learning)\n",
        "\n",
        "For baseline, Prof is suggesting Q network can work too.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ha4GPGL8Dduc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sKnhC54KYNNL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}