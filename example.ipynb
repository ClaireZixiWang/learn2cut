{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ClaireZixiWang/learn2cut/blob/main/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## See README.md file for further details about the project and the environment.\n",
        "\n",
        "### State-Action Description\n",
        "\n",
        "### State\n",
        "State s is an array with give components\n",
        "\n",
        "* s[0]:  constraint matrix $A$of the current LP ($\\max  -c^Tx \\text{ s.t. }Ax \\le  b$) . Dimension is $m \\times n$. See by printing s[0].shape. Here $n$ is the (fixed) number of variables. For instances of size 60 by 60 used in the above command, $n$ will remain fixed as 60. And $m$ is the current number of constraints. Initially, $m$ is to the number of constraints in the IP instance. (For instances generated with --num-c=60, $m$ is 60 at the first step).  But $m$ will increase by one in every step of the episode as one new constraint (cut) is added on taking an action.\n",
        "* s[1]: rhs $b$ for the current LP ($Ax\\le b$). Dimension same as the number $m$ in matrix A.\n",
        "* s[2]: coefficient vector $c$ from the LP objective ($-c^Tx$). Dimension same as the number of variables, i.e., $n$.\n",
        "* s[3],  s[4]: Gomory cuts available in the current round of Gomory's cutting plane algorithm. Each cut $i$ is of the form $D_i x\\le d_i$.   s[3] gives the matrix $D$ (of dimension $k \\times n$) of cuts and s[4] gives the rhs $d$ (of dimension $k$). The number of cuts $k$ available in each round changes, you can find it out by printing the size of last component of state, i.e., s[4].size or s[-1].size.\n",
        "\n",
        "### Actions\n",
        "There are k=s[4].size actions available in each state $s$, with $i^{th}$ action corresponding to the $i^{th}$ cut with inequality $D_i x\\le d_i$ in $s[3], s[4]$."
      ],
      "metadata": {
        "id": "5TN-sMTvcG_9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***QUESTIONS***:\n",
        "1. By \"current\" LP, you mean the LP that the agent was running in the last state? As in, the LP with all the added constraints? \n",
        "  * ==> I think so.\n",
        "1. What do you mean Gomory cuts *available*? As in, after doing Simplex methods, the *variables* that you can choose to cut?\n",
        "  * Yes I think so.\n",
        "2. Isn't the number of variables (n) changing? in the C-G cutting plane method?\n",
        "  * No, as the spec says, **$n$ is the fixed number of variables**.\n",
        "  * If you look that cuttng plane lecture notes, you can see that after each step, the dummy variable is not added in the constraint. They are merely there for the sake of the LP solver (simplex method), but not really relevant for us.\n",
        "    * This is not correct, I think they are still very much relevant, it's just that I think among the 60 variables a lot of them are space holders for dummy variables so that our $n$ is fixed, so that we don't have to worry about using LSTM. Since each time the sequence [a, b] will be of size n+1. And we can just use a fixed-input-size network to do that.\n",
        "    * But still need to verify with the TA about the place holder understanding.\n",
        "3. dimension of s[3] and s[4]? Where is the \"available all\" stored? In which dimension?\n",
        "  * Each row of D is an \"available cut\". Therefore each $D_i x\\le d_i$ is an \"available\" cut in CG method solved from the simplex method.\n",
        "4. pointing towards the slides: why does the number of constraints m increase 1 in each step, if you can choose *multiple* cuts in one step? (OR in the algorithm we just choose one cut each time? or is that a more vanilla version to start, but to expand on multiple cuts a time later?)\n",
        "5. What do you mean by each \"instance\"?"
      ],
      "metadata": {
        "id": "XJE0bz30UL1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYROdPaaZOVa",
        "outputId": "85ddde9b-9cd9-4c0b-9b30-455ccaf50da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/IEOR_RL/Project_learn2cut\n",
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "lTnvB0_iZUrX",
        "outputId": "34edd250-848e-469b-f9d4-2611195f623c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IEOR_RL/Project_learn2cut\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/IEOR_RL/Project_learn2cut'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2o5lVAZgZmdI",
        "outputId": "ceba5d4f-b175-466a-d7fa-98eb608f77bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IEOR_RL/Project_learn2cut\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -i https://pypi.gurobi.com gurobipy"
      ],
      "metadata": {
        "id": "xSXTKB2zurrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f1790b9-56bb-4d0c-aa6e-07008370506a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.gurobi.com\n",
            "Collecting gurobipy\n",
            "  Downloading gurobipy-9.5.1-cp37-cp37m-manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.5 MB 5.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: gurobipy\n",
            "Successfully installed gurobipy-9.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qqq"
      ],
      "metadata": {
        "id": "YULy9ymNvDxN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b3c1bb-5c4f-4570-87ed-8f8d9b975a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8 MB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 46.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 66.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.6 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP model for policy model:\n",
        "#   model.forward\n",
        "#   model.train --> What is in this function? what are the function arguments?\n",
        "# Q value model\n",
        "#   Can I just use the one in Lab4? What does it mean? what does the states and actions mean? --> Print out the s, r to check\n",
        "#   What is a Q-value in our set-up?\n",
        "#   How do I used this? \n",
        "#   (What's the baseline function??)"
      ],
      "metadata": {
        "id": "ACiQz-gESgOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xI0riE6md5V",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8fc67ca0-daef-47ea-fae7-46ba7dbd16e0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mclaire-zixi-wang\u001b[0m (\u001b[33mieor4575-spring2022\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/IEOR_RL/Project_learn2cut/wandb/run-20220504_232943-2oz3zwd8</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ieor4575-spring2022/finalproject/runs/2oz3zwd8\" target=\"_blank\">holographic-fleet-1346</a></strong> to <a href=\"https://wandb.ai/ieor4575-spring2022/finalproject\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading training instances, dir instances/train_10_n60_m60 idx 0\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 1\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 2\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 3\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 4\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 5\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 6\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 7\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 8\n",
            "loading training instances, dir instances/train_10_n60_m60 idx 9\n",
            "Restricted license - for non-production use only - expires 2023-10-25\n",
            "episode 0 step 0 reward 0.04913616336898485 action space size 59 action 54\n",
            "episode 0 step 1 reward 0.009015209293920634 action space size 63 action 45\n",
            "episode 0 step 2 reward 0.018220236171600845 action space size 62 action 47\n",
            "episode 0 step 3 reward 0.0009171547822006687 action space size 62 action 49\n",
            "episode 0 step 4 reward 0.011138662568555446 action space size 64 action 42\n",
            "episode 0 step 5 reward 0.01633023805970879 action space size 65 action 20\n",
            "episode 0 step 6 reward 0.006506092983272538 action space size 66 action 45\n",
            "episode 0 step 7 reward 0.00016976311553662526 action space size 65 action 18\n",
            "episode 0 step 8 reward 0.001100911749745137 action space size 68 action 59\n",
            "episode 0 step 9 reward 0.0029006585214119696 action space size 69 action 51\n",
            "episode 0 step 10 reward 9.422131279279711e-05 action space size 69 action 12\n",
            "episode 0 step 11 reward 0.002429214048788708 action space size 72 action 62\n",
            "episode 0 step 12 reward 0.003430137388932053 action space size 73 action 53\n",
            "episode 0 step 13 reward 0.0006590101183974184 action space size 73 action 35\n",
            "episode 0 step 14 reward 0.004409479886362533 action space size 76 action 70\n",
            "episode 0 step 15 reward 0.0001259379237126268 action space size 74 action 33\n",
            "episode 0 step 16 reward 0.0017864303003989335 action space size 78 action 54\n",
            "episode 0 step 17 reward 0.00044358286231727106 action space size 76 action 50\n",
            "episode 0 step 18 reward 0.00037910402124907705 action space size 78 action 48\n",
            "episode 0 step 19 reward 0.0008226172444665281 action space size 77 action 65\n",
            "episode 0 step 20 reward 0.0015410892642648832 action space size 79 action 64\n",
            "episode 0 step 21 reward 0.0003568854749573802 action space size 79 action 26\n",
            "episode 0 step 22 reward 0.0011238928450438834 action space size 83 action 34\n",
            "episode 0 step 23 reward 2.327858874195954e-05 action space size 84 action 31\n",
            "episode 0 step 24 reward 4.414780960360076e-06 action space size 85 action 65\n",
            "episode 0 step 25 reward 1.6343974948540563e-05 action space size 85 action 11\n",
            "episode 0 step 26 reward 8.470609191135736e-05 action space size 88 action 39\n",
            "episode 0 step 27 reward 0.0007780351911605976 action space size 88 action 87\n",
            "episode 0 step 28 reward 0.0002204717461609107 action space size 86 action 76\n",
            "episode 0 step 29 reward 6.982061677263118e-06 action space size 90 action 41\n",
            "episode 0 step 30 reward 0.00014309096695797052 action space size 91 action 21\n",
            "episode 0 step 31 reward 2.425088041491108e-06 action space size 93 action 48\n",
            "episode 0 step 32 reward 0.0009622722327549127 action space size 92 action 23\n",
            "episode 0 step 33 reward 9.939796200342244e-06 action space size 94 action 1\n",
            "episode 0 step 34 reward 1.0284280961059267e-05 action space size 94 action 41\n",
            "episode 0 step 35 reward 4.080448252352653e-05 action space size 96 action 34\n",
            "episode 0 step 36 reward 7.822493444109568e-06 action space size 96 action 50\n",
            "episode 0 step 37 reward 5.891710316063836e-06 action space size 96 action 50\n",
            "episode 0 step 38 reward 2.3455454538634513e-06 action space size 97 action 71\n",
            "episode 0 step 39 reward 1.031703686749097e-05 action space size 99 action 52\n",
            "episode 0 step 40 reward 1.1799365893239155e-06 action space size 98 action 46\n",
            "episode 0 step 41 reward 1.3964095160190482e-06 action space size 102 action 39\n",
            "episode 0 step 42 reward 1.915169741550926e-05 action space size 102 action 37\n",
            "episode 0 step 43 reward 4.964160325471312e-06 action space size 103 action 13\n",
            "episode 0 step 44 reward 3.035564714082284e-05 action space size 102 action 26\n",
            "episode 0 step 45 reward 1.418934334651567e-05 action space size 106 action 100\n",
            "episode 0 step 46 reward 4.711836027126992e-06 action space size 105 action 10\n",
            "episode 0 step 47 reward 0.0010321641389055003 action space size 106 action 15\n",
            "episode 0 step 48 reward 0.00020207542547723278 action space size 108 action 55\n",
            "episode 0 step 49 reward 0.0004504784087657754 action space size 110 action 75\n",
            "episode 1 step 0 reward 0.6151751669212899 action space size 60 action 0\n",
            "episode 1 step 1 reward 2.2737367544323206e-13 action space size 58 action 48\n",
            "episode 1 step 2 reward 0.0 action space size 63 action 48\n",
            "episode 1 step 3 reward 2.2737367544323206e-13 action space size 62 action 1\n",
            "episode 1 step 4 reward 0.0 action space size 63 action 17\n",
            "episode 1 step 5 reward 2.2737367544323206e-13 action space size 65 action 18\n",
            "episode 1 step 6 reward 4.547473508864641e-13 action space size 65 action 35\n",
            "episode 1 step 7 reward 0.0 action space size 67 action 57\n",
            "episode 1 step 8 reward 2.2737367544323206e-13 action space size 69 action 12\n",
            "episode 1 step 9 reward 2.2737367544323206e-13 action space size 69 action 25\n",
            "episode 1 step 10 reward 2.2737367544323206e-13 action space size 70 action 25\n",
            "episode 1 step 11 reward 2.2737367544323206e-13 action space size 72 action 3\n",
            "episode 1 step 12 reward 4.547473508864641e-13 action space size 71 action 68\n",
            "episode 1 step 13 reward 9.094947017729282e-13 action space size 73 action 38\n",
            "episode 1 step 14 reward 6.821210263296962e-13 action space size 75 action 31\n",
            "episode 1 step 15 reward 4.547473508864641e-13 action space size 74 action 22\n",
            "episode 1 step 16 reward 6.821210263296962e-13 action space size 75 action 70\n",
            "episode 1 step 17 reward 0.0 action space size 76 action 59\n",
            "episode 1 step 18 reward 2.2737367544323206e-13 action space size 76 action 30\n",
            "episode 1 step 19 reward 6.821210263296962e-13 action space size 78 action 7\n",
            "episode 1 step 20 reward 9.094947017729282e-13 action space size 78 action 10\n",
            "episode 1 step 21 reward 6.821210263296962e-13 action space size 78 action 54\n",
            "episode 1 step 22 reward 2.2737367544323206e-13 action space size 82 action 33\n",
            "episode 1 step 23 reward 2.2737367544323206e-13 action space size 83 action 55\n",
            "episode 1 step 24 reward 2.2737367544323206e-13 action space size 83 action 31\n",
            "episode 1 step 25 reward 1.1368683772161603e-12 action space size 84 action 19\n",
            "episode 1 step 26 reward 9.094947017729282e-13 action space size 85 action 13\n",
            "episode 1 step 27 reward 4.547473508864641e-13 action space size 86 action 60\n",
            "episode 1 step 28 reward 9.094947017729282e-13 action space size 85 action 83\n",
            "episode 1 step 29 reward 4.547473508864641e-13 action space size 86 action 34\n",
            "episode 1 step 30 reward 0.0 action space size 89 action 78\n",
            "episode 1 step 31 reward 2.2737367544323206e-13 action space size 91 action 4\n",
            "episode 1 step 32 reward 0.0 action space size 91 action 7\n",
            "episode 1 step 33 reward 0.0 action space size 93 action 87\n",
            "episode 1 step 34 reward 4.547473508864641e-13 action space size 92 action 17\n",
            "episode 1 step 35 reward 4.547473508864641e-13 action space size 90 action 69\n",
            "episode 1 step 36 reward 0.0 action space size 97 action 70\n",
            "episode 1 step 37 reward 4.547473508864641e-13 action space size 95 action 20\n",
            "episode 1 step 38 reward 0.0 action space size 96 action 78\n",
            "episode 1 step 39 reward 4.547473508864641e-13 action space size 97 action 49\n",
            "episode 1 step 40 reward 2.2737367544323206e-13 action space size 101 action 48\n",
            "episode 1 step 41 reward 2.2737367544323206e-13 action space size 99 action 34\n",
            "episode 1 step 42 reward 2.2737367544323206e-13 action space size 97 action 8\n",
            "episode 1 step 43 reward 0.0 action space size 103 action 32\n",
            "episode 1 step 44 reward 2.2737367544323206e-13 action space size 105 action 84\n",
            "episode 1 step 45 reward 2.2737367544323206e-13 action space size 101 action 36\n",
            "episode 1 step 46 reward 6.821210263296962e-13 action space size 106 action 50\n",
            "episode 1 step 47 reward 2.2737367544323206e-13 action space size 106 action 73\n",
            "episode 1 step 48 reward 6.821210263296962e-13 action space size 107 action 80\n",
            "episode 1 step 49 reward 4.547473508864641e-13 action space size 108 action 46\n",
            "episode 2 step 0 reward 8.52804005262442e-05 action space size 62 action 29\n",
            "episode 2 step 1 reward 8.338905035998323e-05 action space size 62 action 28\n",
            "episode 2 step 2 reward 2.0854164176853374e-05 action space size 61 action 11\n",
            "episode 2 step 3 reward 2.9967142381792655e-05 action space size 63 action 30\n",
            "episode 2 step 4 reward 0.003449138772793958 action space size 62 action 7\n",
            "episode 2 step 5 reward 0.11168045232125223 action space size 66 action 0\n",
            "episode 2 step 6 reward 0.0 action space size 66 action 46\n",
            "episode 2 step 7 reward 9.094947017729282e-13 action space size 67 action 19\n",
            "episode 2 step 8 reward 9.094947017729282e-13 action space size 64 action 43\n",
            "episode 2 step 9 reward 4.547473508864641e-13 action space size 70 action 58\n",
            "episode 2 step 10 reward 1.3642420526593924e-12 action space size 70 action 48\n",
            "episode 2 step 11 reward 4.547473508864641e-13 action space size 71 action 53\n",
            "episode 2 step 12 reward 4.547473508864641e-13 action space size 70 action 54\n",
            "episode 2 step 13 reward 0.0 action space size 74 action 62\n",
            "episode 2 step 14 reward 0.0 action space size 72 action 39\n",
            "episode 2 step 15 reward 0.0 action space size 73 action 40\n",
            "episode 2 step 16 reward 0.0 action space size 75 action 19\n",
            "episode 2 step 17 reward 4.547473508864641e-13 action space size 75 action 70\n",
            "episode 2 step 18 reward 4.547473508864641e-13 action space size 79 action 46\n",
            "episode 2 step 19 reward 4.547473508864641e-13 action space size 75 action 12\n",
            "episode 2 step 20 reward 4.547473508864641e-13 action space size 77 action 20\n",
            "episode 2 step 21 reward 0.0 action space size 79 action 60\n",
            "episode 2 step 22 reward 0.0 action space size 83 action 12\n",
            "episode 2 step 23 reward 0.0 action space size 79 action 77\n",
            "episode 2 step 24 reward 0.0 action space size 85 action 28\n",
            "episode 2 step 25 reward 0.0 action space size 83 action 28\n",
            "episode 2 step 26 reward 0.0 action space size 86 action 48\n",
            "episode 2 step 27 reward 4.547473508864641e-13 action space size 86 action 73\n",
            "episode 2 step 28 reward 9.094947017729282e-13 action space size 88 action 61\n",
            "episode 2 step 29 reward 9.094947017729282e-13 action space size 89 action 0\n",
            "episode 2 step 30 reward 4.547473508864641e-13 action space size 89 action 37\n",
            "episode 2 step 31 reward 0.0 action space size 89 action 67\n",
            "episode 2 step 32 reward 0.0 action space size 92 action 69\n",
            "episode 2 step 33 reward 4.547473508864641e-13 action space size 92 action 30\n",
            "episode 2 step 34 reward 4.547473508864641e-13 action space size 94 action 19\n",
            "episode 2 step 35 reward 0.0 action space size 95 action 60\n",
            "episode 2 step 36 reward 4.547473508864641e-13 action space size 96 action 9\n",
            "episode 2 step 37 reward 4.547473508864641e-13 action space size 97 action 14\n",
            "episode 2 step 38 reward 0.0 action space size 95 action 55\n",
            "episode 2 step 39 reward 0.0 action space size 99 action 20\n",
            "episode 2 step 40 reward 0.0 action space size 97 action 31\n",
            "episode 2 step 41 reward 0.0 action space size 101 action 27\n",
            "episode 2 step 42 reward 4.547473508864641e-13 action space size 102 action 76\n",
            "episode 2 step 43 reward 4.547473508864641e-13 action space size 103 action 89\n",
            "episode 2 step 44 reward 0.0 action space size 104 action 57\n",
            "episode 2 step 45 reward 0.0 action space size 103 action 102\n",
            "episode 2 step 46 reward 0.0 action space size 106 action 43\n",
            "episode 2 step 47 reward 0.0 action space size 105 action 16\n",
            "episode 2 step 48 reward 4.547473508864641e-13 action space size 107 action 46\n",
            "episode 2 step 49 reward 9.094947017729282e-13 action space size 108 action 22\n",
            "episode 3 step 0 reward 0.005665076272634906 action space size 59 action 32\n",
            "episode 3 step 1 reward 0.003077497198319179 action space size 63 action 35\n",
            "episode 3 step 2 reward 0.004285621843791887 action space size 61 action 56\n",
            "episode 3 step 3 reward 0.000796548934886232 action space size 63 action 17\n",
            "episode 3 step 4 reward 0.0056719017852628895 action space size 66 action 5\n",
            "episode 3 step 5 reward 0.0016135853193190997 action space size 64 action 42\n",
            "episode 3 step 6 reward 0.0013926594560871308 action space size 68 action 31\n",
            "episode 3 step 7 reward 8.177664813047159e-05 action space size 69 action 38\n",
            "episode 3 step 8 reward 0.0054415822105511324 action space size 68 action 49\n",
            "episode 3 step 9 reward 8.40259908727603e-05 action space size 71 action 38\n",
            "episode 3 step 10 reward 0.0008144511311911629 action space size 71 action 17\n",
            "episode 3 step 11 reward 0.00047195040269798483 action space size 72 action 23\n",
            "episode 3 step 12 reward 0.0010857402403416927 action space size 68 action 25\n",
            "episode 3 step 13 reward 0.0006426914178518928 action space size 74 action 32\n",
            "episode 3 step 14 reward 0.004704055061665713 action space size 72 action 21\n",
            "episode 3 step 15 reward 0.0006946284961486526 action space size 75 action 18\n",
            "episode 3 step 16 reward 0.0025813024440139998 action space size 76 action 10\n",
            "episode 3 step 17 reward 0.00022301780791167403 action space size 74 action 48\n",
            "episode 3 step 18 reward 9.443989210922155e-05 action space size 77 action 33\n",
            "episode 3 step 19 reward 0.00021989007746014977 action space size 80 action 3\n",
            "episode 3 step 20 reward 0.0002466601467858709 action space size 81 action 63\n",
            "episode 3 step 21 reward 0.0012094359990442172 action space size 80 action 3\n",
            "episode 3 step 22 reward 0.0014906014557709568 action space size 81 action 76\n",
            "episode 3 step 23 reward 3.315995945740724e-05 action space size 83 action 63\n",
            "episode 3 step 24 reward 0.0005844170927957748 action space size 82 action 16\n",
            "episode 3 step 25 reward 0.0007280590511982155 action space size 83 action 52\n",
            "episode 3 step 26 reward 0.00015535634111074614 action space size 87 action 68\n",
            "episode 3 step 27 reward 0.00044391961318979156 action space size 87 action 23\n",
            "episode 3 step 28 reward 0.00021331767720766948 action space size 88 action 66\n",
            "episode 3 step 29 reward 0.00022669668987873592 action space size 89 action 74\n",
            "episode 3 step 30 reward 0.004819987505015888 action space size 89 action 86\n",
            "episode 3 step 31 reward 3.0005894586793147e-05 action space size 89 action 56\n",
            "episode 3 step 32 reward 3.0738406167074572e-06 action space size 94 action 60\n",
            "episode 3 step 33 reward 2.3190738829725888e-05 action space size 93 action 52\n",
            "episode 3 step 34 reward 3.773482239921577e-05 action space size 91 action 54\n",
            "episode 3 step 35 reward 3.306113694634405e-05 action space size 95 action 11\n",
            "episode 3 step 36 reward 6.146891155367484e-05 action space size 96 action 18\n",
            "episode 3 step 37 reward 1.2004131349385716e-05 action space size 99 action 74\n",
            "episode 3 step 38 reward 0.00017960299010155722 action space size 97 action 43\n",
            "episode 3 step 39 reward 1.1879767498612637e-05 action space size 100 action 78\n",
            "episode 3 step 40 reward 6.162363570183516e-05 action space size 100 action 26\n",
            "episode 3 step 41 reward 0.001823638590394694 action space size 102 action 64\n",
            "episode 3 step 42 reward 0.0005047942358942237 action space size 102 action 82\n",
            "episode 3 step 43 reward 0.0008405193561884516 action space size 102 action 40\n",
            "episode 3 step 44 reward 2.7572194994718302e-05 action space size 105 action 31\n",
            "episode 3 step 45 reward 6.503461872853222e-05 action space size 102 action 103\n",
            "episode 3 step 46 reward 0.00036607503488994553 action space size 107 action 44\n",
            "episode 3 step 47 reward 0.0013346124587769737 action space size 105 action 74\n",
            "episode 3 step 48 reward 0.0010168411890845164 action space size 109 action 17\n",
            "episode 3 step 49 reward 3.35696390720841e-05 action space size 108 action 26\n",
            "episode 4 step 0 reward 0.01984363312089954 action space size 61 action 21\n",
            "episode 4 step 1 reward 0.007690874761919986 action space size 61 action 54\n",
            "episode 4 step 2 reward 0.02053914961220471 action space size 63 action 42\n",
            "episode 4 step 3 reward 0.013126877204967968 action space size 61 action 24\n",
            "episode 4 step 4 reward 0.03504536183027085 action space size 65 action 38\n",
            "episode 4 step 5 reward 0.0055202651899435295 action space size 66 action 4\n",
            "episode 4 step 6 reward 0.002476551720974385 action space size 65 action 21\n",
            "episode 4 step 7 reward 0.0024330504691079113 action space size 68 action 62\n",
            "episode 4 step 8 reward 0.002373431878595511 action space size 69 action 45\n",
            "episode 4 step 9 reward 0.021777676779265676 action space size 71 action 40\n",
            "episode 4 step 10 reward 0.0010295366541868134 action space size 70 action 60\n",
            "episode 4 step 11 reward 0.009155797415132838 action space size 71 action 38\n",
            "episode 4 step 12 reward 0.00428319164120694 action space size 73 action 54\n",
            "episode 4 step 13 reward 0.0002611351042105525 action space size 75 action 21\n",
            "episode 4 step 14 reward 0.00026408994176563283 action space size 76 action 27\n",
            "episode 4 step 15 reward 0.002964388396776485 action space size 74 action 23\n",
            "episode 4 step 16 reward 0.002015803378299097 action space size 77 action 33\n",
            "episode 4 step 17 reward 0.0021561021492289 action space size 78 action 46\n",
            "episode 4 step 18 reward 0.00112228346347365 action space size 80 action 35\n",
            "episode 4 step 19 reward 0.0014899442380738037 action space size 78 action 31\n",
            "episode 4 step 20 reward 0.00048143226899810543 action space size 82 action 18\n",
            "episode 4 step 21 reward 0.000978960659722361 action space size 82 action 73\n",
            "episode 4 step 22 reward 0.0011280924568382034 action space size 83 action 24\n",
            "episode 4 step 23 reward 0.0011544206577127625 action space size 82 action 1\n",
            "episode 4 step 24 reward 0.002304103299820781 action space size 85 action 67\n",
            "episode 4 step 25 reward 4.038367728753656e-05 action space size 84 action 7\n",
            "episode 4 step 26 reward 0.0011611003280904697 action space size 85 action 40\n",
            "episode 4 step 27 reward 0.0025101976304995333 action space size 88 action 83\n",
            "episode 4 step 28 reward 0.0004231596519730374 action space size 87 action 81\n",
            "episode 4 step 29 reward 0.0005883977769371995 action space size 90 action 43\n",
            "episode 4 step 30 reward 0.005201582800054894 action space size 89 action 45\n",
            "episode 4 step 31 reward 0.0008526424535375554 action space size 93 action 57\n",
            "episode 4 step 32 reward 0.003513292403340529 action space size 93 action 74\n",
            "episode 4 step 33 reward 0.007124803608348884 action space size 91 action 6\n",
            "episode 4 step 34 reward 2.929791298811324e-05 action space size 93 action 53\n",
            "episode 4 step 35 reward 0.0013727952907629515 action space size 96 action 46\n",
            "episode 4 step 36 reward 0.004393909965983767 action space size 98 action 20\n",
            "episode 4 step 37 reward 0.0012025202770473697 action space size 97 action 60\n",
            "episode 4 step 38 reward 0.0005803822084544663 action space size 99 action 15\n",
            "episode 4 step 39 reward 0.0009905661477205285 action space size 101 action 85\n",
            "episode 4 step 40 reward 0.0019843426211991755 action space size 100 action 93\n",
            "episode 4 step 41 reward 0.0005136032646078093 action space size 100 action 65\n",
            "episode 4 step 42 reward 1.1631834922809503e-05 action space size 104 action 45\n",
            "episode 4 step 43 reward 0.0004970898428382498 action space size 103 action 62\n",
            "episode 4 step 44 reward 0.0008443023114068637 action space size 103 action 92\n",
            "episode 4 step 45 reward 2.085741175505973e-05 action space size 105 action 79\n",
            "episode 4 step 46 reward 0.00014810172183388204 action space size 106 action 61\n",
            "episode 4 step 47 reward 0.0011997939745924668 action space size 104 action 56\n",
            "episode 4 step 48 reward 0.0005329859752691846 action space size 108 action 64\n",
            "episode 4 step 49 reward 2.512532773835119e-05 action space size 108 action 79\n",
            "episode 5 step 0 reward 0.1059210658545453 action space size 61 action 30\n",
            "episode 5 step 1 reward 0.03361605837858406 action space size 60 action 60\n",
            "episode 5 step 2 reward 0.004557373539000764 action space size 62 action 44\n",
            "episode 5 step 3 reward 0.03577877189241008 action space size 63 action 12\n",
            "episode 5 step 4 reward 0.0006612265460717026 action space size 66 action 48\n",
            "episode 5 step 5 reward 0.001433820339570957 action space size 66 action 9\n",
            "episode 5 step 6 reward 0.00034695067893153464 action space size 63 action 3\n",
            "episode 5 step 7 reward 0.007385561439377852 action space size 69 action 61\n",
            "episode 5 step 8 reward 0.002669855174872282 action space size 69 action 65\n",
            "episode 5 step 9 reward 0.0077171262419142295 action space size 69 action 3\n",
            "episode 5 step 10 reward 0.00011230218728996988 action space size 71 action 57\n",
            "episode 5 step 11 reward 0.0012145801088081498 action space size 72 action 51\n",
            "episode 5 step 12 reward 0.00201324492331878 action space size 73 action 35\n",
            "episode 5 step 13 reward 0.0005745725504766597 action space size 75 action 54\n",
            "episode 5 step 14 reward 1.4018738283994026e-05 action space size 73 action 58\n",
            "episode 5 step 15 reward 2.7283233521302463e-06 action space size 74 action 40\n",
            "episode 5 step 16 reward 0.0014637717690675345 action space size 76 action 38\n",
            "episode 5 step 17 reward 0.002248784133598747 action space size 79 action 21\n",
            "episode 5 step 18 reward 0.0005038785450324212 action space size 80 action 11\n",
            "episode 5 step 19 reward 0.00047276183158828644 action space size 80 action 45\n",
            "episode 5 step 20 reward 0.0008816808747269533 action space size 81 action 26\n",
            "episode 5 step 21 reward 0.0009797248362701794 action space size 79 action 48\n",
            "episode 5 step 22 reward 0.0007681173160563048 action space size 81 action 11\n",
            "episode 5 step 23 reward 0.0004437017148575251 action space size 83 action 21\n",
            "episode 5 step 24 reward 0.00024827775632729754 action space size 83 action 81\n",
            "episode 5 step 25 reward 5.461810133056133e-06 action space size 85 action 65\n",
            "episode 5 step 26 reward 0.0001863571392277663 action space size 85 action 23\n",
            "episode 5 step 27 reward 0.00010442826192047505 action space size 84 action 58\n",
            "episode 5 step 28 reward 4.594863207785238e-05 action space size 86 action 78\n",
            "episode 5 step 29 reward 2.8306041031100904e-05 action space size 89 action 63\n",
            "episode 5 step 30 reward 1.3645057606481714e-05 action space size 89 action 76\n",
            "episode 5 step 31 reward 0.0002540294899517903 action space size 92 action 58\n",
            "episode 5 step 32 reward 0.0003530893245624611 action space size 92 action 90\n",
            "episode 5 step 33 reward 0.0002029273118751007 action space size 93 action 22\n",
            "episode 5 step 34 reward 1.015200018628093e-05 action space size 94 action 41\n",
            "episode 5 step 35 reward 0.0001639722861455084 action space size 97 action 18\n",
            "episode 5 step 36 reward 0.0001493688046139141 action space size 96 action 68\n",
            "episode 5 step 37 reward 6.850709314676351e-05 action space size 95 action 33\n",
            "episode 5 step 38 reward 0.00015781949878146406 action space size 98 action 15\n",
            "episode 5 step 39 reward 9.78438947640825e-07 action space size 99 action 51\n",
            "episode 5 step 40 reward 6.241081450752972e-05 action space size 100 action 73\n",
            "episode 5 step 41 reward 2.893983628382557e-05 action space size 102 action 34\n",
            "episode 5 step 42 reward 1.1355761671438813e-05 action space size 103 action 67\n",
            "episode 5 step 43 reward 1.4239749134503654e-05 action space size 105 action 94\n",
            "episode 5 step 44 reward 8.060642176133115e-05 action space size 106 action 28\n",
            "episode 5 step 45 reward 4.180318228463875e-06 action space size 105 action 2\n",
            "episode 5 step 46 reward 1.6653298189339694e-06 action space size 104 action 39\n",
            "episode 5 step 47 reward 2.969580373246572e-05 action space size 108 action 7\n",
            "episode 5 step 48 reward 7.129064670152729e-06 action space size 108 action 69\n",
            "episode 5 step 49 reward 1.8584417148304055e-05 action space size 110 action 64\n",
            "episode 6 step 0 reward 0.0041847917314044025 action space size 60 action 13\n",
            "episode 6 step 1 reward 0.0003538057180776377 action space size 62 action 32\n",
            "episode 6 step 2 reward 0.00031483369320994825 action space size 63 action 24\n",
            "episode 6 step 3 reward 0.03480070040905048 action space size 65 action 25\n",
            "episode 6 step 4 reward 0.003217632187443087 action space size 64 action 21\n",
            "episode 6 step 5 reward 0.006957585407235456 action space size 66 action 48\n",
            "episode 6 step 6 reward 0.00013377925961322035 action space size 66 action 50\n",
            "episode 6 step 7 reward 0.00015930695144561469 action space size 67 action 36\n",
            "episode 6 step 8 reward 0.001685655884557491 action space size 68 action 29\n",
            "episode 6 step 9 reward 0.007544909768512298 action space size 71 action 60\n",
            "episode 6 step 10 reward 0.0026701312099248753 action space size 72 action 63\n",
            "episode 6 step 11 reward 5.026877215641434e-05 action space size 73 action 54\n",
            "episode 6 step 12 reward 0.0002780547806651157 action space size 73 action 13\n",
            "episode 6 step 13 reward 0.0002310125983058242 action space size 73 action 2\n",
            "episode 6 step 14 reward 0.0008684184967933106 action space size 76 action 32\n",
            "episode 6 step 15 reward 0.0034755168958326976 action space size 76 action 39\n",
            "episode 6 step 16 reward 0.0005094744569760223 action space size 77 action 50\n",
            "episode 6 step 17 reward 0.004180902442385559 action space size 78 action 1\n",
            "episode 6 step 18 reward 0.007233489514874236 action space size 79 action 30\n",
            "episode 6 step 19 reward 0.0037688028405682417 action space size 78 action 76\n",
            "episode 6 step 20 reward 0.0030706433244631626 action space size 77 action 36\n",
            "episode 6 step 21 reward 0.00039058500578903477 action space size 82 action 31\n",
            "episode 6 step 22 reward 5.5561245517310454e-05 action space size 80 action 24\n",
            "episode 6 step 23 reward 0.0009352444658361492 action space size 84 action 69\n",
            "episode 6 step 24 reward 0.0010476069724063564 action space size 85 action 25\n",
            "episode 6 step 25 reward 0.0007948452384880511 action space size 86 action 78\n",
            "episode 6 step 26 reward 0.001124097604133567 action space size 87 action 76\n",
            "episode 6 step 27 reward 0.6122231973054113 action space size 86 action 0\n",
            "episode 6 step 28 reward 4.547473508864641e-13 action space size 88 action 80\n",
            "episode 6 step 29 reward 4.547473508864641e-13 action space size 88 action 70\n",
            "episode 6 step 30 reward 4.547473508864641e-13 action space size 89 action 48\n",
            "episode 6 step 31 reward 4.547473508864641e-13 action space size 91 action 10\n",
            "episode 6 step 32 reward 4.547473508864641e-13 action space size 93 action 3\n",
            "episode 6 step 33 reward 4.547473508864641e-13 action space size 90 action 17\n",
            "episode 6 step 34 reward 4.547473508864641e-13 action space size 92 action 30\n",
            "episode 6 step 35 reward 4.547473508864641e-13 action space size 91 action 4\n",
            "episode 6 step 36 reward 0.0 action space size 92 action 7\n",
            "episode 6 step 37 reward 0.0 action space size 94 action 70\n",
            "episode 6 step 38 reward 0.0 action space size 98 action 3\n",
            "episode 6 step 39 reward 4.547473508864641e-13 action space size 99 action 77\n",
            "episode 6 step 40 reward 4.547473508864641e-13 action space size 101 action 70\n",
            "episode 6 step 41 reward 0.0 action space size 101 action 81\n",
            "episode 6 step 42 reward 0.0 action space size 102 action 77\n",
            "episode 6 step 43 reward 0.0 action space size 102 action 0\n",
            "episode 6 step 44 reward 0.0 action space size 102 action 76\n",
            "episode 6 step 45 reward 4.547473508864641e-13 action space size 100 action 45\n",
            "episode 6 step 46 reward 4.547473508864641e-13 action space size 103 action 69\n",
            "episode 6 step 47 reward 0.0 action space size 107 action 33\n",
            "episode 6 step 48 reward 0.0 action space size 108 action 31\n",
            "episode 6 step 49 reward 0.0 action space size 109 action 38\n",
            "episode 7 step 0 reward 0.01998220491623215 action space size 61 action 51\n",
            "episode 7 step 1 reward 0.009674699454080837 action space size 61 action 39\n",
            "episode 7 step 2 reward 0.0021618096479869564 action space size 62 action 50\n",
            "episode 7 step 3 reward 0.008391435204430309 action space size 63 action 23\n",
            "episode 7 step 4 reward 0.009442829888939741 action space size 62 action 15\n",
            "episode 7 step 5 reward 0.0026956890051224036 action space size 67 action 20\n",
            "episode 7 step 6 reward 0.018044207533876033 action space size 65 action 48\n",
            "episode 7 step 7 reward 0.0008137671325130214 action space size 68 action 48\n",
            "episode 7 step 8 reward 5.3971986744727474e-05 action space size 68 action 2\n",
            "episode 7 step 9 reward 0.0008378622342206654 action space size 70 action 26\n",
            "episode 7 step 10 reward 0.009364399168134696 action space size 71 action 67\n",
            "episode 7 step 11 reward 0.001007299477350898 action space size 72 action 1\n",
            "episode 7 step 12 reward 3.933231255359715e-05 action space size 73 action 24\n",
            "episode 7 step 13 reward 0.0005600629760920128 action space size 73 action 3\n",
            "episode 7 step 14 reward 0.0019162116450388567 action space size 73 action 37\n",
            "episode 7 step 15 reward 0.001001664539671765 action space size 76 action 29\n",
            "episode 7 step 16 reward 0.002985160188472946 action space size 78 action 39\n",
            "episode 7 step 17 reward 0.0005213290100982704 action space size 79 action 49\n",
            "episode 7 step 18 reward 0.0011423536043366767 action space size 78 action 27\n",
            "episode 7 step 19 reward 0.0012410303916112753 action space size 80 action 52\n",
            "episode 7 step 20 reward 0.00036914256588715944 action space size 82 action 47\n",
            "episode 7 step 21 reward 4.461087428353494e-05 action space size 80 action 30\n",
            "episode 7 step 22 reward 0.0002179930042984779 action space size 83 action 26\n",
            "episode 7 step 23 reward 0.0010493568802303344 action space size 83 action 45\n",
            "episode 7 step 24 reward 0.0001435678796042339 action space size 84 action 45\n",
            "episode 7 step 25 reward 2.2418214939534664e-05 action space size 87 action 13\n",
            "episode 7 step 26 reward 5.9986945871060016e-05 action space size 86 action 46\n",
            "episode 7 step 27 reward 3.478276221358101e-05 action space size 88 action 72\n",
            "episode 7 step 28 reward 2.3551974663860165e-05 action space size 89 action 70\n",
            "episode 7 step 29 reward 9.556118038744899e-05 action space size 89 action 65\n",
            "episode 7 step 30 reward 2.316829068149673e-06 action space size 90 action 41\n",
            "episode 7 step 31 reward 3.6585278394341e-05 action space size 92 action 53\n",
            "episode 7 step 32 reward 2.8419082809705287e-05 action space size 92 action 77\n",
            "episode 7 step 33 reward 3.316239781270269e-05 action space size 91 action 70\n",
            "episode 7 step 34 reward 1.2248275197634939e-05 action space size 95 action 60\n",
            "episode 7 step 35 reward 8.753627298574429e-06 action space size 94 action 64\n",
            "episode 7 step 36 reward 1.5794240425748285e-05 action space size 96 action 26\n",
            "episode 7 step 37 reward 0.0005590939367721148 action space size 97 action 28\n",
            "episode 7 step 38 reward 9.166798008664045e-06 action space size 97 action 35\n",
            "episode 7 step 39 reward 1.2267273632460274e-05 action space size 95 action 93\n",
            "episode 7 step 40 reward 1.7936574749910505e-05 action space size 100 action 45\n",
            "episode 7 step 41 reward 0.00020671037782449275 action space size 99 action 29\n",
            "episode 7 step 42 reward 0.00021102692335261963 action space size 104 action 40\n",
            "episode 7 step 43 reward 2.363990915910108e-05 action space size 103 action 2\n",
            "episode 7 step 44 reward 8.00821994744183e-05 action space size 102 action 16\n",
            "episode 7 step 45 reward 5.784445420431439e-07 action space size 106 action 14\n",
            "episode 7 step 46 reward 3.784261525652255e-05 action space size 107 action 88\n",
            "episode 7 step 47 reward 2.210106686106883e-06 action space size 107 action 39\n",
            "episode 7 step 48 reward 8.52801763358002e-05 action space size 110 action 75\n",
            "episode 7 step 49 reward 4.2477122406126e-06 action space size 111 action 93\n",
            "episode 8 step 0 reward 0.00017956798865270684 action space size 61 action 36\n",
            "episode 8 step 1 reward 0.025329350203719514 action space size 62 action 11\n",
            "episode 8 step 2 reward 0.00039728190404275665 action space size 64 action 23\n",
            "episode 8 step 3 reward 0.017704048892937863 action space size 65 action 2\n",
            "episode 8 step 4 reward 0.0039822418507355906 action space size 66 action 50\n",
            "episode 8 step 5 reward 0.0004176862971689843 action space size 62 action 60\n",
            "episode 8 step 6 reward 0.0028452759888750734 action space size 67 action 23\n",
            "episode 8 step 7 reward 0.0004860663148065214 action space size 69 action 58\n",
            "episode 8 step 8 reward 0.0030048349185562984 action space size 69 action 24\n",
            "episode 8 step 9 reward 0.002143615236036567 action space size 70 action 65\n",
            "episode 8 step 10 reward 2.475740075169597e-07 action space size 70 action 31\n",
            "episode 8 step 11 reward 1.6667195268382784e-06 action space size 71 action 16\n",
            "episode 8 step 12 reward 1.0393322554591578e-05 action space size 72 action 70\n",
            "episode 8 step 13 reward 0.004716488678695896 action space size 73 action 63\n",
            "episode 8 step 14 reward 0.00010289024521625834 action space size 74 action 19\n",
            "episode 8 step 15 reward 0.0004998496256121143 action space size 75 action 17\n",
            "episode 8 step 16 reward 0.00033771495009204955 action space size 78 action 24\n",
            "episode 8 step 17 reward 0.00018803798639055458 action space size 79 action 34\n",
            "episode 8 step 18 reward 0.0011250174325141415 action space size 75 action 77\n",
            "episode 8 step 19 reward 0.0006225609545253974 action space size 79 action 27\n",
            "episode 8 step 20 reward 0.0046228734740907385 action space size 80 action 66\n",
            "episode 8 step 21 reward 0.001183667937766586 action space size 81 action 59\n",
            "episode 8 step 22 reward 0.00015329481175285764 action space size 82 action 62\n",
            "episode 8 step 23 reward 0.00025643623530413606 action space size 84 action 73\n",
            "episode 8 step 24 reward 0.001771331826603273 action space size 86 action 13\n",
            "episode 8 step 25 reward 0.00020319001077950816 action space size 86 action 34\n",
            "episode 8 step 26 reward 0.0010135867978533497 action space size 86 action 70\n",
            "episode 8 step 27 reward 8.9709742951527e-05 action space size 87 action 35\n",
            "episode 8 step 28 reward 0.00017990832247960498 action space size 87 action 79\n",
            "episode 8 step 29 reward 0.0004875950494351855 action space size 89 action 62\n",
            "episode 8 step 30 reward 0.00018206346840088372 action space size 88 action 60\n",
            "episode 8 step 31 reward 2.9163020826672437e-05 action space size 87 action 72\n",
            "episode 8 step 32 reward 0.00010117276087839855 action space size 91 action 4\n",
            "episode 8 step 33 reward 0.0005991803782308125 action space size 90 action 10\n",
            "episode 8 step 34 reward 0.0012620499996955914 action space size 93 action 65\n",
            "episode 8 step 35 reward 1.1665812962746713e-05 action space size 95 action 88\n",
            "episode 8 step 36 reward 3.3463755244156346e-05 action space size 98 action 93\n",
            "episode 8 step 37 reward 8.717335913388524e-05 action space size 99 action 25\n",
            "episode 8 step 38 reward 6.010389370203484e-06 action space size 99 action 46\n",
            "episode 8 step 39 reward 0.00026270418220519787 action space size 100 action 37\n",
            "episode 8 step 40 reward 0.0003783626552831265 action space size 97 action 28\n",
            "episode 8 step 41 reward 0.00012296077102291747 action space size 101 action 27\n",
            "episode 8 step 42 reward 2.956922344310442e-06 action space size 101 action 98\n",
            "episode 8 step 43 reward 2.546450241425191e-05 action space size 101 action 22\n",
            "episode 8 step 44 reward 1.0710928108892404e-06 action space size 103 action 42\n",
            "episode 8 step 45 reward 3.138005877190153e-05 action space size 105 action 26\n",
            "episode 8 step 46 reward 4.6113204007269815e-05 action space size 106 action 102\n",
            "episode 8 step 47 reward 5.5756485380697995e-05 action space size 107 action 69\n",
            "episode 8 step 48 reward 0.0001122649423450639 action space size 104 action 21\n",
            "episode 8 step 49 reward 0.00011725770445991657 action space size 109 action 43\n",
            "episode 9 step 0 reward 0.023634381345573274 action space size 62 action 13\n",
            "episode 9 step 1 reward 0.005808910749237839 action space size 62 action 55\n",
            "episode 9 step 2 reward 0.0027290193561384513 action space size 59 action 32\n",
            "episode 9 step 3 reward 0.0015622026405708311 action space size 63 action 4\n",
            "episode 9 step 4 reward 0.006045935205293063 action space size 64 action 18\n",
            "episode 9 step 5 reward 0.002160249891176136 action space size 65 action 59\n",
            "episode 9 step 6 reward 7.240041668410413e-07 action space size 66 action 12\n",
            "episode 9 step 7 reward 7.734392579550331e-05 action space size 68 action 47\n",
            "episode 9 step 8 reward 0.002062037845462328 action space size 68 action 17\n",
            "episode 9 step 9 reward 0.00229746363720551 action space size 68 action 43\n",
            "episode 9 step 10 reward 0.0019303581527765346 action space size 70 action 33\n",
            "episode 9 step 11 reward 0.0012393786037137033 action space size 72 action 16\n",
            "episode 9 step 12 reward 0.00044868778832096723 action space size 71 action 30\n",
            "episode 9 step 13 reward 0.00028432675389922224 action space size 74 action 11\n",
            "episode 9 step 14 reward 0.0008249938020981062 action space size 75 action 4\n",
            "episode 9 step 15 reward 0.000500250993809459 action space size 76 action 52\n",
            "episode 9 step 16 reward 1.790767259990389e-05 action space size 74 action 17\n",
            "episode 9 step 17 reward 0.0016578204881625425 action space size 78 action 29\n",
            "episode 9 step 18 reward 0.0023878082413375523 action space size 78 action 6\n",
            "episode 9 step 19 reward 0.0019293061739062978 action space size 80 action 37\n",
            "episode 9 step 20 reward 0.007389403603838218 action space size 79 action 8\n",
            "episode 9 step 21 reward 0.0003763848790185875 action space size 83 action 45\n",
            "episode 9 step 22 reward 0.012470464705984341 action space size 81 action 81\n",
            "episode 9 step 23 reward 0.0015412447141898156 action space size 82 action 27\n",
            "episode 9 step 24 reward 0.0005152577439275774 action space size 83 action 38\n",
            "episode 9 step 25 reward 1.0575375426924438e-05 action space size 87 action 26\n",
            "episode 9 step 26 reward 0.00027511668213264784 action space size 86 action 26\n",
            "episode 9 step 27 reward 0.00319757080387717 action space size 89 action 47\n",
            "episode 9 step 28 reward 0.0014507413632145472 action space size 88 action 3\n",
            "episode 9 step 29 reward 0.0005643787917506415 action space size 88 action 22\n",
            "episode 9 step 30 reward 3.943491947211442e-06 action space size 89 action 68\n",
            "episode 9 step 31 reward 0.0008303661281843233 action space size 92 action 6\n",
            "episode 9 step 32 reward 3.769282238863525e-05 action space size 94 action 5\n",
            "episode 9 step 33 reward 0.0001350372194792726 action space size 92 action 52\n",
            "episode 9 step 34 reward 2.5698680019559106e-05 action space size 96 action 80\n",
            "episode 9 step 35 reward 0.00013928700627729995 action space size 97 action 44\n",
            "episode 9 step 36 reward 1.814675897549023e-05 action space size 97 action 51\n",
            "episode 9 step 37 reward 1.6910303202166688e-07 action space size 97 action 75\n",
            "episode 9 step 38 reward 3.656522267192486e-05 action space size 100 action 43\n",
            "episode 9 step 39 reward 0.00020987049424547877 action space size 99 action 51\n",
            "episode 9 step 40 reward 9.681699793873122e-05 action space size 99 action 63\n",
            "episode 9 step 41 reward 1.2572502100738348e-05 action space size 103 action 56\n",
            "episode 9 step 42 reward 5.777947080787271e-06 action space size 103 action 2\n",
            "episode 9 step 43 reward 7.12281967025774e-05 action space size 104 action 31\n",
            "episode 9 step 44 reward 5.057250655227108e-05 action space size 102 action 32\n",
            "episode 9 step 45 reward 6.519682870020915e-05 action space size 106 action 9\n",
            "episode 9 step 46 reward 2.892616066674236e-07 action space size 108 action 21\n",
            "episode 9 step 47 reward 1.5456143955816515e-06 action space size 106 action 55\n",
            "episode 9 step 48 reward 3.428864965826506e-05 action space size 106 action 27\n",
            "episode 9 step 49 reward 2.632089763210388e-05 action space size 109 action 83\n",
            "episode 10 step 0 reward 0.06206298983806846 action space size 61 action 14\n",
            "episode 10 step 1 reward 0.002428535947274213 action space size 59 action 38\n",
            "episode 10 step 2 reward 0.029035054525593296 action space size 64 action 1\n",
            "episode 10 step 3 reward 0.005998930366331479 action space size 64 action 46\n",
            "episode 10 step 4 reward 0.0012132593228670885 action space size 62 action 10\n",
            "episode 10 step 5 reward 0.0028963525819563074 action space size 65 action 26\n",
            "episode 10 step 6 reward 0.004610720476193819 action space size 68 action 32\n",
            "episode 10 step 7 reward 0.0023299558165490453 action space size 69 action 63\n",
            "episode 10 step 8 reward 0.007565041567431763 action space size 68 action 32\n",
            "episode 10 step 9 reward 0.008253437282746745 action space size 66 action 57\n",
            "episode 10 step 10 reward 0.001561272381877643 action space size 70 action 54\n",
            "episode 10 step 11 reward 0.0002822596907208208 action space size 73 action 61\n",
            "episode 10 step 12 reward 0.011815028950877604 action space size 73 action 34\n",
            "episode 10 step 13 reward 0.0006977191219448287 action space size 73 action 18\n",
            "episode 10 step 14 reward 0.00146500237087821 action space size 73 action 71\n",
            "episode 10 step 15 reward 2.3819916350475978e-05 action space size 76 action 13\n",
            "episode 10 step 16 reward 0.0004131350046918669 action space size 77 action 59\n",
            "episode 10 step 17 reward 0.0006818862070758769 action space size 78 action 14\n",
            "episode 10 step 18 reward 0.0011221058339287993 action space size 79 action 70\n",
            "episode 10 step 19 reward 0.001032671991197276 action space size 81 action 69\n",
            "episode 10 step 20 reward 0.00021045449602752342 action space size 81 action 59\n",
            "episode 10 step 21 reward 1.2194912414997816e-05 action space size 83 action 55\n",
            "episode 10 step 22 reward 5.80713031013147e-05 action space size 84 action 79\n",
            "episode 10 step 23 reward 0.0008885649549483787 action space size 84 action 16\n",
            "episode 10 step 24 reward 0.0002447981323712156 action space size 83 action 13\n",
            "episode 10 step 25 reward 0.0010222477967545274 action space size 84 action 64\n",
            "episode 10 step 26 reward 0.00034742678872135 action space size 87 action 51\n",
            "episode 10 step 27 reward 0.0004346608361629478 action space size 88 action 43\n",
            "episode 10 step 28 reward 0.00015103089572221506 action space size 90 action 9\n",
            "episode 10 step 29 reward 0.00020032379870826844 action space size 91 action 37\n",
            "episode 10 step 30 reward 0.000402686145662301 action space size 91 action 21\n",
            "episode 10 step 31 reward 4.965397693013074e-06 action space size 92 action 24\n",
            "episode 10 step 32 reward 5.2770190450246446e-05 action space size 94 action 55\n",
            "episode 10 step 33 reward 0.0006928963675818522 action space size 95 action 73\n",
            "episode 10 step 34 reward 1.9316652469569817e-05 action space size 90 action 44\n",
            "episode 10 step 35 reward 8.106462155410554e-05 action space size 95 action 87\n",
            "episode 10 step 36 reward 4.1825981497822795e-05 action space size 97 action 6\n",
            "episode 10 step 37 reward 5.763765329902526e-06 action space size 98 action 33\n",
            "episode 10 step 38 reward 2.0554911316139624e-05 action space size 98 action 49\n",
            "episode 10 step 39 reward 8.698530473338906e-05 action space size 101 action 11\n",
            "episode 10 step 40 reward 9.96861444946262e-06 action space size 101 action 83\n",
            "episode 10 step 41 reward 0.000108450144125527 action space size 102 action 74\n",
            "episode 10 step 42 reward 2.3061941192281665e-05 action space size 102 action 69\n",
            "episode 10 step 43 reward 9.618952844903106e-06 action space size 102 action 24\n",
            "episode 10 step 44 reward 8.079062217802857e-05 action space size 102 action 100\n",
            "episode 10 step 45 reward 4.247897913955967e-05 action space size 106 action 18\n",
            "episode 10 step 46 reward 1.3981375559524167e-06 action space size 107 action 39\n",
            "episode 10 step 47 reward 0.5515173043418145 action space size 104 action 0\n",
            "episode 10 step 48 reward 0.0 action space size 106 action 92\n",
            "episode 10 step 49 reward 0.0 action space size 107 action 89\n",
            "episode 11 step 0 reward 0.0002707345920498483 action space size 59 action 41\n",
            "episode 11 step 1 reward 0.0024271764486911707 action space size 61 action 13\n",
            "episode 11 step 2 reward 0.0020089639065190568 action space size 64 action 52\n",
            "episode 11 step 3 reward 0.0011648605864138517 action space size 65 action 46\n",
            "episode 11 step 4 reward 0.01040850218214473 action space size 64 action 47\n",
            "episode 11 step 5 reward 0.0002248148789476545 action space size 66 action 30\n",
            "episode 11 step 6 reward 0.003461962523033435 action space size 67 action 29\n",
            "episode 11 step 7 reward 0.0005206638948038744 action space size 68 action 31\n",
            "episode 11 step 8 reward 0.008444648893146223 action space size 69 action 22\n",
            "episode 11 step 9 reward 0.0028283904830459505 action space size 69 action 20\n",
            "episode 11 step 10 reward 0.0024938951742115023 action space size 72 action 36\n",
            "episode 11 step 11 reward 0.00273569333830892 action space size 72 action 25\n",
            "episode 11 step 12 reward 0.004243311014761275 action space size 74 action 26\n",
            "episode 11 step 13 reward 0.004344319494521187 action space size 75 action 47\n",
            "episode 11 step 14 reward 0.00047534345048916293 action space size 75 action 45\n",
            "episode 11 step 15 reward 9.251712117475108e-05 action space size 74 action 40\n",
            "episode 11 step 16 reward 0.000873733119078679 action space size 75 action 39\n",
            "episode 11 step 17 reward 0.0035617659100353194 action space size 77 action 67\n",
            "episode 11 step 18 reward 0.06476778484056922 action space size 76 action 0\n",
            "episode 11 step 19 reward 9.094947017729282e-13 action space size 79 action 51\n",
            "episode 11 step 20 reward 4.547473508864641e-13 action space size 80 action 74\n",
            "episode 11 step 21 reward 4.547473508864641e-13 action space size 81 action 59\n",
            "episode 11 step 22 reward 4.547473508864641e-13 action space size 80 action 6\n",
            "episode 11 step 23 reward 0.0 action space size 83 action 20\n",
            "episode 11 step 24 reward 0.0 action space size 84 action 35\n",
            "episode 11 step 25 reward 9.094947017729282e-13 action space size 83 action 9\n",
            "episode 11 step 26 reward 9.094947017729282e-13 action space size 86 action 19\n",
            "episode 11 step 27 reward 0.0 action space size 86 action 74\n",
            "episode 11 step 28 reward 4.547473508864641e-13 action space size 87 action 36\n",
            "episode 11 step 29 reward 4.547473508864641e-13 action space size 89 action 22\n",
            "episode 11 step 30 reward 0.0 action space size 89 action 44\n",
            "episode 11 step 31 reward 0.0 action space size 91 action 82\n",
            "episode 11 step 32 reward 0.0 action space size 90 action 24\n",
            "episode 11 step 33 reward 0.0 action space size 93 action 47\n",
            "episode 11 step 34 reward 9.094947017729282e-13 action space size 92 action 50\n",
            "episode 11 step 35 reward 4.547473508864641e-13 action space size 96 action 49\n",
            "episode 11 step 36 reward 4.547473508864641e-13 action space size 92 action 14\n",
            "episode 11 step 37 reward 4.547473508864641e-13 action space size 95 action 60\n",
            "episode 11 step 38 reward 0.0 action space size 97 action 23\n",
            "episode 11 step 39 reward 0.0 action space size 99 action 87\n",
            "episode 11 step 40 reward 0.0 action space size 99 action 24\n",
            "episode 11 step 41 reward 9.094947017729282e-13 action space size 97 action 14\n",
            "episode 11 step 42 reward 4.547473508864641e-13 action space size 101 action 55\n",
            "episode 11 step 43 reward 0.0 action space size 102 action 66\n",
            "episode 11 step 44 reward 4.547473508864641e-13 action space size 104 action 41\n",
            "episode 11 step 45 reward 4.547473508864641e-13 action space size 106 action 34\n",
            "episode 11 step 46 reward 0.0 action space size 106 action 8\n",
            "episode 11 step 47 reward 0.0 action space size 107 action 64\n",
            "episode 11 step 48 reward 0.0 action space size 108 action 60\n",
            "episode 11 step 49 reward 0.0 action space size 105 action 75\n",
            "episode 12 step 0 reward 0.0057782136041169 action space size 60 action 4\n",
            "episode 12 step 1 reward 0.010188870879574097 action space size 63 action 16\n",
            "episode 12 step 2 reward 0.0022829558392913896 action space size 64 action 56\n",
            "episode 12 step 3 reward 0.0014110788101788785 action space size 63 action 60\n",
            "episode 12 step 4 reward 0.0031628304059267975 action space size 65 action 21\n",
            "episode 12 step 5 reward 0.0035457181434139784 action space size 66 action 3\n",
            "episode 12 step 6 reward 0.005824584655783838 action space size 67 action 61\n",
            "episode 12 step 7 reward 0.00020534636723823496 action space size 67 action 36\n",
            "episode 12 step 8 reward 0.00020536271222226787 action space size 70 action 17\n",
            "episode 12 step 9 reward 0.0003605053016144666 action space size 70 action 42\n",
            "episode 12 step 10 reward 0.0006595311192540976 action space size 72 action 56\n",
            "episode 12 step 11 reward 7.119755127860117e-05 action space size 72 action 49\n",
            "episode 12 step 12 reward 0.0005986923424643464 action space size 73 action 24\n",
            "episode 12 step 13 reward 0.0022116631130302267 action space size 75 action 42\n",
            "episode 12 step 14 reward 2.2893624645803357e-05 action space size 74 action 21\n",
            "episode 12 step 15 reward 0.00040445437389280414 action space size 75 action 43\n",
            "episode 12 step 16 reward 0.0015383827962978103 action space size 78 action 64\n",
            "episode 12 step 17 reward 0.0005700536307813309 action space size 78 action 31\n",
            "episode 12 step 18 reward 6.667796697001904e-07 action space size 79 action 32\n",
            "episode 12 step 19 reward 0.0010408217490294192 action space size 80 action 59\n",
            "episode 12 step 20 reward 0.0010283828019055363 action space size 81 action 27\n",
            "episode 12 step 21 reward 7.455216200469295e-05 action space size 80 action 58\n",
            "episode 12 step 22 reward 0.0001358546937808569 action space size 81 action 51\n",
            "episode 12 step 23 reward 3.558608614184777e-05 action space size 84 action 53\n",
            "episode 12 step 24 reward 9.56202302404563e-06 action space size 84 action 61\n",
            "episode 12 step 25 reward 0.00031564578966936097 action space size 85 action 60\n",
            "episode 12 step 26 reward 3.752066731976811e-05 action space size 86 action 58\n",
            "episode 12 step 27 reward 3.3344325856887735e-05 action space size 85 action 60\n",
            "episode 12 step 28 reward 3.3292564694420435e-05 action space size 89 action 79\n",
            "episode 12 step 29 reward 4.496808287512977e-06 action space size 90 action 86\n",
            "episode 12 step 30 reward 4.111802218176308e-05 action space size 92 action 35\n",
            "episode 12 step 31 reward 7.778168856020784e-05 action space size 89 action 86\n",
            "episode 12 step 32 reward 4.986553494745749e-05 action space size 93 action 52\n",
            "episode 12 step 33 reward 4.91197288283729e-05 action space size 93 action 53\n",
            "episode 12 step 34 reward 8.323610882143839e-05 action space size 95 action 80\n",
            "episode 12 step 35 reward 0.00023553982282464858 action space size 97 action 31\n",
            "episode 12 step 36 reward 2.600475772851496e-05 action space size 98 action 85\n",
            "episode 12 step 37 reward 0.00013047798620391404 action space size 99 action 87\n",
            "episode 12 step 38 reward 2.1512968032766366e-05 action space size 99 action 64\n",
            "episode 12 step 39 reward 0.0004027589175166213 action space size 100 action 13\n",
            "episode 12 step 40 reward 0.00010483763526281109 action space size 102 action 30\n",
            "episode 12 step 41 reward 5.9538397181313485e-06 action space size 102 action 1\n",
            "episode 12 step 42 reward 2.8732061764458194e-05 action space size 102 action 14\n",
            "episode 12 step 43 reward 2.5434207145735854e-05 action space size 102 action 88\n",
            "episode 12 step 44 reward 7.150168266889523e-05 action space size 97 action 38\n",
            "episode 12 step 45 reward 1.1593036106205545e-05 action space size 105 action 56\n",
            "episode 12 step 46 reward 7.995904525159858e-06 action space size 107 action 29\n",
            "episode 12 step 47 reward 2.0021160253236303e-05 action space size 106 action 50\n",
            "episode 12 step 48 reward 1.933523390107439e-05 action space size 106 action 101\n",
            "episode 12 step 49 reward 3.227843353670323e-05 action space size 108 action 60\n",
            "episode 13 step 0 reward 0.02939867646841776 action space size 60 action 9\n",
            "episode 13 step 1 reward 0.0002066729605303408 action space size 62 action 40\n",
            "episode 13 step 2 reward 0.0325206343550235 action space size 64 action 3\n",
            "episode 13 step 3 reward 0.0005576865535203979 action space size 60 action 46\n",
            "episode 13 step 4 reward 0.0017645179980263492 action space size 66 action 14\n",
            "episode 13 step 5 reward 0.0007044393528303772 action space size 66 action 8\n",
            "episode 13 step 6 reward 0.8564633858795787 action space size 66 action 0\n",
            "episode 13 step 7 reward 0.0 action space size 65 action 30\n",
            "episode 13 step 8 reward 2.2737367544323206e-13 action space size 67 action 0\n",
            "episode 13 step 9 reward 0.0 action space size 65 action 10\n",
            "episode 13 step 10 reward 4.547473508864641e-13 action space size 69 action 52\n",
            "episode 13 step 11 reward 4.547473508864641e-13 action space size 67 action 50\n",
            "episode 13 step 12 reward 2.2737367544323206e-13 action space size 70 action 14\n",
            "episode 13 step 13 reward 0.0 action space size 68 action 50\n",
            "episode 13 step 14 reward 4.547473508864641e-13 action space size 71 action 45\n",
            "episode 13 step 15 reward 2.5011104298755527e-12 action space size 70 action 30\n",
            "episode 13 step 16 reward 2.9558577807620168e-12 action space size 76 action 5\n",
            "episode 13 step 17 reward 4.547473508864641e-13 action space size 74 action 2\n",
            "episode 13 step 18 reward 4.547473508864641e-13 action space size 78 action 11\n",
            "episode 13 step 19 reward 6.821210263296962e-13 action space size 78 action 69\n",
            "episode 13 step 20 reward 4.547473508864641e-13 action space size 79 action 39\n",
            "episode 13 step 21 reward 4.547473508864641e-13 action space size 79 action 61\n",
            "episode 13 step 22 reward 4.547473508864641e-13 action space size 78 action 37\n",
            "episode 13 step 23 reward 0.0 action space size 83 action 52\n",
            "episode 13 step 24 reward 0.0 action space size 82 action 66\n",
            "episode 13 step 25 reward 2.2737367544323206e-13 action space size 82 action 33\n",
            "episode 13 step 26 reward 2.2737367544323206e-13 action space size 85 action 71\n",
            "episode 13 step 27 reward 2.2737367544323206e-13 action space size 86 action 19\n",
            "episode 13 step 28 reward 2.2737367544323206e-13 action space size 86 action 14\n",
            "episode 13 step 29 reward 2.2737367544323206e-13 action space size 88 action 55\n",
            "episode 13 step 30 reward 2.2737367544323206e-13 action space size 89 action 16\n",
            "episode 13 step 31 reward 2.2737367544323206e-13 action space size 90 action 40\n",
            "episode 13 step 32 reward 4.547473508864641e-13 action space size 89 action 51\n",
            "episode 13 step 33 reward 0.0 action space size 88 action 23\n",
            "episode 13 step 34 reward 0.0 action space size 89 action 51\n",
            "episode 13 step 35 reward 0.0 action space size 94 action 25\n",
            "episode 13 step 36 reward 4.547473508864641e-13 action space size 92 action 43\n",
            "episode 13 step 37 reward 2.2737367544323206e-13 action space size 94 action 33\n",
            "episode 13 step 38 reward 4.547473508864641e-13 action space size 98 action 67\n",
            "episode 13 step 39 reward 0.0 action space size 95 action 29\n",
            "episode 13 step 40 reward 2.2737367544323206e-13 action space size 97 action 90\n",
            "episode 13 step 41 reward 0.0 action space size 96 action 79\n",
            "episode 13 step 42 reward 2.2737367544323206e-13 action space size 100 action 55\n",
            "episode 13 step 43 reward 2.2737367544323206e-13 action space size 99 action 50\n",
            "episode 13 step 44 reward 6.821210263296962e-13 action space size 98 action 5\n",
            "episode 13 step 45 reward 4.547473508864641e-13 action space size 97 action 74\n",
            "episode 13 step 46 reward 2.2737367544323206e-13 action space size 104 action 52\n",
            "episode 13 step 47 reward 6.821210263296962e-13 action space size 106 action 18\n",
            "episode 13 step 48 reward 0.0 action space size 106 action 85\n",
            "episode 13 step 49 reward 4.547473508864641e-13 action space size 105 action 59\n",
            "episode 14 step 0 reward 0.04061605224706 action space size 61 action 17\n",
            "episode 14 step 1 reward 0.04294820979976066 action space size 60 action 18\n",
            "episode 14 step 2 reward 0.032814354107813415 action space size 62 action 31\n",
            "episode 14 step 3 reward 0.0007991419665813737 action space size 64 action 10\n",
            "episode 14 step 4 reward 0.00016454706883450854 action space size 65 action 1\n",
            "episode 14 step 5 reward 0.013817674258007173 action space size 65 action 3\n",
            "episode 14 step 6 reward 0.01427956708766942 action space size 68 action 26\n",
            "episode 14 step 7 reward 0.002292759055762872 action space size 69 action 64\n",
            "episode 14 step 8 reward 0.010986783469434158 action space size 68 action 11\n",
            "episode 14 step 9 reward 0.0001871382141871436 action space size 68 action 62\n",
            "episode 14 step 10 reward 1.7062429833458737e-06 action space size 66 action 45\n",
            "episode 14 step 11 reward 0.0002280587209497753 action space size 70 action 9\n",
            "episode 14 step 12 reward 9.550484446663177e-05 action space size 74 action 49\n",
            "episode 14 step 13 reward 8.680004793859553e-05 action space size 74 action 16\n",
            "episode 14 step 14 reward 0.0011778037496696925 action space size 75 action 40\n",
            "episode 14 step 15 reward 0.00952531740313134 action space size 77 action 34\n",
            "episode 14 step 16 reward 0.0007504802692892554 action space size 75 action 70\n",
            "episode 14 step 17 reward 0.001636337259242282 action space size 76 action 51\n",
            "episode 14 step 18 reward 0.00018822045012711897 action space size 79 action 15\n",
            "episode 14 step 19 reward 0.0004787164739354921 action space size 80 action 51\n",
            "episode 14 step 20 reward 0.00018736337460723007 action space size 81 action 19\n",
            "episode 14 step 21 reward 0.00027337946494299104 action space size 81 action 72\n",
            "episode 14 step 22 reward 0.00011688196173054166 action space size 82 action 31\n",
            "episode 14 step 23 reward 0.0013973907839499589 action space size 84 action 24\n",
            "episode 14 step 24 reward 9.968155154638225e-06 action space size 82 action 80\n",
            "episode 14 step 25 reward 4.0865797018341254e-05 action space size 83 action 62\n",
            "episode 14 step 26 reward 3.76754851458827e-05 action space size 88 action 6\n",
            "episode 14 step 27 reward 6.603477095268317e-05 action space size 87 action 62\n",
            "episode 14 step 28 reward 4.374776381155243e-05 action space size 88 action 8\n",
            "episode 14 step 29 reward 0.00033733338250385714 action space size 91 action 10\n",
            "episode 14 step 30 reward 0.001247455505108519 action space size 90 action 47\n",
            "episode 14 step 31 reward 0.0018841614514713 action space size 91 action 28\n",
            "episode 14 step 32 reward 0.0009641827869018016 action space size 91 action 53\n",
            "episode 14 step 33 reward 0.0007172495056693151 action space size 92 action 41\n",
            "episode 14 step 34 reward 0.0005062274967713165 action space size 95 action 59\n",
            "episode 14 step 35 reward 8.449996494164225e-05 action space size 95 action 15\n",
            "episode 14 step 36 reward 0.00011588665893214056 action space size 96 action 48\n",
            "episode 14 step 37 reward 1.4377207207871834e-05 action space size 99 action 65\n",
            "episode 14 step 38 reward 3.8072053030191455e-06 action space size 97 action 97\n",
            "episode 14 step 39 reward 0.0002707826383812062 action space size 98 action 88\n",
            "episode 14 step 40 reward 3.5269054933451116e-05 action space size 97 action 70\n",
            "episode 14 step 41 reward 0.00017548560390423518 action space size 101 action 28\n",
            "episode 14 step 42 reward 1.249943034054013e-05 action space size 98 action 81\n",
            "episode 14 step 43 reward 3.1046288768266095e-05 action space size 102 action 95\n",
            "episode 14 step 44 reward 4.3682548493961804e-05 action space size 106 action 81\n",
            "episode 14 step 45 reward 1.7627420675125904e-05 action space size 102 action 71\n",
            "episode 14 step 46 reward 2.0914062588417437e-06 action space size 107 action 48\n",
            "episode 14 step 47 reward 5.445361193778808e-05 action space size 108 action 18\n",
            "episode 14 step 48 reward 7.763734629406827e-06 action space size 108 action 45\n",
            "episode 14 step 49 reward 1.2387853985273978e-05 action space size 108 action 52\n",
            "episode 15 step 0 reward 0.04205345764512458 action space size 59 action 42\n",
            "episode 15 step 1 reward 0.014118794975729543 action space size 61 action 17\n",
            "episode 15 step 2 reward 0.0007276088977050676 action space size 62 action 23\n",
            "episode 15 step 3 reward 0.024136376876413124 action space size 62 action 14\n",
            "episode 15 step 4 reward 0.037098193797191925 action space size 66 action 55\n",
            "episode 15 step 5 reward 0.004553588190901792 action space size 66 action 63\n",
            "episode 15 step 6 reward 0.0005969795615783369 action space size 65 action 27\n",
            "episode 15 step 7 reward 0.004312668761485838 action space size 69 action 52\n",
            "episode 15 step 8 reward 0.003795977414029039 action space size 68 action 39\n",
            "episode 15 step 9 reward 0.021792235115299263 action space size 70 action 39\n",
            "episode 15 step 10 reward 0.00026721261974671506 action space size 72 action 22\n",
            "episode 15 step 11 reward 0.00021141805154911708 action space size 72 action 12\n",
            "episode 15 step 12 reward 5.943714450040716e-05 action space size 73 action 23\n",
            "episode 15 step 13 reward 0.0009853463911895233 action space size 74 action 58\n",
            "episode 15 step 14 reward 0.0001543171774756047 action space size 74 action 4\n",
            "episode 15 step 15 reward 0.0003474752056717989 action space size 76 action 16\n",
            "episode 15 step 16 reward 2.935572138085263e-05 action space size 75 action 26\n",
            "episode 15 step 17 reward 0.0007608926307511865 action space size 78 action 71\n",
            "episode 15 step 18 reward 8.44687019707635e-06 action space size 78 action 47\n",
            "episode 15 step 19 reward 4.056309080624487e-06 action space size 80 action 53\n",
            "episode 15 step 20 reward 0.7307274896156741 action space size 81 action 0\n",
            "episode 15 step 21 reward 4.547473508864641e-13 action space size 81 action 56\n",
            "episode 15 step 22 reward 4.547473508864641e-13 action space size 81 action 20\n",
            "episode 15 step 23 reward 0.0 action space size 79 action 66\n",
            "episode 15 step 24 reward 4.547473508864641e-13 action space size 85 action 3\n",
            "episode 15 step 25 reward 4.547473508864641e-13 action space size 82 action 5\n",
            "episode 15 step 26 reward 4.547473508864641e-13 action space size 84 action 27\n",
            "episode 15 step 27 reward 9.094947017729282e-13 action space size 86 action 8\n",
            "episode 15 step 28 reward 4.547473508864641e-13 action space size 88 action 49\n",
            "episode 15 step 29 reward 4.547473508864641e-13 action space size 86 action 58\n",
            "episode 15 step 30 reward 9.094947017729282e-13 action space size 88 action 71\n",
            "episode 15 step 31 reward 9.094947017729282e-13 action space size 88 action 11\n",
            "episode 15 step 32 reward 4.547473508864641e-13 action space size 89 action 37\n",
            "episode 15 step 33 reward 4.547473508864641e-13 action space size 94 action 50\n",
            "episode 15 step 34 reward 0.0 action space size 89 action 92\n",
            "episode 15 step 35 reward 0.0 action space size 90 action 70\n",
            "episode 15 step 36 reward 4.547473508864641e-13 action space size 96 action 80\n",
            "episode 15 step 37 reward 0.0 action space size 96 action 77\n",
            "episode 15 step 38 reward 4.547473508864641e-13 action space size 96 action 20\n",
            "episode 15 step 39 reward 4.547473508864641e-13 action space size 99 action 90\n",
            "episode 15 step 40 reward 0.0 action space size 100 action 94\n",
            "episode 15 step 41 reward 0.0 action space size 99 action 66\n",
            "episode 15 step 42 reward 9.094947017729282e-13 action space size 103 action 44\n",
            "episode 15 step 43 reward 1.3642420526593924e-12 action space size 103 action 94\n",
            "episode 15 step 44 reward 4.547473508864641e-13 action space size 102 action 89\n",
            "episode 15 step 45 reward 0.0 action space size 105 action 78\n",
            "episode 15 step 46 reward 4.547473508864641e-13 action space size 105 action 56\n",
            "episode 15 step 47 reward 4.547473508864641e-13 action space size 106 action 53\n",
            "episode 15 step 48 reward 0.0 action space size 106 action 94\n",
            "episode 15 step 49 reward 0.0 action space size 108 action 94\n",
            "episode 16 step 0 reward 0.05311140091134803 action space size 61 action 41\n",
            "episode 16 step 1 reward 0.00955922411890242 action space size 61 action 9\n",
            "episode 16 step 2 reward 0.006543230592342297 action space size 64 action 3\n",
            "episode 16 step 3 reward 0.001651773547337143 action space size 63 action 25\n",
            "episode 16 step 4 reward 0.001044831564058768 action space size 65 action 21\n",
            "episode 16 step 5 reward 0.004186571689160701 action space size 64 action 54\n",
            "episode 16 step 6 reward 0.003500732571183107 action space size 65 action 1\n",
            "episode 16 step 7 reward 0.00017361511800118024 action space size 69 action 24\n",
            "episode 16 step 8 reward 0.0013414134241429565 action space size 69 action 52\n",
            "episode 16 step 9 reward 0.012669998532373938 action space size 68 action 56\n",
            "episode 16 step 10 reward 0.002458851456594857 action space size 71 action 25\n",
            "episode 16 step 11 reward 0.0003057480473671603 action space size 72 action 55\n",
            "episode 16 step 12 reward 0.0055839228161858045 action space size 73 action 3\n",
            "episode 16 step 13 reward 6.410846253857017e-05 action space size 74 action 59\n",
            "episode 16 step 14 reward 0.0035837476862070616 action space size 74 action 26\n",
            "episode 16 step 15 reward 0.02365132342333709 action space size 77 action 50\n",
            "episode 16 step 16 reward 0.0008953866047249903 action space size 77 action 72\n",
            "episode 16 step 17 reward 0.007103322102921084 action space size 76 action 75\n",
            "episode 16 step 18 reward 0.000543132022357895 action space size 78 action 30\n",
            "episode 16 step 19 reward 0.0006702504626900918 action space size 80 action 55\n",
            "episode 16 step 20 reward 0.0006484390414698282 action space size 78 action 46\n",
            "episode 16 step 21 reward 1.429661961083184e-05 action space size 82 action 29\n",
            "episode 16 step 22 reward 0.0007361450902862998 action space size 83 action 36\n",
            "episode 16 step 23 reward 0.0003120746073363989 action space size 84 action 32\n",
            "episode 16 step 24 reward 0.0011541807114099356 action space size 86 action 4\n",
            "episode 16 step 25 reward 2.969238926198159e-05 action space size 86 action 74\n",
            "episode 16 step 26 reward 0.00012446340815586154 action space size 85 action 84\n",
            "episode 16 step 27 reward 0.0002028649648764258 action space size 88 action 50\n",
            "episode 16 step 28 reward 0.0006067837734917703 action space size 88 action 47\n",
            "episode 16 step 29 reward 0.0020916846137879475 action space size 88 action 69\n",
            "episode 16 step 30 reward 0.0012203293197217135 action space size 92 action 3\n",
            "episode 16 step 31 reward 4.49393219241756e-05 action space size 93 action 36\n",
            "episode 16 step 32 reward 0.0001302139660310786 action space size 92 action 7\n",
            "episode 16 step 33 reward 2.275328279210953e-05 action space size 93 action 34\n",
            "episode 16 step 34 reward 0.0002275571414429578 action space size 93 action 24\n",
            "episode 16 step 35 reward 8.430369598499965e-05 action space size 96 action 57\n",
            "episode 16 step 36 reward 0.000659804396036634 action space size 96 action 14\n",
            "episode 16 step 37 reward 0.00013560494130615552 action space size 97 action 8\n",
            "episode 16 step 38 reward 0.0003842634464490402 action space size 99 action 36\n",
            "episode 16 step 39 reward 0.00015541553648290574 action space size 97 action 46\n",
            "episode 16 step 40 reward 7.051941702229669e-05 action space size 102 action 56\n",
            "episode 16 step 41 reward 3.3786348012654344e-05 action space size 101 action 100\n",
            "episode 16 step 42 reward 2.0835418581555132e-05 action space size 101 action 31\n",
            "episode 16 step 43 reward 0.0003163483934258693 action space size 104 action 9\n",
            "episode 16 step 44 reward 2.7050574317399878e-05 action space size 106 action 56\n",
            "episode 16 step 45 reward 3.849028939839627e-05 action space size 107 action 26\n",
            "episode 16 step 46 reward 4.009034182672622e-05 action space size 108 action 85\n",
            "episode 16 step 47 reward 2.9067559580653324e-05 action space size 103 action 104\n",
            "episode 16 step 48 reward 1.0514419273022213e-05 action space size 109 action 28\n",
            "episode 16 step 49 reward 0.00018215077125205426 action space size 111 action 85\n",
            "episode 17 step 0 reward 0.0018197951239926624 action space size 61 action 6\n",
            "episode 17 step 1 reward 0.0020484290453168796 action space size 62 action 15\n",
            "episode 17 step 2 reward 0.005718009186239215 action space size 64 action 53\n",
            "episode 17 step 3 reward 0.0013159535519662313 action space size 64 action 48\n",
            "episode 17 step 4 reward 0.015310861037960422 action space size 64 action 14\n",
            "episode 17 step 5 reward 0.00015661972292946302 action space size 67 action 42\n",
            "episode 17 step 6 reward 0.0005252460650808644 action space size 67 action 41\n",
            "episode 17 step 7 reward 0.003123902157312841 action space size 69 action 7\n",
            "episode 17 step 8 reward 0.0011338610383972991 action space size 69 action 11\n",
            "episode 17 step 9 reward 0.0008790879783191485 action space size 71 action 29\n",
            "episode 17 step 10 reward 0.0010951205745186599 action space size 70 action 60\n",
            "episode 17 step 11 reward 0.00043176166673219996 action space size 71 action 61\n",
            "episode 17 step 12 reward 0.0030964082970967866 action space size 74 action 1\n",
            "episode 17 step 13 reward 0.0018877148904721253 action space size 73 action 39\n",
            "episode 17 step 14 reward 0.0008818956048344262 action space size 74 action 40\n",
            "episode 17 step 15 reward 0.0013615915217997099 action space size 75 action 65\n",
            "episode 17 step 16 reward 0.000556251434773003 action space size 77 action 28\n",
            "episode 17 step 17 reward 0.0007352655738941394 action space size 79 action 19\n",
            "episode 17 step 18 reward 3.4034821055684006e-05 action space size 79 action 78\n",
            "episode 17 step 19 reward 8.899832300812704e-05 action space size 79 action 60\n",
            "episode 17 step 20 reward 0.00036096493204240687 action space size 81 action 21\n",
            "episode 17 step 21 reward 0.00020160568192295614 action space size 81 action 62\n",
            "episode 17 step 22 reward 0.0012407993822307617 action space size 83 action 66\n",
            "episode 17 step 23 reward 0.05730691280450628 action space size 82 action 0\n",
            "episode 17 step 24 reward 0.0 action space size 84 action 59\n",
            "episode 17 step 25 reward 9.094947017729282e-13 action space size 85 action 3\n",
            "episode 17 step 26 reward 9.094947017729282e-13 action space size 85 action 41\n",
            "episode 17 step 27 reward 0.0 action space size 87 action 72\n",
            "episode 17 step 28 reward 4.547473508864641e-13 action space size 88 action 57\n",
            "episode 17 step 29 reward 0.0 action space size 87 action 69\n",
            "episode 17 step 30 reward 0.0 action space size 89 action 84\n",
            "episode 17 step 31 reward 4.547473508864641e-13 action space size 89 action 81\n",
            "episode 17 step 32 reward 4.547473508864641e-13 action space size 91 action 51\n",
            "episode 17 step 33 reward 0.0 action space size 90 action 35\n",
            "episode 17 step 34 reward 0.0 action space size 93 action 85\n",
            "episode 17 step 35 reward 0.0 action space size 93 action 44\n",
            "episode 17 step 36 reward 0.0 action space size 97 action 84\n",
            "episode 17 step 37 reward 4.547473508864641e-13 action space size 97 action 49\n",
            "episode 17 step 38 reward 0.0 action space size 97 action 13\n",
            "episode 17 step 39 reward 0.0 action space size 94 action 87\n",
            "episode 17 step 40 reward 1.3642420526593924e-12 action space size 97 action 73\n",
            "episode 17 step 41 reward 4.547473508864641e-13 action space size 101 action 0\n",
            "episode 17 step 42 reward 0.0 action space size 103 action 42\n",
            "episode 17 step 43 reward 4.547473508864641e-13 action space size 104 action 68\n",
            "episode 17 step 44 reward 0.0 action space size 104 action 21\n",
            "episode 17 step 45 reward 0.0 action space size 104 action 103\n",
            "episode 17 step 46 reward 0.0 action space size 105 action 97\n",
            "episode 17 step 47 reward 0.0 action space size 106 action 70\n",
            "episode 17 step 48 reward 0.0 action space size 109 action 84\n",
            "episode 17 step 49 reward 0.0 action space size 105 action 22\n",
            "episode 18 step 0 reward 0.0013739376745434129 action space size 59 action 34\n",
            "episode 18 step 1 reward 0.01750466819066787 action space size 62 action 29\n",
            "episode 18 step 2 reward 0.0013178587335005432 action space size 62 action 37\n",
            "episode 18 step 3 reward 0.001979015610913848 action space size 63 action 29\n",
            "episode 18 step 4 reward 0.003672974080473068 action space size 64 action 58\n",
            "episode 18 step 5 reward 0.004942444774314936 action space size 67 action 6\n",
            "episode 18 step 6 reward 0.001345750156133363 action space size 66 action 29\n",
            "episode 18 step 7 reward 0.025177937804755857 action space size 67 action 27\n",
            "episode 18 step 8 reward 0.0025327068169644917 action space size 69 action 66\n",
            "episode 18 step 9 reward 1.4697163578603067e-05 action space size 70 action 65\n",
            "episode 18 step 10 reward 0.018251124157586673 action space size 68 action 3\n",
            "episode 18 step 11 reward 4.7497100922555546e-05 action space size 70 action 36\n",
            "episode 18 step 12 reward 0.00028909746356475807 action space size 71 action 43\n",
            "episode 18 step 13 reward 2.92025149519759e-05 action space size 73 action 41\n",
            "episode 18 step 14 reward 3.6163485901852255e-05 action space size 74 action 4\n",
            "episode 18 step 15 reward 1.2521031749201939e-05 action space size 75 action 12\n",
            "episode 18 step 16 reward 4.233914751239354e-06 action space size 78 action 58\n",
            "episode 18 step 17 reward 0.0002948081851172901 action space size 77 action 46\n",
            "episode 18 step 18 reward 1.5904506653896533e-06 action space size 79 action 36\n",
            "episode 18 step 19 reward 4.9419248398407944e-05 action space size 77 action 34\n",
            "episode 18 step 20 reward 0.00010064011712529464 action space size 80 action 29\n",
            "episode 18 step 21 reward 4.107438007849851e-05 action space size 81 action 79\n",
            "episode 18 step 22 reward 0.5361589847650521 action space size 81 action 0\n",
            "episode 18 step 23 reward 2.2737367544323206e-13 action space size 81 action 61\n",
            "episode 18 step 24 reward 6.821210263296962e-13 action space size 84 action 33\n",
            "episode 18 step 25 reward 4.547473508864641e-13 action space size 85 action 71\n",
            "episode 18 step 26 reward 0.0 action space size 87 action 79\n",
            "episode 18 step 27 reward 0.0 action space size 84 action 86\n",
            "episode 18 step 28 reward 2.2737367544323206e-13 action space size 85 action 37\n",
            "episode 18 step 29 reward 2.2737367544323206e-13 action space size 87 action 34\n",
            "episode 18 step 30 reward 4.547473508864641e-13 action space size 91 action 35\n",
            "episode 18 step 31 reward 0.0 action space size 90 action 28\n",
            "episode 18 step 32 reward 2.2737367544323206e-13 action space size 91 action 79\n",
            "episode 18 step 33 reward 2.2737367544323206e-13 action space size 94 action 75\n",
            "episode 18 step 34 reward 0.0 action space size 93 action 75\n",
            "episode 18 step 35 reward 2.2737367544323206e-13 action space size 94 action 32\n",
            "episode 18 step 36 reward 0.0 action space size 96 action 67\n",
            "episode 18 step 37 reward 4.547473508864641e-13 action space size 97 action 60\n",
            "episode 18 step 38 reward 2.2737367544323206e-13 action space size 97 action 22\n",
            "episode 18 step 39 reward 2.2737367544323206e-13 action space size 97 action 92\n",
            "episode 18 step 40 reward 4.547473508864641e-13 action space size 97 action 37\n",
            "episode 18 step 41 reward 2.2737367544323206e-13 action space size 100 action 84\n",
            "episode 18 step 42 reward 2.2737367544323206e-13 action space size 103 action 95\n",
            "episode 18 step 43 reward 2.2737367544323206e-13 action space size 102 action 25\n",
            "episode 18 step 44 reward 4.547473508864641e-13 action space size 104 action 67\n",
            "episode 18 step 45 reward 0.0 action space size 105 action 12\n",
            "episode 18 step 46 reward 9.094947017729282e-13 action space size 104 action 10\n",
            "episode 18 step 47 reward 4.547473508864641e-13 action space size 107 action 45\n",
            "episode 18 step 48 reward 0.0 action space size 107 action 97\n",
            "episode 18 step 49 reward 0.0 action space size 106 action 51\n",
            "episode 19 step 0 reward 0.023442453944653607 action space size 61 action 13\n",
            "episode 19 step 1 reward 0.01959512271469066 action space size 62 action 47\n",
            "episode 19 step 2 reward 0.01939242880553138 action space size 64 action 6\n",
            "episode 19 step 3 reward 0.0029016066503118054 action space size 63 action 59\n",
            "episode 19 step 4 reward 0.0012118152906168689 action space size 65 action 46\n",
            "episode 19 step 5 reward 0.004096909209920341 action space size 66 action 54\n",
            "episode 19 step 6 reward 0.002044729059207384 action space size 68 action 59\n",
            "episode 19 step 7 reward 0.0018066772488509741 action space size 69 action 21\n",
            "episode 19 step 8 reward 0.011299043830149458 action space size 69 action 13\n",
            "episode 19 step 9 reward 0.016704593648910304 action space size 69 action 34\n",
            "episode 19 step 10 reward 0.0159804939296464 action space size 67 action 41\n",
            "episode 19 step 11 reward 0.0024115786848142307 action space size 71 action 57\n",
            "episode 19 step 12 reward 0.0030369642113328155 action space size 73 action 24\n",
            "episode 19 step 13 reward 0.017181785809725625 action space size 74 action 21\n",
            "episode 19 step 14 reward 0.002514858127824482 action space size 73 action 67\n",
            "episode 19 step 15 reward 0.04442347458166296 action space size 75 action 51\n",
            "episode 19 step 16 reward 0.006706612063226203 action space size 77 action 4\n",
            "episode 19 step 17 reward 5.543239308281045e-05 action space size 79 action 30\n",
            "episode 19 step 18 reward 0.0011901625382506609 action space size 80 action 33\n",
            "episode 19 step 19 reward 0.01426038611975855 action space size 79 action 23\n",
            "episode 19 step 20 reward 7.056321396703424e-05 action space size 81 action 24\n",
            "episode 19 step 21 reward 0.01187034479949034 action space size 82 action 39\n",
            "episode 19 step 22 reward 0.0016360209419872263 action space size 83 action 59\n",
            "episode 19 step 23 reward 0.006809120077832631 action space size 84 action 33\n",
            "episode 19 step 24 reward 0.0013660171080118744 action space size 83 action 49\n",
            "episode 19 step 25 reward 0.0015492137317778543 action space size 86 action 17\n",
            "episode 19 step 26 reward 0.0008119960909880319 action space size 86 action 74\n",
            "episode 19 step 27 reward 0.0022287192011845036 action space size 87 action 17\n",
            "episode 19 step 28 reward 0.00016381595241909963 action space size 88 action 65\n",
            "episode 19 step 29 reward 0.0022768319727219932 action space size 89 action 28\n",
            "episode 19 step 30 reward 0.00014853373863843444 action space size 87 action 29\n",
            "episode 19 step 31 reward 2.1650088001479162e-05 action space size 89 action 32\n",
            "episode 19 step 32 reward 0.0015217540194498724 action space size 93 action 88\n",
            "episode 19 step 33 reward 0.0017769043672615226 action space size 92 action 59\n",
            "episode 19 step 34 reward 0.0008379005234928627 action space size 95 action 41\n",
            "episode 19 step 35 reward 0.00023958483984642953 action space size 97 action 61\n",
            "episode 19 step 36 reward 0.00039578265864292916 action space size 97 action 47\n",
            "episode 19 step 37 reward 0.0003240176824874652 action space size 96 action 63\n",
            "episode 19 step 38 reward 3.147033294226276e-05 action space size 99 action 91\n",
            "episode 19 step 39 reward 0.0008655007827655936 action space size 100 action 18\n",
            "episode 19 step 40 reward 3.123796477666474e-05 action space size 102 action 77\n",
            "episode 19 step 41 reward 2.446100688757724e-05 action space size 101 action 101\n",
            "episode 19 step 42 reward 0.0002823685260864295 action space size 101 action 25\n",
            "episode 19 step 43 reward 7.399245737360616e-05 action space size 104 action 53\n",
            "episode 19 step 44 reward 5.5260818498936715e-06 action space size 105 action 55\n",
            "episode 19 step 45 reward 0.00022694334779771452 action space size 101 action 8\n",
            "episode 19 step 46 reward 6.53795677862945e-06 action space size 107 action 55\n",
            "episode 19 step 47 reward 0.0001416013421930984 action space size 107 action 33\n",
            "episode 19 step 48 reward 4.783717486134265e-06 action space size 109 action 76\n",
            "episode 19 step 49 reward 1.5291955151042202e-06 action space size 108 action 48\n"
          ]
        }
      ],
      "source": [
        "import gymenv_v2\n",
        "from gymenv_v2 import make_multiple_env\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import wandb\n",
        "wandb.login()\n",
        "run=wandb.init(project=\"finalproject\", entity=\"ieor4575-spring2022\", tags=[\"training-easy\"])\n",
        "#run=wandb.init(project=\"finalproject\", entity=\"ieor-4575\", tags=[\"training-hard\"])\n",
        "#run=wandb.init(project=\"finalproject\", entity=\"ieor-4575\", tags=[\"test\"])\n",
        "\n",
        "### TRAINING\n",
        "\n",
        "# Setup: You may generate your own instances on which you train the cutting agent.\n",
        "custom_config = {\n",
        "    \"load_dir\"        : 'instances/randomip_n60_m60',   # this is the location of the randomly generated instances (you may specify a different directory)\n",
        "    \"idx_list\"        : list(range(20)),                # take the first 20 instances from the directory\n",
        "    \"timelimit\"       : 50,                             # the maximum horizon length is 50\n",
        "    \"reward_type\"     : 'obj'                           # DO NOT CHANGE reward_type\n",
        "}\n",
        "\n",
        "# Easy Setup: Use the following environment settings. We will evaluate your agent with the same easy config below:\n",
        "easy_config = {\n",
        "    \"load_dir\"        : 'instances/train_10_n60_m60',\n",
        "    \"idx_list\"        : list(range(10)),\n",
        "    \"timelimit\"       : 50,\n",
        "    \"reward_type\"     : 'obj'\n",
        "}\n",
        "\n",
        "# Hard Setup: Use the following environment settings. We will evaluate your agent with the same hard config below:\n",
        "hard_config = {\n",
        "    \"load_dir\"        : 'instances/train_100_n60_m60',\n",
        "    \"idx_list\"        : list(range(99)),\n",
        "    \"timelimit\"       : 50,\n",
        "    \"reward_type\"     : 'obj'\n",
        "}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # create env\n",
        "    env = make_multiple_env(**easy_config) \n",
        "\n",
        "    for e in range(20):\n",
        "        # gym loop\n",
        "        s = env.reset()   # samples a random instance every time env.reset() is called\n",
        "        d = False\n",
        "        t = 0\n",
        "        repisode = 0\n",
        "\n",
        "        while not d:\n",
        "            #Take a random action\n",
        "            a = np.random.randint(0, s[-1].size, 1)            # s[-1].size shows the number of actions, i.e., cuts available at state s\n",
        "            \n",
        "            #simulate the environment to get the next state\n",
        "            s, r, d, _ = env.step(list(a))\n",
        "            print('episode', e, 'step', t, 'reward', r, 'action space size', s[-1].size, 'action', a[0])\n",
        "            \n",
        "            A, b, c0, cuts_a, cuts_b = s\n",
        "            #print(A.shape, b.shape, c0.shape, cuts_a.shape, cuts_b.shape)\n",
        "\n",
        "            t += 1\n",
        "            repisode += r\n",
        "\n",
        "    \t    #wandb logging\n",
        "            wandb.log({\"Training reward (easy config)\" : repisode})\n",
        "\t    #make sure to use the correct tag in wandb.init in the initialization on top\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sKnhC54KYNNL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}